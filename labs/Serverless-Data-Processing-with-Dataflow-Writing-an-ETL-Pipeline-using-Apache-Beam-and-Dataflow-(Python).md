---
id: 3602
name: 'Serverless Data Processing with Dataflow - Writing an ETL Pipeline using Apache Beam and Dataflow (Python)'
type: Lab
url: https://www.cloudskillsboost.google/catalog_lab/3602
---

# [Serverless Data Processing with Dataflow - Writing an ETL Pipeline using Apache Beam and Dataflow (Python)](https://www.cloudskillsboost.google/catalog_lab/3602)

In this lab, you a) build a batch ETL pipeline in Apache Beam, which takes raw data from Google Cloud Storage and writes it to BigQuery b) run the Apache Beam pipeline on Dataflow and c) parameterize the execution of the pipeline.

## Step 1: Overview

## Step 2: Setup and requirements

## Step 3: Lab part 1. Writing an ETL pipeline from scratch

## Step 4: Task 1. Generate synthetic data

## Step 5: Task 2. Read data from your source

## Step 6: Task 3. Run your pipeline to verify that it works

## Step 7: Task 4. Add in a transformation

## Step 8: Task 5. Write to a sink

## Step 9: Task 6. Run your pipeline

## Step 10: Lab part 2. Parameterizing basic ETL

## Step 11: Task 1. Create a JSON schema file

## Step 12: Task 2. Write a JavaScript user-defined function

## Step 13: Task 3. Run a Dataflow Template

## Step 14: Task 4. Inspect the Dataflow Template code

## Step 15: End your lab

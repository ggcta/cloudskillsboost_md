---
id: 158
name: 'Machine Learning Operations (MLOps): Getting Started'
datePublished: 2025-03-12
topics:
- CI/CD
- DevOps
- Machine Learning
type: Course
url: https://www.cloudskillsboost.google/course_templates/158
---

# [Machine Learning Operations (MLOps): Getting Started](https://www.cloudskillsboost.google/course_templates/158)

**Description:**

This course introduces participants to MLOps tools and best practices for deploying, evaluating, monitoring and operating production ML systems on Google Cloud. MLOps is a discipline focused on the deployment, testing, monitoring, and automation of ML systems in production. Machine Learning Engineering professionals use tools for continuous improvement and evaluation of deployed models. They work with (or can be) Data Scientists, who develop models, to enable velocity and rigor in deploying the best performing models.

**Objectives:**

- Identify and use core technologies required to support effective MLOps.
- Adopt the best CI/CD practices in the context of ML systems.
- Configure and provision Google Cloud architectures for reliable and effective MLOps environments.
- Implement reliable and repeatable training and inference workflows.

## Welcome to the Machine Learning Operations (MLOps): Getting Started

This module provides the overview of the course

### Video - [Course introduction](https://www.cloudskillsboost.google/course_templates/158/video/526737)

- [YouTube: Course introduction](https://www.youtube.com/watch?v=3jDv4mdAbXo)

Hi, my name is Esra Duygun and I am a Google Certified Professional Machine Learning Engineer and lead course developer. Welcome to Machine Learning Operations or MLOps Fundamentals, the first course of the new series of Machine Learning Operations topic. In the first series of courses, called Machine Learning on Google Cloud, you learn about how machine learning on Google Cloud can make tasks better, faster, and easier. The second series of courses, Advanced Machine Learning on Google Cloud, focuses on more wide-ranging machine learning applications including computer vision, natural language processing and recommendation systems. This series of courses is all about machine learning operations and focuses on machine learning models from an operational perspective. This particular course focuses on the MLOps concept and the considerations behind it. So, what is MLOps? MLOps is an ML engineering culture and practice that aims at unifying ML system development, or Dev, and ML system operations, or Ops, and guide teams through the challenges to the reproducibility of machine learning models. MLOps takes both its name and some of the core principles and tools of DevOps, because the goals of MLOps and DevOps are the same: to shorten the development lifecycle of systems and ensure that high quality software is continuously developed, delivered, and maintained in production. The unique challenges and needs that machine learning poses–managing the lifecycle of data, models, and code–have led MLOps to quickly evolve as a domain of its own. This content is designed for dedicated or aspiring machine learning data scientists, engineers, and analysts who are interested in learning about machine learning in the cloud and using ML models and Vertex AI. To get the most out of this specialization, it is recommended you have: Proficiency with Python (paytaan) on topics covered in the Crash Course on Python (paytaan) offered by Google, and Prior (prayir) experience with foundational machine learning concepts and building machine learning solutions on Google Cloud as covered in the Machine Learning on Google Cloud courses. In the first part of this course, Employing Machine Learning Operations, you explore machine learning models from an operational perspective. First, you examine the challenges that machine learning practitioners face when they operationalize (aa·pr·ay·shuh·nuh·lize) ML models and make them available for production. From there, you get an introduction to the concept of DevOps in machine learning. And finally, you explore the machine learning lifecycle. In the second part, What is Vertex AI and why does a unified platform matter? , you learn about Vertex AI and its importance. Then you discover the MLOps capabilities of Vertex AI. Finally, you explore how Vertex AI helps with the MLOps workflow. Through a hands-on lab at the end, you work on a high-value, real-world use case: predictive customer life value, or CLV in short. You’ll start with a local BigQuery and TensorFlow workflow that you might already be familiar with and progress toward training and deploying your model in the cloud with Vertex AI. You also test your knowledge throughout the course with graded assessments. After you complete this course, you’ll be able to see ML projects from an operational perspective. You’ll understand the concept of DevOps in ML and why you need to operationalize your ML models in a unified AI platform, like Vertex AI. Enroll today to learn about machine learning operations. END

## Employing Machine Learning Operations

This module identifies ML practitioners' pain points before exploring the concept of DevOps in ML. You're introduced to the three phases of the ML lifecycle and automating the ML process.

### Video - [Introduction to MLOps-Why and when to employ MLOps](https://www.cloudskillsboost.google/course_templates/158/video/526738)

- [YouTube: Introduction to MLOps-Why and when to employ MLOps](https://www.youtube.com/watch?v=dMKoiIfK8aA)

Welcome to the first section of the Machine Learning Operations, or MLOps, Fundamentals course. In this part of the course, you explore machine learning, or ML, models from an operational perspective. First, you examine the challenges that ML practitioners currently face when they operationalize and make ML models available for production. From there, you get an introduction to the concept of DevOps in ML. Finally, you learn about the ML lifecycle.

### Video - [Machine learning (ML) practitioners’ pain points](https://www.cloudskillsboost.google/course_templates/158/video/526739)

- [YouTube: Machine learning (ML) practitioners’ pain points](https://www.youtube.com/watch?v=FhQXAh4K0Yg)

Before we start, let's look at what the ML practitioner term refers to. Many users within an organization have a part to play in the ML lifecycle. For example, a product manager who simply types of query to pull necessary insights from a data dashboard or data warehouse. Or a data scientist who works on different aspects of building and validating models. Think also about an ML engineer who is responsible for the model to work without issues to serve end-users in a production environment. ML practitioner is used to describe all these different roles throughout the ML lifecycle. Now, let's look at the challenges these ML practitioners face when they operationalize and make their models available for production. These challenges include managing and keeping track of complex details, such as data, model architectures, hyperparameters, and experiments. As for specific pinpoints, we hear it can be challenging to keep track of different versions of the models and their codes. Different training procedure parameters, hyperparameter values in each trial, and performance metrics control the experiments space to advance. In every iteration, these practitioners need to monitor what changes are being made, which ideas are being tried, which ideas work, and which ideas don't, pinpoint the best performing model when the models are benchmarked against each other. The best model here refers to the one that delivers the ideal result for your specific use case. Collaborate with data scientists, data engineers, ML engineers, application developers, site reliability engineers, business analysts and business users in operationalizing the ML models. Then there's the matter of reproducibility. Deploying a model to a production environment is difficult unless it can be reproduced. In fact, bypassing the reproducibility of the model is often discouraged or disallowed by policies or regulations. Reproducibility can be a major concern for ML practitioners because they want to be able to rerun the best model with a more comprehensive parameter sweep. When a team successfully trained and make some model ready for production in a streamlined fashion, performance, and agility are considerably improved. Even if there's a manual review step in the pipeline, automation ensures that each job is configured and executed in a repeatable manner, which reduces the risk of errors. Also, for a production application, the model needs to be updated regularly as new data comes in. Therefore, traceability becomes paramount.

### Video - [The concept of devOps in ML](https://www.cloudskillsboost.google/course_templates/158/video/526740)

- [YouTube: The concept of devOps in ML](https://www.youtube.com/watch?v=crMVhxo0GWA)

Now, let's walk through the phases of developing and publishing a machine learning model. Given all the barriers that ML practitioners face today, what can be done to mitigate them? One option is to look at machine learning projects through an operational lens. Operationalizing a model means balancing time, resources, and quality throughout the whole system. In software engineering, this approach is called DevOps. That term transfers over to machine learning as MLOps, which aims to streamline AI and ML projects in the same way that DevOps does for application projects. Think of MLOps as a lifecycle management discipline for machine learning. Its goal is a balanced process-driven approach to the management of resources, data, code, time, and quality to achieve business objectives and meet regulatory concerns. There are many similarities between DevOps and MLOps. For example, when software developers work on a project, they don’t all work on the same code at the same time. Instead, they work on a code repository and use source control and a branching strategy, which helps define how each feature, improvement, or bug fix of the product is handled. Code repositories and source control tools provide developers with both a historical record of all tasks, which lets them go back to previous versions, and a space to work on separate tasks in parallel where they can merge their efforts later. A branching strategy lets multiple teams work independently and verify that the changes on each branch do not conflict. Whenever developers want to make changes to the source, they download a copy of the code from the code repository or “check out” the code in short. The code files appear in their local directory and let developers use and compile the code. This way they can make changes to the source and to upload back to the repository later. In short, they complete the task on a branch in this phase. Before the code is returned to the repository, developers need to check whether anything changed in the main version. In other words, developers need to ensure that their changes are made against the latest version of the codebase. Before merging their changes, they also performs unit tests. After developers confirm that their code behaves as they expected, they give permission to the code to be merged to the main branch. When these changes are frequently merged with the main code, the chances of divergence decrease. Branches inevitably diverge, and they diverge exponentially as they run without integrating. Therefore, how often you integrate your branches matters. Developers perform mainline integration when they have a healthy commit they can share, usually less than a day's work. For every push to the repository, it’s very useful to create a set of scripts to build and test your application automatically. These scripts help decrease the chances that you introduce errors in your application. This process is called continuous integration, or CI for short. In a busy development team, this happens several times a day. Any change in the codebase repository, often triggers a CI pipeline. The pipeline is a series of steps that starts from checking out the code stage and ends with merging it. Another process favored by developers is continuous delivery or continuous deployment which depend on the automation level. An important caveat here is that continuous delivery and continuous deployment are not same, although they are both shortened as CD. Both of them refer to a method for building, testing, and releasing software in short cycles. Done this way, the main development code is almost always production-ready and can be released into the live environment at any time. If it is not done this way, the main code is like a race car with its wheels off and its engine out; it can go fast but only after it’s put back together. The difference between these two terms is the automation of deployment. Continuous delivery automates integration or acceptance tests, deployment to staging, and smoke tests. Note that staging refers to a production-like environment and smoke tests refer to testing the application before it is deployed. In continuous delivery, deployment to the production is still done manually. However, continuous deployment compliments continuous integration with additional steps by automating the configuration and deployment of the application to the production environment. Along with continuous integration, delivery and deployment, data is also an important aspect of MLOps. Unlike conventional software, which performs the same action repeatedly, an ML model can go “off.” This means that its predictive power can wane as data profiles inevitably change. A model deployed in production will not be able to adapt to changes in data by itself. This requires something called continuous training, or CT for short. Continuous training is the process of monitoring, measuring, retraining, and serving ML models automatically and continuously to adapt to changes in the data before they’re redeployed. MLOps differs from DevOps in important ways, too: Continuous integration is no longer only about testing and validating code and components, but also about testing and validating data, data schemas, and models. It’s about a whole system—the ML training pipeline—that automatically deploys another service: the model prediction service. Uniquely, ML is also concerned with automatically monitoring, retraining, and serving the models. Another concept that transfers well from software development to machine learning is technical debt. Technical debt represents the pressure to prioritize releases over quality, which might mean not paying close attention to code quality. There’s often a compromise between faster delivery and high quality. Although there might be good reasons to prioritize the release, developers will still need to go back and fix things later. Machine learning could arguably be considered “the high-interest credit card of technical debt.” This means that developing and deploying an ML system can be relatively fast and cheap, but maintaining it over time can be difficult and expensive. The real challenge isn’t building an ML model; the challenge is building an integrated ML system and operating it in production continuously. Just like a high-interest credit card, the technical debt with machine learning compounds and can be incredibly expensive and difficult to pay down. Please check the reading at the end of this section to learn more about The High Interest Credit Card of Technical Debt. Machine learning systems have all the operational challenges of software development, and a few of their own. One challenge is multi-functional team structure. Unlike many business projects, which are usually managed in a single department, ML projects require significant multi-functional expertise. Another challenge stems from the fact that ML is experimental in nature, which requires constantly approaching the data, the models, and parameter configuration in new ways. The real challenge comes when ML practitioners try to track all experiments and metadata while they try to maintain reproducibility and maximize code reusability. And then there is testing ML systems, which is more complex than testing other software systems because you need to validate data, parameters, code, and hyperparameters together in a system, instead of only unit-testing methods or functions. In ML systems, deployment isn't as simple as deploying an offline-trained ML model as a prediction service. ML systems might require you to deploy a multi-step pipeline to automatically retrain and deploy models. And finally, ML systems can present challenges related to concept drift and model decay. Data profiles constantly change. If something changes in the data input, the predictive power of the model in production will probably change with it. Therefore, you need to track summary statistics of your data and monitor the online performance of your model to send notifications or roll back when values deviate from your expectations. Drift is the change in an entity regarding a baseline. With a production ML model, this is the change between the real-time production data and a baseline dataset, most likely the training set, that’s representative of the task the model is intended to perform. To learn more about the several types of drift in ML models, check the Production Machine Learning Systems course in the Google Cloud catalog. Technical debt accumulates in an ML system for many reasons, so we look at ways to mitigate that throughout this course.

### Video - [ML lifecycle](https://www.cloudskillsboost.google/course_templates/158/video/526741)

- [YouTube: ML lifecycle](https://www.youtube.com/watch?v=V6UWNteDHcA)

Let’s explore the three main phases of a machine learning lifecycle and see how they map to tasks within MLOps. The first is the discovery phase, the second one is the development phase, and the third one is the deployment phase. The discovery phase is where the problem is defined and the desired outcome is identified. Some of the tasks performed in this phase can be the following: Business use case definition: Identifying the business need and the desired outcome allows for a clear plan of what a machine learning model will help achieve. Contextual understanding: The discovery phase also includes gaining contextual understanding of the people who are using or may be affected by the solution. This critical information can help further define the problem or task that needs to be solved. Use case feasibility: It's also important to assess whether the problem that you're trying to solve can actually be solved with machine learning. Let's say that you have historical data that can’t be accessed during inference time. If that's the case, ML might not be a feasible option to solve your problem. You'll probably need to perform a more comprehensive analysis before moving forward. Data accessibility and data exploration: During this phase, it’s important to determine which datasets are needed for the ML model, and whether that data is readily available and good enough to train the model. And if external datasets are needed, you must decide how to acquire them. Architecture and algorithm selection: Then, depending on the task that will be performed, the team chooses an architecture and a machine learning algorithm. Prioritizing use cases: Another aspect of the discovery phase is prioritizing the different use cases that the business has as potential ML projects, but this discussion is out of scope for this particular course. Check the Managing Machine Learning Projects with Google Cloud course to learn more about identifying business value for using ML. The development phase: the second phase of the Machine Learning lifecycle is the development phase. After the feasibility assessment is complete and you’ve got the go ahead, development can start. However, sometimes you might see that the development phase starts during data exploration, which is part of the discovery phase. Then you might ask this question: shouldn't we wait until the results of the feasibility study are available? However, in reality, even for data exploration and algorithm selection, some proof of concepts might need to be developed, and that is why the development phase and discovery phase overlap during the data exploration. It starts with a data pipeline creation and feature engineering. This is when all of the necessary data is cleaned, extracted, analyzed, and transformed for us in the model. A data pipeline helps ensure that all data operations will perform as expected–for both offline and stream data–and avoid data skew. You can visit the data preprocessing for ML documentation to learn more about best practices for preprocessing data in an ML pipeline. After the data is ready, model building and the model evaluation begins. The word "begins" is used here because these steps might require a couple of iterations until the ML practitioners are happy with the results and are ready to present them to the main stakeholders. Iteration is a central concept of machine learning. Constant iteration, tuning, and improvement is often required to ensure that a model performs as planned. During this phase, it might be helpful to perform some, or all, of the following activities. First, revisit the model use case. Because the ML algorithm might not identify data patterns for your use case in the first iteration, you might want to ensure that the model will still help you achieve your goal. Revisit the chosen dataset to determine whether the model requires a higher volume or new features. Data should be revisited because the model either needs more of it or it needs additional aspects or new features from the existing data. And finally, it might be helpful to consider whether additional data transformations are needed to improve the model quality, or whether a different algorithm might be better. The deployment phase: The last phase of the ML lifecycle is the deployment phase. Some of the tasks performed in this phase can be the following: Plan for deployment: After results are presented to the stakeholders and all parties are satisfied with the model performance, it’s time to plan for model deployment. This is when the following questions can arise: Which platform should host the model? Which ML model serving tools are needed? And how many nodes are needed for the cluster to scale the model in a cost-effective manner? Model Operationalization and Monitoring: As previously mentioned, operationalizing and monitoring a model helps with maintenance and avoiding model decay. Implementing a strategy to detect a concept or data drift allows signaling when the model needs to be retrained or when the data needs to be adjusted or augmented. Many people could be reliant on your model’s predictions, so it’s important to ensure that your pipeline accounts for all the necessary health checks and alerts.

### Video - [Automating the ML process](https://www.cloudskillsboost.google/course_templates/158/video/526742)

- [YouTube: Automating the ML process](https://www.youtube.com/watch?v=bA1dschO6wo)

In any ML project, after you define the business use case and establish the success criteria, the process of delivering an ML model to production involves many steps. These include: Data extraction Data analysis Data preparation Model training Model evaluation Model validation Model serving And model monitoring These steps can be completed manually or by an automatic pipeline. The level of automation of these steps defines the maturity of the ML process. Many ML professionals build and deploy their models manually. This is called maturity level 0. Other ML practitioners perform continuous training of their models by automating the ML pipeline. This is maturity level 1. Finally, the most mature approach completely automates and integrates the ML training, validation, and deployment phases. This is maturity level 2. Let’s look at each of these levels of automation in a little more detail. At the basic level of maturity, or level 0, many teams have data scientists and ML researchers who can build state-of-the-art models, but their process for building and deploying ML models is entirely manual. The characteristics of MLOps level 0 are: A manual, script-driven, and interactive process. A disconnection between ML and operation teams. Infrequent release iterations. No continuous integration, continuous delivery or continuous deployment. Deployment refers to the prediction service. And a lack of active performance monitoring. Check the documentation to learn more about the characteristics and challenges of MLOps level 0. The goal of MLOps level 1 is to perform continuous training of the model by automating the ML pipeline. This lets you achieve the continuous delivery of the model prediction service. To automate the process of using new data to retrain models in production, you must introduce automated data and model validation steps to the pipeline, as well as pipeline triggers and metadata management. The characteristics of MLOps level 1 are: Rapid experiment Continuous training of the model in production Experimental-operational symmetry Modularized code for components and pipelines Continuous deployment of models, which means continuous delivery of models and automated pipeline deployment. To learn more about the characteristics and challenges of MLOps level 1, check the documentation at the end of this section. One important note is that to enable ML continuous training, you must to add a couple of the components, such as data and model validation, feature store, metadata management, and ML pipeline triggers to the architecture. You’ll explore all these components in upcoming courses of this series MLOps level 2 can be characterized as Continuous Integration/Continuous Deployment, or CI/CD, pipeline automation, because you need a robust automated CI/CD system for a rapid and reliable update of the pipelines in production. This automated CI/CD system lets ML practitioners rapidly explore new ideas around feature engineering, model architecture, and hyperparameters. MLOPs level 2 achieves this automation thanks to the following components: Source control Test and build services Deployment services Model registry Feature store ML metadata store ML pipeline orchestrator. In any ML project, after you define the business use case and establish the success criteria, the process of delivering an ML model to production involves many steps. These include: Development and experimentation: you iteratively test new ML algorithms and new modeling where the experiment steps are orchestrated. The output of this stage is the source code of the ML pipeline steps that are then pushed to a source repository. Then, pipeline continuous integration: you build source code and run various tests. The outputs of this stage are pipeline components such as packages, executables, and artifacts that are deployed in a later stage. Next is pipeline continuous delivery: you deploy the artifacts produced by the CI stage to the target environment. The output of this stage is a deployed pipeline with the new implementation of the model. Then there is automated triggering: the pipeline is automatically executed in production based on a schedule or in response to a trigger. The output of this stage is a trained model that is pushed to the model registry. The next is model continuous delivery: you serve the trained model as a prediction service for the predictions. The output of this stage is a deployed model prediction service. And finally, monitoring: you collect statistics on the model performance based on live data. The output of this stage is a trigger to execute the pipeline or to execute a new experiment cycle. These steps can be completed manually or by an automatic pipeline. In the full stack for a machine learning system with Vertex AI, you can use: Vertex AI Feature Store for feature store Vertex AI Workbench for model development Cloud Source Repositories as your code repository Cloud Build for training operationalization Artifact Registry for your pipeline components Vertex AI Pipelines for your training pipeline Vertex AI Model Registry as your model registry Vertex AI ML Metadata for your ML metadata Cloud Build for model deployment Vertex AI Prediction for prediction serving BigQuery for serving logs Vertex AI Model Monitoring and Vertex Explainable AI, or XAI in short, for continuous monitoring. To learn more about the characteristics of MLOps level 2 and continuous integration/continuous delivery and continuous deployment concepts, check the documentation at the end of the course.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/158/quizzes/526743)

#### Quiz 1.

> [!important]
> **Which of the following characteristics of delivering an ML model is considered as a characteristic of maturity level 0?**
>
> - [ ] Feature store integration
> - [ ] Manual, script-driven, and interactive process
> - [ ] Source control automation
> - [ ] Pipeline continuous integration

#### Quiz 2.

> [!important]
> **What is the process of monitoring, measuring, retraining, and serving ML models automatically and continuously to adapt to changes in the data before they're redeployed?**
>
> - [ ] Continuous delivery
> - [ ] Continuous integration
> - [ ] Continuous training
> - [ ] Continuous deployment

#### Quiz 3.

> [!important]
> **Which of the following steps is part of continuous integration and delivery (CI/CD) but not continuous training (CT)?**
>
> - [ ] Retraining the model
> - [ ] Building the model
> - [ ] Monitoring the model
> - [ ] Measuring the model

#### Quiz 4.

> [!important]
> **What is the important aspect of MLOps which differs from DevOps?**
>
> - [ ] MLOps focuses on a single software package or service.
> - [ ] MLOps constantly monitors, retrains, and serves the model.
> - [ ] MLOps deploys code and moves to another task.
> - [ ] MLOps tests and validates only the code and components.

### Document - [Reading list](https://www.cloudskillsboost.google/course_templates/158/documents/526744)

## Vertex AI and MLOps on Vertex AI

This module explores what Vertex AI is and why a unified platform matters.

### Video - [What is Vertex AI and why does a unified platform matter?](https://www.cloudskillsboost.google/course_templates/158/video/526745)

- [YouTube: What is Vertex AI and why does a unified platform matter?](https://www.youtube.com/watch?v=5U5Bl9mpiu4)

Welcome to the second section of the Machine Learning Operations, or MLOps, Fundamentals course. In this part of the course, you’ll: Be introduced to Vertex AI, Google’s unified AI platform. Be introduced to MLOps on Vertex AI. And explore how Vertex AI helps with the MLOps workflow. If you completed the Machine Learning on Google Cloud course, you’ll recall that building an ML model and taking it to production requires expertise in both the workflow and the products required. This includes tools and services to build, package, deploy, and monitor a model. Let’s recall a few key constructs in machine learning. First, you create datasets by ingesting the data, analyzing the data, and cleaning it up. There are different processes for creating datasets, such as extract, transform, and load or ETL, and extract, load, and transform, or ELT. In the next step called model training, you train a model. This includes experimentation with feature processing, model architecture, and hyperparameter tuning. You also revert or iterate the model when there is new data, when the code changes, or based on a schedule. You then evaluate and compare the model to existing model versions. And finally, you deploy the model and use it for online and batch predictions. Recall that this end-to-end process is called “MLOps,” as defined in the previous section. It’s important to note that the type of data used to train a model will affect the rest of the pipeline. For example, are your data JPEG files or TensorFlow records? Do you store your data in Cloud Storage or in BigQuery? Also, the way you deploy a TensorFlow model is different from how you deploy a PyTorch model. And even the model deployment process might differ based on whether the model is created with AutoML or a custom TensorFlow model. With so many variables to consider when you create a machine learning model, an end-to-end ML platform like Vertex AI brings many benefits. Vertex AI brings together all the Google Cloud services for building ML and AI in one unified platform, which helps enterprises realize more value with their data and accelerate time to value. Vertex AI lets you unify certain parts of an ML workflow: A dataset can be either structured or unstructured. It can have managed metadata, including annotations, and can be stored anywhere on Google Cloud, This currently includes Cloud Storage and BigQuery. A training pipeline consists of steps to train an ML model by using a dataset. The containerization helps with generalization, reproducibility, and auditability. An ML model, which consists of metadata, can be built with a training pipeline or it can be directly loaded from other resources, as long as it is in a compatible format. An endpoint can be invoked by users for online predictions and explanations. It can have one or more models, and one or more versions of those models, with disambiguation carried out based on the request. The main idea is that these endpoints are the same regardless of the dataset type, training pipeline or model. It’s all mix and match. After you create a dataset, you can use it for different models. Please check Vertex AI documentation to learn more about Vertex AI. Because Vertex AI is a unified platform, the user interface can be used to directly manage the following stages in the ML workflow: Creating a dataset and uploading data. Training an ML model on your data which includes: Training the model. Evaluating model accuracy. Tuning hyperparameters, for custom training only. Uploading and storing your model in Vertex AI. Deploying your trained model to an endpoint for serving predictions. Sending prediction requests to your endpoint. Specifying a prediction traffic split in your endpoint. And managing your models and endpoints. Vertex AI is flexible. You can choose either AutoML, which lets you create and train a model with minimal technical effort, or custom training, which lets you create a training application that is optimized for your targeted outcome. In summary, Vertex AI offers fast experimentation, accelerated deployment, and simplified model management to achieve your ML goals. With Vertex AI, you have a platform to experiment with ML model development and quickly deploy solutions that will help meet your machine learning goals. For more information about Vertex AI, explore more courses in the ML training catalog at cloud.google.com/training.

### Video - [Introduction to MLOps on Vertex AI](https://www.cloudskillsboost.google/course_templates/158/video/526746)

- [YouTube: Introduction to MLOps on Vertex AI](https://www.youtube.com/watch?v=3T590EMSkYo)

Now that you’re familiar with what Vertex AI is, let’s explore how Vertex AI can help with MLOps processes. If you worked with ML models before, you know that training and deploying ML models can be time-consuming, because you need to repeatedly add new data and features, try different models, and tune parameters to achieve the best result. To solve this problem, organizations need to build the necessary ML engineering culture and capability. If we consider that MLOps is a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably, it can be the answer that you’re looking for in order to build ML engineering culture and capability. Before we look at workflows and capabilities needed in each phase of the MLOps lifecycle, let’s explore the MLOps concept in depth: MLOps aims to unify ML system development or ML with ML system operations or Ops. It advocates automating and monitoring every step of ML system construction. And finally, it maintains aligned versions of data and models alongside code and components. At this point, it is fair to ask this question: How does MLOps achieve each of these goals? To answer this question, it’s important to understand what ML engineering is and how ML engineering is tightly coupled with data engineering and app engineering: Let’s start with ML engineering. ML engineering is a superset of the discipline of software engineering and is designed to handle the unique complexities of the practical application of ML. MLOps is one of the methodologies adopted by ML engineering that focuses on operationalization and automation of model development, training, deployment, and governance processes. To learn more about ML engineering, check the reading at the end of this section. Let’s continue with data engineering. Data engineering focuses on ingesting, managing, and processing data to prepare datasets and features. All of these outputs created by data engineering, datasets and features, can be used in enterprise data warehouses, business intelligence or BI systems and ML engineering. And finally, there is app engineering. App engineering focuses on designing, developing, or migrating applications. Deploying ML models and integrating them with your applications and systems is the main subject of app engineering when you build an ML application. That means that engineering an ML enabled solution is an iterative process between the three disciplines: ML engineering uses the datasets and features produced by the Data Engineering team and feeds back the data requirements to the Data Engineering team. ML engineering also produces the models deployed by the App Engineering team, which in turn shares the application’s key performance indicators, or KPIs, with the ML Engineering team. Therefore, ML engineering should not be performed in isolation. Instead, it should use existing investments in DataOps and DevOps and integrate with the data engineering and app engineering to be effective. By the inspiration of this integration, the MLOps lifecycle can be divided in six iterative processes, and two cross-cutting processes in the center: The lifecycle starts with the ML development process, which is the developing and prototyping process of your ML models. This is mostly the experimentation phase of ML model development. The second process in the lifecycle is training operationalization, which refers to checking whether your model works on the production. This includes testing internal and external data connections and configurations and putting the model routine and a stable operational phase after the first experimentation phase is performed. Then, in the continuous training process, you retrain your production models with the new data. Next is the model deployment process, where actual continuous integration and delivery of your models occurs. The prediction or inference serving process refers to hosting ML models as services to serve online predictions or as part of a batch prediction system to serve offline predictions. And continuous monitoring is the final process, which stands for identifying and predicting model performance degradation, data skews and outliers. The central element of this lifecycle is data and model management, which are main functions for governing ML artifacts to support auditability, traceability, compliance, shareability, reusability, and discoverability of ML assets. An artifact is a discrete entity or piece of data produced and consumed by an ML workflow, such as datasets, models, input files and training logs. Note that data and model management processes are “transitional” phases. With the traditional components of an ML pipeline, you need to prepare data, perform feature engineering, train and tune the model, upload and store the model, compare the model to existing model versions, deploy the model, send prediction requests to the endpoint, present the model to any edge devices, and then monitor and manage the model. Vertex AI automates some of these steps, such as data preparation, feature engineering, model serving, and the ability to deploy to edge devices. Before you see how Vertex AI automates these steps, let’s first look at the reasons why Vertex AI serves the best in these different roles. Recall the different users within an organization that play a part in the ML lifecycle, such as product managers, data analysts and data engineers. These users have different needs and a comprehensive platform such as Vertex AI helps all of them thanks to its integration with different Google Cloud services that experiment with ML model development and quickly deploy solutions. There are four main reasons why Vertex AI serves the best in these different roles. First it provides a unified data and ML platform. A unified data and ML platform helps to build tighter connection points between data and ML. Therefore, it helps ML practitioners gain even greater value when they use all of our services to solve their largest problems. The second, Vertex AI lets ML practitioners achieve end-to-end MLOps. End-to-end MLOps helps ML practitioners efficiently and responsibly manage, monitor, govern, and explain ML projects throughout the entire development lifecycle. Thanks to its ready to use, prebuilt components, ML practitioners can achieve many ML tasks, including: Creating a new dataset and loading different data types, such as image, tabular, text, or video into the dataset. Exporting data from a dataset to Cloud Storage. Using BigQuery ML, Vertex AI custom training, or Vertex AI AutoML to train a model by using image, tabular, text, or video data. Running a custom training job by using a custom container or a Python package. Uploading an existing model to Vertex AI for batch or online prediction. And monitoring. These prebuilt components offer easier debugging and consistent interfaces to use standardized artifact types for input and output and cost efficiencies. Vertex AI also provides flexibility by delivering open and scalable ML infrastructure. The flexibility of data resources, ML framework, and hardware might accelerate the velocity of models into production. And finally, Vertex AI brings all the resources of Google to open source. In recent years, computing has both expanded as a field and grown in its importance to society. Similarly, the research conducted at Google has broadened dramatically. More than 3,000 Google and Deepmind researchers and more than 7,000 published publications drive better product performance and lower costs in many Google Cloud services recently. Building the next generation of data to AI, end-to-end MLOps and scalable infrastructure is happening in 3 phases: Phase 1 was for building a robust data foundation with services such as Bigtable or Pub/Sub. Phase 2 was for building an ML foundation with TensorFlow, TensorFlow Extended and Kubeflow. Phase 3 is now for building one unified AI platform by using many years of research and academic work. Vertex AI lets you access state-of-the-art AI algorithms developed by Google research to streamline complex AI use cases with optimized built-in infrastructure. Vertex AI drives more value from ML with access to state-of-the-art AI from Google Research and DeepMind and brings together all of Google Cloud services for building one unified AI platform with every ML tool you need, including the next generation of data-to-AI tools end-to-end MLOps capabilities, and scalable infrastructure. Vertex AI also integrates with widely used open source frameworks such as TensorFlow, PyTorch, and scikit-learn, along with supporting all ML frameworks and AI branches through custom containers for training and prediction.

### Video - [How does Vertex AI help with the MLOps workflow, part 1?](https://www.cloudskillsboost.google/course_templates/158/video/526747)

- [YouTube: How does Vertex AI help with the MLOps workflow, part 1?](https://www.youtube.com/watch?v=aQCxOt7xbV4)

Now let’s explore how Vertex AI can help with MLOps processes. Vertex AI gives you total flexibility in the tools you use to complete your ML journeys. Vertex AI was designed to automate ML processes to prevent ML practitioners from starting from the beginning. You can scale your ML models faster and more efficiently with the managed infrastructure provided by Vertex AI. You can also set up ML environments quickly, automate orchestration, manage large clusters, and set up low latency applications. Vertex AI provides a range of AI and ML tools for users of different skill sets alongside built-in MLOps capabilities, which lets enterprises improve insights, make predictions, and automate core business processes across their organization. With Vertex AI, you can: Manage and govern your ML models. Leverage Google Cloud’s managed services to simplify your MLOps processes. Reveal the explanations behind your models and predictions. Monitor your data and models’ performance, and Track and compare multiple experiment runs and analyze main model metrics. Let’s look at Vertex AI’s key components that let you perform those capabilities. Let’s start with managing and governing capabilities. You can manage and govern your ML models with Vertex AI Feature Store, Model Registry, ML Metadata, and model evaluation. Manage features: You can use Vertex AI Feature Store to create and manage features. Vertex AI Feature Store lets you: Share and reuse ML features across use cases. Serve ML features at scale with low latency. And alleviate training serving skew. Manage models: You can use the Vertex AI Model Registry to manage your ML models and use Vertex ML Metadata to track and analyze the metadata produced by your ML workflows. Vertex AI Model Registry is a central repository where you can manage the lifecycle of your ML models. Vertex AI Model Registry lets you: Register, organize, track, and version your trained and deployed ML models. Govern the model launch process. And maintain model documentation and reporting. Vertex ML Metadata lets you record the metadata and artifacts produced by your ML system. Therefore, it lets you: Automatically track inputs and outputs of all components. Query the metadata to help analyze, debug, and audit the performance of your ML system or the artifacts that it produces. And visualize, analyze, and compare detailed ML lineage. Evaluate models: You can run model evaluations in Vertex AI in several ways: First, you can create evaluations through Vertex AI Model Registry in the Google Cloud console. Second, you can use the model evaluation feature from Vertex AI as a pipeline component with Vertex AI Pipelines. Let’s move on to orchestrating ML workflow’s capabilities. You can simplify ML operations by using Vertex AI Pipelines to automate, monitor, and govern your ML systems. Vertex AI Pipelines lets you orchestrate your ML workflow in a serverless manner thanks to Google Cloud’s managed services suite such as BigQuery, Vertex Training, or Dataflow. ML pipelines are portable and scalable ML workflows that are based on containers. Therefore, ML practitioners can iterate faster, get more of their work into production, and work more independently. ML pipelines are composed of a set of input parameters and a list of steps. Each step is an instance of a pipeline component. ML pipelines let ML practitioners spend their time building ML solutions instead of building the infrastructure needed to get those solutions into production. You can use ML pipelines to: Apply MLOps strategies to automate and monitor repeatable processes. Experiment by running an ML workflow with different sets of hyperparameters, for example, different number of training steps or iterations. Reuse a pipeline's workflow to train a new model. You can use Vertex AI Pipelines to run pipelines that were built using the Kubeflow Pipelines SDK or TensorFlow Extended. To learn more about choosing between the Kubeflow Pipelines SDK and TFX, check the reading at the end of section. After you’re satisfied about your ML workflow, the next step is to understand your model’s behavior. You’ll explore that process in the next video.

### Video - [How does Vertex AI help with the MLOps workflow, part 2?](https://www.cloudskillsboost.google/course_templates/158/video/526748)

- [YouTube: How does Vertex AI help with the MLOps workflow, part 2?](https://www.youtube.com/watch?v=bmI753R_bT0)

Let’s continue with MLOps capabilities of Vertex AI. The next capability is understanding model behavior which reveals the “why” behind your model and predictions. You can use Vertex Explainable AI to understand your model's outputs for classification and regression tasks. Vertex Explainable AI tells you how much each feature in the data contributes to the predicted result and identifies model bias. Vertex Explainable AI is a fully managed service on Vertex AI that offers feature-based explanations. By integrating “feature attributions” or “feature importance” into Vertex AI, Vertex Explainable AI provides a better understanding of model decision making. Feature attributions are an explainability method that shows you how much each input feature contributed to your model’s predictions and to the model’s overall predictive power by using sampled Shapley, Integrated gradients, and eXplanation with Ranked Area Integrals (XRAI). When you request predictions, you get predicted values that are appropriate for your model. When you request explanations, you get the predictions along with feature attribution information. Explainable AI is built into multiple Vertex AI services. You can currently get feature attributions in: Vertex AI Prediction AutoML Tables And Vertex AI Workbench Feature attribution is supported for all types of models, both AutoML and custom-trained, frameworks like TensorFlow, scikit-learn, or XGBoost, and modalities such as images, text, tabular, or video. Vertex Explainable AI offers three methods to use for feature attributions: sampled Shapley, integrated gradients, and eXplanation with Ranked Area Integrals, or XRAI. Each feature attribution method is based on Shapley values, which are a cooperative game theory algorithm that assigns credit to each player in a game for a particular outcome. Applying Shapley values to ML models means that each model feature is treated as a "player" in the game. Vertex Explainable AI assigns proportional credit to each feature for the outcome of a particular prediction. For a thorough comparison of attribution methods, see the AI Explanations Whitepaper and check the Feature-based explanations documentation. The next MLOps capability of Vertex AI is proactively monitoring your model performance by using Vertex AI Model Monitoring. A model deployed in production performs best on prediction when the input data is similar to the training data. When the input data deviates from the data used to train the model, the model's performance can deteriorate, even if the model itself hasn't changed. To help you maintain a model's performance, Vertex AI provides a host of products to monitor and govern your models. Vertex AI Model Monitoring maintains your model's performance by monitoring the model's prediction input data for feature skew and drift: Training-serving skew occurs when the feature data distribution in production deviates from the feature data distribution used to train the model. If the original training data is available, you can enable skew detection to monitor your models for training-serving skew. Prediction drift occurs when feature data distribution in production changes significantly over time. If the original training data isn't available, you can enable drift detection to monitor the input data for changes over time. You can enable both skew and drift detection on Vertex AI Model Monitoring, but you should consider skew detection if you provide the original training dataset for your model. Otherwise, you should enable drift detection. For more information, see Introduction to Vertex AI Model Monitoring. The next capability is tracking and comparing multiple experiment runs and analyzing main model metrics. The goal when developing a model for a problem is to identify the best model for that particular use case. Vertex AI hosts different products to monitor and govern your models. For example, you can use Vertex AI Experiments to track, analyze, compare, and search across different model architectures, different ML frameworks, such as TensorFlow, PyTorch or scikit-learn, different hyperparameters and different training environments. In order to understand the nature of Vertex AI Experiments, let’s look at some crucial terms. Recall that an artifact is a discrete entity or piece of data produced and consumed by an ML workflow. A context is used to group artifacts and executions together under a single, queryable, and typed category. Contexts can be used to represent sets of metadata. An example of a “context” can be a run of ML pipeline. Vertex AI Experiments is a context in Vertex ML Metadata where an experiment can contain n experiment runs in addition to n pipeline runs. An experiment run consists of parameters, summary metrics, time series metrics, artifacts, executions and Vertex AI resources such as PipelineJob, which is created when users want to run an ML pipeline on Vertex AI Pipelines. Another tool that lets you track, visualize, and compare ML experiments and share them with your team is Vertex AI TensorBoard. Open source TensorBoard (TB) is a Google open source project for ML experiment visualization. Vertex AI TensorBoard is an enterprise-ready managed version of TensorBoard. Executions and artifacts of a pipeline run are viewable in the Google Cloud console. Vertex AI TensorBoard provides various detailed visualizations that include: Tracking and visualizing metrics such as loss and accuracy over time. Visualizing model computational graphs such as ops and layers. Viewing histograms of weights, biases, or other tensors as they change over time. Projecting embeddings to a lower dimensional space. And Displaying image, text, and audio samples. Check out the documentation to learn more about Vertex AI TensorBoard features and capabilities. You can also simplify your MLOps processes with Vertex AI Tabular Workflows. Vertex AI Tabular Workflow for End-to-End AutoML is a managed instance of Vertex AI Pipelines. It is a set of integrated, fully managed, and scalable pipelines for end-to-end ML with tabular data that uses Google's AutoML technology for model development and providing customization options to fit your needs. The following are some of the benefits of Tabular Workflow for End-to-End AutoML : Supports large datasets that are multiple TB in size. Lets you improve stability and lower training time by limiting the search space of architecture types or skipping architecture search. Lets you improve training speed by manually selecting the hardware used for training and architecture search. Lets you reduce model size and improve latency with distillation or by changing the ensemble size. Additionally, each AutoML component can be inspected in a powerful pipelines graph interface that lets you see the transformed data tables, evaluated model architectures, and many more details. These AutoML components also provide extended flexibility and transparency, such as being able to customize parameters, hardware, view process status, logs and more. In this section, you learned about Vertex AI MLOps tools that help you collaborate across ML teams and improve your models through predictive model monitoring, alerting, diagnosis, and actionable explanations. All of these tools are modular, so you can integrate them into your existing systems as needed. In the next section, which is the final section of the course, you review the main concepts you learned throughout this course.

### Document - [Reading list](https://www.cloudskillsboost.google/course_templates/158/documents/526749)

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/158/quizzes/526750)

#### Quiz 1.

> [!important]
> **What component of an ML pipeline is responsible for deploying the model to any edge devices?**
>
> - [ ] Evaluate
> - [ ] Analyze and transform
> - [ ] Upload and track
> - [ ] Upload model and deploy endpoint

#### Quiz 2.

> [!important]
> **What is the MLOps life cycle iterative process that retrains your production models with the new data?**
>
> - [ ] Continuous training
> - [ ] Continuous delivery
> - [ ] ML development
> - [ ] Predictive serving

#### Quiz 3.

> [!important]
> **How does end-to-end MLOps help ML practitioners with the machine learning life cycle?**
>
> - [ ] End-to-end MLOPs lets ML practitioners only monitor ML models.
> - [ ] End-to-end MLOps lets ML practitioners only perform exploratory data analysis (EDA) and prototyping.
> - [ ] End-to-end MLOps helps ML practitioners efficiently and responsibly manage, monitor, govern, and explain ML projects throughout the entire development lifecycle.
> - [ ] End-to-end MLOPs lets ML practitioners only train and tune ML models.

### Video - [Lab introduction Vertex AI: Qwik Start](https://www.cloudskillsboost.google/course_templates/158/video/526751)

- [YouTube: Lab introduction Vertex AI: Qwik Start](https://www.youtube.com/watch?v=Q450YPbTKqc)

Now, it’s time for practice with Vertex AI. In this hands-on lab, you are introduced to Vertex AI through a high-value, real-world use case: predictive customer life value (CLV).

### Lab - [Training and Deploying a TensorFlow Model in Vertex AI](https://www.cloudskillsboost.google/course_templates/158/labs/526752)

In this lab, you will use BigQuery for data processing and exploratory data analysis, and the Vertex AI platform to train and deploy a custom TensorFlow Regressor model to predict customer lifetime value (CLV). The goal of the lab is to introduce to Vertex AI through a high value real world use case - predictive CLV. Starting with a local BigQuery and TensorFlow workflow, you will progress toward training and deploying your model in the cloud with Vertex AI.

- [ ] [Training and Deploying a TensorFlow Model in Vertex AI](../labs/Training-and-Deploying-a-TensorFlow-Model-in-Vertex-AI.md)

## Summary

Summary

### Video - [Summary](https://www.cloudskillsboost.google/course_templates/158/video/526753)

- [YouTube: Summary](https://www.youtube.com/watch?v=IHqBSh-8XG8)

Congratulations! You’ve made it to the end of the MLOps Fundamentals course. Throughout the course, you’ve been introduced to the MLOps concept and the considerations behind it. In the first section of the course, Employing Machine Learning Operations, you explored ML models from an operational perspective. You first examined the challenges that ML practitioners currently face when they operationalize ML models and make them available for production. Then, you were introduced to the concept of DevOps in ML and the phases of the ML lifecycle. After you explored the main phases of an ML lifecycle, you learned how these phases map to tasks within MLOps. In the second part of the course, the Vertex AI and MLOps on Vertex AI, you explored what Vertex AI is and why a unified platform is useful. Then you learned about the MLOps capabilities of Vertex AI and how Vertex AI helps with the MLOps workflow. In the hands-on lab at the end, you worked on a high-value, real-world use case: predictive customer life value. You started with a local BigQuery and TensorFlow workflow and then progressed toward training and deploying your model in the cloud with Vertex AI. This course is just the beginning of your machine learning operations journey. Stay tuned for future machine learning operations courses with Google Cloud. For more training and hands-on practice with ML and AI, please explore the options available at cloud.google.com/training/machinelearning-ai And if you’re interested in validating your expertise and showcasing your ability to transform businesses with Google Cloud technology, you might consider working toward a Google Cloud certification. You can learn more about Google Cloud’s certification offerings at cloud.google.com/certifications. Thanks for completing this course. We’ll see you next time!

### Document - [All Readings](https://www.cloudskillsboost.google/course_templates/158/documents/526754)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

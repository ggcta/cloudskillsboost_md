---
id: 1122
name: 'Generative Playbooks'
datePublished: 2024-07-18
topics:
- Machine Learning
type: Course
url: https://www.cloudskillsboost.google/course_templates/1122
---

# [Generative Playbooks](https://www.cloudskillsboost.google/course_templates/1122)

**Description:**

In this course, you will learn how to build conversational experiences in Dialogflow CX leveraging Generative Playbooks, a Gen AI feature to develop end to end agents by specifying tasks through natural language

**Objectives:**

- Understand generative playbooks and how they can be used.
- Learn prompt design principles.
- Learn about the types of testing, debugging, and troubleshooting techniques.
- Understand operations planning and production deployment.
- Understand generative steering and its benefits.

## Introduction to Generative Playbooks

This module introduces you to Generative Playbooks, their main components and the use cases they support.

### Video - [What are generative Playbooks?](https://www.cloudskillsboost.google/course_templates/1122/video/495097)

- [YouTube: What are generative Playbooks?](https://www.youtube.com/watch?v=rp3fu5DNki8)

Welcome to this course. Here, you'll learn about generative capabilities and specifically generative playbooks that are available as an out of the box feature in Dialogflow CX. We’ll start with an Introduction to Generative Playbooks, followed by how to set up your first Generative Playbook. Next, we’ll discuss testing. . After that we’ll dive into necessary considerations for productionization like quota limits and integration. Lastly, we’ll end with a case study in using playbooks to perform generative steering. Let’s begin with a high-level overview of generative playbooks. We will be covering three topics in this section. First, what are generative playbooks? Why should you use them? And third, what makes for a good generative playbook use case? Let’s start by introducing the concept of a generative playbook. Google offers a number of generative AI solutions in the conversation space. Gen AI Agents help create an out of the box conversational experience based on information provided by a knowledge domain, such as a website or document. Generative Responses call LLMs for specific fulfillments or no match events by providing simple prompts in natural language. Here, we will focus on Generative Playbooks. Generative Playbooks enable users to specify tasks in natural language, just like they would with a human agent. This intuitive approach eliminates the need for complex programming or technical expertise, making conversational AI development more accessible. Generative Playbooks can be used to create a wide range of conversational experiences, from simple FAQ bots to complex customer support interactions. Let’s start with some definitions. Generative Playbooks are designed to help you build virtual agents using large language models. You can develop agents for chat and voice. You can also enable the large language model to access Application Programming Interfaces (APIs) and tools and to perform transactions. This platform is based on natural language instructions. It allows you to use natural language instructions and conversational examples. As you work with generative playbooks, it's important to remember that Dialogflow CX still provides all the quality controls and enterprise tools you need. The platform currently features tooling to make bot building and maintenance much easier. This includes being able to develop test cases, monitor production traffic, and improve bot quality over time. You can also have environments and versions, configure sharing settings specifically for your needs, and access many other enterprise features. The interface for playbooks allows you to easily configure the playbook name, goal, and steps, or behavior. This will be explored in more detail in a later section of the course.

### Video - [Why use generative Playbooks?](https://www.cloudskillsboost.google/course_templates/1122/video/495098)

- [YouTube: Why use generative Playbooks?](https://www.youtube.com/watch?v=xXTgTRht7gc)

Now that we have introduced generative playbooks, a natural question arises: why use them? What are some key advantages of generative playbooks? First, they break away from rigid state machines. It simplifies bot development and enables a natural conversational flow. They eliminate the need for time-consuming data collection and annotation, enabling rapid prototyping and development. Playbooks foster intuitive development, replacing complex flows and rules with plain English instructions. Now there is no need to consider every possible edge case. Next, LLMs can natively handle natural conversation. Examples include contextual memory, in that it remembers information within a conversation for a more personalized and context-aware experience, or facilitating better information delivery and comprehension through summarizing key points, repeating important information, and itemizing lists for clarity. They offer Out of the Box or built-in functionalities for common tasks, reducing development time. Finally, the data store agent connector enables Generative AI Agents to access and utilize information from third-party sources like knowledge bases and databases for more comprehensive and informative responses, enhancing the overall conversational experience. None of this is to say that generative playbooks should always be used over state machines. Generative playbooks offer flexibility and rapid development, while state machines excel in high-volume, margin-sensitive environments. The choice between the two approaches depends on the specific needs and priorities of the conversational AI application.

### Video - [What makes a good Playbook use case?](https://www.cloudskillsboost.google/course_templates/1122/video/495099)

- [YouTube: What makes a good Playbook use case?](https://www.youtube.com/watch?v=392s-8qTRSA)

Now that we have seen some advantages of playbooks, it’s time to look at what makes for a good playbook use case. A good Playbook use case requires Flexible Statefulness, which occurs when the order of operations is less stringent. Generative AI Agents offer greater flexibility, allowing for more natural and conversational interactions. This contrasts traditional conversational AI systems that often require a rigid sequence of steps. The second advantage is the need for limited resources for development. Building with playbooks is extremely fast: Generative AI Agents enable rapid prototyping and development of conversational AI applications. So if you have limited resources, playbooks may be a better option. By contrast, state machines are often desirable for high-volume if you have resources available to devote; state machines offer greater control and optimization for high-volume interactions. And lastly, Playbooks are well-suited for iteration: Generative AI Agents facilitate easy iteration on parameters, allowing for continuous improvement of conversational flows. There are many examples of particular use cases where a playbook might be useful. There are nine displayed here. Let’s do a deep dive on a couple to further elaborate. One sample use case for playbooks is for creative assistance in storytelling. For instance, suppose that your requirements are to tell a short story based on prompts from the user. It is important to be flexible here; there are a broad range of options for how the story might go. Given their flexible statefulness, playbooks are a good choice for this use case. Also, due to considerations around resource availability. Likely you could build a storytelling flow much faster by having an LLM generate the story, rather than having to map out all of the possible ways the story might go and build subflows for each of them. Finally, there is convenience in leveraging playbooks for this use case from an iteration and disambiguation perspective. For a storytelling flow, likely you want to build something quickly, then test it out and see how it does. This will allow you to tweak things (for instance by changing how dark the story is) and then running things again. Another example is troubleshooting. We know that troubleshooting is often an organic process in which users may have already tried various “first step” solutions, so not being stateful allows for the LLM to assess the situation and recommend the best next option organically. From a resource perspective, if you have a limited set of resources, uses a playbook will likely be faster than building out troubleshooting as a stateful flow. Also, from an iteration perspective if you need to be frequently updating and testing your troubleshooting flows, you may prefer to use a playbook for them, as it’s typically faster to iterate using a playbook. Many other examples could be quoted as good use cases for playbooks, from conversational assistants that can help place an order in a drive-through, vacation planners, agents that can help dispute banking transitions or provide financial advice, to agents that can provide custom advice for customers browsing through a catalog, applications are endless and cut through multiple industries. Now let’s dive deeper into use cases that may not be the best fit for generative playbooks. There are cases that involve strict business rules that possibly include legally required responses or order of operations. When legally binding responses or a specific sequence of actions are mandated, Generative AI Agents may not be the ideal choice due to their generative nature. Therefore, state machines or rule-based systems may be more suitable. Generative AI Agents, generating natural language, should not be tasked with producing exact wording that is legally or critically sensitive such as explicit definitions. Next, there are use cases that are highly procedural. In other words, they have an extremely rigid step execution. In scenarios where the conversational flow must adhere to a strict sequence of steps without deviation, Generative AI Agents may not be the best fit. State machines or rule-based systems offer greater control and predictability for highly procedural use cases. Finally, there are use cases that require mathematical functions. Math should always be handled by functions or external APIs. LLMs are not designed to perform complex mathematical calculations or handle numerical data. For use cases involving mathematical operations, such as calculating sums or applying formulas, dedicated functions or external APIs should be utilized. Now let’s view the platform in action as presented during Google Cloud Next in 2023’s opening keynote. To further understand the differences between stateful flows and playbooks, it will be helpful to compare some of their key components. Stateful flows include: Intents, which represent the user's intentions or goals, providing a way to categorize user input. Entities are specific pieces of information extracted from user input, such as names, dates, or locations. Pages represent individual screens or segments of the conversational flow. Conditions define decision points that determine the direction of the conversational flow based on user input or other factors. By contrast, here are some key components of playbooks. A goal is a concise description of the overall purpose of the conversational flow, applicable to all steps within the flow. Steps is a structured list of instructions outlining the script to be executed in a specific order. Context is session parameters and user data, such as user profile information, that provide context for the conversational flow. Parameters include both input and output parameters. These are things that the playbook will write to the session, akin to declaring arguments for a function. Finally, tools are integration points for calling external APIs to enhance the capabilities of the conversational flow. They also allow you to call data stores.

### Quiz - [Introduction to Generative Playbooks Quiz](https://www.cloudskillsboost.google/course_templates/1122/quizzes/495100)

## How to Set Up Your First Generative Playbook

This module explores the step by step process for the creation of a Generative Playbook and the main best practices for prompt design.

### Video - [The Playbook creation workflow](https://www.cloudskillsboost.google/course_templates/1122/video/495101)

- [YouTube: The Playbook creation workflow](https://www.youtube.com/watch?v=BIiI4HGDD7U)

Now that we have outlined some of the key advantages of playbooks and some of their components, it is time to set up your first playbook. We will start by looking at the playbook creation workflow as a whole. Then, we will run through the steps in detail. First, there is creating the playbook, and next, creating a goal and steps. Crafting good goals and steps requires understanding prompt design principles, so we will overview these principles. Next, we run through three additional things you need to create: tools, parameters, and examples. Let us start by overviewing the entire workflow. The first step in the process is to create a new playbook which contains the following three substeps: Begin by defining the goal: Clearly articulate the main objective of the conversational flow, ensuring it aligns with the overall purpose of the conversational AI application. Next, identify the context: Determine the relevant session parameters and user data that will provide context for the conversational flow. This may include user profile information, previous interactions, or external data sources. Then, outline the steps: Create a rough outline of the steps involved in the conversational flow. This outline should provide a general overview of the interaction, including key actions, responses, and decision points. Note that it is possible to have a playbook invoke another playbook. The playbook that is invoked is called the child playbook. As you’re creating your new playbooks, you’ll want to have a good sense of the parent-child relationships that will exist between your playbooks. The second step in the process is to edit steps and goals. As you do this, you will also need to create tools and parameters, because these will be referenced in your steps. This step contains the following three substeps: To begin, refine your goals: Revisit the goals and ensure they are specific, measurable, achievable, relevant, and time-bound, or SMART for short. Next, flesh out the steps: Expand the step outline into detailed instructions, providing clear guidance for the conversational AI application. This includes defining triggers, responses, and actions for each step. Finally, incorporate context: Integrate relevant context parameters into the steps, ensuring the conversational AI application takes into account the user's background and current situation. As part of the second step, you’ll discover creating tools and parameters. Creating tools requires several substeps, namely: To begin, define the tool requirements: Identify the external APIs or functionalities that need to be integrated into the conversational flow. Develop Tool Integrations: Create code or utilize existing integrations to connect the conversational AI application with the required tools. Test Tool Integration: Verify that the tool integrations function as expected and provide the desired functionality within the conversational flow. The third step is to create examples. If you have created tools, you will want to make sure these examples include cases where you invoke tools. The fourth step is to test your playbook. You can do so within the simulator by interacting with your agent. Once you’ve identified a case that you’re happy with, you can save it as a test case. Once saved, you then have the option to run your test cases and debug any issues. Note that, technically speaking, you can start testing even earlier in the process; examples and tools are not strictly required. So you may wish to test even before you add examples to see how things are functioning. We are ready to look at the big picture. Here, all the steps are visible from creating a new playbook, to editing and creating steps, to editing and creating new tools and parameters, to editing and creating examples, to testing in the simulator and creating test cases. As you proceed through these steps, you should keep in mind that this is an iterative process and development of latter steps may create a need to return to former steps for refining or further development. For example, as you test, you may see the need to refine your steps, tools, parameters, and examples. As you refine these, you may need to adjust test cases. And so on. By embracing this iterative workflow and incorporating the feedback from testing and experimentation, you can create Generative Playbooks that deliver engaging and effective conversational experiences for your users.

### Video - [Creating a Playbook](https://www.cloudskillsboost.google/course_templates/1122/video/495102)

- [YouTube: Creating a Playbook](https://www.youtube.com/watch?v=o9jq1P71BkQ)

Now that we have reviewed the overall playbook creation workflow, let’s start with the first step, creating the playbook itself. Now, let us run through the steps in more detail. We will start with creating your first playbook. You can do so in two different places, either in the DFCX UI or in the Vertex Search and Conversation UI. Let us start with the latter. To create a playbook in the Vertex Search and Conversation UI by selecting “Create App” and then selecting “Generative agent”. Your playbook is now ready to be configured. Now let us talk about how to create a playbook in the DFCX UI. To do so, navigate to the Dialogflow CX console and choose a project that’s allowlisted for Generative Playbooks. Click on “Create agent” and choose “Build your own”. Make sure to choose the “Generative” option in the “Agent type” menu and “Global” in the “Location” menu. Note that you can access the Dialogflow CX console resource in the Additional resources document. When it comes to creating an agent, you can select either an auto-generated data store agent or a build your own. Data store agents are a separate topic, so for now just select “Build your own”. Add a name for your agent. Make sure to choose the correct region, you won’t be able to change it later. Generally, we recommend choosing “Generative” as the agent type. Choose the icon for Generative Playbook on the left and click on create new in the middle of the screen to start building a new playbook.

### Video - [Creating goals and instructions](https://www.cloudskillsboost.google/course_templates/1122/video/495103)

- [YouTube: Creating goals and instructions](https://www.youtube.com/watch?v=UcXmtnjLB1E)

Now that your playbook is created, it’s time to add goals and instructions. When you create a Generative agent, you’re put into the Playbooks view. In this example, we’ve created a playbook which is intended to book flights and hotels for end users. First let’s look at the goal. The goal describes the overall objective of the playbook - a plain language description of the overarching task at hand. Here, we’ve put a very simple goal, but goals can be significantly more complex than this. As a general rule, it is best to start with the simplest form of goal and adjust it as needed. Next, let’s explore the playbook instructions. Playbook instructions include the various steps that may or should be accomplished to fulfill the goal of the playbook. Each step contains a natural language instruction that may contain the following: Minimally, it must contain basic instruction that the LLM can understand. It may also contain an instruction to route the user to another playbook. Playbooks are referenced using the form: dollar sign open curly brace PLAYBOOK, which is in all caps, followed by colon space playbook name close curly brace. It can also contain an instruction to use a specific tool. Tools are referenced using the form: dollar sign open curly brace TOOL in all caps, colon tool name close curly brace. Lastly, it can contain instruction to route the user to a Dialogflow flow. Flows are referenced using the form: dollar sign open curly brace FLOW in all caps, then colon flow name close curly brace. Note that each step description starts with a hyphen, and you can define substeps using indentation. Also note that instructions can be conditional. This means that although the LLM will typically follow the instructions linearly, it may skip some steps if they’re conditional. Now, let us watch a video to see this in action.

### Video - [Prompt design](https://www.cloudskillsboost.google/course_templates/1122/video/495104)

- [YouTube: Prompt design](https://www.youtube.com/watch?v=4mUBkIHkv3s)

Now, let’s discuss some guidelines and best practices for prompt design. Here are a few high-level considerations when writing an LLM prompt. We can start with granularity. In the context of playbooks, granularity means to intentionally break down large tasks into smaller subtasks for the playbook or amongst multiple playbooks working together. This compartmentalized approach enhances clarity, simplifies maintenance, and promotes reusability of playbooks across different conversational flows. Next is the idea of clarity. This means crafting goals that are well-defined, precise and detailed, leaving no room for ambiguity or misinterpretation. Doing so will ensure that your agent is more predictable and easier to measure and maintain. Lastly, concision is key. To optimize the LLM's performance and ensure the playbook functions as intended, it is essential that your description be brief but comprehensive. Avoid unnecessary details and extraneous information to conserve the token limit, allowing the LLM to allocate more resources for processing instructions and examples. This leads to more effective and natural conversational interactions. First, let’s define some terms. A prompt is the text or instructions that you feed to the model. Given this, prompt design is about figuring out how to write and format prompt text to get LLMs to do what you want. Prompt design provides a number of challenges. It is both an art and a science and the exact wording and order of the prompt matters greatly. Given this, prompt design often takes the form of experimenting with different structures, formats, examples, and even the number of examples to see what works best. Let’s take a moment to review some examples of well-defined goals. Here we have examples of retail, hospitality, and insurance goals. First, these goals are very granular. In each case, the playbook has a specific task that needs to be completed. For instance, in “Insurance”, the goal is to create an insurance claim. “You are an insurance claim agent, your job is to the help customer to create a new insurance claim for a car accident. Assume that the user has already been in a car accident.“ Second, the goals are clear and specific. For instance, in the “Retail” goal, we make it clear exactly what the customer is purchasing, namely a phone. “Guide the user to purchase a phone by collecting product selection criteria from them.” Finally, the goals are concise. Even the longest goal, in “Hospitality”, is only a couple of sentences. “As the booking agent for an airline company, your task is to offer customers flight tickets to destinations that match their preferences. You have a list of cities to choose from and will use your knowledge to find the best match.” You can find many resources on prompt design in the Additional resources document. For example, Vertex AI has a great summary of best practices. Here are some general tips when it comes to prompt design. Capitalization serves as a visual cue, emphasizing crucial information or instructions within a prompt. This is useful when conveying instructions or emphasizing sensitive information, such as "Remember to KEEP DETAILS CONFIDENTIAL". This visual emphasis helps the LLM prioritize this instruction and ensure it’s incorporated into the generated response. Using exaggerations or hyperbolic language effectively conveys the importance of certain points or instructions within a prompt. Repetition of essential phrases or concepts within a prompt effectively reinforces the desired direction for the AI model's responses. Through reiteration, the model can consistently generate responses that align with those emphasized aspects. So, emphasizing creativity through phrases like "remember to be creative," "keep in mind to be creative," and "don't forget to be creative," communicates to the AI model that creativity is a crucial factor and helps to generate responses that are imaginative, original, and innovative. When a prompt fails to produce the desired results, modify it, maintaining effective elements from the previous attempts while discarding ineffective ones. This iterative approach allows for gradual improvement and optimization of prompts. This strategy emphasizes the importance of learning from past attempts and refining prompts based on observed successes and failures. By identifying which sections of previous prompts contributed to positive outcomes and eliminating those that hindered progress, users can gradually construct more effective prompts that consistently generate desired responses. Sometimes, an iterative approach may not be working for you, and it may be necessary to start over. Filter out the sections from the previous prompt that “work” (make the model behave the way you want) and build upon them for the new prompt. Finally, modular testing is key to success. Breaking down complex prompts into smaller, more manageable subtasks is very helpful in pinpoint the source of errors. Restating the instructions in slightly different ways can help improve responses. For instance, you might try using synonyms of the words you were using. Explicitly mention what you don't want in the response. This is especially useful when the model tends to produce certain unwanted outputs for specific prompts. Instruct the AI to evaluate or check its own responses before producing them. Here are some more tips. First, use clear prompt structure. For instance, start by defining the role your AI is performing. Constraints help specify exactly what the model should return. So, for instance, you can add constraints to control the length of the output. Delimiters are critical for multiple reasons. LLMs benefit from explicit separation of values because this reduces the need for interpretation and deduction. Reducing any unnecessary interpretation for the LLM can result in better, more predictable, and more consistent results. Delimiters can also serve to benefit co-development through increasing the readability between developers. LLMs can also serve to help generate better prompts for your use case, for example, you can ask Bard to give you feedback on your prompt, perhaps highlighting ambiguity, you can ask it to refine and improve your prompt directly, giving recommendations for replacements in line, or you can also ask it to generate a prompt from scratch based on what you already have or by giving your use case.

### Video - [Tools](https://www.cloudskillsboost.google/course_templates/1122/video/495105)

- [YouTube: Tools](https://www.youtube.com/watch?v=WvUKHULhb-c)

Let’s talk about how to leverage tools in your Generative Playbook to fulfill specific tasks. Tools are one of the most important concepts in Generative Playbooks. They represent a collection of functions that are available to the playbook & the Dialog Manager. You can think of a Tool as a collection of functions that can work together to solve a particular customer problem. In the context of a playbook, a tool can be defined by a schema in the OpenAPI 3.0 format, and also by selecting an existing Search & Conversation Data Store. Once a tool is defined, you may call the tool from the instructions in your playbook. For example, you might have a calendar management tool that can book meetings, reserve rooms, and invite guests. Tools in Generative Playbooks can be used to make API requests to other services for typical CRUD which stands for Create, Read, Update, and Delete, operations. Let's say that it is necessary to look up a user's profile that is stored somewhere other than Dialogflow. For this example we’ll look up a user profile from a BigQuery table, but the process is largely the same regardless of the application. Create a tool by selecting Tools from the Resources sidebar and then select Create. You will be required to enter a name for the Tool, the type of Tool it is, in this case it’s OpenAPI, a description of the tool’s purpose, and the OpenAPI schema of the tool. The schema you enter needs to conform to the OpenAPI spec. You can use the Swagger Editor to write & check your OpenAPI 3.0 schema. Bard is also useful as a starting point for generating schemas. So, go ahead and access Swagger Editor and Bard in the Additional resources document. Think of the OpenAPI Schema as a set of instructions that tells your API how to behave. The fundamental pieces of a schema are: Version Info: This is where we mention which OpenAPI version we’re using. Example: openapi three dot oh for version 3 of OpenAPI. Info Object: Here’s where you introduce your API — it’s name or title, a description of what it does, and a current version of the schema. Paths Object: The heart of the schema, this part describes all the URLs, or endpoints, the API has and what they do. Components Object: This is your collection of reusable components, like responses and parameters. It allows you to cut down on duplication of code by only specifying something once and referring to from one or more locations. This example shows an HTTP POST request to a Cloud Function at forward slash get underscore user underscore profile, passing in profile underscore id, and defining the expected response to contain an object with the properties link ,name, snippet, and title. To expand a bit on the previous slide, you have a couple options when defining the requestBody & response schemas for your paths. You can define the schema inline which allows you to have your schema in close proximity to the rest of your path definition, but the downside to doing so is that if you have any other requestBody forward slash response schemas that use the same structure, you will be repeating the same code in multiple places. Alternatively, you can define the schema once in the components section which is separate from the paths section, and then just refer to that schema by name with the dollar sign ref colon syntax in your path definition as shown in the screenshot. The second screenshot shows the inclusion of a special query parameter for passing the Dialogflow session ID to the API server you are sending a request to. In the near future you will be able to pass an arbitrary list of query parameters, but for now you must include all arbitrary parameters as part of the requestBody. A common development pattern is to create tools that call Cloud Functions. This is useful because Cloud Functions are extremely versatile and give you the flexibility to make requests in the language of your choice to any API. Languages currently supported in cloud functions are Python, dot NET, Java, Ruby, PHP, Node js, and Go. Here, we’re returning to our example of pulling information from a BigQuery table and there are a few things which you should note. First, Python is being used with a micro web framework called Flask. Second, there is only one endpoint in this cloud function that can receive requests, which is shown on line 20 in the screenshot as At-sign app dot post open paren quote forward slash get underscore user underscore profile quote close paren. That is the path requests are being made to as defined in the previous slide when the schema was created. Third, a project ID and table name are needed to make a connection to the BigQuery API, and an SQL query is made to look up the user’s profile by their profile id, as highlighted in line 27 as profile underscore id. And lastly, we have defined that the resulting profile data from BigQuery is then returned in the JSON response. To add a data store agent as a tool, make sure it is in the same project as your playbook. Then, navigate to the tools section and connect your data store. We will talk more about this in a moment. To add a date store as a tool, there are five steps. First, go to Tools Next, give the tool a name Then select its type as “Data Store” Give it a description And lastly, select the data store you wish to add. Let us see an example of how to configure a data store agent tool. Two notes before we begin: First, the presenter uses an older term to refer to data stores, namely “Infobot”. Second, the video makes reference to examples and testing. We will see more about how to use examples and test them in later sections.

### Video - [Parameters](https://www.cloudskillsboost.google/course_templates/1122/video/495106)

- [YouTube: Parameters](https://www.youtube.com/watch?v=15rXUEex1ss)

Now, let us talk about playbook parameters. You can pass parameters between playbooks. To do so, select the parameters tab of your playbook. You can specify input parameters, those that a playbook receives, and output parameters which are those that the playbook passes out. Note that there are several ways to set output parameters. You can collect these from the user, from a tool, and/or manipulate existing values of parameters. When you create a new parameter, you give it a name, type, and description. The description is especially important in making sure that the LLM understands your parameter.

### Video - [Examples](https://www.cloudskillsboost.google/course_templates/1122/video/495107)

- [YouTube: Examples](https://www.youtube.com/watch?v=ZAobHINcPLs)

Now, let’ discuss examples in playbooks. Examples are the third step of playbook creation. Adding examples can help cut down on unpredictability. Without examples, you may find that an agent doesn’t follow steps in the correct order, that it doesn’t follow certain instructions at all, even if they are clearly written, and that even given the same inputs, it may give wildly different outputs. Let’s define what an example is and how to create one. An example is a turn-by-turn run through your playbook. It includes starting conditions, exactly what happens during your playbook, and what the end state is. For instance, maybe you have a billing playbook that offers users information about their bill. Your example’s starting conditions tell the system where the user came from such as maybe they said “please describe my bill”. Then, maybe within your playbook, the agent said “how can I help you with your bill?”, the user responded “what is my current bill” the playbook called a tool to pull information regarding the user’s current bill and then responded “you currently owe $32 due at the end of the month.” At the end, the playbook concluded successfully and the system moved on to the next task. To create a good example, it is important to specify the usage trigger. This says when the system can use the example in training. On the right hand pane, you specify exactly what happens during your playbook, including agent turns, user turns, and tool invocation. A playbook’s summary is designed to help you pass context between different playbooks. For example, you could use this field to set “User placed an order for iPhone 14 Pro 256 with order id hashtag ABC123456789”. This way, you can instruct your playbooks to send this order number back to a parent playbook once the child completes a given task. Finally, you should add a final playbook state. Generally, you use the state OK for most of your examples but if you need to escalate, labeled ESCALATED in all caps, or mimic a behaviour where the bot fails, labeled FAILED in all caps, you’d change the configuration here to reflect it. If a user bails out of a process you were in, such as PLACE underscore ORDER child playbook, but the user canceled placing their order, you could set the state to CANCELED and go back to the parent playbook. Here’s an example of a well-defined conversation for a hospitality use case with some tool usage. Note that in this example, we include not only what the agent and users say, but also information about tools and parameters. For example, we include that the hotel_search tool was triggered, with one input parameter and one output parameter. Showing where tools get invoked within conversations and what input parameters and output parameters they use enables the system to call tools at the appropriate time and pass along the appropriate information. Ensure that input and output parameters for your tool are clearly specified to guarantee accurate performance. As shown on this slide, we have a hotel booking tool that requires the following input parameters: check-in date, number of travelers, checkout date, number of rooms, and hotel name. It also produces two output parameters: a booking reference and a confirmation number. The tool's primary function is to transform the input parameters into a confirmation number that serves as a booking reference. It is designed to take in user information such as their desired check-in date, the number of travelers, and additional details that aid in finding the appropriate hotel. The tool then communicates the confirmation number back to the user. There are a few useful features to help you manage your examples: Copy and paste examples. This lets you go back to the list of all examples to copy an existing one and make edits to speed up new example creation. Make example names descriptive and consistent, for instance: you might start all happy path examples with the the words “Happy Path”. Add examples of child-playbook invocation. To best guide your agent, make sure to add examples that include multiple playbooks.

### Quiz - [How to set up your first Generative Playbook Quiz](https://www.cloudskillsboost.google/course_templates/1122/quizzes/495108)

## Testing

This module explores key best practices for testing, debugging and troubleshooting Generative Playbooks.

### Video - [Test cases](https://www.cloudskillsboost.google/course_templates/1122/video/495109)

- [YouTube: Test cases](https://www.youtube.com/watch?v=ToNzZNCdknE)

You have created a playbook or several of them! Now it’s time to test. When it comes to testing playbooks, we’ll be discussing three topics. First, we’ll talk about test cases. Next, we’ll talk about types of testing. Finally, we’ll talk about debugging and troubleshooting. Let us start by talking about how to add test cases. As you’re building your playbook, you’ll want to frequently test your playbook by simulating interactions. Once you have identified behavior that meets your goals, that is whether or not your playbook can currently deliver the desired results, you can save this as a test case. One way to save a test case is directly in the simulator. You can make edits to the turns in the simulator and save an edited version of the conversation as a test case or as an example. The square icon lets you save as a test case, the circle as an example. When viewing a playbook or playbook version, you can click the Test cases tab to see test case results and to execute a test case on demand. When you click to save your test case, you will see this window, which enables you to add actions. The test case verifies that the actions were performed as expected. If the expected behavior is to invoke a tool, playbook, or flow, make sure to indicate that when saving a test case. When you click the “Test cases” tab, you will see this window, in which your test cases will be visible as a list. Note that when you first save a test, you won’t see the conversation upon opening the test case. You must first run the test, after which, you’ll be able to see the results of the test run. Choose two test runs to compare test results and see differences in agent behavior by clicking on the compare button. You’ll see how test runs compare to each other in a traditional diff format. The test will show as Fail if an action such as a tool, playbook or flow invocation, doesn’t match the action in the original test case. If the test is passing and you compare results of two successful test runs, you’ll only see the differences highlighting session ID and timestamp. Now that we have learned some best practices about testing, let us watch a video to see how we can add quality assurance into our scheduling playbook. There are also a number of best practices. First, define standard hashtags like #bug or #eval or #(username) to define and identify golden test cases in a simulator that can then be quickly identified in the future. Second, Gen AI by design is not deterministic, so when evaluating answers a manual review of answers is required to assess the quality and pass/fail decisions. We should not be looking to do exact text matches. Third, unit tests should be created by developers and validated by the Quality Assurance, or QA, team. Fourth, the QA team should stress test the agent and should cover 100% of the functionality.

### Video - [Types of testing](https://www.cloudskillsboost.google/course_templates/1122/video/495110)

- [YouTube: Types of testing](https://www.youtube.com/watch?v=IkeQA1mSi3k)

There are several different types of testing that will be done. The first type of testing is unit testing, which helps catch bugs early in the process. This can be done in the simulator or via test cases. Unit tests are most often created by developers, but can also be developed by the QA team depending on the team structure. Unit tests help to identify and address bugs early in the development process, preventing them from causing problems in more complex interactions or integrated systems. Crucially, you should note that unit testing is at least initially done in conjunction with development. The next type of testing is integration testing. This is required to ensure that your playbook is correctly integrated. The goal here is to ensure that end-to-end the application will function as desired. It is also recommended to test using different channels. For example, on desktop you might test multiple browsers from different networks. example wifi residential internet, public internet, corporate internet, while on mobile you might test multiple devices such as Apple iOS, or Android, to verify mobile experience is as expected. Note that this can be part of integration testing or part of User acceptance testing, or UAT. Next, there is performance testing. This will help to identify any performance issues that arise, such as issues related to timing and scale. Sample metrics include: Response Time, which is the agent’s average response time. Here, you should identify any variations or delays. Concurrence is the ability to handle multiple concurrent users and maintain performance. Scalability is the ability to scale up to handle increased user loads and maintain performance. Another crucial form of testing is user acceptance testing. This, in simplest terms, is having testers play the role of real-life users, interacting with the agent in a natural conversation flow. This will help ensure that real-life users will derive value from what you have built. Examples of aspects you should test include context handling, bias and fairness, safety and security, user satisfaction, and overall experience. Another form of testing is black box testing. This involves testing by those unfamiliar with the underlying workings of the product, so people outside the team or real users are the best participants. A final form of testing is regression testing. This can be done within dialogflow or through a script. If you do wish to use a script, one option to do so is with SCRAPI, which has built in features supporting running test sets. You will likely need to perform regression test multiple times during the playbook development process as well as whenever playbooks are adjusted.

### Video - [Debugging and troubleshooting](https://www.cloudskillsboost.google/course_templates/1122/video/495111)

- [YouTube: Debugging and troubleshooting](https://www.youtube.com/watch?v=O92di5Z-oZ0)

Now let’s go over some ways to debug your Playbooks when things don’t quite work as expected. There are a variety of resources available to help you get to the bottom of issues you may experience during the bot building process with Generative Playbooks. It’s good to familiarize yourself on where all of these tools are in DFCX and GCP. Let’s go over each one now. The execution trace can be reached by clicking the little bug icon inside the simulator. The execution trace provides turn by turn information that allows you to understand what actions the LLM is performing and how it is responding. It’s a good place to look to find out whether the actions you defined were invoked, whether it be a Playbook action, Flow action, or Tool action. These types of actions are prefixed with pb^ (playbook), flow^, and tool^, respectively, see the second Screenshot. The original response can be reached by clicking on the little clipboard icon next to the bug icon inside the simulator. The original response is great for inspecting the raw input/output of each request. For example, if you are calling a Tool that retrieves a payload from a cloud function, the raw JSON that was returned from the cloud function can be seen in the original response as shown in the third screenshot. It’s important to note that in order to enable Conversation History, you must first go to your Agent Settings menu and click the “Enable interaction logging” checkbox and hit Save. Conversation History in DFCX is a useful tool for seeing a detailed summary of a past conversation with the agent. As you can see from the screenshot, the conversation history page shows a list of all past conversations by conversation ID, and clicking on any of them will take you to a detailed recreation of the conversation between the user and agent with Utterances, Actions, and Playbook columns. The Actions column is particularly useful for debugging to be able to see when Tools, Flows, and Playbooks were invoked and if so, what input and output parameters were used. The Playbook column helps you figure out whether the correct Playbook was used for a given utterance. It’s important to note that in order to enable Cloud Logging, you must first go to your Agent Settings menu and click the “Enable Cloud Logging” checkbox and hit Save. In the Logs Explorer, you can search by either the timeframe, for example: show me activity from the last 5 minutes, 1 hour, 24 hours, or by conversation ID in order to refine the scope of the logs being shown. If you are calling out to a Cloud Function within your agent, the Cloud Functions and Cloud Run logs are a great place to go to diagnose issues. It’s very helpful to add logging statements in your cloud function — the more logging you have in your code, the faster you will be able to discern where the problem is happening. For example if you have a Python cloud function using Flask, you can use app.logger to dump the contents of a variable into the logs (for example, you could use the app.logger.warning method) and you’ve initialized your app like this: app = flask. Flask(__name__) You can use app.logger to dump the contents of a variable into the logs, such as app.logger.warning("REQUEST: %s", request_json) The Developer Tools built into the Chrome browser can be very helpful for troubleshooting your agent. You can get to the Developer Tools Network tab by using the 3-dot menu => More tools => Developer tools => Network, or by simply using the keyboard shortcut Option + ⌘ + I on Mac, or Shift + CTRL + I on PC. One the developer tools panel opens up and you are on the Network tab, you can click on any of the requests in the list to be able to drill down into that request and see things like the headers, payload, and response that were sent. As you can see from the screenshot, you are able to see the contents of the payload that was returned from the cloud function query. Please note that Sherlog is available only to Google employees. If you are not a Google employee, you can reach out to a Google contact for more details. Sherlog can be found by simply typing “sherlog” in your browser location bar, or via the link in the Additional resources document. Once there, the first thing you need to do is click the “enable tracking” checkbox in the upper right corner. This will give you a 2 hour window where all dialogflow requests made by your currently logged in, authenticated account will be logged. The second important piece is that you need to enter “detectintent” into the search bar to narrow down on the DFCX requests you will be needing to diagnose. Now if you go to your agent’s test simulator and start interacting with your chatbot, you should see those detectintent requests appearing in the sherlog result list. Clicking on any of them will take you to an extremely verbose trace of that request. For more information on how to use sherlog, visit the Additional resources document.

### Quiz - [Testing Quiz](https://www.cloudskillsboost.google/course_templates/1122/quizzes/495112)

## Deployment and Ongoing Optimization

This module explores how to set up the right incident management plan and CI/CD process to ensure quality in the deployment of Generative Playbooks.


### Video - [Deployment and ongoing optimization](https://www.cloudskillsboost.google/course_templates/1122/video/495113)

- [YouTube: Deployment and ongoing optimization](https://www.youtube.com/watch?v=DTX52B95994)

In this section, we will talk about deployment and ongoing optimization. We will be discussing two topics: operations planning and production deployment. We’ll start by talking about operations planning. There are a number of considerations when it comes to operations planning. You should begin thinking about these prior to deployment. They include: Define the testing process and key stakeholders. Key stakeholders could be developers, your Quality Assurance team or the business unit overseeing the project Identify the types of testing. For instance, maybe you will focus mostly on regression testing and user acceptance testing. Define key roles and responsibilities. Who is responsible for identifying requirements. What sorts of development are needed and who will be responsible for each? And so on. Identify the ticketing system that will be used for tracking defects/features as well as how to set up and automate the ticketing process. Define the process to deploy new versions to production. How often will there be releases? How exactly will new versions be pushed? These considerations are key in ensuring smooth sailing in your implementation journey. Now, we are ready to talk about production deployment Once your plan is in place and your playbooks are built, you are finally ready for production. This is an exciting stage of the process but one where you will need to pay careful attention to both data and expectations. if you are concerned about quality or potential end user backlash, consider a dark launch or an internal launch and collect some data first before a full launch. You could also consider a canary launch depending on the client Once you have launched to production, you should begin reviewing traffic, billing, and end user conversations.

### Quiz - [Deployment & ongoing optimization Quiz](https://www.cloudskillsboost.google/course_templates/1122/quizzes/495114)

## Case Study: Generative Steering

This module provides an overview of Generative Steering, one of the main use cases for Generative Playbooks.

### Video - [Case Study: Generative Steering](https://www.cloudskillsboost.google/course_templates/1122/video/495115)

- [YouTube: Case Study: Generative Steering](https://www.youtube.com/watch?v=rSHra9vU4XY)

Let us look at a case study for using playbooks, namely generative steering. Steering is the initial step of any automated interaction, namely, collecting the reason that the user has decided to call or chat with this service. In the context of customer service, collecting the reason for the interaction is necessary for routing the user to the correct service interaction, whether that be self-service flows, like making a payment with an automated system, or talking with a live agent. Typically, this has been solved by natural language understanding, or NLU for short, trained with an intent taxonomy, however, it is now possible to serve this same function with a generative playbook. Let’s talk through some of the benefits: A generative steering playbook can be set up with a few clicks, potentially reducing a many month long process of finely tuning an NLU to a couple of days or even hours. Another benefit is out of the box handling of utterances and multi-intent scenarios. Additionally, a well crafted steering playbook should promote task fragmentation by breaking down large complex tasks into smaller bite-sized chunks. Let’s look at a real steering example. As always, the goal is a high-level description of what the playbook should accomplish. Here, the goal is primarily steering. Instructions provide the LLM guidance on how your generative playbook should accomplish steering, including what sort of greeting should be provided to the user, whether or not disambiguation should be performed, and where the user should be routed once their intent is determined. In this example: Step 1 instructs the LLM to NOT attempt to help the user. We don’t want to do that directly in the steering playbook. Step 2 instructs the playbook to always route to a specialist (i.e. child playbook) Step 3 instructs the LLM to route the user to the appropriate specialist (out of the 4 displayed in pink) based on the user’s intent. Note that the instructions also include things to avoid, such as prematurely attempting to help the user. Congratulations, you have completed this training on generative playbooks.

### Quiz - [Case study: Generative steering Quiz](https://www.cloudskillsboost.google/course_templates/1122/quizzes/495116)

### Lab - [Create a Conversational Agent Playbook that connects to an unstructured data store tool](https://www.cloudskillsboost.google/course_templates/1122/labs/495117)

Create a chatbot using Converstaional Agents Playbooks and connect it to an unstructured data store tool to ground your agent on your existing enterprise data.

- [ ] [Create a Conversational Agent Playbook that connects to an unstructured data store tool](../labs/Create-a-Conversational-Agent-Playbook-that-connects-to-an-unstructured-data-store-tool.md)

## Additional Resources

This module includes the list of additional resources that complement the course learning

### Document - [Additional Resources](https://www.cloudskillsboost.google/course_templates/1122/documents/495118)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

---
id: 552
name: 'Introduction to Vertex AI Studio'
datePublished: 2025-04-07
topics:
- Machine Learning
- Artificial Intelligence
- Data Science
type: Course
url: https://www.cloudskillsboost.google/course_templates/552
---

# [Introduction to Vertex AI Studio](https://www.cloudskillsboost.google/course_templates/552)

**Description:**

This course introduces Vertex AI Studio, a tool to interact with generative AI models, prototype business ideas, and launch them into production. Through an immersive use case, engaging lessons, and a hands-on lab, you'll explore the prompt-to-product lifecycle and learn how to leverage Vertex AI Studio for Gemini multimodal applications, prompt design, prompt engineering, and model tuning. The aim is to enable you to unlock the potential of gen AI in your projects with Vertex AI Studio.

**Objectives:**

- Explain the prompt-to-production lifecycle with Vertex AI Studio.
- Prototype a generative AI application with Gemini multimodal capabilities.
- Design effective prompts by applying configurations and best practices.
- Tune generative AI models using various methods.

## Introduction to Generative AI Studio

This course introduces Vertex AI Studio, a tool to interact with generative AI models, prototype business ideas, and launch them into production. Through an immersive use case, engaging lessons, and a hands-on lab, you'll explore the prompt-to-product lifecycle and learn how to leverage Vertex AI Studio for Gemini multimodal applications, prompt design, prompt engineering, and model tuning. The aim is to enable you to unlock the potential of gen AI in your projects with Vertex AI Studio.

### Video - [Use case](https://www.cloudskillsboost.google/course_templates/552/video/529863)

- [YouTube: Use case](https://www.youtube.com/watch?v=jRmGcaM1bNg)

SPEAKER: Have you ever wondered how to harness the potential of generative AI, or gen AI, to revolutionize your business? What if there are tools to help interact with AI models and turn your gen AI ideas into production? Bea, a business analyst of Cymbal Insurance; Ann, the AI developer; and Ian, the ML engineer, are exploring these possibilities. Bea, the business analyst, oversees a national insurance company with a strong presence in the Western states. She envisions gen AI streamlining the company's insurance risk analysis and automating customized report generation. She believes gen AI could significantly reduce her workload, liberating her time for more strategic initiatives. But can she quickly test and prototype her idea without any technical background? Ian and Ann also believe gen AI would benefit the business and are eager to assist. However, they are also looking for gen AI to solve challenges they face. As an AI developer, Ann seeks a user-friendly development platform that facilitates prompt engineering from drafting, evaluating, and refining to manage prompts. Meanwhile, as an ML engineer, Ian requires a robust, secure, and scalable tool that builds a pipeline to deploy prompt to production and fine tune gen AI models for optimal results. They've all heard how Vertex AI Studio on Google Cloud is powered by Google's advanced gen AI models, like Gemini, and has an enterprise-ready AI infrastructure. Could Vertex AI Studio be the key to transforming their business? So what is Vertex AI Studio? It's a lot of things. Simply put, Vertex AI Studio is your gateway to generative AI. It's a development environment for developers and nondevelopers to interact with gen AI models, prototype their ideas, and launch them into production. Envision Vertex AI Studio as an innovative workshop where gen AI models are your raw materials. You are the craftsperson, and the Vertex AI Studio toolkit is your arsenal for shaping and refining these models into powerful AI solutions. Intrigued? Join Ann, Bea, and Ian to learn how to use this magical tool from prompt to production. In this lesson, you will start with the use case to see a practical application, then move to idea to app, where you discover how to quickly turn a prompt into an application with no code. Third is prompt engineering, where you design, evaluate, refine, and manage prompts. The fourth lesson is about deployment and model tuning, where you build the application and continuously improve performance. And we will end with a recap and summary of the course. Ready to embark on a journey from questions, or prompts, to solutions, or production? Let's get started with Vertex AI Studio.

### Video - [Idea to app](https://www.cloudskillsboost.google/course_templates/552/video/529864)

- [YouTube: Idea to app](https://www.youtube.com/watch?v=sVEeYSBOv-c)

SPEAKER: In the last lesson, you learned that Vertex AI Studio is the gateway to Google's advanced generative AI models like Gemini. It aims to transform your questions into solutions. But how? Well, let's take Bea, the business analyst of Cymbal Insurance, as an example. Bea has no technical background but understands that the prompt-to-production process may involve multiple steps, such as designing, evaluating, and refining prompts which are part of the prompt engineering stage, and building and testing apps, and monitoring and optimizing gen AI models, which makes up the integration and deployment stage. Can she quickly turn her idea into an application without writing a single line of code? Or consider Ann, a seasoned developer. Even with her coding expertise, can she rapidly prototype a solution with minimal effort before refining it? Let's find the answer in this lesson, idea to app. Everything starts with a prompt. When you first use Vertex AI Studio, you tell the AI what you want to do. You can ask a question or give an instruction using natural language. This is called a prompt. Simply put, a prompt is a natural language request to an AI model. The request can be a question, a task, or anything in between. Once the model receives the prompt, it generates text, code, images, videos, music, and more. However, just like how we communicate with one another, the way you communicate with AI makes a difference in what you get. You need to be good at asking questions to get the results you want. This process of creating prompts to get the response you want is called prompt design. And the iterative process of repeatedly drafting and refining prompts and assessing the model's responses is called prompt engineering. Gemini models often perform well without prompt engineering, especially for simple tasks. However, for complex tasks, effective prompt engineering is still important. So what makes a good prompt? To answer this question, let's first take a closer look at the anatomy of a prompt. Generally, a prompt includes one or more of the following key components-- task, context, and examples. Let's explore each one in more depth. Task-- this is the core of your prompt. It's what you want the model to do. For example, conduct a risk analysis for an insurance company. Depending on the complexity of the task, you may only need to provide the task itself. This is called zero-shot prompting. Now context, often called system instructions-- think of context as setting the stage for the AI to perform a task. It provides background information, helping the AI model understand the request and generate a more relevant and accurate response. For example, in addition to simply prompting, "conduct a risk analysis report," you can add role information, such as, "you are a business analyst overseeing risk assessment for an insurance company. You pull information from multiple resources daily. Rate the risk level, and generate a report." Now to examples-- sometimes context alone isn't enough. You may need to show the AI how to respond. You can provide examples of answers, step-by-step instructions, or even specify the output format. This is known as few-shot prompting. For instance, to generate a comprehensive risk analysis report, you can guide the AI with detailed steps and a report template. When crafting effective prompts, it's important to focus on two key aspects, content and structure. For content, ensure your prompt includes all relevant information for the task, such as clear instructions, context, and examples. And for structure, organize the information in a way that the model can easily understand, such as the order, labels, and delimiters. Let's look at an example of a well-structured prompt. First, describe the context. You are an IT help desk technician at a university. Your daily job is to help faculty and students solve their technology issues. Then specify the task by providing a step-by-step instruction, such as, "to complete the task, you will need to follow these steps-- step 1, step 2, and step 3." Lastly, provide some common question-and-answer examples, such as how to reset the password or how to create a new account. Now that you understand the ingredients of a good prompt, here are some tips for crafting effective ones. Be direct and specific. State your request up front, give context, and use keywords. Instead of, "Generate a risk analysis report," try, "Generate a risk analysis report for real estate from 2024 to 2025, considering market trends and regulatory changes." Apply structure. Use delimiters like bullet points, dashes, or headings to separate sections like tasks, context, and examples. Try to break down a complex task to actionable, small steps. Iterate and refine. Start simple, and refine based on the AI's output. Level up. Explore advanced techniques like few-shot prompting, chain-of-thought prompting, or Retrieval Augmented Generation, or RAG, which will be discussed later in this course. And remember the basics. Avoid jargon, set clear goals, create scenarios, and encourage analysis. As Bea and Ann reflect on their discovery journey with Vertex AI Studio, they want to create a prompt that utilizes key components and best practices. Which of the following prompts is the best option for them to choose? A-- provide a risk assessment report. B-- conduct a market risk analysis for a health insurance company in the United States. C-- you are an analyst at a regional health insurance provider in the southeastern United States. Your task is to generate a market risk analysis by following the steps A, B, and C. Please find the report template that includes 1, 2, and 3. C is the correct answer. Take a moment to reflect and think about why. What makes C an effective prompt? With the information they have just learned, Bea and Ann are excited to build a prototype of a web-based application directly from a prompt with Vertex AI Studio. They begin at the starting point for inputting prompts and interacting with gen AI models by answering the question, what do you want to do today? Bea is a little worried that her first prompt may not be effective. But Vertex AI Studio provides AI-assistant prompting to help via "Help me write." It polishes the prompt in terms of both content, by clarifying and adding necessary information, and format, by dividing them into components. It also helps divide complex tasks. Additionally, the Prompt gallery supports Bea in getting started by providing many examples she can browse. She can search by keyword; filter them by modality, like text, image, and video; by task, like code, summarize, and classify; and by features, like prompting with YouTube videos and live streaming. While writing the prompt, Bea was amazed to discover that Vertex AI Studio supports multimodal prompts and outputs. She could embed multimedia elements in the prompt, such as documentation, like docs or PDFs, images, videos, and even YouTube videos. The output responses can also be in these multimodal formats. After using the AI assistant and the abundant examples from the Prompt gallery, Bea feels much more confident using Vertex AI Studio. Here's her first prompt. "Conduct a risk assessment in housing in southern Los Angeles. You are a business analyst for Cymbal Insurance. Analyze the articles from the internet, and extract the following information. Risk assessment-- identify potential risks and rate severity from 1 to 5. Categorization-- classify risks by geography, type, and sentiment. Impact analysis-- evaluate potential consequences of each risk. And additional insights-- provide relevant observations and recommendations." With a few rounds of playing with prompt experimentation, Bea and Ann are ready to see their first prototype. They click the Build With Code button and Create Generative App. And voila, Vertex AI Studio automatically generates a web-based application. Bea and Ann are amazed at how quickly they were able to prototype an idea and discover the capabilities of gen AI. They can't wait to see more options provided by Vertex AI Studio and dive deeper to design, evaluate, and refine prompts. You'll learn more about this in the next lesson.

### Video - [Prompt engineering](https://www.cloudskillsboost.google/course_templates/552/video/529865)

- [YouTube: Prompt engineering](https://www.youtube.com/watch?v=ezJhqojb9Zk)

SPEAKER: In the previous lesson, Bea and Ann transformed their prompt into a web application. While Bea was thrilled with the quick turnaround, Ann was keen to delve deeper into prompt engineering. This marks the first half of the prompt-to-production lifecycle, from prompt design to evaluation and refinement. Remember from the previous lesson that a good prompt considers content, such as instructions, context, and examples. A good prompt also has structure that organizes the information through order, labels, and delimiters. So how do you engineer a good prompt? Let's learn more about how to do this. It begins with prompt design and the toolkit Vertex AI Studio provides to help you craft effective prompts. This is your primary playground for crafting prompts, with the left side for writing and the right side for configuration. On the left side, start by setting the scene in the system instructions section, and then pose your tasks or questions in the prompt section. Need some help? Use Gemini, the built-in AI assistance, to help you create your prompt. You can even make your data more dynamic. Include multimodal data like docs, images, and videos from multiple sources, such as Google Cloud Storage, Google Drive, your local computer, or URL. This is where you upload your data. You can even embed YouTube video links directly into the prompt. You can guide the AI's output by adding examples in a flexible format, by using the default input and output features, or go with whatever you like. Maybe you prefer question and answer. And for enterprise users, the ability to import an example file of their company's data can be very useful. As a developer, Ann wonders if there's a way to code a prompt. Perhaps using a coding structure like a function or a method with variables to streamline repetitive actions could work. Vertex AI Studio's new prompt template feature is the answer to Ann's developer needs. It uses replaceable variables, allowing you to reuse a prompt simply by changing values. Think of a prompt template as a function in coding but using natural language instead. The good thing is you only need to tell gen AI what to do rather than worrying about the specific programming language for execution. Look at this example. By clicking Add Variables, you can assign values to the variables, just like passing arguments to a function in coding. For example, you can ask AI to research Los Angeles tenant vacancy rate and generate a report about real estate market analysis. You can also instruct AI to add variables to study-- annual crime rate-- and conduct an insurance risk assessment by using the same prompt template but passing different values to the variables. When your draft is complete, navigate to the right side of the user interface to experiment with various model parameters, beginning with model selection. Vertex AI Studio provides you with access to both Google models and third-party models. Let's look at these in more depth. While Vertex AI Studio allows you to access third-party models such as Anthropic Claude, Meta Llama, and OpenAI GPT models, one of the significant advantages of utilizing Vertex AI Studio is access to the latest and most advanced Google generative AI models. Now, how to choose the most appropriate Google model depends on your task. For general purposes and multimodal data use cases, the Gemini family, such as Gemini Flash or Gemini Pro, is your best option. For specific purposes, you may want to consider specialty models. For example, use Imagen for image generation, Codey for code completion, Veo for video processing, or Embeddings models for semantic search and data representation. Each model is tuned to perform well on specific tasks. Scan the QR code for Google documentation that contains the latest updates and detailed comparisons. You can also access the Google documentation through the reading list. After learning all of this, Ann wants to leverage AI to assess risk more effectively. She has access to a variety of data, including real estate images, property inspection reports, and even video walkthroughs of properties. Which AI model would be best suited to help Ann analyze this multimodal data-- Codey, Embeddings, Imagen, or Gemini? Gemini is the winner for this use case for its multimodal feature. After model selection, the next step is to specify parameters, like temperature, top P, and top K. These parameters control the randomness of the model's responses by adjusting how output tokens are selected. But how do parameters actually work? Let's look at an example. The garden was full of beautiful-- when prompted with this incomplete sentence, language models predict the probability of potential words that could complete the sentence, such as just flowers, trees, herbs, and bugs. The strategy used to select the next word impacts the outcome. Always choosing the most probable word may result in repetitive texts and ignore other possibilities, while random sampling can yield unlikely responses such as bug. By adjusting model parameters to control the degree of randomness, you can balance between predictability and variety, which enables you to find the ideal strategy for specific task. Let's talk about the parameters mentioned earlier. First, temperature-- this is a number used to control the degree of randomness in generated output. A low temperature setting narrows the range of possible output to words with high probability and that are more typical. This setting is generally better for tasks like question answering and summarization where a more typical answer with less variability is expected. A high temperature setting expands the range of possible output to include words with lower probability and that are more unusual. This setting is useful for generating more creative or unexpected content. Another parameter is top K. Top K allows the model to randomly select a word from the top K most probable words where K equals a number. For example, top two means the model will randomly select either of the two most probable words, such as flowers or trees. This approach gives high-scoring words an equal chance to be selected. However, if the probability distribution of the words is highly skewed with one word that is very likely and the rest is very unlikely, the approach can sometimes result in strange responses. For example, suppose the top two word predictions are flowers and books, with skewed probabilities of 80% and 10%, respectively. Using these predictions might result in a sentence that most likely doesn't make sense, such as "The garden is full of beautiful books." The challenge of selecting the optimal top K value has led to another popular approach that dynamically sets the size of the word shortlist. Top P allows the model to return a random word from the smallest subset with the sum of likelihoods that exceeds or equals P. For example, a P of 0.75 means sampling from a set of words that have a cumulative probability greater than 0.75. In this case, it would include three words-- flowers, trees, and herbs. This way, the size of the word set can dynamically increase and decrease according to the probability distribution of the next word on the list. And that is an overview of the model parameters, model type, temperature, top K, and top P. Note that you are not required to adjust them constantly, especially top K and top P. After crafting the prompt and specifying the parameters, how can you ensure that you selected the optimal model and parameters for the task? This is where the next step, evaluation and refinement, comes in. Vertex AI Studio allows you to compare prompts side by side to see which one produces the best results. This helps you see how different prompts, models, and/or parameter settings change the model output. You can even generate your own evaluation metrics by adding ground truth from your field knowledge. Ground truth is your preferred answer to the prompt, and all other model responses are evaluated against the ground truth answer. Ready to take your prompt to the next level? Optimize it in a Colab Enterprise notebook by adding labeled examples to refine the results. You can perform these tasks-- comparison, optimization, and evaluation-- under the Prompt Management menu. Now, imagine Prompt Management as storage to save and share prompts for future use and collaboration, plus the tools to manage the prompts, such as version control and security. Aside from general purpose prompts, you can apply these prompt engineering techniques and tools on Vertex AI Studio to specific tasks, such as generating real-time streaming, creating multimedia content, translating content, and converting speech and text. Ann has learned so much about what she can do with prompts and is eager to leverage these tools and create custom prompts using her own data to solve business problems. She's excited to learn how to deploy the prompt to code, which will be revealed in the next lesson.

### Video - [Deployment and model tuning](https://www.cloudskillsboost.google/course_templates/552/video/529866)

- [YouTube: Deployment and model tuning](https://www.youtube.com/watch?v=f7J3gMUliik)

SPEAKER: In the previous lesson, Ann experimented with the Vertex AI Studio toolkit to design, evaluate, and manage prompts. Now she's ready to deploy the prompt to an application. She teams up with Ian, the ML engineer who is responsible for building a pipeline and monitoring performance. We are now at the second half of the prompt-to-production lifecycle, from built and test to monitor and optimize. Recall that at the beginning of their journey, Bea and Ann quickly tested their ideas by simply clicking the Create Generative App button and built their own app. However, what if they wanted to customize the application or integrate its feature into other applications? Vertex AI Studio provides this flexibility by automatically generating the code for you. Besides the User Interface, or UI, which requires no code to explore and test prompts, Vertex AI Studio also provides two other approaches to access AI models. Simply click Build with Code, and you'll find the code describing the prompt and its parameters. The first approach is through using predefined SDKs in different languages. You can open a notebook with the SDKs code of your preferred programming languages like Python. The other approach is through using APIs together with command line tools like cURL or client URL. The automated code generation simplifies application development. Additionally, the integrated development environment with Cloud Run and Cloud Shell streamlines production and removes the need to worry about the underlying cloud architecture that supports application deployment. Now, after you build the application, it's important to continually monitor and optimize its performance. But how can you do this? And how can you ensure the gen AI models produce accurate results with updated information? One way is through grounding and RAG, or Retrieval-Augmented Generation. Remember that gen AI models are pretrained, so their answers depend on the training data, which can be outdated and inaccurate. But grounding links AI models to reliable external data sources, ensuring that their responses are checked against the most current information. And RAG is one way to implement grounding. Simply put, grounding is the concept, while RAG is the implementation. Think of grounding as a fact-checker that prevents outdated and wrong information. But what if you wanted to improve the article's generation process itself, like data collection and writing methods? That's where model tuning comes in. Model tuning is another way to enhance gen AI accuracy by providing the model with the training data set a specific downstream task examples. While fine tuning refines the model's internal knowledge and abilities, grounding augments its knowledge with external, real-time, and reliable information. So when constructing your prompt, you can now opt to ground the results either through Google real-time search for the most current information or your own data to instruct the AI with field-specific knowledge. To further your knowledge of these advanced technologies, we recommend our courses, Create embeddings, vector search, and RAG with BigQuery and Vector search and embeddings with Vertex AI. These courses introduce how to implement RAG pipelines with Google's two widely used platforms, BigQuery and Vertex AI, respectively. Scan the QR code on the screen, or you can find the link in your reading list. OK, let's look at how to tune and customize a gen AI model with Vertex AI Studio. You have different options to customize and tune a generative AI model, ranging from less technical methods, like prompt design, which require fewer computational resources, to more technical methods that require more computational resources, like full fine tuning. You are already familiar with prompt design, which lets you tune a gen AI model with examples and instructions in natural language. Remember that prompt design does not alter the parameters of the AI model. Instead, it improves the model's ability to respond appropriately by guiding it how to react. One benefit of prompt design is that it enables rapid experimentation and customization of gen AI results. Another benefit is that it doesn't require specialized machine learning knowledge or coding skills, making it accessible to a wider range of users. However, for more complex tasks that require tailored results, consider customizing an AI model with either parameter-efficient tuning or full fine tuning. Parameter-efficient tuning, also called adapter tuning, enables efficient adaptation of large models to your specific tasks or domain. This method also updates a relatively small subset of the model's parameters during the tuning process. Full fine tuning is ideal for highly complex tasks, as it can achieve higher quality results. However, this method requires more computational resources for both tuning and serving, as it updates all the model's parameters. Given these options and even some variations between them, Vertex AI currently supports supervised fine tuning to customize foundational models. Supervised fine tuning improves model performance by teaching it a new skill. It uses data containing hundreds of labeled examples to teach the model to mimic a desired behavior or task. Each labeled example demonstrates the desired model output. The output of the tuning job is a new model that combines newly learned parameters with the original model. Supervised fine tuning is a good option for well-defined tasks with available labeled data. For example, it can improve model performance for classification, summarization, extraction, and chat tasks. Now, let's move to Vertex AI Studio and see how to start a tuning job. From the Vertex AI Studio menu, select Tuning, Create a Tuned Model. Specify the model details and the tuning data set. Note that the UI may change as the product progresses. The training data should be structured as a supervised training data set in a JSONL file. Each record or row contains a pair of text data-- the input text, which is the prompt, and the output text, which is the expected response from the model. For example, if the prompts are, "This commercial building is architecturally interesting and has a great interior layout." And, "The room was terrible. It needs major rework." The expected sentiment labels would be positive and negative, respectively. This structure allows the model to learn and adapt to your desired behavior. You can then start the tuning job and monitor the status in the Google Cloud console. When the tuning job completes, you'll see the tuned model in the Vertex AI model Registry. And you can deploy it to an endpoint for serving or further test it in Vertex AI Studio. That was a lot of information. Ann and Ian can't wait to explore and start experimenting with Vertex AI Studio themselves. It's time for you to have some hands-on practice. The lab will give you the opportunity to analyze images with Gemini multimodal, explore additional multimodal capabilities, and design prompts with the Vertex AI Studio toolkit. By the end of the lab, you'll be well equipped to use Gemini multimodal with Vertex AI Studio.

### Video - [Summary](https://www.cloudskillsboost.google/course_templates/552/video/529867)

- [YouTube: Summary](https://www.youtube.com/watch?v=6aJ1LZaUCwQ)

SPEAKER: We hope you enjoyed the journey exploring Vertex AI Studio, an innovative workshop for interacting with generative AI models, designing effective prompts, and quickly turning your ideas into fully functional applications. The key features and benefits of Vertex AI Studio include, Google's most advanced AI models. Stay ahead of the curve with access to continually updated models. Enterprise-grade infrastructure and security. Vertex AI Studio integrates with Google Cloud's enterprise-grade infrastructure and security, ensuring your data's protection and your AI model's reliability. Prototype to code, Vertex AI Studio helps you quickly prototype your ideas and move seamlessly from concept to production. Multi-modality support, prompt across a variety of modalities, including text, images, and videos, for optimal model outputs and customization, and tuning. Fine-tune GenAI models with your own data, and create custom solutions tailored to your specific needs and use cases. Let's do a quick recap of the course. You first joined Bea, the business user, and Anne, the AI developer, in creating a prototype that quickly turned an idea into an application. You learned what makes a prompt good, by understanding its components, aspects, and best practices. Next, you delved into prompt engineering, from prompt design to evaluation and refinement. Here, you learned how to engineer a good prompt with the Vertex AI Studio toolkits, such as the AI-assisted prompt writing tool, prompt templates, GenAI model selection, model parameter configuration, prompt comparison, and optimization. Finally, you joined Anne and Ian and progress to application deployment. This included building, testing, and tailoring the application by tuning models and utilizing grounding features. Learners, are you ready to become the hero of your workspace by trying Vertex AI Studio, asking good questions to GenAI, and turning those questions into solutions? Hope you enjoyed this learning journey, and don't forget to check out our other courses.

### Lab - [Get Started with Vertex AI Studio](https://www.cloudskillsboost.google/course_templates/552/labs/529868)

In this lab, you will learn how to use Vertex AI Studio to create prompts and conversations with Gemini's multimodal capabilities.

- [ ] [Get Started with Vertex AI Studio](../labs/Get-Started-with-Vertex-AI-Studio.md)

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/552/quizzes/529869)

#### Quiz 1.

> [!important]
> **Which of the following is the best way to generate more creative or unexpected content by adjusting the model parameters in Vertex AI Studio?**
>
> - [ ] Set the model type to a multimodal model.
> - [ ] Set the temperature to a low value.
> - [ ] Set the K value in top K to 1.
> - [ ] Set the temperature to a high value.

#### Quiz 2.

> [!important]
> **If you want to tune a generative AI model using your own dataset containing pairs of inputs and desired outputs (e.g., symptoms 1, 2, and 3 result in diagnosis A), which tuning method is most appropriate?**
>
> - [ ] Prompt engineering
> - [ ] Unsupervised fine tuning
> - [ ] Zero-shot prompt
> - [ ] Supervised fine tuning

#### Quiz 3.

> [!important]
> **What is NOT a capability of Vertex AI Studio?**
>
> - [ ] Train a large language model from scratch.
> - [ ] Deploy prompts to applications.
> - [ ] Manage prompts through drafting, evaluation, refinement, saving, and sharing.
> - [ ] Design an effective prompt.

#### Quiz 4.

> [!important]
> **Assume your task requires analyzing a variety of data modalities, including real estate images, property inspection reports, and even video walkthroughs of properties. Which AI model provided by Google would be best suited to help you analyze multimodal data?**
>
> - [ ] Imagen
> - [ ] Embeddings
> - [ ] Codey
> - [ ] Gemini

#### Quiz 5.

> [!important]
> **Assume you are a business analyst for an insurance company. Which of the following is the most effective prompt to get a gen AI to produce a risk assessment report?**
>
> - [ ] You are an analyst at a regional health insurance provider in the Southeastern United States. Your task is to generate a market risk analysis by following steps a, b, and c. Please find the report template that includes 1, 2, and 3.
> - [ ] Provide a risk assessment report.
> - [ ] Generate a report for an insurance company.
> - [ ] Conduct a market risk analysis for an insurance company in the United States.

### Document - [Reading List](https://www.cloudskillsboost.google/course_templates/552/documents/529870)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

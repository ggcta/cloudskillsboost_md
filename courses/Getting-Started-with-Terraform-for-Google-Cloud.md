---
id: 443
name: 'Getting Started with Terraform for Google Cloud'
datePublished: 2024-09-19
topics:
- Automation
- Terraform
- DevOps
type: Course
url: https://www.cloudskillsboost.google/course_templates/443
---

# [Getting Started with Terraform for Google Cloud](https://www.cloudskillsboost.google/course_templates/443)

**Description:**

This course provides an introduction to using Terraform for Google Cloud. It enables learners to describe how Terraform can be used to implement infrastructure as code and to apply some of its key features and functionalities to create and manage Google Cloud infrastructure.
Learners will get hands-on practice building and managing Google Cloud resources using Terraform.

**Objectives:**

- Define the business need for infrastructure as code and the benefits of using it in your environment.
- Explain the features and functionalities of Terraform.
- Use Terraform resources, variables, and output values to create Google Cloud infrastructure resources.
- Use Terraform modules to build reusable configurations.
- Explain Terraform state and its importance.

## Course Introduction

This section welcomes learners to the Google Cloud Fundamentals: Core Infrastructure course, and provides an overview of the course structure and goals.

### Video - [Course Introduction](https://www.cloudskillsboost.google/course_templates/443/video/508936)

- [YouTube: Course Introduction](https://www.youtube.com/watch?v=bJR8r7aHxHA)

– (intro splash music) Rekha: So what is Terraform, and how can it be used to help you manage your infrastructure? Eoin: What is infrastructure as code and how can it benefit the business? If you're asking yourself any of these questions, you're in the right place. Rekha: Terraform is an open source, Infrastructure as Code tool by HashiCorp, for provisioning resources – including Google Cloud resources – with declarative configuration files. Eoin: These files can be shared amongst team members, treated as code, edited, reviewed, and even versioned. This enables you to build and deploy complex cloud infrastructure by running a few simple commands. Eoin: In the Getting Started with Terraform for Google Cloud course, you will learn how to use Terraform – an infrastructure as Code tool – to create and manage your Google Cloud infrastructure. Rekha: Hello! My name is Rekha Eoin: And I’m Eoin, we're both Course Developers at Google Cloud and we want to welcome you to the “Getting Started with Terraform for Google Cloud course. Rekha: The purpose of this course is to explore the Terraform workflow in detail. Eoin: You will become familiar enough with the Terraform workflow that you will know the purpose of each phase and how it is implemented. Rekha: This content is designed for DevOps Engineers, Cloud Architects, Cloud Engineers and anyone who is interested in using Terraform to create and manage their Google Cloud Infrastructure. This is a fundamental course, that covers the basics of Terraform for Google Cloud. Eoin: The prerequisite for this course is Google Cloud Fundamentals: Core Infrastructure. You’ll also need to have basic programming skills, familiarity with using CLI and general familiarity with Google Cloud. Eoin: Through a series of videos and hands-on labs, you will explore the business need for Terraform and Infrastructure as Code and the benefits of using it in your environment. Rekha: You’ll learn about Terraform features and functionalities. Eoin: You’ll also be equipped to use Terraform resource blocks, variables, and output values to create Google Cloud infrastructure resources. Rekha: You will also learn to use modules to build reusable configuration. Eoin: In addition, you’ll be equipped to explain the Terraform state file and its importance. Eoin: Let’s get started!

## Introduction to Terraform for Google Cloud

This is an introductory module that covers the business need for Terraform. We'll start with the basics by providing an overview of infrastructure as code (IaC), which is the basic concept for Terraform. We will explore how Terraform can be used as an IaC tool on Google Cloud and also cover its features and benefits. We'll then look at how Terraform transforms lines of code into real infrastructure on Google Cloud.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/443/video/508937)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=jyAt2IL58Gk)

Hello and welcome to the “Introduction to Terraform for Google Cloud” module. Cloud computing has played a major role in how companies build, scale, and maintain technology products. It has transformed how products and services are provisioned; the ability to provision cloud infrastructure in just a few clicks has proven to be simple and highly productive. So, why would you want to use lines of code to provision your infrastructure? What is Infrastructure as Code, and what are the benefits of using it? What is the difference between Infrastructure as Code and Terraform, and how do they relate? In this module, you’ll find the answers to these questions. Starting with the basics, this module provides an overview of infrastructure as code – or IaC – which is the basic concept for Terraform. You’ll learn about the features and benefits of using Terraform, and also explore how it can be used as an IaC tool for Google Cloud. You’ll then investigate how Terraform transforms lines of code into infrastructure. This module concludes with a short quiz and recap of topics covered. Let’s jump in! This is an introductory module that covers the business need for Terraform. We’ll start with the basics by providing an overview of infrastructure as code (IaC), which is the basic concept for Terraform. We'll cover the features and benefits of using Terraform, and also explore how Terraform can be used as an IaC tool on Google Cloud. We’ll then look at how Terraform transforms lines of code into real infrastructure on Google Cloud. This module concludes with a short quiz and recap of topics covered. Let’s jump in!

### Video - [Infrastructure as Code](https://www.cloudskillsboost.google/course_templates/443/video/508938)

- [YouTube: Infrastructure as Code](https://www.youtube.com/watch?v=Xmhl0lwE9Fo)

Let’s start with the fundamental concept required to understand Terraform: Infrastructure as code, or IaC. With IaC you can write code using a configuration language to define, provision, and manage your infrastructure. Gone are the days where a system administrator had to manually configure hundreds of servers, networks, and firewall rules by interacting with a user interface. With IaC, you only declare the desired end state of the infrastructure –IaC handles management and provisioning. The rapid increase of business demand has manifested a cultural shift known as DevOps. DevOps emphasizes collaboration and communication between developer and operations teams, and automates software delivery and infrastructure changes. Let’s explore some challenges and the role IaC plays in addressing them. With competition growing among industries to benefit from the cloud, DevOps teams are struggling to manage growing environments and rapidly expanding businesses. This struggle involves four major challenges. First, high business demand requires rapid scaling of IT infrastructure across industries. Due to rapid scaling of IT infrastructure, Ops teams must overcome new operational and technical bottlenecks, such as managing infrastructure consistently at scale. When infrastructure is changed, DevOps teams often struggle to collaborate and audit changes. Closing the communication gap is imperative for successful deployments. Increased quantity and scale have also led to human, manual error that can potentially have significant effects. Now, let’s discuss the benefits of IaC. First, its declarative. Instead of having to specify the exact sequence of steps to make a particular change, you can focus on the desired state of the infrastructure. For example, you might use a production label to specify three subnets across two regions. Terraform will update the live state to match the desired state by adding a label to the existing subnet, and creating two new subnets in additional regions. Through declarative abstractions, IaC tools manage the implementation details so you can focus on changes made to your desired state. This declarative approach allows anyone to read the state of the infrastructure, as opposed to asking a system admin. Another benefit of IaC is that it’s managed in the same way as application source code. Typically, if you make changes directly in the Google Cloud Console that cause an outage, you’d have to manually identify the breaking changes - an error-prone process. With IaC, you can see a full history of versions and infrastructure changes. If something breaks, you can roll back to a previous state. The entire history of your infrastructure is captured in the commit log. Version control also enables developers to collaborate on changes. For example, perhaps a developer needs a port opened on a firewall to support their application. They can simply submit a pull request to open the port instead of waiting in a queue for an administrator to manually open it. Changes can be discussed, reviewed, and audited without creating information silos, which can lead to more collaborative ownership as infrastructure evolves. IaC also features an auditable history of your infrastructure. Typically, infrastructure doesn’t contain comments. You might see changes in audit logs, but it’s often difficult to understand why those changes were made. With IaC, you can include explanations. For example, you might comment that a specific subnet allocation is required for a certain application. This auditable history gives a clear view into how infrastructure has evolved over time. When proposing new changes, you can also preview them and inspect exactly how they will affect live infrastructure before they’re applied. These previews let you detect drift and ensure that your infrastructure remains robust. Portability is another benefit of IaC. You can build reusable modules that encapsulate conventions and let you consistently build infrastructure from a shared template. Instead of having to rebuild infrastructure manually, you can have many instances of the same template deployed for different applications or regions. Google Cloud has developed reusable modules that can be found in the Cloud Foundation Toolkit. Using the library of reusable, documented, tested infrastructure code makes it easier to scale and evolve your infrastructure. Provisioning and configuring are two terms that are sometimes misinterpreted. Fundamentally, IaC is used for provisioning and managing cloud resources, and configuration management is used for VM OS-level configuration. For example, infrastructure as code creates and provisions a VM instance, and configuration management configures the internals of the VMs. Configuration management is a broad topic that covers more than we can discuss in this section. To simplify, activities like configuring a VM for application dependencies are considered configuration management. Configuration often consists of manual tasks such as starting services, installing dependencies, installing applications, and running updates. To elaborate, the term Infrastructure as code refers to frameworks that manipulate Google Cloud APIs to deploy the infrastructure required to run application code. In contrast, configuration management refers to package configurations and software maintenance. Let’s look at another common example to differentiate between provisioning and configuration. IaC automates tasks involved in launching a GKE cluster into Google Cloud, and configuration management automates tasks involved in deploying containers into the GKE cluster. An important principle to understand about infrastructure as code is that it’s declarative. Most programming languages use an imperative model, where you specify the exact action you want to take, such as create five servers. This model is challenging for infrastructure because if you run the script again, it might create five new servers even if some exist. Imperative workflows make it difficult to determine the difference between live infrastructure and your desired state, leading to repeated resource creation. With IaC, you declare the desired state of your infrastructure and let the tool determine the details. For example, you might declare that you should have five servers. The first time Terraform runs, it might create all five servers. Then let’s say someone accidentally deletes a server. The next time Terraform runs, it would recognize that four servers exist and restore only the missing server. We encourage adopting declarative infrastructure tools like Terraform. Focus on how the infrastructure should be, and let automation handle the details of updating the infrastructure to match your desired state. Declarative management focuses on the WHAT rather than the HOW.

### Video - [Terraform Overview](https://www.cloudskillsboost.google/course_templates/443/video/508939)

- [YouTube: Terraform Overview](https://www.youtube.com/watch?v=JKKdAYue1Zc)

You now know the basics of infrastructure as code, but what exactly is Terraform? Terraform is an infrastructure as code tool created by HashiCorp, and is currently licensed under the HashiCorp Business Source License v1.1. It lets you provision Google Cloud resources with declarative configuration files. Examples of resources include virtual machines, containers, storage, and networks. Terraform allows infrastructure to be expressed as code in a simple, human-readable language called HashiCorp Configuration Language, or HCL. Terraform reads configuration files and provides an execution plan of changes, which can be reviewed, applied, and provisioned. At a high level, Terraform lets operators author files containing resource definitions on the Google Cloud provider, and automates the creation of those resources. Terraform features include: Multi-cloud and multi-API support. Terraform supports all major cloud providers, in addition to Google Cloud and API-exposed services such as GitHub and Kubernetes. Three different editions that range from self-hosted to fully managed, including enterprise support. A large community, including a registry with publicly available modules for Google Cloud deployments. And infrastructure provisioning, rather than configuration. You can use Terraform for Google Cloud to provision resources, meaning you can use resource blocks to define infrastructure elements such as VMs, networks, and firewalls. You can create explicit dependencies between resources, so that a given resource can only be created after the creation of another resource. You can standardize how a given resource is created by creating reusable modules. And you can limit the values provided for a given resource argument using validation rules. Next let’s view the standard IaC configuration workflow. Before jumping into the Terraform workflow, you must determine what resources should be created for a project. For example, for a common 2-tier architecture, you need a pool of web servers that use a database tier. Therefore during the “scope” phase, you scope the requirements for the Google Cloud resources and plan how they should be connected. In this case scope the type of compute and database instances needed. The Terraform workflow begins with the author phase, where you author the configuration code for the infrastructure you want to create. Referring to our example, during this phase, you code the configuration of the instances and the VPC network. You then organize your code in configuration files, such as variables, main, and tfvars. The next phase is initialize, where any plugins or modules are installed. During this phase, you run the terraform init command, which initializes the Terraform configuration directory and installs Google Cloud as the provider. In the plan phase, you run the terraform plan command. The terraform plan command provides an execution plan for the resources created, changed, or destroyed as per the configuration defined in the author phase. You can then review the plan before applying it to your Google Cloud infrastructure. After you review the configuration described in the generated plan, apply it to create the infrastructure and a state file. Later in the course you will explore the Terraform workflow in more detail. Now let’s examine common Terraform use cases. Terraform is used to manage infrastructure. It takes an immutable approach, meaning you write code to reduce the complexity involved in upgrading or modifying the services and infrastructure. Terraform is also used to track infrastructure changes. Whenever a new change is planned or applied, you will be prompted to approve the change before Terraform modifies the state of the infrastructure. When an infrastructure is created using Terraform, a state file is automatically generated. State files reflect the current state of your infrastructure, and provide the amount and type of Google Cloud resources modified in your configuration. Terraform is used to automate changes. Because configuration files are declarative in nature, you do not have to write detailed instructions to build the infrastructure; you only define the end state. Terraform manages the dependencies and provisions the resources. It’s also used to standardize configurations. You can use modules to save time and implement best practices. You can also leverage publicly available modules from the Terraform Registry. Terraform can also be used to automate the enforcement of policies on the types of resources teams can provision and use.

### Video - [Using Terraform](https://www.cloudskillsboost.google/course_templates/443/video/508940)

- [YouTube: Using Terraform](https://www.youtube.com/watch?v=u5TXVqVFysw)

So, how can you use Terraform to create, update, or destroy infrastructure resources? First, you must write your infrastructure as code in configuration files. Configuration files describe to Terraform the resources you want to provision. Terraform generates an execution plan for the desired state, and then executes the plan to build the described infrastructure. As the configuration changes, Terraform can determine what changed and create incremental execution plans that can be applied. Terraform is available in three editions: Community Edition, Cloud, and Enterprise. Community Edition is a free version of the software available for download on a local machine or compute resource in the cloud. With this version, many features are available with no license cost. You can provision several different types of resources and codify your infrastructure. Community Edition grants access to publicly available templates so you can apply code writing best practices. You can only use the Community Edition version on your local machine, and it does not support concurrent deployments. Terraform Community Edition does not have version control, so you can't track changes or ensure that your commits do not affect the infrastructure setup. With the Community Edition version, Terraform can only be interacted with through the CLI, whereas Terraform Cloud and Enterprise come with a GUI option. Terraform Cloud is useful for collaborative environments. Terraform Cloud has three plans: free, standard and plus. Unlike Terraform Community Edition, Terraform Cloud and Terraform Enterprise support concurrent deployment. With Terraform Cloud – like most other SaaS solutions – the operational overhead is low. Terraform Enterprise is hosted on-premises or on an infrastructure controlled by you. Due to infrastructure maintenance and its integration with Terraform, Terraform Enterprise has a high operational overhead. Terraform is pre-installed on Cloud Shell, but you can also install it on your local machine. You can install Terraform as a binary package or use popular package managers. To manually install Terraform on a Windows machine: First, download the package that meets your system requirements. Extract the package. Terraform includes a single binary called terraform. Edit the PATH variable to include Terraform. And then verify the installation by entering terraform -help in a new terminal. The authentication mechanism used for Google Cloud varies based on where Terraform is run. The Google Cloud provider – not Terraform – will require authentication to communicate to the resource API for resource creation. Terraform on Cloud Shell is pre-authenticated. Cloud Shell is a Compute Engine virtual machine, and the service credentials are automatic, so there’s no need to set up a service account key. If you’re running Terraform on your workstation, authenticate by using the Cloud SDK. You first must install gcloud CLI, and then run the gcloud auth application-default login command to authenticate with Google Cloud. If you’re running Terraform in a VM on Google Cloud, configure that VM to use a Google Service Account. A Google Service Account allows Terraform to authenticate without a separate credential or authentication file. Ensure that the VM has the Google Cloud API enabled. If you’re running Terraform outside Google Cloud, you can use a Google Cloud Service Account with Terraform. From the service account key page in the Cloud Console, choose an existing account or create a new one. Then download the JSON key file. Name it something you can remember, and store it somewhere secure on your machine. Supply the key to Terraform using the environment variable GOOGLE_APPLICATION_CREDENTIALS, setting the value to the location of the file. Terraform can then use this key for authentication. This method does have a few limitations. Service account keys are short-lived. Key rotation is not allowed, and the keys must be protected. Workload identity and workload identity federation are tools for mitigating short-lived identity tokens when running Terraform outside of Google Cloud. Once you’ve downloaded Terraform and authenticated successfully, you’re ready to start authoring a Terraform configuration. Let’s create a simple VPC network. We won’t get into the details of the code just yet. For now, let’s focus on the workflow. First, create a configuration file with a . tf extension. and define Google Cloud as the provider. Then add HCL code to create a Google Compute instance. After you save the code, navigate to the directory where you saved the file and run terraform init, terraform plan and terraform apply. After you run terraform apply, a new VPC network named mynetwork will be created on Google Cloud. Once you’ve downloaded Terraform and authenticated successfully, you’re ready to start authoring a Terraform configuration. Let’s create a simple VPC network. We won’t get into the details of the code just yet. For now, let’s focus on the workflow. First, create a configuration file with a . tf extension. Then, define Google Cloud as the provider and run the terraform init command to initialize the provider. Add the HCL code to create a Google Compute instance. After you save the code, navigate to the directory where you saved the file and run the terraform plan and terraform apply. After you run terraform apply, a new VPC network named mynetwork will be created on Google Cloud.

### Quiz - [Quiz : Introduction to Terraform for Google Cloud](https://www.cloudskillsboost.google/course_templates/443/quizzes/508941)

#### Quiz 1.

> [!important]
> **Select the two use cases for Terraform.**
>
> - [ ] Automate changes
> - [ ] Run OS level customization
> - [ ] Standardize configurations
> - [ ] Provision an application
> - [ ] Provide financial analytics

#### Quiz 2.

> [!important]
> **Select the three Terraform editions available in production.**
>
> - [ ] Terraform Cyber
> - [ ] Terraform Enterprise
> - [ ] Terraform Analytics
> - [ ] Terraform Community Edition
> - [ ] Terraform Cloud

#### Quiz 3.

> [!important]
> **What is infrastructure as code (IaC)?**
>
> - [ ] IaC is a data warehouse running on serverless infrastructure.
> - [ ] IaC is a process to define, provision, and manage cloud infrastructure by writing code in files.
> - [ ] IaC is a cloud computing model that offers resources on demand to businesses and individuals by using the cloud.
> - [ ] IaC is a tool to maintain consistency in an application deployment environment.

#### Quiz 4.

> [!important]
> **Which one of the following statements is true regarding Terraform?**
>
> - [ ] Terraform can only be used for on-premises deployments.
> - [ ] Terraform is used to configure applications on Google Cloud.
> - [ ] Terraform uses the imperative approach to define infrastructure components.
> - [ ] Terraform can be used for multi-cloud deployments.

### Video - [Module Summary](https://www.cloudskillsboost.google/course_templates/443/video/508942)

- [YouTube: Module Summary](https://www.youtube.com/watch?v=5GE8-eS38rQ)

This brings you to the end of the first module of the Getting Started with Terraform for Google Cloud course. This module covered the basics of Terraform and Infrastructure as Code. We defined Infrastructure as code and covered the business case for IaC. We explained the features and benefits of using Terraform. We also discussed common use cases, how to use Terraform, and the consumption model for Terraform.

## Terms and Concepts

 In this module, we introduce you to HashiCorp Language and discuss the terms and concepts involved in authoring a Terraform configuration. We also explore some of the important Terraform commands involved in managing the terraform configuration. Upon completion of this module, you will be able to interpret what each code block means, create basic configuration files within Terraform and be able to explain the purpose of a few few important terraform commands and we will also explore what a Validator tool is.`

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/443/video/508943)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=Gu7cWY4uRKU)

Hi there. Welcome to Module 2: Terms and Concepts. This module elaborates on the Terraform workflow that was introduced in Module 1. Now this is going to be a very short module; while there's a lot to cover about how to author infrastructure, this module explores the foundation concepts you’ll need to be familiar with before getting into the details of code constructs such as resources variables and output values. This module includes key concepts and terminology and the basics of the HashiCorp Language – or HCL. Wondering what HCL language looks like? What do resources mean in the Terraform world? This module is for you. This module will cover each phase of the Terraform workflow, from author to apply. You’ll learn to create basic configuration files and explore the HCL language. HCL is similar to JSON, easy to learn, and powerful for configuring infrastructure resources. You’ll learn about the initialize phase, which includes providers. Next comes the plan and apply phases, where you’ll examine the purpose of a few important terraform commands. This module will also cover an optional phase called validate, where you’ll learn about the Terraform validator tool. And it concludes by describing how to create, update, and destroy Google Cloud resources using Terraform. This module concludes with a short demo on creating infrastructure objects, a hands-on lab to apply your knowledge, and a recap of topics covered in the module. Let’s get started!

### Video - [Terraform Configurations and the HashiCorp Language](https://www.cloudskillsboost.google/course_templates/443/video/508944)

- [YouTube: Terraform Configurations and the HashiCorp Language](https://www.youtube.com/watch?v=9M-Ls2jrSxc)

Let’s get started with an overview of Terraform configurations and the Hashicorp Language. This course focuses on the core Terraform workflow: author, initialize, plan, and apply. In this module, you’ll explore how these individual phases fit together to transform code to cloud resources. Let’s start with the author phase, where you write Terraform code in . tf files. Before writing code, start by creating directories for a Terraform configuration. A Terraform configuration is a complete document in the Terraform language that tells Terraform how to manage a given collection of infrastructure. The configuration is stored with a . tf extension. A Terraform directory can consist of multiple files and directories. A Terraform configuration consists of: A root module, also referred to as the root configuration file, And an optional tree for child modules. Child modules are optional, and can be variables, outputs, providers, and so forth. You can have a series of resources and other code constructs within a single root configuration, but the best practice is to logically separate your files. The root module is the working directory in which Terraform commands are run. In that directory, Terraform will look for any . tf files and use them to create a plan and infrastructure elements. Now that you know how to create a directory structure, let’s explore the language used for Terraform configurations. The language used to write configurations is the HashiCorp Configuration language, or HCL. Generic HCL syntax is shown in this example. HCL is used to create and manage API-based resources, predominantly in the cloud. Resources are infrastructure objects such as virtual machines, storage buckets, containers, and networks. Terraform uses HCL to define resources in your Google Cloud environment, create dependencies with those resources, and define the data to be fetched. Despite some commonalities, HCL is a configuration language, not a programming language. It’s a JSON-based variant that’s human and machine friendly. The simplicity of HCL makes Terraform accessible to developers. HCL includes a limited set of primitives such as variables, resources, outputs, and modules. It does not include any traditional statements or control loops. The logic is expressed through assignments, count, and interpolation functions. Let’s explore HCL syntax in detail. Blocks are lines of code that belong to a certain type. Examples include resource, variable, and output. A block can be simple or nested to include another block type. Arguments are part of a block and used to allocate a value to a name. Some blocks have mandatory arguments, while others are optional. Identifiers are names of an argument, block type, or any Terraform-specific constructs. Identifiers can include letters, underscores, hyphens, and digits, but cannot start with a digit. Expressions can be used to assign a value to an identifier within a code block. These expressions can be simple or complex. Comment syntax start with a # for a single-line comment. Remember, HCL is declarative by nature, which means you define the end state of an infrastructure. Therefore the order of the blocks or files does not matter.

### Video - [Author Phase Terms and Concepts](https://www.cloudskillsboost.google/course_templates/443/video/508945)

- [YouTube: Author Phase Terms and Concepts](https://www.youtube.com/watch?v=nnxC2RYhcCI)

We’ve covered Terraform configurations and the HashiCorp Language. Now let’s discuss common terms and concepts that you encounter during the author phase of the Terraform workflow. Resources are code blocks that define the infrastructure components. A resource is identified by the keyword resource, followed by the resource type and a custom name. The resource type depends on the provider defined in your configuration. Inside the curly brackets are the resources arguments, where you specify the inputs needed for the configuration. Terraform uses the resource type and the resource name to identify an infrastructure element. The keyword resource identifies the block as a cloud infrastructure component. The resource type is google_storage_bucket, which identifies the Google Cloud resource. This terminology is Terraform-specific and the convention cannot be customized. The resource type varies based on the provider defined. The resource name is example-bucket. Terraform uses the resource type and the resource name together as an identifier for the resource. This example assumes that Google Cloud is defined as the provider and shows two resource blocks: a Cloud Storage bucket and a compute instance. The arguments differ based on the resource type being defined. For the google_storage_bucket resource, you only must specify the name and location to successfully create the resource. For the google_compute_instance resource, you must specify the name, machine_type, and the network_interface. Zone and tags are optional. You can use separate files – for example, files for instances, storage buckets, and datasets – if you have lengthy resource configurations. Providers implement every resource type; without providers, Terraform can't manage any kind of infrastructure. In the providers.tf file, you specify the Terraform block that includes the provider definition you will use. Terraform downloads the provider plugin in the root configuration when the provider is declared. Providers expose specific APIs as Terraform resources, and manage their interactions. Provider configurations belong in the root module of a Terraform configuration. An example of a provider block is shown on screen. The source argument provides the global source address for the provider that you intend to use. In the above example, the source argument is assigned to the Terraform Registry URL hashicorp/google. The name Google is the local name of the provider to be configured. To ensure that the local name is configured correctly, the provider must be included in the required provider block. The arguments – such as project and region – are specific to the Google provider. When a provider block is not included within a Terraform configuration, Terraform assumes an empty default configuration. You can also assign a version to each provider. The version argument is optional, but recommended. Version arguments constrain the provider to a specific version or a range of versions to prevent downloading a new provide that may contain breaking changes. If the version isn't specified, Terraform will automatically download the most recent provider during initialization. Variables are used to parameterize your configuration. Input variables serve as parameters for Terraform, allowing easy customization and sharing without having to alter source code. Once a variable is defined, there are different ways to set its values at runtime: environment variables, CLI options, key or value files, and so forth. You can define a resource attribute at run time or centrally in a file with a . tvars extension. You can also easily separate attributes from deployment plans. In this example, main.tf declares a Cloud Storage bucket. The location attribute has been parameterized because it’s declared as a variable in the variables.tf file. By parameterizing the attribute, you can define the values of these variables at run time. You’ll learn more about variables in the next module. The outputs.tf file holds output values from your resources. Resource instances managed by Terraform each export attributes whose values can be used elsewhere in configuration. If needed, output values are a way to expose some of that information. Some resource attributes are computed upon their creation. For example, a self-link of the resource or the URL of a bucket is generated upon bucket creation. These computed attributes might be required for accessing the bucket or uploading objects. With an output value, you can output this information and make it accessible. The label after the output keyword is the name, which must be a valid identifier. In a root module, this name is displayed to the viewer. In a child module, it can be used to access the value. The value argument takes an expression that returns the results to the user. Terraform saves the state of resources that it manages in a state file. By default, the state file is stored locally, but it can also be stored remotely. Remote storage is often the preferred method when working in a team environment. Do not modify or touch this file; it’s created and updated automatically. States are covered in detail in an upcoming module. Finally, a Terraform module is a set of Terraform configuration files in a single directory. Even a simple configuration consisting of a single directory with one or more . tf files is considered a module. Modules are the primary method for code reuse in Terraform. They are reused by specifying the source from which the code can be retrieved. Sources can either be local or remote. You can use an upstream module from the HashiCorp module registry or create your own.

### Video - [Terraform Commands](https://www.cloudskillsboost.google/course_templates/443/video/508946)

- [YouTube: Terraform Commands](https://www.youtube.com/watch?v=jTJXNigqDgw)

Once Terraform is installed on your machine, you can use commands at your root module to interact with Terraform. Common commands covered in this module include terraform init, Terraform plan, Terraform apply, Terraform destroy And terraform fmt. terraform init is used to initialize the provider with a plugin. terraform plan provides a preview of the resources that will be created after terraform apply. terraform apply creates infrastructure resources. terraform destroy destroys infrastructure resources. And terraform fmt auto formats to match canonical conventions. The terraform init command is run during the initialize phase. It’s the first command to run after creating a configuration or checking out an existing configuration from version control. Terraform init ensures that the Google provider plugin is downloaded and installed in a subdirectory of the current working directory, along with various other bookkeeping files. The provider block includes a source attribute specifying where the provider plugins will be downloaded from. Terraform uses a plugin-based architecture to support the numerous infrastructure and service providers available. Each "provider" is its own encapsulated binary that is distributed separately from Terraform itself. The terraform init command will automatically download and install any provider binary for the providers to use within the configuration. In this case, the provider is Google. After you run terraform init, a hidden directory called . terraform is created inside the current working directory. You will see an "Initializing provider plugins" message, letting you know that Terraform will find the latest plugin and download the associated files. The output of the command tells you the provider version that Terraform has installed, in this case version 4.21. Terraform plan creates an execution plan detailing all the resources that will be created, modified, or destroyed upon executing terraform apply. When terraform plan is run, Terraform: Reads the current state of existing remote objects to ensure that Terraform state is up to date. Compares the current configuration to the prior state and notes any differences. And builds an execution plan that only modifies what is necessary to reach your desired state. Terraform plan does not actually create or change any infrastructure resources, but instead provides you with an opportunity to preview your infrastructure changes before applying them. For example, you might want to run this command before committing a change to version control to be sure that it will behave as expected. You can use the optional -out=FILE option to Optionally, you can save the generated plan to a file on disk, which you can later execute by passing the file to terraform apply as an extra argument. Terraform apply executes the actions proposed in a Terraform plan, creates the resources, and establishes the dependencies. The symbols next to the resources and arguments indicate the action performed on the resource. The plus next to the resource means that Terraform will create this resource. Terraform also shows the attributes that will be set. Minus slash plus means that Terraform will destroy and recreate the resource, rather than updating it in-place. The tilde means that Terraform will update the resource in-place. The minus indicates that the instance and the network will be destroyed. As with terraform apply, Terraform shows its execution plan and waits for approval before making any changes. If the plan is created successfully, Terraform pauses and waits for approval before proceeding. If anything in the plan is incorrect or unsafe, you can abort here without changing your infrastructure. If terraform apply fails, read the error message and troubleshoot the issues. Just like with terraform plan, Terraform determines the order in which things must be destroyed. For example, Google Cloud won't allow a VPC network to be deleted if it still has resources. Terraform waits until the instance is destroyed before destroying the network. Let’s cover some code formatting best practices: Separate the meta arguments from the other arguments by placing them first or last in the code with a blank line. Indent your arguments with two spaces from the block definition When two or more arguments are defined in a given block, align the values at the equal sign When a block includes a nested block, place the block following all the arguments. Finally, when your code includes multiple blocks, separate them with a black line for readability. Running terraform fmt on your modules and code automatically applies all formatting rules and recommended styles to assist with readability and consistency. Terraform fmt automatically maintains consistent formatting, so you don't have to manually change configuration to ensure it meets the standards. The last command to cover in this module is terraform destroy, which destroys resources. Terraform destroy is similar to terraform apply, but it behaves as if all resources have been removed from the configuration. Terraform is sometimes used to manage ephemeral infrastructure for development purposes. In this case, you can use terraform destroy to conveniently clean up temporary objects once you’re finished with your work. You can also destroy specific resources by specifying a target in the command. Destroying your infrastructure is a rare event in production environments. But if you're using Terraform to create multiple environments such as development, testing, and staging, then destroying is often a useful action. Use terraform destroy carefully - it will destroy any resource and the data associated with it. For example, if there’s data in a bucket, be careful when running terraform destroy, as that data cannot be recovered.

### Video - [The Terraform Validator](https://www.cloudskillsboost.google/course_templates/443/video/508947)

- [YouTube: The Terraform Validator](https://www.youtube.com/watch?v=5z08__JjDFw)

Let’s think back to the Terraform workflow, and explore the validate phase. Between the plan and apply phases, is the option to validate. During this phase, pre-deployment checks are run against organizational policies. The Terraform validator is a tool for enforcing policy compliance as part of an infrastructure CI/CD pipeline. It’s also incredibly useful in an infrastructure-as-code environment, as it helps mitigate configuration errors that can cause security and governance violations. Although validation is optional, The Terraform Validator is a useful tool in an IaC environment. Businesses are shifting toward infrastructure-as-code, and with that change comes the risk that configuration errors can cause security and governance violations. Furthermore, many organizations have compliance and governance policies in place that must be adhered to. For example, perhaps there are data residency laws in place, and your governance team must ensure that resource creation is only allowed in certain regions. To address this policy, the security and governance teams can set up guardrails. These guardrails are in the form of constraints. Constraints define the source of truth for security and governance requirements. Constraints must be compatible with tools across every stage of the application lifecycle, from development, to deployment, to auditing. The Terraform Validator is run by executing the gcloud beta terraform vet. Executing the command enforces policy compliance as part of an infrastructure CI/CD pipeline. The tool retrieves project data with Google Cloud APIs, so you can accurately validate your plan. You can use the Terraform Validator to detect policy violations and provide warnings or halt deployments before they reach production. The same set of constraints that you use with the tool can also be used with any other tool that supports the same framework. gcloud beta terraform vet is different from the terraform validate command. Terraform validate is used for testing syntax and the structure of your configuration without deploying any resources. The Terraform Validator is used to ensure that the configuration adheres to the set of constraints. These constraints automate the enforcement of the organization policies. With The Terraform Validator you can: Enforce policies at any stage of application development Remove manual errors by automating policy validation And reduce learning time by using a single paradigm for all policy management Let’s examine a few Terraform Validator use cases, and show how it can help different teams. Platform teams can easily add guardrails to infrastructure CI/CD pipelines, to ensure that all requests for infrastructure are validated before deployment to the cloud. This limits platform team involvement by providing failure messages to end users during their pre-deployment checks. These messages tell you which policies they have violated. Application teams and developers can validate their Terraform configurations against a central policy library to identify misconfigurations early in the development process. Before submitting to a CI/CD pipeline, you can ensure that your Terraform configurations are in compliance with organizational policies, thus saving time and effort. Security teams can create a centralized policy library that is used by all teams across the organization to identify and prevent policy violations. Depending on how your organization is structured, the security team or other trusted teams can add the necessary policies needed to meet compliance requirements.

### Video - [Demo - Terraform Workflow](https://www.cloudskillsboost.google/course_templates/443/video/508948)

- [YouTube: Demo - Terraform Workflow](https://www.youtube.com/watch?v=23WzKokmha8)

Hi, this demonstration will help you become familiar with the Terraform configuration to create a Compute Engine instance. We will show you how to create configuration files and use the Terraform CLI, to execute a few Terraform commands such as terraform init, terraform plan, terraform apply and terraform destroy. While watching this demonstration, you will discover how easy it is to use and adopt Terraform to manage your Google Cloud infrastructure. Let's get started. For demonstration purposes, we are using Terraform on Cloud Shell. Terraform comes preinstalled on Cloud Shell. With Cloud Shell, you have command line access to your cloud resources directly from your browser, so you can easily manage projects and resources without having to install any tools on your local machine. Further, command line tools suggest Terraform and other utilities are automatically authenticated so you can use them setup free. To verify the Terraform installation, enter terraform in the command line. You can check the version of Terraform running on Cloud Shell by running terraform version command. As a first step, let's define the provider. To do this, we first create a folder called infra. Right-click underneath your project to create New Folder. Give it the name of your choice. Create a new file called main.tf to author the terraform code. Before creating the resources, we define the provider so Terraform knows which provider to download. At this point, because you might not be familiar with the code and syntax, we leverage Terraform Registry. Navigate to the registry. Under Google Cloud Provider, click the Use Provider button and copy the code underneath it. In the configuration define, the Google providers source is defined as hashicorp/google, which is shortened for Terraform Registry for Google Cloud. In this example, we already have a project created. Let's edit the configuration options to include the project and assign the project ID to it. Save the configuration changes. Switch to Cloud Shell. Change to the current directory. Execute terraform init to initialize Terraform and download the provider plug-ins. Let's next define our first Google Cloud resource, a Google Compute Engine. Let's edit the project ID to our current project. Save the code and return to the Cloud Shell window. Next, execute terraform plan. Authorize when prompted. You can see a summary of Compute Engine instances created. Execute terraform apply, to apply your configuration. The output has a plus next to google_compute_instance, which means that Terraform will create this resource. The sign varies based on the configuration applied. Beneath the resource update status, the attributes that will be set are displayed. When the value says ‘known after apply’ the value cannot be determined until the resource is provisioned. Review the output of the apply command to ensure that the resource is configured as per your expectations. If anything in the output seems incorrect or unsafe, enter ‘no’ so that no changes are made to your infrastructure. The plan looks acceptable here so we type ‘yes’. While we wait for the resources to be created, we switch to the editor to see that the terraform state file is automatically created. The terraform state defines the current state of the infrastructure. Let's verify the resource created on the Google Cloud console. You can see a Terraform resource is now being created in the region defined. We can also destroy the resources created by simply executing the terraform destroy command. Let's navigate to the Cloud Shell and delete the resource we just created. The minus prefix indicates that the resource will be destroyed. As with apply, Terraform shows its execution plan and waits for approval before making any changes. Enter ‘yes’. You can see that the resources are now deleted. Let's verify the deletion on the Google Cloud console. Navigate to Compute Engine. Click VM instances. You can now see the Terraform instance is no more available in the instance list. This completes the demonstration. In this demonstration, we defined a provider to download the provider plug-ins. We created a Google Compute Engine using Terraform. We used the command terraform plan to review the resource creation. We used the command terraform apply to create infrastructure resources. We then finally executed terraform destroy to destroy the resources we just created. Thanks for watching. Hope you enjoyed it.

### Video - [Lab Intro: Infrastructure as Code with Terraform](https://www.cloudskillsboost.google/course_templates/443/video/508949)

- [YouTube: Lab Intro: Infrastructure as Code with Terraform](https://www.youtube.com/watch?v=5K2uv6cCDkQ)

In this lab, you will use Terraform to create, update, and destroy Google Cloud resources. You will start by defining Google Cloud as the provider. You will then create a VM instance without mentioning network to see how terraform parses the configuration code. You will then edit the code to add network and create a VM instance on Google Cloud. You will explore how to update the VM instance. You will edit the existing configuration to add tags and then edit the machine type. You will then execute terraform commands to destroy the resources created.

### Lab - [Infrastructure as Code with Terraform](https://www.cloudskillsboost.google/course_templates/443/labs/508950)

In this lab, you will explore how terraform can be used to create, manage, and destroy Google Cloud resources.

- [ ] [Infrastructure as Code with Terraform](../labs/Infrastructure-as-Code-with-Terraform.md)

### Quiz - [Quiz: Terms and Concepts](https://www.cloudskillsboost.google/course_templates/443/quizzes/508951)

#### Quiz 1.

> [!important]
> **In which phase of the Terraform workflow do you write configuration files based on the scope defined by your organization?**
>
> - [ ] Plan
> - [ ] Scope
> - [ ] Author
> - [ ] Apply
> - [ ] Initialize

#### Quiz 2.

> [!important]
> **Which command creates infrastructure resources?**
>
> - [ ] terraform apply
> - [ ] terraform plan
> - [ ] terraform fmt
> - [ ] terraform init

#### Quiz 3.

> [!important]
> **In which phase of the Terraform workflow can you run pre-deployment checks against the policy library?**
>
> - [ ] Validate
> - [ ] Plan
> - [ ] Initialize
> - [ ] Scope

### Video - [Module Summary](https://www.cloudskillsboost.google/course_templates/443/video/508952)

- [YouTube: Module Summary](https://www.youtube.com/watch?v=cudoOr-ahXs)

This concludes Module 2: Terms and Concepts. Before writing code, you‚Äôll need to have a strong understanding of the HCL and Terraform concepts that were covered in this module. Let‚Äôs review. This module described terms and concepts relating to each phase of the Terraform workflow. You learned how to create basic configuration files within Terraform, and how to describe a Terraform provider. This module also explained the purpose of a few important Terraform commands. In addition, you learned about an optional phase in the Terraform workflow called validate. You also learned how to create, update, and destroy Google Cloud resources. Check out the next module to learn more about writing infrastructure code.

## Writing Infrastructure Code for Google Cloud

In this module, you will explore more about resources, variables, and output resources. We will begin by exploring how to create infrastructure components using resources and then explore how Terraform handles dependencies within resources. While we have been covering resource creation by using hard-code resource arguments, we will explore how you can parameterize a given configuration using variables. We will explore the syntax to declare, define and use them within your configuration. We will then discuss how you can export resource attributes outside the resource declaration using output values. We will then wrap up the module by discovering how you can simplify code authoring using Terraform registry, and Cloud Foundation Toolkit.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/443/video/508953)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=zinw-M3bBxM)

Hello again! Welcome to Module 3 of the Getting Started with Terraform for Google Cloud course, where you’ll dive deeper into resources, variables, and output values, and learn how to write infrastructure code for Google Cloud. This module focuses on the first phase of the Terraform workflow: the author phase. During this phase, you’ll write your code in terraform language, HCL. This module begins by exploring how to create infrastructure components using resources, and then discusses how Terraform handles dependencies within resources. You’ll learn how to parameterize a configuration using variables, and walkthrough the syntax used to declare and define them within your configuration. You’ll then learn how to use output values to export resource attributes outside the resource declaration. This module also explains how to simplify code using the Terraform registry and Cloud Foundation Toolkit. You’ll conclude with a lab to apply what you’ve learned. Let’s get started!

### Video - [Introduction to Resources](https://www.cloudskillsboost.google/course_templates/443/video/508954)

- [YouTube: Introduction to Resources](https://www.youtube.com/watch?v=6hsFAsp6YJA)

The first topic in this module is resources. Let’s get started with an introduction to resources, before jumping into meta-arguments and dependencies. In the Terraform world, resources are infrastructure elements, such as Compute Engine instances and Cloud Storage buckets. These elements can be configured with Terraform code. Real-world infrastructure has a diverse set of resources and resource types. Terraform uses the underlying APIs of each Google Cloud service to deploy your resources. Resources include instances, instance templates, groups, VPC networks, firewall rules, VPN tunnels, Cloud Routers, and load balancers. Resources are defined within a . tf file. It’s recommended that you place similar types of resources in a directory and define resources in the main.tf file. In this example, main.tf is the root configuration. The resource block is used to declare a single infrastructure object. The resource type identifies the type of resource being created, and depends on the provider being declared within a Terraform module. A provider is a plugin that provides a collection of resource types. Generally, a provider is a cloud infrastructure platform. In this course, Google Cloud is the provider. Resource arguments use expressions to declare attributes. Some resource arguments are mandatory for resource creation, and others are optional. Attributes can be used to define any advanced features associated with a resource. You can include multiple resources of the same or different types within the same Terraform configuration file. These resources can even span across multiple providers. Here, the first resource block declares the VPC network, and another that declares the subnet. Both resources are in the same main.tf file. Let’s examine a couple more resource blocks. A resource is identified by the resource keyword, followed by the resource type. This example shows a VPC resource named vpc_network, which is of the type google_compute_network. The name is required for the google_compute_network block, but the other arguments are optional. You can also define advanced features, such as versioning, within the same block. This example defines a VPC subnet called subnetwork-ipv6. For the subnetwork block, the name, the network in which the subnet should be created, and the IP CIDR range are required. Notice that the resource arguments depend on the resource type. This means that the network includes arguments such as name, project, and auto_create subnetworks, and the subnetwork includes arguments such as name, IP_cidr_range, and network. When accessing a resource attribute from another resource block, use the format ... In this example, when a subnet is created, the subnet requires the network ID of the VPC network it belongs to. The network ID is a computed resource attribute of a google_compute_network block. The attribute is generated when the network is created. The subnet resource block uses the network ID created from the vpc_network block and uses the format google_compute_network.vpc_network.id. This method can be used only when resources are defined within the same root configuration. When defining a resource block, there are important factors to consider. First, a declared resource is identified by its type and name. Therefore the resource name must be unique within the module. The resource type is a keyword associated with the provider and cannot be user-defined. A Cloud Storage bucket is associated with the Google Cloud provider and is defined by the keyword google_storage_bucket. Any user-defined type would result in an error when terraform plan or terraform apply is executed. All configuration arguments must be enclosed within the resource block body, which is between the curly brackets. An infrastructure element and its associated attributes are defined within a resource block. A Terraform configuration will not pass through the plan and apply phases successfully without all the required arguments defined within the configuration.

### Video - [Meta-arguments for Resources](https://www.cloudskillsboost.google/course_templates/443/video/508955)

- [YouTube: Meta-arguments for Resources](https://www.youtube.com/watch?v=TdOWdb3NHKY)

Let’s transition and examine resource meta-arguments. The Terraform language defines several meta-arguments, which can be used with any resource type to change the behavior of resources. Count creates multiple instances, depending on the value you define. for_each, creates multiple instances according to a map or set of strings. Depends_on is used to specify explicit dependencies. Lifecycle defines the lifecycle of a resource. With the lifecycle argument you can prevent destruction of a resource for compliance purposes, and create a resource before destroying the replaced resource. This approach is often used for high availability. Provider selects a non-default provider configuration. You can have multiple configurations for a provider, including default. This course covers count and for_each in detail. Let’s start with the count meta-argument. Perhaps you must deploy multiple VM instances. In the resource definition here, each Compute Engine instance is created with a separate google_compute_instance resource block. Writing code in this way is redundant. Instead, replace redundant code by adding the count argument at the beginning of the resource definition. The count argument tells Terraform to create three instances of the same kind. The expression on the second line, count.index, represents the index number of the current count loop. The count index starts at 0 and increments by 1 for each resource. Include the count index variable in strings using interpolation. When deployed, Terraform names the instances dev_VM1, dev_VM2, and dev_VM3. If your instances are almost identical, count is appropriate. If some of their arguments need distinct values that can't be directly derived from an integer, it's safer to use for_each. The for_each argument can be assigned to a string of values or a map. Terraform will create one instance for each member of the string. Consider a scenario where you need three similar instances configured in three specific zones and you want the names to have zones as prefixes for identification. Instead of writing lengthy repetitive code, you can use the for_each argument to assign specific values. The example code creates three instances in their respective zones: dev-us-central1-a, dev-asia-east1-b, and dev-europe-west4-a.

### Video - [Resource Dependencies](https://www.cloudskillsboost.google/course_templates/443/video/508956)

- [YouTube: Resource Dependencies](https://www.youtube.com/watch?v=5tCUjRc3mLA)

Next up are resource dependencies. While building an infrastructure, you may prefer to have a visual representation of how your infrastructure is connected and interdependent. A dependency graph helps you understand your infrastructure before deploying it. Terraform builds a dependency graph from your configurations to generate plans and refresh state. The attributes are interpolated during run time, and primitives such as variables, output values, and providers are connected in a dependency tree. Terraform creates a dependency graph to determine the correct order of operations. In more complicated cases with multiple resources, Terraform will perform operations in parallel when it's safe to do so. Terraform can handle two kinds of dependencies: implicit and explicit. Implicit dependencies are known to Terraform, whereas explicit dependencies are unknown. Sometimes, one resource creation depends on the information generated from another. For example, you cannot create a compute instance unless the network is created. Similarly, you cannot assign a static IP address for a Compute Engine instance until a static IP is reserved. These dependencies are implicit. There are other scenarios where you induce a dependency. A given resource can only be created upon creation of another resource. In such cases, you would want to explicitly mention dependencies that Terraform cannot see. For example, let’s say you use a specific Cloud Storage bucket to run an application. That dependency is configured inside the application code and not visible to Terraform. In this scenario, you can use depends_on to explicitly declare the dependency. Let’s take a closer look at how Terraform handles implicit dependencies using another example. Here, the compute instance my_instance is created in a custom VPC called my_network. In Google Cloud, you cannot create a compute instance without a network. Terraform is informed of these relationships by interpolation expressions. Interpolation expressions should be used whenever possible. The reference to my_network in the network argument creates an implicit dependency on the network mentioned in the google_compute_network block. When you run terraform apply, you can view the order in which the resources are created. Terraform by default knows this order. Because of implicit dependency, Terraform is able to infer a dependency and knows it must create the network before creating the instance. In this example, Terraform creates the VPC my_network before creating the compute instance named my_instance. When Terraform reads the configuration, it will: First ensure that my_network is created before my_instance. Then save the properties of my_network in the state. And set the network argument in google_compute_instance to the value of the name argument in the google_compute_network block. Next, let’s examine explicit dependencies, which are not visible to Terraform. Explicit dependencies are defined with the depends_on argument within the dependent resource block. The depends_on argument gives you the flexibility to control the order in which Terraform processes the resources in a configuration. Depends_on can be used within the module block regardless of the resource type. The value can be an expression that directs to the resource. For example, let’s say you need to create two VMs—server and client —and want the client VM to only be created upon the successful creation of the server VM. This dependency is not visible to Terraform and has to be explicitly mentioned. You can use depends_on to explicitly declare the dependency of the client VM on the server VM. So, where in your configuration should these resource dependencies be defined? The order in which the resources are defined has no effect on how Terraform applies your changes, so organize your configuration files in a way that makes the most sense for you and your team. Upon executing terraform apply, you will notice that the client VM is created after the server VM. During interpolation of expression, Terraform processes the resource specified in the meta argument depends_on, and creates the server VM before creating the client VM.

### Video - [Variables](https://www.cloudskillsboost.google/course_templates/443/video/508957)

- [YouTube: Variables](https://www.youtube.com/watch?v=F7j1we-iN8g)

So far in this module you’ve been hardcoding resource argument values, but what if you want to parameterize your configuration, and define argument values during the apply phase of the Terraform workflow? Perhaps you want to standardize your code but maintain the flexibility to customize resource attributes at runtime. This is where variables come in. With variables, you can parameterize values shared between resources. Input variables serve as parameters for Terraform, allowing easy customization and sharing without having to alter the source code. After a variable is defined, there are different ways to set its values at runtime, including environment variables, CLI options, and key-value files. In the code shown in the example, the name, location, and storage class are hardcoded. You can declare any of these attributes as a variable, and specify the details at run time. Variables separate source code from value assignments. Let’s explore how to declare an input variable. Variables must be declared in the variable block. It’s recommended that you save all variable declarations within a separate file named variables.tf. The label next to the keyword variable gives the variable a name. There are two rules for naming variables. First, the name of the variable must be unique within a module. Second, variable names cannot be keywords. There are no required arguments for a variable, so a variable block can be empty. Terraform can automatically deduce the type and default values. The type argument specifies value types that are accepted for the variable. Terraform supports the following primitive variable types: Bool, which is used for binary values such as true or false without the quotes. Number, which is used for numeric variables. And string, which is used for a sequence of unicode characters. Default is another meta argument, used to assign a default value to an attribute. To access the value of a variable declared within the module, you can use the expressions var. . In the example on the slide, the variable bucket_storage_class is formatted as var.bucket_storage_class in the resource block. The name of the variable in the variable block has to match the reference made within the resource block. The default value can be overridden by assigning a value in environment values, or . tfvars files or -var option. The folder structure shows that the variable declaration is written within the variables.tf file, which is a recommended best practice. The variable is assigned to the storage_class argument. The default value in quotes is used when creating the resource. The description documents the purpose of the variable. The description is displayed during the apply phase when the variable doesn't have a defined value. The description should explain the purpose of the variable and the expected value. The description string is often included in documentation, so it should be written from the perspective of the user rather than its maintainer. Comments can be used by the maintainer. Sensitive, as the name suggests, is a variable argument used to protect sensitive information from being displayed in command outputs or log files. The acceptable value for sensitive is true. When set to true, the value is marked sensitive in the output of terraform plan or terraform apply. This argument is beneficial when dealing with information such as database credentials or API tokens. Marking variables as sensitive will eliminate the accidental exposure of confidential information. In this example, the user_information variable is marked sensitive. The resource foo uses name and address, which are both sensitive variables. When terraform plan or apply is run, values are not displayed because they are marked as sensitive. There are several ways to set variable values at run time. First, you can use . tfvars files to quickly switch between and version sets of variables. You can also use CLI options. CLI options are useful for running quick examples on simple files. Environment variables are useful in scripts and pipelines. If a required variable has not been set by using one of the described methods, you can use the CLI prompt When you have many variable definitions to input, providing the value in the command line might not be feasible. Instead, specify the variables in a definitions file with either a . tfvars or . tfvars.json extension. Variable definitions follow the same syntax as HCL, but include only variable name assignments. Terraform automatically loads the variable definitions files as long as they are exactly named terraform.tfvars, terraform.tfvars.json, . auto.tfvars, or . auto.tfvars.json. The definition provided in the . tfvars file overrides the definition in the default argument and environment variable. If you want to specify the value of a variable individually on the command line, you can use the -var option. These values can be entered when running either terraform plan or terraform apply. This method is frequently used for automation, where the -var is sourced from another environment variable. It’s also useful when running quick examples on simple files. If you use a . tf extension, you must specify the filename using the -var-file option on the command line. Set variables can be overridden at deployment. You can reuse the variable file and still customize the configuration at deployment. The -var option takes the highest precedence over all other variable assignment methods. If the variable value is assigned using multiple methods, the value defined using the -var option is the value that is assigned to the variable. If a required variable has not been set using a described method, Terraform prompts you on the CLI. In this example, the variable is not parameterized and has not been assigned a value. Therefore the CLI prompts you to enter a value during the plan phase. You can also validate the value assigned to a variable by including a validation subblock with the variable block. The validation block includes a condition argument for which the validation rule is assigned. In this example, contains is used as the condition argument, and validates that the storage class value is upper case and an accepted value.

### Video - [Variables Best Practices](https://www.cloudskillsboost.google/course_templates/443/video/508958)

- [YouTube: Variables Best Practices](https://www.youtube.com/watch?v=y-7-KFonxr4)

Now that you learned how variables can be used in your configuration, let’s explore some best practices for using them. First, only parameterize values that vary for each instance or environment. When deciding whether to expose a variable, ensure that you have a concrete use case for changing it. If there's only a small chance that a variable might be needed, don't expose it. Changing or adding a variable with a default value is backward-compatible, removing a variable is not. For root modules, provide values to variables by using a . tfvars variables file. Avoid alternating between var-files and command-line options. Command-line options are ephemeral and easy to forget, and they cannot be checked into source control. Default variable files are more predictable. Give variables descriptive names that are relevant to their usage or purpose. Variables representing numeric values—such as disk sizes or RAM size—must be named with units. Google Cloud APIs don't have standard units, so following this naming convention clears the expected input unit for configuration maintainers. To simplify conditional logic, give boolean variables positive names, for example, enable_external_access. Finally, variables must have descriptions. Descriptions are automatically included in documentation, and add additional context for new developers.

### Video - [Output Values](https://www.cloudskillsboost.google/course_templates/443/video/508959)

- [YouTube: Output Values](https://www.youtube.com/watch?v=1WsBIpPw7a4)

We’ve covered resources, meta-arguments, dependencies, and variables. Let's wrap up by exploring output values. Output values are similar to return values in common programming languages. With outputs, you can view information about the infrastructure resources you created on the command line. Output values are used for several purposes. The most common use case is to print root module resource attributes in the CLI after its deployment. Most of the server details are calculated at deployment and can only be inferred post-creation. Output values are also used to pass information generated by one resource to another. For example, you can extract server-specific values – such as an IP address – to another resource that requires this information. Output values are declared using the output block. The keyword ‘output’ indicates that the label associated with the keyword is the name of the output value. You can declare an output value anywhere within a configuration, but the recommended best practice is to declare them in a separate file named output.tf. The arguments that can be included within an output block are: value, which is a required argument that returns a value to the user of the module. Description, which is an optional argument used to provide an explanation of the purpose of the output and the value expected. The description is often used for documentation purposes. And sensitive, which is another optional argument used to mask the value to a resource attribute. This argument is useful to hide the accidental display of a resource attribute that is meant to be confidential, such as password information. In this example, we have declared an output value for the object named picture. After the object is successfully uploaded, the object URL is displayed on the screen. We recommend that you use output values, instead of user-supplied inputs, for the computed attributes of a resource. You can query all output values used in a project by running the terraform output command. Let’s explore best practices for output values. Only output useful information, such as computed information. Avoid outputting values that simply regurgitate variables or provide known information. For example, for a network resource, the following computed attributes are useful: id, which is an identifier for the resource Gateway_ipv4, which is the gateway address for default routing out of the network. And self_link - the URI of the created resource. As with variables, provide meaningful names and descriptions. Organize your code to include all output values in a file named output.tf. Finally, mark sensitive outputs. Instead of attempting to manually encrypt sensitive values, rely on built-in support for sensitive state management. When exporting sensitive values to output, make sure that the values are marked as sensitive. When a value is marked sensitive, the data is masked from the output of terraform plan or terraform apply command.

### Video - [Terraform Registry and Cloud Foundation Toolkit](https://www.cloudskillsboost.google/course_templates/443/video/508960)

- [YouTube: Terraform Registry and Cloud Foundation Toolkit](https://www.youtube.com/watch?v=2zQwDmND94I)

There are a couple resources available to help you write infrastructure code for Google Cloud. The Terraform Registry is an interactive resource for discovering a wide selection of integrations and configuration packages, otherwise known as providers and modules. The Registry includes solutions developed by HashiCorp, third-party vendors, and the Terraform community. The Registry provides plugins to manage any infrastructure API, pre-made modules to quickly configure common infrastructure components, and examples of how to write quality Terraform code. In addition, the Cloud Foundation Toolkit – also known as CFT – is available for you to use. CFT provides a series of reference modules for Terraform that reflect Google Cloud best practices. These modules can be used to quickly build a repeatable foundation in Google Cloud. CFT modules are also referred to as Terraform blueprints. We also have Cloud Foundation Fabric (CFF), a collection of Terraform modules and end to end examples meant to be cloned as a single unit and used for fast prototyping or decomposed and modified for usage in organizations. The repository on github provides end to end blueprints, and a suite of Terraform modules for Google Cloud, which support different use cases. For more information on the Cloud Foundation Toolkit, Terraform blueprints, and Cloud Foundation Fabric, links have been added to the student PDF in the Course Resources. With the Terraform Registry you can surface modules for all providers, such as Google, AWS, and so forth. CFT is a collection of Google Cloud Terraform modules built and maintained by Googlers. These modules are published to the Terraform Registry. CFT modules let you maintain the IAM roles for multiple projects within the same module, as opposed to updating roles for each project individually. This example shows a standard Terraform IAM binding. The binding is used to: Assign the network user, network group, and network admin role on project-one and project-two. And assign the App Engine user, App Engine group, and the App Engine admin role on project-one and project-two. The equivalent CFT module defines the role and user bindings for multiple projects within the same module. Infrastructure Manager, or Infra Manager, is a managed service that automates the deployment and management of Google Cloud infrastructure resources. Infrastructure is defined using Terraform and deployed onto Google Cloud by Infra Manager, enabling you to manage resources using Infrastructure as Code. Infra Manager does not manage the deployment of applications onto your resources. To manage application deployment, you can use Google Cloud products like Cloud Build and Cloud Deploy. You can also use third-party tools or your own toolchain. For more information, refer to the Infrastructure Manager documentation.

### Video - [Lab Intro: Creating Resource Dependencies with Terraform](https://www.cloudskillsboost.google/course_templates/443/video/508961)

- [YouTube: Lab Intro: Creating Resource Dependencies with Terraform](https://www.youtube.com/watch?v=O2JSGQRQj10)

In this lab, you will create two VMs in the default network. You will use variables to define the VM's attributes at runtime, and use output values to print a few resource attributes. You will then add a static IP address to the first VM to examine how terraform handles implicit dependencies. Finally, you will create a Google Cloud Storage bucket by mentioning explicit dependency to the VM to examine how terraform handles explicit dependency. Writing infrastructure code is a fundamental skill needed to manage your infrastructure on Google Cloud. In this module, you learned how to declare resources: infrastructure elements you can configure using Terraform. In addition, you examined resource blocks. You also learned how to specify resource dependencies, and how and why to use variables and output values within a configuration. This module also explained the Terraform Registry and the Cloud Foundation Toolkit, two tools for simplifying the code writing process.

### Lab - [Creating Resource Dependencies with Terraform](https://www.cloudskillsboost.google/course_templates/443/labs/508962)

Explore implicit and explicit resource dependencies and examine the use of lifecycle meta-argument.

- [ ] [Creating Resource Dependencies with Terraform](../labs/Creating-Resource-Dependencies-with-Terraform.md)

### Quiz - [Quiz: Writing Infrastructure Code for Google Cloud](https://www.cloudskillsboost.google/course_templates/443/quizzes/508963)

#### Quiz 1.

> [!important]
> **Which dependency can be automatically detected by Terraform?**
>
> - [ ] Implicit dependency
> - [ ] Explicit dependency

#### Quiz 2.

> [!important]
> **How many resource types can be represented in a single resource block?**
>
> - [ ] Three
> - [ ] One
> - [ ] Two
> - [ ] Four

#### Quiz 3.

> [!important]
> **Can a variable be assigned values in multiple ways?**
>
> - [ ] No
> - [ ] Yes

#### Quiz 4.

> [!important]
> **What is the most common use case for output values in Terraform?**
>
> - [ ] Print resource attributes of a root module CLI after its deployment.
> - [ ] Parameterize a resource configuration.
> - [ ] Declare a resource within a Terraform configuration.

### Video - [Module Summary](https://www.cloudskillsboost.google/course_templates/443/video/508964)

- [YouTube: Module Summary](https://www.youtube.com/watch?v=UTjUHxPANeI)

Writing infrastructure code is a fundamental skill needed to manage your infrastructure on Google Cloud. In this module, you learned how to declare resources: infrastructure elements you can configure using Terraform. In addition, you examined resource blocks. You also learned how to specify resource dependencies, and how and why to use variables and output values within a configuration. This module also explained the Terraform Registry and the Cloud Foundation Toolkit, two tools for simplifying the code writing process.

## Organizing and Reusing Configuration with Terraform Modules

You will explore what modules are, how to use them from a public registry, how to use modules to reuse configurations, and parameterize configurations using input variables. You will also explore how to use output values to access resource attributes outside of the module.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/443/video/508965)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=zszy0qmMZqE)

Welcome to Module 4: Organizing and Reusing Configuration with Terraform Modules. Abstracting and modularizing your code is a common practice In the programming world. As your infrastructure grows, so does your code base, and your team will have to spend a fair amount of time to understand the code, change it, test it, and then deploy it. The convenience that abstraction brings along with the flexibility to standardize code is undeniable. Developers commonly refer to the “Don’t Repeat Yourself” principle, also known as DRY. The idea of DRY is to avoid repeating the same set of code multiple times. In this module, we’ll explore how Terraform implements the DRY principle using modules. With modules, you can group sets of resources together so you can reuse them later. Should you have to update code, you’ll only need to do so in one location. This module explores use cases for modules and how to use them when writing your infrastructure code. We’ll start by describing a scenario in which modules play a critical role in building efficient code. Upon completion of this module, you’ll be able to define Terraform modules and use them to reuse configuration. To simplify the code writing process, you’ll learn how to use publicly available modules on Terraform or GitHub. You’ll also explore how to use input variables to parameterize configurations, and output values to access resource attributes outside the module. In addition, you’ll learn best practices for using modules, and examine how modules can be useful when working in different environments, such as development, testing, and production. You’ll conclude with a lab to apply the concepts that were covered. Ready? Let’s dive in!

### Video - [Introduction to Terraform Modules](https://www.cloudskillsboost.google/course_templates/443/video/508966)

- [YouTube: Introduction to Terraform Modules](https://www.youtube.com/watch?v=xDk4PgcCFMk)

Let’s get started with an introduction to Terraform modules. Before defining modules, let’s view a simple scenario demonstrating why modules are necessary. Let’s say you must create a web server in a custom network. Typical attributes that represent the web server include: The machine type, disk, a static IP address, and a Google service account. The associated code to deploy a server with these attributes is similar to the code shown in this example. What if you want to deploy several servers of the same kind? You might have to manually copy the code. What if you have to update one attribute for all these servers? You have to manually find and update that attribute in every occurrence. When new resources are added or the code is updated, the code becomes bigger, unmanageable, and harder to read. Copying the code becomes a cumbersome process where every little change has to be applied error-free across all environments. It also makes the code inefficient. Similar, duplicated blocks can cause discrepancies when updated. In the programming world, disadvantages of code repetition are addressed with the “Don’t Repeat Yourself” principle, also known as DRY. The idea of DRY is to avoid repeating the same set of codes multiple times. Instead, replace it with abstraction to avoid redundancy. This practice encourages building efficient code that is readable and reusable. In general-purpose programming languages like Ruby, Java, and Python, functions are used to implement the DRY principle. Any piece of code that has to be manually copied is placed inside a function and reused across the main code. With Terraform, you can place your reusable code inside a module and reuse that module in multiple places. Define the reusable code in a module named server, so that any changes you make to the module are reflected across all the environments that you plan to reuse. The definition of a module ia a group of one or more Terraform configuration files in a directory. Modules allow you to group a set of resources together and reuse them later, and they can be referenced from other modules. So far, we have unintentionally written our terraform configuration in a module, called the root module. The root module is the directory from which you run terraform commands. Notice that the root module consists of . tf files that are stored in your working directory. This working directory is where terraform plan and terraform apply are run. Other modules and resources are instantiated in the root module. Now that you know what modules are and why they’re useful, let’s examine the creation process. In this example, let’s create two modules, one called “server, and the other called “network”. The network module will contain networking resources to host the server. The server module will contain necessary compute resources that define the server. To create a module, first create a directory of Terraform files. In this example, create two directories, named network and server. Each directory has its own main.tf file. Next, enter the code in the main.tf file to create a custom network within the network directory. Notice that multiple resources are grouped in the network module. In the main.tf file of the server directory, enter the code to create a virtual server. And that’s all there is to it! Two modules have been created. At this point, you created the modules and wrote the configuration code, but this process does not create the infrastructure resources. These modules are instantiated when they are called with the terraform apply command, which you’ll learn about in the next lesson.

### Video - [Modules use cases and benefits](https://www.cloudskillsboost.google/course_templates/443/video/508967)

- [YouTube: Modules use cases and benefits](https://www.youtube.com/watch?v=y_84qUm1EAo)

Let’s next look into where and how modules can be useful. Terraform is a tool for managing your infrastructure as code. But imagine having a single Terraform configuration file for managing your entire cloud environment. Sounds challenging, right? If you have a single Terraform file for all the infrastructure components within your environment, the code will be unreadable. As your business scales, your code inevitably will too. Thus you should break your code into reusable modules so that it’s readable and easy to manage. Modules are used to eliminate repetition. When a set of resources is repeated, the code becomes longer and more difficult to read. Modules are used to eliminate repetition. You can standardize the configuration by placing code in a module. This is useful for when a set of resources must be created in a specific way. When the module is called, the same source code will be used. For example, if you want to deploy database servers with encrypted disks, you can ensure encryption by hardcoding the encryption configuration in a module. You can then call the module when a disk has to be created. Now let’s explore the benefits of using modules in your configuration. First, modules enhance the readability of code by eliminating lines with a call to the source module. They’re reusable. You can write code once and reuse it multiple times across various environments. They’re abstract. You can separate configurations into logical units, reducing their dependency and making them easier to debug. With modules, you can also package sets of resource configurations for consistent resource replication.

### Video - [Reuse Configurations with Modules](https://www.cloudskillsboost.google/course_templates/443/video/508968)

- [YouTube: Reuse Configurations with Modules](https://www.youtube.com/watch?v=zj33IHhgGFc)

Now that modules are created, the next step is to call the modules from the parent main.tf file. To call a module means to reuse it in your configuration. You can call the module to reference the code in the module block. In this example, main.tf is the calling module. The parent main.tf file uses the source argument to call the server and network modules. Run the terraform init command to download any modules referenced by a configuration. The source argument determines the location of the module source code. Every module you call within Terraform requires a mandatory source argument, which is a meta-argument within the module block. This value can either be a local path within the root directory or a remote path to a module source that Terraform downloads. Different source types supported by Terraform include Terraform Registry, GitHub, Bitbucket, HTTP URLs, and Cloud Storage buckets This course covers local paths, Terraform Registry, and GitHub. Let’s start with the local path. Local path is used to reference a module stored within the same directory as the calling module. For example, if the module that you want to call is stored in a directory named “servers”, located in the same directory as your root module, your root configuration will look like the example on screen. A local path starts with either . / or . ./. Local paths are unique when compared to other module sources, because they do not require any installation. The files are locally referenced from the child module to the parent module directly. Therefore no explicit update is required. Terraform Registry contains a directory of publicly available modules for various infrastructure components, such as load balancers, SQL instances, and so forth. These publicly available modules are incredibly useful for complex deployments. The registry source address has to be in the format //. To use the code published in a Terraform Registry for the Google Cloud provider, use the format terraform-google-modules/gcloud/google. To avoid any unwanted changes to your Terraform configuration, it’s recommended that you use version constraint. The version argument can be assigned a version string. The version string allows Terraform to automatically upgrade the module to new patch releases while still keeping a solid target. Only the modules installed from the Terraform Registry support this constraint. After Terraform Registry, the most commonly used remote source is the GitHub repository. Similar to Terraform Registry, you can directly enter the GitHub URL where the source code is located.

### Video - [Variables and Outputs](https://www.cloudskillsboost.google/course_templates/443/video/508969)

- [YouTube: Variables and Outputs](https://www.youtube.com/watch?v=xxXDkFUQ1ks)

Now let’s examine how you can use variables to parameterize a module, and outputs to pass resource attributes outside a module. The examples covered so far all had hardcoded resource attributes. For example, the name of the network is hardcoded in the main.tf file within the server module. If you use the server module more than once, you will receive name conflict errors when you execute terraform plan or terraform apply. In such scenarios, you must have the flexibility to configure a few attributes differently in different environments, and standardize them in others. With variables, you can customize aspects of modules without altering the source code. Variables are also useful when working with different environments such as development, production, and staging. It’s a best practice to run a small machine type in the staging environment and a larger machine type in the production environment. Let’s view an example of how to parameterize the name argument with input variables. The first step is to replace the hardcoded values within your module with a variable. Assign the argument that you want to parameterize – in this case network name – by using the format var. . This assignment provides the flexibility to configure the name argument when the module is called. Then declare the attributes that are parameterized in the variables.tf file. Place the declared variables in the same directory as the defined resource. Be sure to specify the appropriate variable type. Pass the value to the input variable when you call the module. Since you parameterized the network name, you can now reuse the same network module twice in the main configuration and provide a different name for each instance. Remember to run the terraform init command to download any modules referenced in a configuration. Unlike root configuration, you cannot pass values to variables at run time. To pass resource arguments from one module to another, the argument must be configured as an output value in Terraform. For example, the network module includes the network name. The server module should receive the network name from the module that defines the network. If configured in two separate modules, pass this value by using the output values. To pass the network name from the network module, declare the network name as the output value to expose the resource attribute outside of the module. Then define the network name as a variable in the server module, so that it can accept the values passed outside the module. Now, in the main configuration, reference the output value when calling the server module. You can refer to the output value by using the format module... In our example, we refer to the output value of the my_network module using module.my_network_1.network_name. Notice that both modules are called from the root configuration. Each time a module is instantiated, terraform init has to be executed. After you run terraform init, you can pass the network name from the network module to the server module.

### Video - [Best Practices and a Real Time Scenario](https://www.cloudskillsboost.google/course_templates/443/video/508970)

- [YouTube: Best Practices and a Real Time Scenario](https://www.youtube.com/watch?v=876cSkIWFR8)

Finally, let’s examine some best practices for using modules. Don’t over-use modules. Modularize your code to keep your codebase DRY. Try not to fixate on eliminating all the duplications in your configurations. Duplication allows for more explicit configuration, and the infrastructure is easier to visualize. If you want to loop over multiple values, use Terraform features such as count or for_each instead of building your own custom scripting. Parameterize modules intelligently only if they make sense for end users to change. For example, in a custom network module, the MTU and routing_mode can be standardized, but its name has to be parameterized to ensure reusability. When considering parameterization, focus on the values that you must change. If a value is always fixed in your environment, hardcoding is okay. Use local modules to organize and encapsulate your code. Using local modules to organize your configuration from the beginning will significantly reduce the burden of maintenance as your infrastructure grows in complexity. Use the public Terraform Registry to find modules. By using modules from the Registry, you can quickly and confidently implement your configuration. Publish and share modules with your team. Modules can be used across your team to create and maintain infrastructure. You can publish modules either publicly or privately. To wrap up the module, let’s view a scenario describing how modules can help manage complex infrastructure in Terraform. In a typical application development environment, when a new feature is added or if an existing feature is modified, code is approved by passing it from development to staging, and then to production. Each environments has the same type of resources but differ in their quantity. Let’s assume that the current directory structure for this application includes development, staging, and production folders. When creating a new resource, the developer will add code to the development environment first. The code is then approved and tested. Without modules, the code is manually copied to staging and then to production. The solution is to define the reusable code within a module named server. Then, any change you make to the module is reflected across all the environments that you plan to reuse. You can now reference the code without having to make the changes manually across all the environments. In the example shown, the development, staging, and production environment can reuse the same module, but have different names and deploy a different number of servers.

### Video - [Lab Intro: Automating the Deployment of Infrastructure Using Terraform](https://www.cloudskillsboost.google/course_templates/443/video/508971)

- [YouTube: Lab Intro: Automating the Deployment of Infrastructure Using Terraform](https://www.youtube.com/watch?v=CcjYHY_N5QQ)

In this lab, you create a Terraform configuration with a module to automate the deployment of Google Cloud infrastructure. Specifically, you deploy one auto mode network with a firewall rule and two VM instances. The instance module allowed you to re-use the same resource configuration for multiple resources while providing properties as input variables. You can leverage the configuration and module that you created as a starting point for future deployments.

### Lab - [Automating the Deployment of Infrastructure Using Terraform](https://www.cloudskillsboost.google/course_templates/443/labs/508972)

In this lab, you create a Terraform configuration with a module to automate the deployment of GCP infrastructure.

- [ ] [Automating the Deployment of Infrastructure Using Terraform](../labs/Automating-the-Deployment-of-Infrastructure-Using-Terraform.md)

### Quiz - [Quiz: Organizing and Reusing Configuration with Terraform Modules](https://www.cloudskillsboost.google/course_templates/443/quizzes/508973)

#### Quiz 1.

> [!important]
> **What happens when a version argument is specified in a module block?**
>
> - [ ] Terraform automatically upgrades the module to the latest version matching the specified version constraint.
> - [ ] Terraform automatically downgrades the modules to the specific version.
> - [ ] Terraform automatically downgrades the module to the oldest version.
> - [ ] Terrafomr automatically upgrades the modules to the specific version.

#### Quiz 2.

> [!important]
> **State true or false. 
The source of a module can only be remote.**
>
> - [ ] True
> - [ ] False

#### Quiz 3.

> [!important]
> **Which code construct of Terraform helps you parameterize a configuration?**
>
> - [ ] Variables
> - [ ] Output values
> - [ ] Resources
> - [ ] Modules

#### Quiz 4.

> [!important]
> **What is the purpose of output values within modules?**
>
> - [ ] Parameterize a configuration.
> - [ ] Initialize Terraform to download the plugins.
> - [ ] Pass resource attributes outside a module.
> - [ ] Ensure that the syntax is in canonical format.

### Video - [Module Summary](https://www.cloudskillsboost.google/course_templates/443/video/508974)

- [YouTube: Module Summary](https://www.youtube.com/watch?v=LIu9abJHPXE)

This brings us to the end of Module 4. This module was all about – well – modules! In Terraform, modules are used to reuse configuration so you can write efficient, readable, and reusable code. Let’s review what was covered. You learned the definition of a module, viewed a few examples, and learned how you can use them to reuse configurations. In addition, you learned how to use input variables to parameterize configurations, and output values to access resource attributes outside the module. This module concluded with best practices and use cases for modules.

## Introduction to Terraform State

The module starts with an introduction to Terraform state. You'll then learn about the different ways to store Terraform state. Later in the module you'll explore the benefits of storing the state file in a remote location. While there are many remote locations in which you can store the state file, this module describes how to store it in a Google Cloud Storage Bucket. You'll wrap up the module by learning best practices for working with state files.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/443/video/508975)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=5eV35DA0WQo)

Hello, and welcome to the final module of this course: Terraform States. This one will be relatively short, introducing you to the basics of Terraform State. To ensure efficient Terraform workflows and foster collaboration, it is imperative that infrastructure changes are tracked and monitored. In Terraform, you can use the state to achieve these objectives. The Terraform State stores metadata for your infrastructure configuration, so you can keep track of your configuration. Put simply, as its name suggests, a state describes the state of your infrastructure resources. The module starts with an introduction to Terraform state. You’ll then learn about the different ways to store Terraform state. Later in the module you’ll explore the benefits of storing the state file in a remote location. While there are many remote locations in which you can store the state file, this module describes how to store it in a Google Cloud Storage Bucket. You’ll wrap up the module by learning best practices for working with state files. Let’s dive in.

### Video - [Introduction to Terraform State](https://www.cloudskillsboost.google/course_templates/443/video/508976)

- [YouTube: Introduction to Terraform State](https://www.youtube.com/watch?v=NbMqKWGLWZA)

Let’s get started with an introduction to terraform state. Terraform state is a metadata repository of your infrastructure configuration. Terraform saves the state of the resources that it manages in a state file. By default, state is stored locally in a file named "terraform.tfstate", but it can also be stored remotely, which is recommended for team environments. Terraform uses the local state to create plans and change your infrastructure. Before any operation, Terraform does a refresh to update the state with the real infrastructure. The primary purpose of Terraform state is to store bindings between objects in a remote system and resource instances declared in your configuration. When Terraform creates a remote object in response to a change of configuration, it will record the identity of that remote object against a particular resource instance. Terraform then potentially updates or deletes that object in response to future configuration changes. Every infrastructure component created within the resource block is identified by its name within the terraform state. When a terraform configuration is applied for the first time, infrastructure resources are created and a state file is automatically generated with a reference to the name mentioned in the resource block. If a resource already has an entry within the Terraform state file, then Terraform compares the configuration with the state file and the current live state. Based on the comparison, a plan is generated. When the plan is applied, it updates the resource to match the configuration defined. Once the configuration is applied, the Terraform state file is updated to reflect the current state of the infrastructure. If arguments cannot be updated in-place due to remote API limitations, then the resource is destroyed and re-created. If a resource is removed from the current configuration but has an entry in the state file, then terraform compares the configuration and destroys the resources that no longer exist.

### Video - [Storing State Files](https://www.cloudskillsboost.google/course_templates/443/video/508977)

- [YouTube: Storing State Files](https://www.youtube.com/watch?v=PZ96K8m4abQ)

Now that you’re familiar with state files and their purpose, let’s transition to state file storage. Terraform, by default, saves local state files in the current working directory with a . tfstate extension, so they don’t require additional maintenance. Local states work well when there’s only one developer working on a project. The default configuration can get tricky when multiple developers run Terraform simultaneously and each machine has its own understanding of the current infrastructure. If you’re working in a team where multiple developers are writing code to manage the infrastructure, then you should store state files remotely in a central location. That way when your infrastructure is changed, your Terraform state file is updated and synced, and your team will always be working with up-to-date infrastructure. Let’s examine some issues you may face when using local states for team environments. Local states do not have shared access. To update your infrastructure using Terraform, each member of your team needs access to the same state files. That means that those files must be stored in a shared location. You can’t lock local state files. If two team members are running Terraform at the same time, they might encounter RACE conditions because multiple Terraform processes are making updates to the state files. These conditions can lead to conflicts, data loss, and state file corruption. Local state files are not confidential. The information is in plain text, often exposing sensitive data such as database credentials. Now let’s observe how storing the state file in a remote location addresses these issues. First, when stored remotely, the state file is automatically updated. Once you configure a remote backend, Terraform will automatically load the state file from the backend every time you run the plan or apply commands. It will also automatically store the state file in that backend after each apply, so there’s no chance of manual error. Remote Cloud Storage buckets natively support state locking. The file can be locked so that if multiple developers run terraform apply simultaneously, it won’t be corrupted by simultaneous updates. Remote file storage is also more secure than local. Cloud Storage buckets natively support encryption in transit and encryption on disk. In addition, Cloud Storage includes several ways to configure access permissions, so you can control who has access to your state files. For example you can use IAM policies with a bucket. Though Cloud Storage buckets are encrypted at rest, you can use customer-supplied encryption keys to provide an added layer of protection. You can provide an extra layer of protection with the GOOGLE_ENCRYPTION_KEY environment variable. Even though secrets shouldn’t be in the state file to start with, always encrypt the state as an extra measure of defense. Let’s walk through how to store a Terraform state remotely in a Cloud Storage bucket. First, add the google_storage_bucket resource to a Terraform configuration file, such as main.tf. In the code snippet, the location field is hardcoded to US, meaning a multi-region bucket in the US will be created. You can change this field to a location of your choice. After you’ve added the code, run terraform apply to create the storage bucket. Next, add the code to a new Terraform configuration file called backend.tf. Ensure that the bucket name is updated to match the name of your new Cloud Storage bucket. Run terraform init to configure your Terraform backend. Terraform detects that you already have a state file locally and prompts you to copy it to the new Cloud Storage bucket. Enter yes. After you run terraform init, your Terraform state is stored in the Cloud Storage bucket. Terraform pulls the latest state from this bucket before running a command, and pushes the latest state to the bucket after running it. Here is a snippet of the state file from the Cloud Storage bucket. The state includes the metadata of the resources created, such as the resource type, resource name and the provider name.

### Video - [Terraform State Best Practices](https://www.cloudskillsboost.google/course_templates/443/video/508978)

- [YouTube: Terraform State Best Practices](https://www.youtube.com/watch?v=7vfaJqgvrEY)

Let’s explore some best practices for Terraform state optimization and security. First, use remote state for team environments, so that you can lock and version state files. Google Cloud customers should use the Cloud Storage state backend to lock the state, separate sensitive information from version control, and ensure that only the build system and highly privileged administrators have access to the remote state bucket. To prevent accidentally committing development state to source control, use gitignore for Terraform state files. Don't store secrets in a state. Many resource and data providers store secret values in plain text in the state file. Where possible, avoid storing secrets in a state file. To add an extra layer of defense, always encrypt the state file. Even though Cloud Storage buckets are encrypted at rest, customer-supplied encryption keys provide an added layer of protection. Don’t modify Terraform state manually. The state file is critical for maintaining mapping between the Terraform configuration and Google Cloud resources. Corruption can lead to major infrastructure problems.

### Video - [Lab Intro: Creating a Remote Backend](https://www.cloudskillsboost.google/course_templates/443/video/508979)

- [YouTube: Lab Intro: Creating a Remote Backend](https://www.youtube.com/watch?v=Gj7IhhXkjY4)

This is going to be a short lab. In this lab, you will create a local backend and then create a Cloud Storage bucket to migrate the state to a remote backend.

### Lab - [Creating a Remote Backend](https://www.cloudskillsboost.google/course_templates/443/labs/508980)

In this lab, you will learn how to create a local and remote backend.

- [ ] [Creating a Remote Backend](../labs/Creating-a-Remote-Backend.md)

### Quiz - [Quiz: Introduction to Terraform State](https://www.cloudskillsboost.google/course_templates/443/quizzes/508981)

#### Quiz 1.

> [!important]
> **State true or false.
A state file is stored by default in a local file named terraform.tfstate.**
>
> - [ ] True
> - [ ] False

#### Quiz 2.

> [!important]
> **Select the three benefits of storing a Terraform state file remotely.**
>
> - [ ] Usage analytics
> - [ ] Automatic insights
> - [ ] Sharing and delegation
> - [ ] Locking
> - [ ] Secure access

### Video - [Module Summary](https://www.cloudskillsboost.google/course_templates/443/video/508982)

- [YouTube: Module Summary](https://www.youtube.com/watch?v=YcFOSW8uQ_0)

This brings us to the end of the final module in the Getting Started with Terraform for Google Cloud course. You are now ready to use Terraform to write your own IaC configuration to manage your Google Cloud infrastructure. This short module covered the Terraform state and listed the benefits of storing the state in a remote location, including in a Google Cloud Storage Bucket. You also learned some best practices for states and applied what you learnt in the lab.

## Course Summary

In this final section, we review what's been presented in this course.

### Video - [Course Summary](https://www.cloudskillsboost.google/course_templates/443/video/508983)

- [YouTube: Course Summary](https://www.youtube.com/watch?v=o4jg24lFubo)

Rekha: Congratulations! You’ve reached the end of the Getting Started with Terraform for Google Cloud course. Eoin: This course covered a lot, from Terraform and its workflow, to Infrastructure as Code and configuration files, to modules and state files. Let’s recap the key points. Eoin: You learned how to describe Terraform, Infrastructure as Code, and the HashiCorp Language. All are tools for provisioning resources and managing infrastructure on Google Cloud. This course explained the features and functionalities of Terraform, as well as the benefits of IaC – a declarative, manageable, auditable, and portable approach to infrastructure management. You explored the Terraform workflow, from author to apply. This course also explored how to use Terraform code constructs such as resources, variables and output values to create Google Cloud infrastructure resources. We also explored how to build reusable components with modules. In addition to being reusable across your code, modules are a great way to improve readability. Finally, this course included an introduction to the state file, where infrastructure metadata is stored. Eoin: That’s it for this course. You are now familiar with Terraform, how to use it, and its benefits. Feel free to get started writing your own code to provision and manage your Google Cloud infrastructure using Terraform.

### Document - [Course Resource: All Slides](https://www.cloudskillsboost.google/course_templates/443/documents/508984)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

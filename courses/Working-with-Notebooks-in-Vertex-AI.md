---
id: 923
name: 'Working with Notebooks in Vertex AI'
datePublished: 2025-03-12
topics:
- MLOps
- Colab Enterprise
- Python
type: Course
url: https://www.cloudskillsboost.google/course_templates/923
---

# [Working with Notebooks in Vertex AI](https://www.cloudskillsboost.google/course_templates/923)

**Description:**

This course is an introduction to Vertex AI Notebooks, which are Jupyter notebook-based environments that provide a unified platform for the entire machine learning workflow, from data preparation to model deployment and monitoring. The course covers the following topics: (1) The different types of Vertex AI Notebooks and their features and (2) How to create and manage Vertex AI Notebooks.



**Objectives:**

- Explain Vertex AI Notebook Solutions
- Describe Vertex AI Colab Enterprise Notebooks
- Describe Vertex AI Workbench Notebooks
- Use Vertex AI Notebook Solutions

## Introduction

This course is an introduction to Vertex AI Notebooks, which are Jupyter notebook-based environments that provide a unified platform for the entire machine learning workflow, from data preparation to model deployment and monitoring. The course covers the following topics: (1) The different types of Vertex AI Notebooks and their features and (2) How to create and manage Vertex AI Notebooks.

### Video - [Working with Notebooks in Vertex AI](https://www.cloudskillsboost.google/course_templates/923/video/526704)

- [YouTube: Working with Notebooks in Vertex AI](https://www.youtube.com/watch?v=jbtOaql7-1o)

Video Name: T-AIMLGC-B_1_M0_L1_Coruse introduction Welcome to “Working with Workbench Instances and Colab Enterprise on Google Cloud. Welcome to “Working with Workbench and Colab Enterprise on Google Cloud. In this course, You learn to: Explain Vertex AI Notebook solutions. Describe Vertex AI Colab Enterprise notebooks Describe Vertex AI Workbench Instances Notebooks And use Vertex AI Notebook Solutions.

### Video - [Vertex AI Notebook Solutions](https://www.cloudskillsboost.google/course_templates/923/video/526705)

- [YouTube: Vertex AI Notebook Solutions](https://www.youtube.com/watch?v=MaC4lxpYZFE)

The machine learning workflow has three major phases. Data preparation, model training, and model serving. In data preparation, you’re collecting data based upon a business problem or use case and preparing it for input into a machine learning model. In model training, you’re using the data you collected to inform predictions for the use case. And after the model is trained and evaluated, you then need to deploy or serve that model into a production environment so that it can be used to make real-world decisions or predictions. The machine learning workflow is more complex than presented here. As such, there are three tools you can use to implement the workflow. You can use Automated Machine Learning or AutoML, which allows you to implement the workflow without writing a single line of code. You could use BigQuery Machine Learning, or BQML, which allows you to use SQL (or Structured Query Language) to implement the model training and serving phases, or You could use Custom Training, which allows you to use a programming language such as Python or TensorFlow to implement every phase of the workflow. Custom training a machine learning model requires writing code. The code you need to write is determined by the use case. The tool most used for writing code for data science projects, are Jupyter notebooks, which are interactive computing environments that allow users to create and share documents that contain live code, equations, visualizations, and narrative text. Notebooks are the development environment preferred by Data Analysts and Data Scientists. They are Interactive, meaning they let user’s run code and see results immediately This is important because data science/ analysis requires a lot of trial and error. You want to be able to iterate fast, and see the results right away. Google Vertex AI offers a one stop shop for managing the machine learning workflow. Vertex AI Notebooks offers: A Jupyter-based fully managed, scalable, enterprise-ready compute infrastructure with easily enforceable policies and user management Seamless visual and code-based integrations with data & analytics services And at-your-fingertips integration, meaning you can load and share notebooks alongside your AI and data tasks. Vertex AI offers two notebook solutions. With Colab Enterprise and Workbench Instances Jupyter notebooks you can: Manage the machine learning workflow from end-to-end. Use "Fully managed" compute, which refers to a computing infrastructure or service that is handled entirely by Google, relieving users of many of the operational responsibilities associated with managing and maintaining the underlying infrastructure, such as provisioning, scaling, monitoring, maintenance, and security. You can also establish a connection between your application, service, or system and various Google Cloud Platform (GCP) services. For example, you can also connect and work with Google BigQuery, a fully managed, serverless data warehouse. There is built-in support for Dataproc, a Google Cloud Platform managed version of Apache Spark, an open-source distributed processing framework built for large-scale data processing designed to run on clusters of machines. So, when should you choose Colab Enterprise or Workbench instances? Colab Enterprise is appropriate for users who don’t want to worry about managing compute, where they need Zero configuration and serverless infrastructure. It's great for projects that can be encapsulated in a single notebook. And it’s good for users who don’t want to worry about using Git because it has built-in version-control and sharing capabilities. Workbench is flexible, customizable, and a good choice for data scientist’s transitioning to Cloud from a workstation or laptop. It’s great for complex projects spanning multiple files, with complex dependencies. And it has native support for GitHub. Let’s briefly look at how Vertex AI Notebook solutions help manage the machine learning workflow. In data preparation and exploration, Vertex AI Jupyter notebooks facilitate seamless data access and integration with Google Cloud Storage, which allows for direct retrieval and manipulation of datasets stored in the cloud. Additionally, integration with services like BigQuery, Dataproc, and Spark streamlines data ingestion, preprocessing, and exploration tasks. Vertex AI Jupyter notebooks come with pre-installed libraries such as scikit-learn, TensorFlow, and Pytorch. This allows developers to utilize these libraries' functionalities directly within the notebook, streamlining the development process. And, running different machine learning model experiments to perform hyperparameter tuning and model evaluations can all be done in the library you choose. Vertex AI Jupyter notebooks streamline model deployment to production environments by using Vertex AI Pipelines, which automates the deployment process and ensures consistency between training and production environments. Vertex AI Monitoring allows for continuous monitoring of model performance in production, alerts users to potential issues, and ensures optimal model performance over time.

### Video - [Vertex AI Colab Enterprise notebooks](https://www.cloudskillsboost.google/course_templates/923/video/526706)

- [YouTube: Vertex AI Colab Enterprise notebooks](https://www.youtube.com/watch?v=8yRI8W1feRM)

Colab Enterprise is a great option if your project's priorities are collaboration and reducing the amount of time spent managing infrastructure With Colab Enterprise, users can Get up and running quickly with a zero-configuration experience. Be more productive through native integration with Duet AI. And, with easy collaboration capabilities like IAM based notebook sharing, commenting, and co-editing, achieve greater productivity and deployment speed. Vertex AI Colab Enterprise components consist of: A Notebook Editor Notebook storage And Runtimes. The notebook editor allows you to edit and execute notebooks. With Notebooks, you can combine executable code and rich text in a single document. Notebooks consist of cells, which can either be python code or text. When you execute a notebook cell the system automatically connects to an ipython kernel on a runtime. The code is executed by that kernel. Colab Enterprise uses Dataform to store notebooks (ipynb files). Colab Enterprise’s notebook storage offers similar functionality to Google Drive: versioning and sharing. Runtimes are virtual machines your code runs on. They come in two varieties: Default runtimes (or pre-defined runtimes), which are where Vertex AI automatically creates a VM for each user. And templatized runtimes (or long-lived runtimes). Administrators can create runtime templates that users can use to create new runtimes. These runtimes are flexible, configurable, and long-lived. We recommend using templatized runtimes if: You need to use GPUs. You want to use large machine shapes. And you want to install packages. Next, let's look at Colab Enterprise, which is located under NOTEBOOKs in the Vertex AI Tools panel. This image shows five numbered bubbles. Number one shows the location of Notebook storage, number two shows the notebook actions that you can choose by selecting the three dots, number three shows the location of the runtimes and the runtime templates selections, number four shows the notebooks editor, and number five shows an actual notebook code cell. When you create a new notebook, your userID is autopopluated. The notebook opens with some standard code: a “Welcome to Colab Enterprise'' text cell and a “Getting started” section with some sample code. You need to connect to a runtime before you can execute the code. In this example, the code cell below “Getting Started” uses numpy to generate some random data and uses matplotlib to visualize it. To edit the code, just click the cell. In the backend, clicking Create Notebook creates an industry standard . ipynb file. If you have an existing notebook, you can upload it to the service and your code will work. Let’s see how to create a runtime instance. Recall that runtimes are instances derived from runtime templates that allow users to run Colab notebooks. To create a runtime, you need to first create a runtime template. You begin by providing basic information, like a display name. Selecting the region the notebook will live in, a description, and any labels you want to identify and group templates. Next, you choose the machine configuration. You can use the default values, or you can set the accelerator and disk properties. Here, you can also set idle shutdown, which will shut the machine down after the specified time interval of inactivity in your notebooks (for example, no running commands or UI connection). You will not be charged for the CPUs or GPUs after shutdown. Disk charges still apply. Next, you can choose the network and security (which is also optional). Here you can specify network and security settings. The runtime template has been created and it shows default because everything was accepted, and no configuration was made optional. Now that you’ve connected to a Runtime, you can begin executing your code. One of the challenges with coding is that no one remembers all the code that is written in a particular programming language. So, Colab Enterprise offers in-line code completion and code generation. Simply type something in - like in this example df =, which is the beginning of code to bring data into a Pandas dataframe (in essence, you are connecting to a location where your data is stored and you want to bring it into the notebook). Duet AI gives you the entire statement. You can then just modify it to show the path to your dataset. Believe it or not, It gets better as it learns the context of what you are typing. One of the most important features of software development is the ability to track version history. This image shows revision history. Number one shows that revision history is a selection from the Actions menu. Number two shows that when revision history is selected, you see the changes side by side with a date stamp and color-coding to see the “old” in red and the “new” in green. And number three shows three options to view revision history: the raw source, the inline differences, or the source output. Another important need of software development is the ability to share and collaborate on your code by using notebooks. After you are ready to share, you must only select Share from the actions menu of a notebook. When you select “Share”, a share permissions window appears, which allows you to edit or delete permissions, or select "Add Principal" to grant new access. When you grant principals access to a resource, you also add roles to specify what actions the principals can take. Optionally, you can add conditions to grant access to principals only when a specific criteria is met. Principals are users, groups, domains, or service accounts. Roles are composed of sets of permissions and determine what the principal can do with this resource.

### Video - [Vertex AI Workbench instances notebooks](https://www.cloudskillsboost.google/course_templates/923/video/526707)

- [YouTube: Vertex AI Workbench instances notebooks](https://www.youtube.com/watch?v=GIJgpzxUoqU)

Recall that Vertex AI Workbench is a Jupyter notebook-based environment provided through virtual machine (VM) instances with features that support the entire data science workflow. Vertex AI Workbench Instances is a good option for projects that prioritize control and customizability. It’s great for complex projects spanning multiple files, with complex dependencies. It’s also a good choice for a data scientist who is transitioning to the cloud from a workstation or laptop. A Vertex AI Workbench Instance gives you a collaborative environment and version control when you use GitHub. Github is a web-based interface where users can collaborate on code projects, manage and store code, review and discuss changes, and track code changes over time. Vertex AI Workbench Instances comes with a preinstalled suite of deep learning packages, including support for the TensorFlow and PyTorch frameworks. With Vertex AI Workbench Instances, you can store ML models, features, and training sets and run your ML applications. And, just like Colab Enterprise, Vertex AI Workbench Instances has a notebook editor and notebook storage. Vertex AI Workbench Instances, however, offers more customization options. Vertex AI Workbench Instances offers a range of customization options to cater to the diverse needs of data scientists and machine learning practitioners. These customization options allow users to tailor their workspaces to their specific workflows, preferences, and project requirements. For example, Vertex AI Workbench Instances give you the most control over your Jupyter notebook environment. When creating an instance, select Advanced options to fully customize your notebook environment. There are seven steps to create a new instance by using advanced options. In step one, you configure the instance details. In the details window, you can give your instance a meaningful name, select the specific geographical location where you can run your resources, and enable access to the Dataproc kernel. Dataproc is a fully managed cloud service for running big data processing, analytics, and machine learning workloads on Google Cloud. You can add key and value pair labels to identify your instance, and assign tags to your network Vertex AI Workbench Instances resources. In step two you configure the instance environment. All environments use JupyterLab 3 by default and have the latest NVIDIA GPU and Intel libraries and drivers installed. You can also specify a previous version. Also, you can add metadata to your environment. In step 3, select the machine type. Machine types determine the specifications of your machines, such as the amount of memory, virtual cores, and persistent disk limits a notebook will have. If you need GPUs,which are graphical processing units that accelerate model training, ensure that the machine type you select supports GPUs. Shielded VM offers verifiable integrity of your Compute Engine VM instances, so you can be confident knowing your instances haven't been compromised by boot or kernel-level malware or rootkits. As a best practice, select Enable idle shutdown. The machine will be shutdown after the specified time interval of inactivity in your notebooks,Ffor example, no running commands or UI connection. There will be no charges for the CPUs or GPUs after shutdown. Disk charges still apply. In step four, select the data disk type. Data disk type refers to storage space. Storage space is much less expensive for a standard persistent disk. In cloud computing, a persistent disk is a type of storage that retains data even after a virtual machine (VM) instance is shut down or terminated. Persistent disks are typically used to store critical data that needs to be preserved, such as operating system files, application data, and user files. Other disk types are also available from the menu, such as an SSD or solid-state drive persistent disk, which is better for streaming throughput because they offer higher performance and lower latency than standard persistent disks. Persistent disk performance is tied to the size of the persistent disk volume. Here, you can select data disk size in gigabytes. Encryption in cloud security is the process of converting data into an unreadable format, known as ciphertext, to protect it from unauthorized access. The instance requires internet access to be used. In step five, select network values. Ensure that one of the following is selected: Either Assign an external IP address, where you select a network that has internet access or turn on Private Google Access. Private Google Access also allows access to the external IP addresses used by App Engine, including third-party App Engine-based services. Identity and Access Management (or IAM) and security determines who can use the instance's JupyterLab interface. This cannot be changed after the instance is created. In step six, select the IAM and security options. Specify whether anyone with a specific service account can access the instance account or restrict access to a single user. Alternatively, use the default Compute Engine service account. There are four security options, including allowing users to download a notebook or provide terminal access, which allows users to run shell commands from JupyterLab. Google Cloud continuously monitors and evaluates system health to ensure that Vertex AI provides a reliable, secure, and performant platform for machine learning development and deployment. In step 7, you configure system health. You can select environment auto-upgrade to automatically upgrade the instance if it's running. Under reporting, you can select report system health, which verifies the status of core services. You can also select to report custom metrics to Cloud Monitoring, which collects system status and JupyterLab metrics. Selecting Install Cloud Monitoring will report system and application metrics such as disk, CPU, network and process metrics. Lastly, you can report Domain Name Service (or DNS) status for required Google domains. This verifies the DNS status of domains for proxy registration and status event reporting. This image shows a newly created instance. It shows the instance name, the region the instance lives in, that it will be auto-upgraded, the machine type, GPU status,which is none,owner, and created date. What if you want to change or modify the instance configurations? Simply select the instance name to make edits to the configurations. Forget to add a GPU? GPUs or Graphical Processing Units, are specialized hardware designed to accelerate tasks. They are well-suited for the training and inference of machine learning models, because they can efficiently process large volumes of data. GPUs can accelerate data analytics and big data processing workloads by efficiently processing large datasets and performing parallel computations. To add a GPU, stop the instance, modify the hardware configuration by selecting GPU type and the number of GPUs, and then click the submit button. Here is your newly modified Vertex AI Workbench instance with a new GPU! Click OPEN JUPYTER LAB to see your new notebook. After creating an instance (or starting an existing one), click OPEN JUPYTERLAB to start the Jupyter Server on the browser. After you click, OPEN JUPYTER LAB, your Workbench notebook instance opens. Vertex AI Workbench instances offers seamless integration with BigQuery, Dataproc, and software libraries such as Python, Pytorch, and Tensorflow. For example, clicking the BigQuery icon opens the BigQuery and Query Editor. You can browse BigQuery tables and author SQL from JupyterLab. Here you can see a list of packages and separate notebooks for each. Note that there is a corresponding version using the Google console. Vertex AI Workbench instances also have support for Dataproc, which allows you to create, manage, and run computations on DataProc clusters. Notebook customization is the ability to control the main menu selections to interact with your notebook. Two important menu items that are used most frequently are “Run” and”Kernel”. Run helps you more efficiently run code in your project. Do you need to “restart the kernel”? Select the menu item. Restarting the kernel in Jupyter notebook refers to the process of terminating the current Python session and initializing a new one. This is often done when you encounter errors or unexpected behavior in your code, because it helps clear any cached data or variables that might be causing the issue. It can also be helpful if you made significant changes to your code and want to ensure that everything is working properly.

### Video - [Summary](https://www.cloudskillsboost.google/course_templates/923/video/526708)

- [YouTube: Summary](https://www.youtube.com/watch?v=4WY7ObBKg2Q)

tf1\ansi\ansicpg1252\cocoartf2758 \cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 ArialMT;} {\colortbl; ed255\green255\blue255; ed0\green0\blue0;} {\*\expandedcolortbl;;\cssrgb\c0\c0\c0;} \margl1440\margr1440\vieww11520\viewh8400\viewkind0 \deftab720 \pard\pardeftab720\partightenfactor0 \f0\fs29\fsmilli14600 \cf0 \expnd0\expndtw0\kerning0 \outl0\strokewidth0 \strokec2 \ \pard\pardeftab720\partightenfactor0 \cf0 Let\'92s summarize what you learned. \ \ Machine learning workflows can be very complex. And, some use cases require more \'93custom\'94 work than others. This \'93custom work\'94 is called \'93custom training\'94, where you are doing the coding. \ \ For example,\'a0\ \ Does your use case require you to share and collaborate code when preparing data, training models, and serving them to production? \ \ Do you need to modify Generative AI Studio prompts by using the Python SDK? \ \ Or use PyTorch, Python, or TensorFlow to build and train machine learning models? \ \ How about adding custom Docker container images? \ \ Then you need to use a Jupyter notebook. \ \ \pard\pardeftab720\sa240\partightenfactor0 \cf0 \strokec2 Data analysts can use Vertex AI Notebooks to analyze data. \ \pard\pardeftab720\partightenfactor0 \cf0 \strokec2 \ \pard\pardeftab720\sa240\partightenfactor0 \cf0 \strokec2 Data scientists can use Vertex AI Notebooks to train machine learning models. \ \pard\pardeftab720\partightenfactor0 \cf0 \strokec2 \ \pard\pardeftab720\sa240\partightenfactor0 \cf0 \strokec2 And Machine Learning Engineers can use Vertex AI Notebooks to deploy machine learning models into production. \ \pard\pardeftab720\partightenfactor0 \cf0 \strokec2 \ \pard\pardeftab720\sa240\partightenfactor0 \cf0 \strokec2 Essentially, the data analyst, data scientist, and ML Engineer can use Vertex AI notebooks in every phase of the machine learning workflow, all without having to worry about the underlying infrastructure. \ \ \pard\pardeftab720\partightenfactor0 \cf0 \strokec2 Vertex AI Jupyter notebooks use Google Cloud's secure and reliable infrastructure, which ensures data privacy, protection, and integrity. Regular security updates and patches maintain a secure environment and data confidentiality, and mitigate cyber threats. \ \ Vertex AI Jupyter notebooks seamlessly integrate with other Google Cloud AI services, such as Vertex AutoML for automated model development, Vertex AI Predictions for real-time model inference, and Vertex AI Explainable AI for interpreting model predictions. This integration expands the product capabilities and provides a comprehensive suite of tools for machine learning tasks. \ \ Jupyter notebooks can be scaled up or down based on computational needs, which ensures optimal resource utilization and cost-effectiveness. Pay-as-you-go pricing allows for flexible usage and aligns with resource consumption. \ \ Overall, Vertex AI Jupyter notebooks significantly enhance the machine learning workflow by providing a unified, collaborative, and scalable environment for data preparation, model development, deployment, and monitoring. The platform's integration with other Google Cloud services further expands its capabilities, which makes it a valuable tool for machine learning practitioners of all levels. \ \ \pard\pardeftab720\sa240\partightenfactor0 \cf0 \strokec2 \ }

### Quiz - [Working with Notebooks in Vertex AI: Quiz](https://www.cloudskillsboost.google/course_templates/923/quizzes/526709)

### Lab - [Exploratory Data Analysis using Bigquery and Colab Enterprise](https://www.cloudskillsboost.google/course_templates/923/labs/526710)

Exploratory Data Analysis using Bigquery and Colab Enterprise

- [ ] [Exploratory Data Analysis using Bigquery and Colab Enterprise](../labs/Exploratory-Data-Analysis-using-Bigquery-and-Colab-Enterprise.md)

### Lab - [Exploratory Data Analysis using Bigquery and Workbench Instances](https://www.cloudskillsboost.google/course_templates/923/labs/526711)

Exploratory Data Analysis using Bigquery and and Workbench Instances

- [ ] [Exploratory Data Analysis using Bigquery and Workbench Instances](../labs/Exploratory-Data-Analysis-using-Bigquery-and-Workbench-Instances.md)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

---
id: 255
name: 'API Security on Google Cloud's Apigee API Platform'
type: Course
url: https://www.cloudskillsboost.google/course_templates/255
date_published: 2024-04-05
topics:
  - OAuth 2.0
  - API Development
  - Cloud APIs
---

# [API Security on Google Cloud's Apigee API Platform](https://www.cloudskillsboost.google/course_templates/255)

**Description:**

In this course, you learn how to secure your APIs. You explore the security concerns you will encounter for your APIs. You learn about OAuth, the primary authorization method for REST APIs. You will learn about JSON Web Tokens (JWTs) and federated security. You also learn about securing against malicious requests, safely sending requests across a public network, and how to secure your data for users of Apigee.

Through a combination of lectures, hands-on labs, and supplemental materials, you will learn how to design, build, secure, deploy, and manage API solutions using Google Cloud's Apigee API Platform.

This is the second course of the Developing APIs with Google Cloud's Apigee API Platform series. After completing this course, enroll in the API Development on Google Cloud's Apigee API Platform course.

**Objectives:**

* Discuss the role of user authentication and authorization and the importance of API security.
* Identify capabilities available to secure, scale, and manage APIs and API products.
* Explore and put into practice API design, development and management concepts.
* Interact with the Apigee API Platform.

## Introduction

Welcome to API Security! This is the second course in the Developing APIs with Google Cloud's Apigee API Platform series.

### Video - [Course Series Introduction](https://www.cloudskillsboost.google/course_templates/255/video/466006)

* [YouTube: Course Series Introduction](https://www.youtube.com/watch?v=sYc68Qum0Hs)

Mike: Hi, I'm Mike Dunker, a course developer at Google. Hansel: And I'm Hansel Miranda, also a course developer at Google. Mike: We'd like to welcome you to Developing APIs with Google Cloud's Apigee API Platform. This is a series of three courses that will teach you API concepts and skills that will help you build great APIs. Hansel: We will teach you how to use Google Cloud's full featured API management platform Apigee to design, build, and secure your APIs. You will also learn about how Apigee's developer portal can allow app developers to discover your APIs and register apps to use them. We will also discuss how Apigee can help you manage and grow your API program. Mike: These courses are not just about how to use Apigee. These courses are also focused on the skills required of an API engineer. You will learn how to design APIs that follow best practices. You will learn about API security concerns and how to mitigate them. You will also learn how to productize your APIs. Hansel: These courses are intended for a technical audience. You will build an API from the ground up, completing a series of labs. Many of the labs build on each other, adding more features and security to your API. It is recommended that you take all three courses in order and complete the labs in order. Mike: These courses cover a wide range of topics, and the information may sometimes feel overwhelming. Take your time to absorb the content and make sure that you understand both the lectures and labs. When Hansel and I joined Apigee, we started with zero knowledge of Apigee and minimal knowledge of APIs. Hansel: We learned how to be API engineers during years of helping companies build their APIs and API programs. Mike: This course teaches you the skills, knowledge and best practices that we've found most important for API engineers.

### Video - [Course Introduction](https://www.cloudskillsboost.google/course_templates/255/video/466007)

* [YouTube: Course Introduction](https://www.youtube.com/watch?v=C4Ffs3G9ScA)

Hansel: Welcome to API security, the second course in developing APIs with Google Cloud's Apigee API platform. In this course, you will learn about different API security concerns and how you can use Apigee to secure your APIs to address these concerns. We will learn about OAuth, an authorization framework for APIs. You'll learn how to use OAuth for API authorization and how to choose between the different OAuth grant types, which represent the different scenarios that can be handled by OAuth. You will also learn about JWT tokens and federated security for APIs. We will discuss content-based attacks and how to protect against them. You will learn how to secure API requests and responses being sent across the internet. We will learn about internal security features in Apigee that allow us to control access for and hide sensitive data from users logged into the Apigee management UI. Finally, you will use labs to explore these security topics. You will continue to add functionality to a lab that was started in the API Design and Apigee Fundamentals course. If you have not taken that course, we recommend you take that course before you take this one. But don't worry. We'll provide a starting API proxy for you if you do not have the proxy from the previous course. You will add OAuth to your retail proxy and test using OAuth tokens with your proxy. You will also add JSONThreatProtection to your API proxy to protect against malicious JSON payloads, and you will store and use backend credentials in a way that prevents users of Apigee from seeing the credentials. Other labs will use regular expression threat protection to protect against dangerous patterns in your incoming requests. And you'll learn how to use private variables and data masking to keep users of the Apigee UI from seeing sensitive data while tracing API proxy traffic.

## Authentication, Authorization, and OAuth

This module introduces API security concerns, OAuth, JSON Web Tokens, SAML and OpenID Connect

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/255/video/466008)

* [YouTube: Module Overview](https://www.youtube.com/watch?v=5CSwWHCOdY8)

Mike: In this module, you'll learn about API security concerns. You will also learn about OAuth, an authorization framework for REST APIs. We'll discuss the OAuth grant types, the different scenarios that OAuth was designed to handle, and learn the authorization flows for the grant types and how Apigee can implement those flows. You will complete a lab where you will add OAuth to your retail API proxy. Finally, you will learn about JSON web tokens and the federated security standards SAML and OpenID Connect.

### Video - [API Security Concerns](https://www.cloudskillsboost.google/course_templates/255/video/466009)

* [YouTube: API Security Concerns](https://www.youtube.com/watch?v=3a4W_gDgS-o)

Person: In this lecture, you'll learn about API security concerns. API security is vital to ensuring that your apps and back end services are not compromised. There are many different aspects to API security, and this lecture will introduce you to many of them. We will be diving deeper into most of these topics in future lectures. If you read or watch the news, it seems like there are constant reports of data breaches. Many of those data breaches involve apps and APIs that were not properly secured. As APIs become more and more important to companies, securing those APIs is equally important. You want to make sure that you don't end up in the news for the wrong reason. Before we look at the different types of API security, let's categorize API exposure types. We'll call the first type public APIs. Public APIs are available and discoverable on the Internet. This public exposure means easy access for bad actors, and generally makes these APIs more prone to attack. Some public APIs might not have any sensitive data, and it is possible that you will not have to provide significant security for these. This is the exception, though, and not the rule. Most public APIs still deal with sensitive data, so you'll definitely need to authenticate callers and secure the APIs. The second type are private APIs. We often think of these as internal APIs. These APIs are not exposed on the Internet. We tend to worry less about securing these APIs. And yes, the attack factor is smaller. However, any sensitive APIs should still be secured. User data should always be protected, even for APIs you think will never be made public. Some security breaches happen using internal access. Note also that any sensitive APIs that are accessible outside your firewall should be fully authenticated and encrypted, even if the API's existence and details are not publicized. The most important point to remember is that all APIs require a thoughtful consideration of security. Even if you decide not to secure a particular API, which should be rare, you should always think about the security requirements when creating a new API. Now let's discuss some security considerations for your APIs. You'll learn about the different types of security that are required and how Apigee can help you provide the security for your APIs. One important security consideration is the infrastructure and network security of the API management platform. APIs cannot be secure unless the platform on which they are built is secure. Google has years of experience designing data centers, infrastructure, and networks that are secure by design. And Google Cloud leverages its infrastructure to provide a secure platform for APIs you build on Apigee. In addition, Google Cloud also provides powerful security tools that you can use to protect your APIs. Cloud Armor is a web application firewall that can protect your APIs against distributed denial of service and other types of attacks. ReCAPTCHA uses algorithms that apply continuous machine learning to protect against bots and other automated attacks. You often need to limit the rate of requests coming into your APIs, especially for public APIs. APIs can be overwhelmed when traffic is allowed to exceed back end service capacity. Rate limiting your APIs can reduce traffic to a reasonable level and allow requests to be serviced successfully. This can help ensure that app performance is maintained by not allowing certain apps or users to consume the majority of the bandwidth. Apigee has two rate-limiting policies available for your API proxies. The first is the Spike Arrest policy, which smooths traffic by allowing only a specific rate of traffic through. Overall traffic rates can be set for the API, or traffic can be rate limited by app, user, IP address, or any other variable. The second policy is the Quota policy. This policy sets a limit on the allowed number of requests over a specified period of time. The Quota policy does not enforce a rate at which those requests can be made. You'll learn more about the Spike Arrest and Quota policies in a later lecture. Sometimes you know that requests should only come in from specific IP addresses or ranges, or you want to block traffic from specific regions or IP addresses. The access control policy can be used to allow or deny traffic based on incoming IP address. A series of rules can be set up to allow or deny access based on IP ranges or specific IP addresses. When you provide an API that is to be used by multiple apps, you want to be able to track which app is making a request, and you want to make sure that only apps registered for the API can make a request. Apigee allows the creation of a unique API key for each app. API keys are associated with API products, which are used to grant access to specific APIs. API keys can also be revoked by the API creator when it is necessary to remove access for these apps. The Verify API Key policy will block any traffic that does not provide an API key that allows access to the requested API. Whenever your APIs manage user data, it is vitally important to protect that data by authenticating and authorizing app users. Apigee provides policies to help with authentication and authorization. The basic authorization, OAuth 2.0, JSON Web Token, and SAML policies can be used to provide authentication and authorization for your API proxies. We will discuss all of these policies in later lectures. Apigee proxies can also be used to integrate with other security providers or integrate with your own token services. Transport Layer Security, or TLS, should be used for all your APIs. TLS encrypts API requests and responses across the Internet, keeping your API data private. TLS should be enforced for requests from the client to your API proxies and for requests from your API proxies to your back end or third party services. Incoming requests should be secured using a domain validation certificate on a load balancer hosted in your Google Cloud project. Requests to back end services can be secured using TLS configured in Apigee. Both one-way and two-way TLS are supported. We will discuss this in a later lecture. APIs typically accept payloads of data to be saved in back end databases. A well-known category of data attack is called an injection attack. The point of an injection attack is to send untrusted data to a service causing the execution of the service to be altered. Your back end services may not be protected against all of these attacks, especially if they have previously only been used inside the company network. The Apigee API proxy provides an opportunity to inspect incoming data before passing it on to your back ends. The Regular Expression Protection policy allows you to craft regular expressions to detect dangerous content in the request. This policy can be used to check for patterns in the payload, headers, query parameters, or any other variables in your proxy. When a pattern match is found, the request is rejected and the back end is not compromised. Another type of data attack is an application-level denial of service attack, which tries to overwhelm the service so that it can't handle traffic. One form of this attack uses large or malformed JSON or XML structures to cause issues when they are being parsed. The malformed JSON or XML can cause a parser to use excessive memory, which may greatly reduce API capacity or stop the operation of the service. Apigee provides policies to protect against these larger malformed payloads. The JSON Threat Protection and XML Threat Protection policies detect these dangerous payloads without parsing them, protecting both the proxy and the back end from adverse effects. We will discuss these policies in a later lecture. It is very important to make sure you protect user data from being accessed by entities that should not be allowed access. In addition to locking down your APIs with authentication and authorization, you also need to consider access by your internal users, those logging into the Apigee management UI. Apigee provides some features to help you lock down internal access. You can block most users from being able to access production and trace production traffic by using role-based access control. Role-based access control allows you to set up roles and assign them to your users. Permissions can be enabled and disabled for a role, providing only the access that is required for a role. Support teams often need to be able to trace production traffic to help debug issues. You can keep users from seeing sensitive data when tracing production traffic by using the data masking and private variables features. We will talk about all of these features in a later lecture.

### Video - [Identity, Authentication, and Authorization](https://www.cloudskillsboost.google/course_templates/255/video/466010)

* [YouTube: Identity, Authentication, and Authorization](https://www.youtube.com/watch?v=2fB_NLsf9vE)

Mike: This lecture introduces the concepts of identity, authentication, and authorization with regard to APIs. Let's explore the differences between identity tracking, authentication, and authorization. Identity tracking is the act of determining the identity of the app or user for a request. Some part of the request is used to identify the caller or app. This is like asking someone for a ticket. A ticket could be required for access and may be associated with a particular person, but the ticket isn't proof that the person is who they say they are. Authentication is similar to identity tracking, except that some confidential information is used to prove that someone is who they say they are. Authentication is the process of validating credentials. Once the identity of the caller is authenticated, you can trust it. Authorization is determining what the app or user is allowed to do. Authorization can only take place after the app or user has been authenticated so that you are sure that you are granting access to the correct person or entity. Apps are generally identified using API keys. API keys are passed in with each request. This provides access to protected APIs and also allows you to track API usage by app. Users can be identified by information like username or account number. When you need proof of identity, use authentication. Authentication is the act of validating credentials to prove identity. For apps, the credentials are the app's consumer key and secret. User credentials are often username and password. A client certificate can also be used as credentials. Because you will use credentials to provide access and authorization for your APIs, protecting credentials is important. All authentication traffic must be sent using TLS. Authentication standards include Active Directory, LDAP, and OpenID Connect. Authorization is determining what a user or app is allowed to do. Authorization only makes sense if the user or app has been authenticated. Tokens are often presented as proof of authorization. API authorization standards include OAuth 2.0 and SAML 2.0. Here are examples of how identity, authentication, and authorization are specified in an API request. An API key is often passed using a query parameter. It is recommended, though, that the API key be passed in the header because a header is less likely to be logged in access logs. The authentication for a user or app is usually put in a basic authentication header. The basic auth header is used when passing some form of a username and password in an authorization header. For a user, it might be a username and password, and for an app, it is generally the consumer key and secret. An access token, which is used for authorization, is generally passed in the authorization header as a bearer token.

### Video - [OAuth Introduction (1)](https://www.cloudskillsboost.google/course_templates/255/video/466011)

* [YouTube: OAuth Introduction (1)](https://www.youtube.com/watch?v=ucq9KiVH8ho)

Mike: Let's discuss OAuth, an authorization framework for APIs. The first obvious question is, what is OAuth? Let's parse this statement. OAuth is an authorization framework for APIs, which can be used to control permissions for accessing APIs. There are currently two versions of OAuth: 1.0a and 2.0. Version 1.0a is deprecated. Version 2.0 is the current industry standard, and this is supported by Apigee. When we discuss OAuth during the rest of this course, we are referring to OAuth 2.0. OAuth allows users or clients to grant access to server resources to another entity without sharing credentials. This is a key feature of OAuth. You can grant access to resources without sharing the user or client credentials that would typically be used to access the resources on the resource server. You grant access by using an access token. We'll parse this statement too. Access tokens are issued to allow limited access to specific resources. An authorization server issues OAuth tokens. In the examples we'll be seeing in this course, Apigee is acting as the authorization server. You may, however, want another authorization server to issue the tokens, maybe one in your backend data center, and Apigee can use that model too. Limited access to specific resources means that the token does not need to provide full access to the resources of the user. Access tokens are also valid for a limited time. Limiting the time for an access token limits the exposure in case the token is compromised. Access tokens can also be revoked, making them no longer valid. A revoked token has no access. Revocation can be initiated by either the user that originally granted permission to access the user resources or by the issuing server. If either the user or issuing server believes the access token has been compromised, the token should be revoked. We will learn more about access tokens during the next several lectures. Let's introduce some other terms you'll need to know. Grant types specify the different kinds of authorization scenarios that OAuth has been designed to handle. There are four grant types specified by the OAuth 2.0 specification. OAuth client IDs and secrets are used to identify and authenticate apps. For Apigee apps, the consumer key and consumer secret are used as the client ID and client secret respectively. Scopes can be used to limit the access for a specific access token, granting permission only for necessary operations and access. I've already mentioned TLS, or transport layer security. You may also know it as SSL, or secure socket layers, or you may know it as HTTPS. TLS is the successor to SSL, and SSL should no longer be used. TLS is how API requests and responses are encrypted between the client and service. OAuth has a strict requirement that all OAuth traffic be encrypted, including any API request containing a token. This will protect entities like tokens, client IDs, and client secrets from being compromised. Here are some terminology we'll use regarding types of apps. First, apps can be considered confidential or public. Confidential apps can keep secrets confidential. This means that tokens and client secrets are stored in a way that they cannot be accessed. Public apps are those that are not confidential. You can't store secret information in public apps because they cannot be secured. A couple of examples of public apps are client-side web apps and native mobile apps. The storage for code running locally in a browser or in a mobile app on a phone or tablet can be accessed by a bad actor. Whether an app is confidential or public affects how OAuth is used for the app. Second, apps can be considered trusted or untrusted. Trusted or untrusted indicates whether the app could be trusted with seeing your password. First-party apps made by a company that is also storing the data being accessed may be considered trusted apps. Third-party apps would always be untrusted. User credentials should never be entered into untrusted apps. For example, if you were logging into a game app using your Google account to confirm your identity, you would definitely not want the game developer to have access to your Google password. This game app would be an untrusted app. OAuth can be used to allow that app to get specific information about you from your Google account without ever providing it with your password or giving it full access to your account. We'll learn more about how this works in a later lecture. You should generally classify your app as public or confidential and trusted or untrusted. This will help you choose the OAuth grant type to use.

### Video - [OAuth Introduction (2)](https://www.cloudskillsboost.google/course_templates/255/video/466012)

* [YouTube: OAuth Introduction (2)](https://www.youtube.com/watch?v=P7M4AuYmI88)

person: Let's learn a bit more about access tokens. As we said before, an access token allows a specific application limited access to protected resources for a limited period of time. Apogee OAuth access tokens are opaque strings. There is no encoded or encrypted information in the token. An access token is just a random set of characters. This means that all of the interesting information about the token is stored in the authorization server. When you use an access token, in a request to a protected resource, put the access token into the authorization header and pass it as a bearer token. We'll see how to do that later. How do you get an access token? First, the application needs to authenticate with the authorization server. In Oauth, this is done using the client ID and client secret of the app. In apps created on Apogee, they are called the consumer key and consumer secret. Second, the owner of the resource or resources, if it is the user of the app, needs to authenticate with the authorization server using their credentials. This confirms that the user of the app is who they say they are, and that they want to grant the application access to the resource or resources. OAuth can also be used to access nonuser resources like application data. In this case, there would be no resource owner credentials, just the application credentials in the form of client ID and secret. Third, a scope can be provided which is optional. This would indicate the level of access that should be allowed for the token. The app credentials resource, owner credentials and scope can be used to get an access token and optionally a refresh token. A refresh token is used to reauthorize the granted access by allowing the app to obtain an access token without the user credentials. The refresh token would be used when the previous access token expires, and it's no longer valid. Like the access token, a refresh token is an opaque string. How do you use a refresh token to get a new access token? Just like the original access token request, the app provides its client ID and secret to authenticate with the authorization server. In this case, the refresh token is used instead of the resource owner credentials. This means that the user would not need to re-enter their username and password. An access token generally has a fairly short lifespan to limit the damage that could be done if it were compromised. A common expiration time for access tokens is five minutes. Can you imagine the user experience for an app if a user had to enter their username and password every five minutes. This is why we use refresh tokens. The scope is again optional. You cannot use a scope that has more access than was originally used when creating the first access token. If the app provides its client ID and secret, the refresh token and optionally a scope, a new access token can be generated. A new refresh token can also be created. In a later lecture, we will see why it is recommended to create a new refresh token every time you use a refresh token. A scope identifies what an app can do with a requested resources when using the access token. The authorization server defines both the scope names and access allowed for a particular scope. Requests containing tokens without the correct scope can be blocked by an API proxy using the verify access token policy. Let's look at the example on the left. For this photo editing service, there are two scopes. The first scope is called read, and it allows read only operations on the user's photos. The second scope update allows the read operations, but also allows creation of new photos using post and updates to existing photos using put. Remember that OAuth grant types specify the different authorization servers that OAuth is designed to handle. We will review the details of the different grant types in the next lectures. But let's discuss the different grant types and when you should use them. First is the client credentials grant type. It is designed for system to system interactions. For example, this may be a partner service calling into your API. It is used only when there are no user resources involved. The second is called the resource owner password grant type, often just called the password grant type. This grant type and the following grant types can be used when user resources are involved. The password grant type can only be used when an app is trusted. For this grant type, the user's credentials are passed through the app to the authorization server. Because the app has access to the user's credentials, it makes sense to use this grant type only if the app was created by the same company that hosts the resources being accessed. The third is the authorization code grant type, also called the auth code grant type. This grant type can be used when the app is untrusted. We'll see later how the auth code grant type allows a user to pass credentials to the authorization server without the app gaining access to them. The fourth is the implicit grant type. This was originally designed for client side browser or mobile apps. Remember, we call these public apps as opposed to confidential apps. The implicit grant type is no longer recommended even when using a public app. Instead, there is a way to use the auth code grant type with a public app, and you'll learn how to do that when we discuss the auth code grant type in a later lecture. All of the grant types follow a common pattern. The app determines a need for a token, requests a new token, and finally uses the token to gain access to the protected resource. Note the three entities shown at the top of the interaction diagram. The client is the app making the requests, Apogee is the API gateway. Tokens are issued and validated by proxies running on Apogee. The backend service provides access to protected resources. First, the client determines the need for a new access token. This often happens when apps try to access a resource using an access token that is expired. The Apogee proxy detects that the token is no longer valid and rejects the request, returning 401 unauthorized. The request to access the resource is not sent to the back end. The client then requests creation of a new token. This process is different for each grant type and we'll cover each grant type's flow during the next lectures. After getting a new access token, the client retries the request, Apogee validates the token and because it is valid, proxies a request to the backend service and retrieves the resource. Notice that once a token is created, it is generally used in the same way regardless of the grant type being used. In the next lectures, you will learn much more about the specific grant types, focusing on use cases and how tokens are created.

### Video - [OAuth Client Credentials Grant](https://www.cloudskillsboost.google/course_templates/255/video/466013)

* [YouTube: OAuth Client Credentials Grant](https://www.youtube.com/watch?v=L7Khhzh22rY)

Person: In this lecture, we will talk about the client credentials grant type. We will review the use cases for the client credentials grant type, learn the details and interactions for the grant type and see which policies should be used and how they should be configured. The client credentials grant type is generally used for business system server-to-server interactions. This is often used for providing access to internal or partner data. Another use case is authorization for publicly available APIs. These services may be paid or may have usage limitations. Using the OAuth client credentials grant type is an excellent way to control access to these services. The number one rule to remember for the client credentials grant type is to never use it when protected user data is being accessed. This grant type does not collect any user credentials, so the user has no chance to authenticate or consent to an app gaining access to the data. The first participant in the client credentials grant type interaction is the confidential client consuming the API. The client must be confidential because the client credentials grant requires a client secret. The Apigee proxy generates tokens. It also rejects request request to the back end if the provided token is not valid. The last participant is the back end service which serves the protected resources. Unlike the other grant types, the client credentials grant type does not return a refresh token. A refresh token is used to avoid sending in user credentials when refreshing an access token, and because there are no user credentials involved when using the client credentials grant type, the refresh token is unnecessary. This is the overall flow for the client credentials grant type. Access tokens are used in the same way for all grant types, but the access token creation process is different for each type. The overall flow diagram will be shown for each grant type, and the intention is to show you the relative complexity of each grant type. For each grant type, we will look at the detailed flow for token creation. Let's look at how tokens are created for the client credentials grant type. The first thing to note is that the back-end service has no part in token creation for any of the grant types. The client makes the client credentials request by sending a post request to a token end point. In this case, we show a post to /token, but your API path can be different. It is important to have the request be a post because get requests can be bookmarked or cashed, which is not appropriate for token requests. Typically, the OAuth token creation functionality is implemented in a proxy that is separate from the proxies that use your back end services. The post parameters are sent using form parameters in the request payload. The grant type is specified as client credentials. The client ID and client secret for the app are also sent which allows the app to be authenticated by the OAuth proxy. For all grant types, a token should only be used by the app that created it. An optional scope is passed in as well. The OAuth proxy validates the client ID and secret and, if valid, returns an access token and information about the scope of the token and the expiration time. Remember that there is no refresh token generated because there are no user credentials for this grant type. The OAuth proxy will use an OAuthV2 policy to create the token. The OAuthV2 policy is used in many different ways in our proxies. Its behavior is controlled by the operation element. In this case, the operation is generate access token. The ExpiresIn element specifies the time to live for the token in milliseconds. The grant type element specifies where the grant type should be found in the request. This example shows the grant type being passed in the form parameter grant_type. This form parameter is the default location. If the grant type element is not included, the grant_type form parameter is the expected location. The generate response element specifies whether the policy should automatically generate the API response payload. When the policy runs, it creates lots of variables for all of the information about the token. You can create your own response format by setting generate responses enabled field to false and then using the variables set by the policy to craft your own response. Let's look at an example request and response when getting a new token using the client credentials grant type. We post our request to the token end point. The client ID and client secret are encoded in the authorization header. We use basic authentication, often shortened to basic auth. The credentials are the app's consumer key and consumer secret separated by a colon with that entire string being base 64 encoded. The header value is the capitalized word BASIC and then a single space followed by the base 64 encoding credentials. It is important to note that base 64 in coding is not encryption. If you have base 64 encoded credentials, you can decode the string and retrieve the original credentials. We count on TLS to encrypt the request in response, protecting the data while it travels across the network. The payload contains URL-encoded form parameters, specifying the content type header as applications/X-www-form-urlencoded indicates that the payload contains form parameters. For the client credentials grant type, the only required form parameter is grant_type, although you may pass in a scope if necessary. The response shows the default response format returned by Apigee. The access token and expiration time are typically important for the app. The expiration time returned here is in seconds. The policy configuration uses milliseconds. Many of the other fields have default values or are unnecessary, so you may choose to return a simpler response format. Once you have a token, always use it in the same way. When you make a request to a protected resource, include the token in the authorization header as a bearer token. The Apigee proxy for the back end can verify the access token using an OAuthV2 policy with the operation VerifyAccessToken. You generally don't need to include any other information in the policy, including the location to find the token. As long as you pass a bearer token using the authorization header, which is the default location for OAuth, you don't need to specify the location. The VerifyAccessToken operation will ensure that the token is valid and not expired. It will then verify that the products associated with the app that created and presented the token are allowed access to the proxy and URL being called. If the token is invalid or expired, or it does not grant access to the called proxy and URL, the policy will return a 401 unauthorized.

### Video - [OAuth Password Grant](https://www.cloudskillsboost.google/course_templates/255/video/466014)

* [YouTube: OAuth Password Grant](https://www.youtube.com/watch?v=hDWthpvuB00)

person: The password grant type is the second OAuth grant type. We will reiterate the use cases for the resource owner password grant type, review the interactions, and see how policies can be used to implement this grant type. The resource owner password grant type is usually called the password grant type. The password grant can be used when protected user data is being accessed. The password grant is appropriate only for a trusted app provided by a company that already has access to the data. If there's any reason for a user to be uncomfortable about providing credentials to the app, and therefore to the app developer, the password grant types should not be used. The primary benefit of the password grant is that there is reduced friction when logging into the app. We will see in the next lecture that the authorization code grant involves leaving the app to enter credentials and consent in a web browser. However, the auth code grant is significantly more secure. And many companies use the auth code grant instead of the password grant, even for first party apps. The first participant for the password grant is the confidential and trusted app that consumes the API. The client must be confidential, so it can protect the client secret, and it must be trusted because the user's password will be passed through the app. Like the client credentials grant type, the apigee proxy generates tokens and rejects requests to the backend if the provided token is not valid. There is now an app user involved who is granting permissions to their protected resources. Another new participant is the authorization server responsible for validating user credentials. The last participant is again the backend service, which serves the protected resources. Unlike the client credentials grant, the password grant generates a refresh token along with the access token. One key item to remember when implementing the password grant is to never run the password grant OAuth flow in client side code when running on a device. App code and storage on a device are susceptible to hacking. So the client secret could be compromised if stored locally. This is the overall flow for the password grant type. Highlighted in light blue are the parts of the flow that differ from the client credentials grant type flow. The app must be a trusted and confidential app. The user must trust the app because the user's username and password will be provided to the app. There is now an authorization server involved. The authorization server maintains the usernames and passwords for the users. In the post request to the OAuth proxy, in addition to the grant type, client ID and secret and optional scope, we also pass the username and password of the user that is granting access to the protected resources. After the proxy validates the client ID and secret, the user credentials must be authenticated. Apigee calls the authorization servers authorization endpoint with the username and password of the user. The authorization server validates the username and password and returns details about the user if the user credentials are valid. If the user credentials are not valid, the authorization server returns an error, and the OAuth proxy returns an error back to the app. If authentication of the user is successful, the OAuth proxy creates an access token and refresh token for the app that provides access to the protected resources. Typically, the proxy also attaches custom attributes to the access and refresh tokens. These attributes contain any user details returned from the authorization server that the backend service will need. These custom attributes are available when a token is validated. The returned information is the same as for the client credentials grant type, except the response includes a refresh token. The token is used by the app in the same way as the token is used for the client credentials grant. Upon validating the token, the apigee proxy has access to the user details that were attached as custom attributes. The user details can be sent to the backend service if required. The configuration of the Generate Access Token OAuthV2 policy for the password grant type is similar to the configuration for the client credentials grant type, with just a few differences. The refresh token expires in element contains the refresh token expiration in milliseconds. The username and password elements tell the policy where to find the user's username and password. The form parameter values shown are the default locations as defined by the OAuth spec. Note that the policy does not and cannot validate the values of username and password because the credentials are not stored on apigee. The policy only verifies that the locations specified have nonempty values. The proxy developer must make the proxy call the authorization server to validate the values in those locations. The app end user element specifies a variable containing the ID of the end user. This is typically a username or email address. The example configuration also specifies that an attribute, backend.data, be populated using the received data variable and attach the access and refresh tokens. If the received data variable is empty or doesn't exist, the attribute element's value--none-- is used instead. This attribute is automatically populated as a variable in the proxy when the token is verified. To request a token using the password grant flow, the API request is identical to the client credentials request, except that the username and password are passed as form parameters. For the response, the access token and expires in fields are the same as with the client credentials grant type. The password grant type response has additional fields for the refresh token and its expiration. If the app end user has specified, it will also be returned in the response. The call to the protected resource is identical for all grant types. The token is sent using a bearer token in the authorization header.

### Video - [OAuth Authorization Code Grant (1)](https://www.cloudskillsboost.google/course_templates/255/video/466015)

* [YouTube: OAuth Authorization Code Grant (1)](https://www.youtube.com/watch?v=8R2-K7otEtI)

Mike: The authorization code grant type, also called auth code grant type, is the third OAuth grant type. We will reiterate the use cases for the auth code grant type, review the interactions, and see how policies can be used to implement this grant type. We will also see how to use the auth code grant in place of the implicit grant. Like the password grant type, the auth code grant can be used when protected user data is being accessed. But unlike the password grant type, the auth code grant can be used for both trusted and untrusted apps. The auth code grant is designed to allow a user to authenticate without exposing their credentials to the app. In addition, the user is given full visibility and control over the app access using scopes. Finally, the auth code grant is the best choice when the app developer doesn't want to maintain passwords for its users. An app can use the auth code grant to use accounts with common providers like Google, Twitter, and Facebook to identify the app's users. This can also be a benefit for users because they don't need to maintain separate accounts and passwords for all of the apps and services they use. The first participant for the auth code grant is the client that consumes the API. The client may be trusted or untrusted. In addition, the client can be confidential or public. For public apps, you learn how to add an OAuth extension called Proof Key for Code Exchange, or PKCE, to the auth code grant for public clients that cannot protect a client secret. There is a user involved who is granting permission to their protected resources. The Apigee OAuth proxy generates tokens, and the API proxies to the backend services will reject requests to the backend when the provided token is not valid. The authorization server is responsible for validating user credentials and maintaining the list of scopes that can be used for protected resources. A new participant is a user agent or browser that is used to communicate with the authorization server. The last participant is again the backend service, which serves the protected resources. And like the password grant, the auth code grant generates a refresh token along with the access token to avoid having to reenter or save the user's password too often.

### Video - [OAuth Authorization Code Grant (2)](https://www.cloudskillsboost.google/course_templates/255/video/466016)

* [YouTube: OAuth Authorization Code Grant (2)](https://www.youtube.com/watch?v=wOQcQOhH04s)

Person: Here's the flow for the authorization code grant type for confidential apps. I don't expect you to be able to read the diagram on this page, we will go through the details in the next slides. You can see that this flow is significantly more complex than the password grant type flow. With that added complexity, we get better security. Let's get started. Let's first look at the new participant in the interaction, a user agent, typically a browser allows the user to interact directly with the authorization server and not through the application. This prevents the user's credentials from being exposed to the app. You've probably encountered the OAuth authorization code flow before. When you try to log into an app or website with your Google credentials, and you are directed away from your app to a direct browser connection with Google, you are using the Auth code flow. This flow allows the user to log in and confirm the level of access requested directly with Google and not through the app. The authorization process is initiated by the application with a call to an authorization endpoint in the Apigee OAuth proxy. The response type of code indicates that we want to get an authorization code, typically shortened to auth code from the authorization server. The auth code will eventually be returned to the app, and the app will exchange the auth code for an access token and refresh token. We will see this entire process shortly. In this initial request, the app sends its client ID, but not its client secret, the client secret will be sent later when the app exchanges the auth code for a token. The app also sends the requested scope and a redirection URI. The redirection URI will be used by the authorization server to redirect the auth code into the app, after the user has authenticated and consented to the scope. More about the redirection URI later. The app may also send an optional state parameter that will be returned when returning from the user authentication process, allowing the app to resume processing the request. The state is exposed to the OAuth proxy and the authorization server, so it is best not to send sensitive information in the state. The proxy validates the client ID and verifies that the redirect URI passed by the app matches the redirect URI associated with the Apigee app. An apps' redirect URI is configured by the app developer when registering the app on Apigee. Assuming that the client ID and redirect URI are valid, the proxy redirects the app to the authorization servers login page with the scope state and client ID as query parameters. Note that the return client ID value is shown as the auth client ID. This client ID will be used to identify the app for the login page. The app is registered with both Apigee and the authorization server, that authorization server registration may use a separate client ID for the app, if so, the OAuth proxy needs to map the Apigee client ID to the separate client ID used by the authorization server and include the authorization server client ID in the login page URL. The app redirects to the login page within the browser outside of the app. During this next section of the flow, the user interacts with the browser and not the app. You'll notice that neither Apigee nor the app is part of the interaction. This direct interaction between the user and authorization server ensures that the user can safely authenticate and provide consent for the level of access being requested by the app. This interaction provides a level of security that the password grant type clearly it does not. Let's see how this interaction works. The browser opens the login page URL, which includes the scope, state and client ID query parameters, and it's typically a webpage on the authorization server. The login page is returned to the browser, which displays the page. The user interests or credentials to authenticate, and the login page is submitted. After the authorization server confirms the user's identity, the consent page is returned and displayed in the browser. The consent page specifies the application requesting access and provides a human readable description of the scope or scopes that have been requested. You've probably noticed this type of page before, for example, if you use your Google account to log into a third-party app, the consent page might say that the app is requesting access to your email address and name. This is a reasonable level of access for an app that is only using Google for a login account. Another app might legitimately need the ability to read or write documents in your Google drive, and that access might be requested. A malicious app might request full access to your account, which you don't want to provide. The consent page is where Google or whichever authorization services being used, can confirm that the user is informed of the requested level of access for the app and capture consent. Because the app is not involved in this process at all, the app cannot request access without the user knowing, and the app cannot get access without the consent of the user. This is a key strength of the off code grant type. When the consent page is submitted to the authorization server, the authorization server begins the process of creating the auth code. The response to the browser will only happen after the auth code has been created. The process for creating the auth code is not specified by the OAuth specification. A solution that uses a call from the authorization server directly to an OAuth proxy is shown here. The authorization server posts a request to an OAuth proxy to create a new auth code. The client ID required by the proxy is the Apigee client ID for the app. If the authorization server does not know the Apigee client ID, the proxy must map the authorization server client ID to the Apigee ID. The redirect URI sent by the authorization server must match the redirect URI configured for the app on Apigee, the scope parameter contains the scope to which the user consented. The state is the original state passed with the first request. The app configuration on the authorization server might be configured to send extra information about the user, like the name or email address, this information could then be attached to the auth code and then the access and refresh tokens, so that the user data would be available for calls using the access token. This requires a custom implementation, but we'll show it here. The OAuth proxy validates the client ID and matches the provided redirect URI with the redirect URI registered for the app on Apigee. If these validate successfully, the OAuth proxy creates an auth code. This auth code is associated with the Apigee app client ID and the user consented scope. The user specific information can also be attached to the auth code as custom attributes, just like the access and refresh tokens, an auth code is an opaque string with no in-coded information. All of the configured information for the auth code is stored on Apigee. The OAuth proxy returns the redirect URI with the auth code and state as query parameters. This URI is used by the authorization server to redirect the user's browser back into the app. This redirect URI generally uses a specially formatted URI with a custom scheme, for example, instead of https://, the URI for the Fu app might start with Fu://. This app scheme name could be registered for Android and iOS. And opening a link with this scheme on the device would open the Fu app instead of the browser. The browser then redirects back into the app and the app can now extract the auth code in the original state from the URL. Next the app will exchange the auth code for an access token and refresh token. The app posts a request to the OAuth proxy to exchange an auth code for an access and refresh token. The grant type is specified as authorization code. The authorization code and redirect URI are passed in. The app has not yet been authenticated, so both the client ID and client secret will be sent via the basic authentication header. The client ID, secret and redirect URI are all validated. The auth code is checked to make sure it is valid and that it is associated with the app. The auth code is then used to create the access and refresh tokens. The tokens are provided with the user consented scope that was specified for the auth code, the tokens automatically inherit any user specific info that was attached to the auth code as custom attributes. Finally, the access token and refresh token are returned to the app. At this point, the app uses the access and refresh tokens as they're used for the other grant types. Token use is the same as for the password grant. If you were able to understand all of that during the first pass, congratulations, most people do not understand the auth code flow without going through the flow a few times. So go ahead and rewind, if you want to review the flow, try to understand the information being passed between the participants and why the information is being passed the way it is. Another recommendation is to read RFC 6749, which is the OAuth 2.0 authorization framework specification.

### Video - [OAuth Authorization Code Grant (3)](https://www.cloudskillsboost.google/course_templates/255/video/466017)

* [YouTube: OAuth Authorization Code Grant (3)](https://www.youtube.com/watch?v=DW-hnJOPNvU)

Mike: Now let's look at the auth code solution for public clients. When the OAuth spec was originally released, the implicit grant type was the recommended solution, but there are security issues with the implicit grant type. The current recommendation is to use the authorization code grant type with PKCE instead. The problem with public clients is that they cannot safely store secrets. Mobile apps and client side JavaScript apps are examples of public clients. The TLS communication used for OAuth is secure over the network, but the redirect on the mobile device may not be secure. The redirect URL contains the auth code. If the auth code is compromised, how do we keep the bad actor from exchanging the auth code for an access token if we can't require a client secret? The answer is that we use the OAuth extension called Proof Key for Code Exchange, known as PKCE. PKCE is specified in RFC 7636. PKCE uses cryptography to guarantee that the client exchanging an auth code for tokens is the same client that started the original auth request. This is the flow for auth code with PKCE. Most of the flow is the same as for auth code without PKCE. Let's look at the changes to the auth code flow when using PKCE. The changes are shown in light blue. Before each request for a token, the app generates a PKCE code challenge and code verifier. The code verifier is a cryptographically random number. Cryptographically random numbers are unguessable. The code challenge is a base 64 URL encoded string of the SHA256 hash of the code verifier. A hash is a one-way operation. It is easy to calculate a hash in a value but effectively impossible to determine the original value from its hash. It is also effectively impossible to build another value that has the same hash value. Passwords are stored in plain text files using hashes. The hash is stored in the password file. Then when a password is entered, the system hashes the entry and compares the calculated hash against the hash of the password file. If they match, it means the password is correct. It also means that compromising the password hash file does not allow retrieval of the passwords. PKCE takes advantage of this property of hashes. The app sends the code challenge, the hash, and the first communication. Later, when exchanging the auth code for tokens, the app sends the code verifier to prove that it is the same client that initiated the original communication. The proxy can calculate the hash for the code verifier and confirm that it matches the code challenge that was originally sent. Even if a bad actor is able to hijack the code challenge, they won't be able to provide the code verifier. Two additional parameters are sent when initiating the auth code flow. Code challenge is the hash value. The code challenge method parameter specifies the type of code challenge being sent, which is SHA256. Apigee should cache the code challenge to be used later when the auth code is exchanged for tokens. The key for the cache entry is the code challenge, and the value is the client ID. The user authentication section is unchanged for PKCE. The redirect URL from the authorization server, including the auth code in the query parameter, may be vulnerable on a compromised device. A bad actor may be able to get the auth code, but with PKCE, the auth code can't be exchanged for tokens without the code verifier. The app has the original code verifier, which has never been sent across the network. Instead of the client secret, which the public app cannot secure, the code verifier is sent in the token request. The OAuth proxy can now validate the client ID redirect URL in auth code as before. The code challenge hash is calculated for the provided code verifier. That calculated hash can be looked up in the API proxy cache. And as long as the entry is in the cache, and the client ID value from the cache matches the client ID in the request, the OAuth proxy can be confident that this request came from the original requester and not a bad actor. If the entry is not in the cache, or the client ID does not match, the OAuth proxy should reject the request. The access tokens and refresh tokens are created as before and returned to the caller. Usage of the tokens is unchanged. So now you understand how PKCE can be used for public apps and how it affects the auth code flow. Effectively, we're just creating a new password or client ID for every auth code request. Remember, for both the password and auth code grant types after you have an access token and refresh token, you can easily keep retrieving new access tokens until the refresh token expires. Let's see how to implement the policies for the auth code flow on Apogee. The first step uses the client ID, redirect URI, and scope with the OAuth V2 policy Generate Authorization Code operation. You can also attach the app end user and custom attributes to an auth code, and they will automatically be attached to the access and refresh token created from the auth code. This policy is the same whether or not PKCE is being used. The Generate Access token for the auth code grant type takes an auth code instead of the username and password used for the password grant type. Note that the Generate Access Token operation expects the request to have a basic auth header with the client ID and secret. If you're using PKCE, the app won't send the basic auth header with the request. The OAuth proxy must create the basic auth header before the policy will generate the access token. The verify API key policy is used to verify the client ID provided by the app. The policy creates a variable containing the client secret, then the OAuth proxy can build the basic auth header using the client ID, and client secret, and the basic authentication policy. We haven't looked at the refresh flow yet, but you'd also use the same process when using PKCE, since the client secret is not passed when refreshing the token. When getting a token using the auth code grant type without PKCE, the auth code form parameter replaces the username and password parameters. The default response is identical to the password grant type response. For PKCE, we can't pass the client secret, so there is no basic auth header. The client ID and code verifier are passed using form parameters. Once you have an access token, it is used the same way regardless of grant type.

### Video - [OAuth Wrap-up](https://www.cloudskillsboost.google/course_templates/255/video/466018)

* [YouTube: OAuth Wrap-up](https://www.youtube.com/watch?v=AaMXVLKnz6c)

Mike: We have covered OAuth 2.0 access and refresh tokens and the basic grant-type use cases and flows. In this OAuth wrap-up module, we'll learn about the refresh grant flow and a few more Apigee policies that will help with your OAuth proxies. Now that we've discussed the basic OAuth grant-type use cases, let's revisit the refresh token. When a refresh token is used, there is no user interaction. The app exchanges the refresh token for a new token, and optionally, a new refresh token. By default, new access and refresh tokens generated using a refresh token keep the scope associated with the refresh token. The app can choose to get reduced scope for the access token, but this is unusual. As discussed before, a new refresh token can be created when using a refresh token, and we will see why this is a best practice. A new refresh token will always keep the same scope as the previous refresh token. No new scopes can be added for the new refresh token because the user does not have the opportunity to provide consent. When an app uses the auth code flow with PKCE, the client secret is not sent in the refresh token request. This is the refresh token flow. Only a single request is required to refresh tokens. As mentioned before, it is a best practice to always get a new refresh token when using a refresh token. When a new refresh token is created during the refresh grant flow, the original refresh token becomes invalid. The advantage to getting a new refresh token each time is that compromised refresh tokens can be detected. If an app goes to use a refresh token and it is invalid, it means that the refresh token might have been used. The best practice is to invalidate all tokens related to the refresh token In case a bad actor has gained access to a refresh token. The app will need to collect the user's credentials again anyway to get a new access token. The refresh access token operation for the OAuthV2 policy will create new tokens from a refresh token. Any custom attributes associated with the refresh token will automatically be inherited by tokens created during this process. When set to true, ReuseRefresh token will not create a new refresh token. By default, ReuseRefresh token is false, causing a new refresh token to be created each time a refresh token is used. The previous refresh token will be made invalid. Creating a new refresh token each time is highly recommended. The refresh token flow requires that a valid and unexpired refresh token be supplied as a form parameter. For a request without PKCE, the basic auth header should be created using the app's client ID and secret. The response for the refresh token flow is identical to the response for the original token creation. When using PKCE, you can't send in a client secret. The client ID should be passed in as a form parameter along with the refresh token. The OAuth proxy will need to create the basic auth header before using the OAuthV2 policy to create the new access and refresh token. There is an invalidate token operation for the OAuthV2 policy. This can be used to revoke specified access or refresh tokens. The cascade attribute, when set to true, will cause all related access and refresh tokens to be invalidated. cascade=true should be used when you think a refresh token or access token may have been compromised. The invalidate token operation of the OAuthV2 policy requires a token. The RevokeOAuthV2 policy can invalidate all access tokens for an app or end user ID. The app ID element specifies the ID for a developer app. The end user ID element specifies the ID of the end user that was provided when generating the token. Specifying the app ID without an end user ID will invalidate all access tokens for an app. Specifying both will only invalidate the access tokens that contain that end user ID. The cascade attribute, when set to true, will cause all refresh tokens for the app and end user to be revoked as well. If RevokeBeforeTimestamp is specified, only the tokens that were issued before the specified time stamp will be revoked. The GetOAuthV2Info policy will get information about a token, auth code, or client app and populate variables with the details. This policy is rarely needed because the VerifyAccess token operation of the OAuthV2 policy will populate similar variables for use in your proxy. The SetOAuthV2 policy is used to set custom attributes for tokens, auth codes, or apps. This policy can be used to update attributes associated with a token, or add new attributes. These attributes will be populated as variables when the access token is verified.

### Video - [Lab Intro: Using OAuth Client Credentials Grant Type](https://www.cloudskillsboost.google/course_templates/255/video/466019)

* [YouTube: Lab Intro: Using OAuth Client Credentials Grant Type](https://www.youtube.com/watch?v=1IiVQJntgwE)

person: In this lab, you add OAuth to your retail API proxy. First, you replace the Verify API Key policy with an OAuth V2 policy that uses the Verify Access Token operation. You create an access token for your app using a second OAuth proxy, and then you test your retail proxy. When you finish testing your proxy with OAuth tokens, you will replace the OAuth V2 policy with the Verify API Key policy.

### Document - [Reading: Labs in this course](https://www.cloudskillsboost.google/course_templates/255/documents/466020)

### Document - [Reading: REST clients](https://www.cloudskillsboost.google/course_templates/255/documents/466021)

### Lab - [Apigee Lab 4: Using OAuth](https://www.cloudskillsboost.google/course_templates/255/labs/466022)

In this lab, you'll learn how to use OAuth, requiring an OAuth token to access an API proxy.

* [ ] [Apigee Lab 4: Using OAuth](../labs/Apigee-Lab-4-Using-OAuth.md)

### Video - [JWT, JWS, SAML, and OpenID Connect](https://www.cloudskillsboost.google/course_templates/255/video/466023)

* [YouTube: JWT, JWS, SAML, and OpenID Connect](https://www.youtube.com/watch?v=wUjpos9PBtA)

Person: We've covered quite a bit about OAuth 2.0, the authorization framework used by many APIs. In this lecture, we'll discuss JSON Web Tokens and Signatures. We'll also cover federated identity and two protocols that can be used for federated identity, SAML and OpenID Connect. A JSON Web Token, or JWT, is a JSON-based access token. The JWT is used to assert claims that can be trusted by the recipient. JWTs are digitally signed. This means that the JWT creator uses encryption to create a signature. By decrypting the digital signature, the recipient of the JWT can verify that the token was signed by the token service, and that the token has not been modified since it was created. JWT Tokens can therefore be verified by a service without requiring a network hop. This is in contrast to an opaque OAuth token, which cannot be verified without sending it to a token service because there is no encoded value in the token itself. This makes JWTs very useful for microservices where there might be several microservices for a single API call, and it would cause significant latency for each microservice to make a network call to verify the token. The downside to JWTs is that they typically cannot be revoked. Opaque OAuth tokens require validation by a token service for each call, so a token can be invalidated at that service so that it is not usable in the future. JWT Tokens are validated by the service locally, so it generally isn't practical to create a revocation list at each service. This leads to a best practice for JWTs. Keep the time to live short because the JWT will be valid as long as it lives. The JWT format includes three sections. These sections are Base64URL encoded separately, and then separated by dots. The first section is the header, a JSON structure with claims about the token itself. The header is primarily used to specify the algorithm used to generate the signature. In this case, the algorithm is HMACSHA256. The second section is the payload, which contains claims about the user. There are some predefined claim names for standard types of claims. In this example, the standard claims are a subject, an issuer, an audience, and issued-at time, and an expiration time. Custom claims can also be created. Here we have a name, locale, and e-mail address for the user. The third section is the signature, which is calculated by encoding and cryptographically signing the header and payload. The signature guarantees the integrity of the token. The header shows HMACSHA256 as the hashing function, so the signature will be an SHA256 hash of the Base64URL encoded header and payload separated by a dot. The token shown is the Base64URL encoded sections concatenated and separated by periods. Note that this token is not encrypted. The first two sections are Base64URL encoded and they are easily reversed to reveal the JSON. The JWT will be encrypted while traveling across the network because it must always be sent via TLS. Like an opaque OAuth token, a JWT should be stored securely. Apigee has policies that generate, decode, and verify JWTs. The GenerateJWT Token policy creates a signed JWT with a configured set of claims and stores the JWT string in an output variable. JWTs can be generated with key encryption algorithms that are supported by the OpenSSL library. The verified JWT policy verifies the validity of a signed JWT. If the signature is invalid, the JWT is expired, or a claim set in the policy don't match the claims in the token, the policy will raise a fault. If the JWT is valid, all of the JWT information will be populated into variable for use in the proxy. The DecodeJWT policy decodes the signed JWT without validating the signature, expiration, or any claims. This policy will just extract the values of the JWT into variables. The DecodeJWT policy is generally used only when the information from the JWT is required to verify the signature. For example, if you allow multiple signing algorithms, DecodeJWT might be used to determine the algorithm, and then VerifyJWT would be used to make sure the token is valid. Apigee also provides policies for handling a JSON Web Signature, or JWS. A JWS is more flexible than a JWT. JWS doesn't have format requirements for the payload, and the payload does not need to be attached to the JWS. A signed JWT is just a JWS with an attached JSON payload that contains a set of claims. There are three JWS policies that are similar to the three JWT policies, GenerateJWS, VerifyJWS, and DecodeJWS. Now let's talk about federated identity. Management of users involves managing user profile information like names, e-mail addresses, and passwords. An Identity Provider, or IdP, manages and secures the user information stored in its database and authenticates those users. A service provider needs to manage users of its service. Securing passwords and user data is of utmost importance. Many service providers choose not the manage user data, but instead delegate the management to one or more trusted identity providers, or IdPs. For example, many apps and services allow you to use your Google account to log in. The service provider can choose to store the name and e-mail of the user, but relying on Google to maintain the security of the rest of the profile information. Users also benefit from federated identity. Users have fewer accounts and passwords to manage and can benefit from single sign-on to multiple apps and services. Let's learn about two of the most popular standards that can be used to provide federated identity: SAML and OpenID Connect. SAML stands for Security Assertion Markup Language. SAML 2.0, the current version in use, was finalized in 2005. It is a SOAP and XML based protocol that uses XML formatted tokens known as security assertions to exchange authentication and authorization information between IdPs and service providers. SAML is a fairly complex protocol still used by many large enterprises. Apigee provides two SAML policies you can use in your proxies: GenerateSAMLAssertion creates a security assertion, and ValidateSAMLAssertion validates a security assertion and sets variables containing the information from the assertion. OpenID Connect, or OIDC, is a lightweight RESTful redesign of SAML. OIDC layers identity and authentication on top of the OAuth 2.0 authorization framework, adding an ID token to OAuth. The ID token can be created by an OpenID provider when a user authenticates. The ID token will contain claims about the user as represented as a secure JWT Token. An ID token can then be used to verify the identity of the bearer and get user details without contacting the IdP that issued the token. OIDC is typically preferred over SAML for mobile applications or systems that are already using OAuth 2.0. Apigee's OAuthV2 and JWT policies can be used to create OIDC providers and consumers.

### Quiz - [Module Quiz](https://www.cloudskillsboost.google/course_templates/255/quizzes/466024)

#### Quiz 1.

> [!important]
> **Why does the client credentials grant type not use refresh tokens?**
>
> * [ ] Refresh tokens are only used when user credentials are necessary.
> * [ ] The client credentials grant type flow cannot secure refresh tokens.
> * [ ] An app's credentials do not change, so a refresh token is unnecessary.
> * [ ] The authorization code grant type with PKCE should now be used instead of the client credentials grant type.

#### Quiz 2.

> [!important]
> **Which of the following statements about the Proof Key for Code Exchange (PKCE) extension are true? Select two.**
>
> * [ ] PKCE is necessary because a token may be intercepted by a bad actor.
> * [ ] The authorization code grant type with PKCE should be used instead of the implicit grant type.
> * [ ] PKCE adds an extra call to the authorization code flow that is used to validate the code verifier.
> * [ ] PKCE can be used to secure OAuth when TLS is not being used.
> * [ ] PKCE uses a one-way hash to prove the identity of the app.

#### Quiz 3.

> [!important]
> **Which of the following statements about JWTs are true? Select two.**
>
> * [ ] JWTs can be validated without sending them to a token server.
> * [ ] The JWT payload is used to guarantee the integrity of the token.
> * [ ] SAML uses JWTs for passing authentication and authorization information between IdPs and service providers.
> * [ ] JWTs are encrypted, so TLS is not required.
> * [ ] Apigee provides policies for generating and verifying JWTs.

#### Quiz 4.

> [!important]
> **Which OAuth grant type should be used for untrusted apps that need access to user data?**
>
> * [ ] Client credentials grant type
> * [ ] Authorization code grant type
> * [ ] Implicit grant type
> * [ ] Resource owner password grant type

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/255/video/466025)

* [YouTube: Module Review](https://www.youtube.com/watch?v=eI2cH_uV288)

Mike: In this module, you were introduced to API security concerns. You learned about OAuth, the most popular authorization framework for REST APIs, and added verified OAuth tokens in your retail API proxy. We also learned about JWT tokens and API federated identity.

## Content, Transport, and Platform Security

This module introduces content-based attacks, transport security, and protection against unauthorized access

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/255/video/466026)

* [YouTube: Module Overview](https://www.youtube.com/watch?v=hqp3zjGN7Y8)

Hansel: In the last module, you learned about authentication and authorization. This module will teach you about content-based attacks and the Apigee policies that can help protect your APIs against these attacks. We will learn about transport security and about features of Apigee that keep users of the Apigee console from seeing sensitive data when API calls are traced. You will add JSON Threat Protection to your retail API proxy and add a key value map to store backend credentials. You will also complete a lab that uses the Regular Expression Threat Protection policy and a lab that uses the Apigee API to create a debug mask to mask variables while tracing an API proxy.

### Video - [Protecting Against Content-Based Attacks (1)](https://www.cloudskillsboost.google/course_templates/255/video/466027)

* [YouTube: Protecting Against Content-Based Attacks (1)](https://www.youtube.com/watch?v=X1BxVWuF-8g)

person: In this lecture, you'll learn about content-based attacks against APIs and how Apigee can help you protect your APIs against them. Content-based API attacks use malformed API requests to cause issues with APIs and backend services. Some attacks use text fields to compromise data in the backend, either retrieving data that the user should not be permitted to get or destroying data in backend databases. Other attacks use JSON or XML payloads that are crafted specifically to cause problems for parsers. This type of attack can cause an application-level denial of service, where the API or backend service stops responding to requests. Legacy services are often susceptible to these types of attacks. When services are designed to receive traffic only from inside the company network, developers may not pay much attention to content-based attacks. When you start using your legacy services to build your external APIs, all of a sudden, your services are now exposed to traffic from the internet. It is a good practice to add protection against these attacks in your API proxies so that you can block the malicious data from reaching your backend services. Apigee has policies that can help you create this level of protection in your proxies. You may need to use many different types of input validation for your APIs, and most of this validation can be done in the API proxy, reducing traffic to the backend that would be rejected anyway. API payloads are often in JSON or XML format. Fields within your JSON and XML can be extracted using the JSONPath and XPath configuration within an ExtractVariables policy. Required fields and field dependencies can be validated using Boolean conditions. Complex formatting patterns can also be checked by using regular expressions and conditions, or by using a JavaScript policy. If you choose not to validate all input at the proxy layer, make sure that you know all of the different error messages that might be returned by your backends and have a method for remapping each one to your consistent error format for your API. Blocking dangerous input at the API proxy layer helps protect your backend services from intentional attacks. For example, a common attack on an API is a SQL injection attack, where the attacker creates inputs that have SQL code or common characters embedded in them. These inputs can cause leakage or destruction of your backend database data if you do not block them. The correct way to block SQL injection is to escape dangerous characters and not build SQL queries using concatenation. You should protect against SQL injection in your backend services. However, blocking known bad requests will protect your APIs, even if the backend is not inherently protected. You can use the RegularExpressionProtection policy to block dangerous string patterns. The RegularExpressionProtection policy can be used to search for block patterns in the input request. You can search inside variables or inside specific fields in an XML or JSON payload using XPath and JSONPath. If any regular expression pattern in the policy matches the value in the corresponding location, the message is considered a threat and the policy raises a fault. The API request should be rejected as a bad request.

### Video - [Protecting Against Content-Based Attacks (2)](https://www.cloudskillsboost.google/course_templates/255/video/466028)

* [YouTube: Protecting Against Content-Based Attacks (2)](https://www.youtube.com/watch?v=5TM65ILIBvo)

person: Let's take a quick but important detour. We've talked about using JSONPath and XPath to find specific fields inside the JSON or XML payload. How do your proxies' policies know whether the payload is JSON or XML? You might say, if we see curly braces, it's JSON, and angled brackets are XML. That's how humans tell the difference. The proxy actually uses the content-type header. The content-type header specifies which format is being used for the message. Apigee recognizes application/json as the JSON payload. There are multiple formats for XML, including application/xml. text/plain indicates a plain-text payload. As you use some of the powerful JSON and XML parsing functions and Apigee policies, remember that the content-type header must be set correctly at the time the policy is executed. For example, if you are trying to use JSONPath in a policy and the content-type header is not application/JSON, that part of the policy will be silently skipped. Look at this example payload from an HTTP message. What format is it? If you think it is a trick question, you're right. It certainly looks like JSON, but we don't really know what the format is until we know what the content type is. If the content type is set to application/xml, this payload is invalid XML, not JSON. If the content-type header is not set, the payload is also not considered JSON. When creating an API that only uses JSON, you might want the default content type to be application/JSON when no content-type header is provided. You can do this with a series of policies in a proxy. The first condition is true if the content-type header has a value and the content type is set to something other than application/JSON. In this case, the caller has set a content type that is not allowed for this API. The policy named RF-ContentTypeInvalid would raise a fault and cause an error to be returned for invalid content type. The second condition is true if the content-type header is not set. In this case, you could use the policy AM-SetContentTypeToJSON to set the content-type header in the request to application/JSON. Now that you have a valid content type, the EV-ExtractFromJSON extract variables policy will be able to parse JSON. XML and JSON payloads can be crafted to overwhelm parsers, causing application-level denial of service attacks. The JSON and XML threat protection policies use string-based evaluation of the payload instead of loading it into a parser. By using string-based evaluation of the payload, you can detect XML or JSON payloads that exceed configured limits and reject the request before you ever load it into a parser. It is important to run these protection policies before you attempt to use JSON or XML parsing at all. For example, you may want to validate fields within your JSON by using JSONPath and an extract-variables policy. You should use the JSONThreatProtection policy to confirm that the payload is safe before parsing it. The JSONThreatProtection policy allows you to specify limits on your JSON, like how deep your JSON can be nested or how many elements can be in an array. The policy will check for these structural limits by scanning through the text of the JSON object without parsing the JSON. The first time a limit is exceeded, the policy will raise a fault, allowing you to reject the request. Only the first error encountered in the JSON will be mentioned in the response. It is important to set limits that allow legitimate JSON payloads through so you don't reject requests as false positives. The XMLThreatProtection policy works exactly the same way as the JSONThreatProtection policy. The XML payload is validated against configured limits without using a parser. Note that the configuration elements are very different for XML and there are many more options. This is because the XML and JSON formats are very different. The JSON format is simple and the XML format is significantly more complex.

### Video - [Lab Intro: JSON Threat Protection](https://www.cloudskillsboost.google/course_templates/255/video/466029)

* [YouTube: Lab Intro: JSON Threat Protection](https://www.youtube.com/watch?v=-2ZadIlxzWo)

person: In this lab, you add JSON Threat Protection to your retail API proxy. You will test with different payloads to see how the JSON Threat Protection policy's limits work.

### Lab - [Apigee Lab 5: Protecting Against JSON Content Attacks](https://www.cloudskillsboost.google/course_templates/255/labs/466030)

In this lab, you'll protect your API against JSON payload attacks.

* [ ] [Apigee Lab 5: Protecting Against JSON Content Attacks](../labs/Apigee-Lab-5-Protecting-Against-JSON-Content-Attacks.md)

### Video - [Lab Intro: Regex Threat Protection](https://www.cloudskillsboost.google/course_templates/255/video/466031)

* [YouTube: Lab Intro: Regex Threat Protection](https://www.youtube.com/watch?v=cL57-ixnXic)

person: In this lab, you add a regular expression threat protection policy to a new API proxy, and test that the regular expression threat protection policy rejects requests with data that matches the configured regular expressions.

### Lab - [Apigee Lab 5a: Using Regex Threat Protection](https://www.cloudskillsboost.google/course_templates/255/labs/466032)

In this lab, you'll protect your API against malicious requests by using regular expressions.

* [ ] [Apigee Lab 5a: Using Regex Threat Protection](../labs/Apigee-Lab-5a-Using-Regex-Threat-Protection.md)

### Video - [Transport Security (1)](https://www.cloudskillsboost.google/course_templates/255/video/466033)

* [YouTube: Transport Security (1)](https://www.youtube.com/watch?v=-Ciecb-HUDA)

person: During this lecture, you will learn about Transport Layer Security, or TLS, which is the primary method of securing API requests and responses when sent across the network. You learn about how TLS works, and how it is supported on Apigee. You'll also learn how to allow or deny traffic based on source IP address. TLS is the successor to Secure Sockets Layer, also known as SSL. When you hear someone talk about SSL, they are generally referring to TLS because all versions of SSL have been deprecated due to vulnerabilities. TLS establishes an encrypted link over HTTP between a client and a server. When you connect to a webpage, or API, over HTTPS, you are using TLS. TLS uses certificates with public and private keys to prove identity. When we discussed OAuth, you'll learn that one of the firm requirements is that all OAuth traffic be sent using TLS. And in fact, it is recommended to send all API traffic over TLS. Two types of TLS connections can be made. They are commonly called one-way and two-way TLS. One-way TLS, also call server validation, is probably very familiar to you. When you open a web page in your browser and the request URL starts with https://, you are using one way TLS. The server being connected is required to present a certificate to the client to prove its identity. For an API, we typically use something called a trust store on the client side to validate the certificate. For web requests, we trust the certificate because it has been signed by a trusted third party certificate authority. certificate authorities are outside the scope of this course. Two-way TLS, also called mutual authentication, is the recommended method for securing the network connection between an Apigee proxy and the back end services it uses. Both the client and server presents certificates and each can validate the other certificate. Because your back end typically needs to let traffic through the firewall, it is important to validate that backend requests are coming from a legitimate source. Let's look at one-way TLS and how a client can trust a server. We are calling the participants the client and the server. The client will initiate the request. Even though the client is represented in this diagram with the mobile device icon, the client could also be an Apigee proxy, with the server being a back end or third party service. Both one-way and two-way TLS can be used for HTTP traffic between any client and server. For one-way TLS, the server will need to present a certificate to the client. This certificate, which contains a public key, will be stored in a key store on the server side. In addition, the key store will contain the private key associated with the server certificate. The client will need to validate the certificate from the server. The server certificate or chain of certificates can be stored in a trust store. First, the client sends a request to access a resource on the server. Before creating the encrypted connection, the server must prove its identity to the client. The server will present its certificate containing its public key to the client. The certificate and public key are presented to any client connecting to the server. So the certificate is not a secret. However, the server is the only entity that should have the associated private key. The client will confirm that the certificate is the expected one by validating it against the trust store. Note that a simplified logical version of the communication between client and server is shown here. The actual TLS handshake is a bit more complex. During this handshake, the client will typically encrypt some random data using the public key from the server certificate and send it to the server. When the server proves to the client that it can decrypt the data, the client knows that the server must have the private key and is therefore the legitimate holder of the certificate. In addition to proving that the server has the private key, the two sides also negotiate the encryption cipher for the handshake and the symmetric keys that will be used to encrypt traffic across the network. If the client is confident that the server is legitimate, the encrypted connection setup will be completed, and the client can access the resource via TLS. The TLS connection between client and server can remain up for future communication between client and server. Let's see how two-way TLS is set up between client and server. This two-way TLS is client validation layered on top of one way TLS. We still have the service key store, and the client's truststore as before. In addition, the client will need to present a certificate and encrypt using its private key. So there will be a client key store. The server will need to validate that client certificate, so it will have a trust store. Step one through three of the interaction are the same as before. The client requests a resource, and the server presents its certificate and proves it has the private key. After the client is convinced of the authenticity of the server, the client needs to prove its identity. The client takes its certificate from the keystore and presents it to the server. The server will validate the client certificate against its trust store. During the handshake, the validity of the associated private key will also be proven. Once each side is convinced of the other's identity, the encrypted TLS connection setup can complete and the client can securely access resources on the server.

### Video - [Transport Security (2)](https://www.cloudskillsboost.google/course_templates/255/video/466034)

* [YouTube: Transport Security (2)](https://www.youtube.com/watch?v=dW9blM0MiWk)

person: On Apigee, you'll create keystores to store certificates and private keys to prove the Apigee proxy's identity over secure connections. You'll also create truststores to store certificates that are expected from remote participants so the proxy can verify that it is communicating with the correct participant. For incoming traffic, TLS should be configured on a load balancer in the Google Cloud project. For Apigee communication with the backend, the TLS configuration will be set up in the target end point in the proxy or in a target server configuration referenced by the proxy. For one-way or two-way TLS, a truststore is used to store trusted backend certificates. For two-way TLS, an Apigee keystore is used to store the private keys and the certificates to be presented to the backend service. When you use a keystore or truststore on Apigee, you have two choices. Specify by using the keystore or truststore name or by using a reference. A reference is a variable containing the name of a keystore or truststore. References are configured within the scope of an environment. If you use a name in your proxies instead of a reference, changes to the certificates and private keys will only be picked up after the proxy is undeployed and redeployed. With a reference, a new keystore or truststore with the new certificates and keys can be created. And the reference can be updated on the fly without downtime for your proxies. Rotating keys and certificates is a best practice, so we recommend that you always use references. When you create a target definition either in a proxy or in a target server, the backend certificate will not be validated by default. This means that Apigee will not validate that the certificate has expired, that the certificate's common name matches the host name in the URL, or that it has been signed by a trusted certificate authority. In order to validate the backend certificate, you must configure a truststore, preferably using a reference. This truststore must contain the server certificate or a certificate chain. If the server certificate is signed by a third party, you will need to upload the entire certificate chain up to the root certificate authority or CA certificate. Unlike a web browser, Apigee does not implicitly trust any certificate authorities. It is typically recommended to have the server validate the proxy's identity using two-way TLS. The truststore is configured the same way as for one-way TLS. In addition, the target's client auth enabled element should be set to true and the keystore and key alias should be configured. The keystore contains a certificate and private key. You should configure the keystore as a reference. The key alias is the name of the certificate and key within the keystore. Multiple certificate and key pairs can be stored in the same keystore by using different key alias names. Key aliases cannot be specified by reference. So a new keystore should use the same key alias name when used for certificate rotation. An additional method to restrict incoming connections to your API proxies is to use the AccessControl policy. Allow and deny rules for IP addresses and IP address ranges can be specified, and they are evaluated in order. The action of the first matching rule determines whether the traffic is allowed or denied. Address and address ranges in rules can be hard coded in the policy or specified using variables. The no rule match action element specifies whether the default behavior is to allow or deny traffic if none of the rules match. Note that the IP address that is validated may be found in a header like the X forwarded for header rather than using the actual connected IP address. If Apigee is fronted by a load balancer, the connection IP address would be from the load balancer and not the original request. Load balancers and proxies typically add the upstream IP address to the X forwarded for header. Alternatively, you can specify the client IP to be verified in the client IP variable element.

### Video - [Apigee Platform Security (1)](https://www.cloudskillsboost.google/course_templates/255/video/466035)

* [YouTube: Apigee Platform Security (1)](https://www.youtube.com/watch?v=lHtMh0J-iCE)

person: You've learned quite a bit about securing APIs from external threats. Now we'll discuss platform security, which protects internal access. Cloud Identity and Access Management, or IAM, is used to grant access to an Apigee organization to Google Cloud user accounts using Apigee roles. Data masking and private variables can be used to prevent sensitive data from being visible while traffic is being traced. And key value maps can be used to store and use configuration data like credentials without allowing users of the Apigee program to see the values. Apigee users are managed using Google Cloud's Identity and Access Management, or IAM. Apigee users are configured as user accounts within the customer-managed project that is tied to the Apigee organization. In Cloud IAM, we think of access control as defining who has what access for which resource. The Apigee org is tied one-to-one with the customer-managed project that was used to create it. The Apigee org and the entities it contains are resources within the customer-managed project. When we refer to an Apigee user, we are referring to an authenticated user account that can access an organization and some or all of the entities within the organization. Permission to access a specific resource in Google Cloud is not granted directly to a user. This can be a maintenance nightmare if we needed to specifically grant permissions for each resource to each user. Instead, permissions are grouped into roles, and then a role may be granted to an authenticated user. A role can therefore be thought of as a collection of permissions. Granting a user access to a role specifically provides the user with all of the permissions contained by the role. Within Google Cloud, the resource hierarchy is made up of organizations, folders, and projects. For most companies, the root of the resource hierarchy is a Google Cloud Organization. Inside that organization is a hierarchy of folders and projects. Folders can only be created in an organization or inside other folders. Projects can also be created without an organization, in which case, the project is a root element. Resources are created inside projects. Organizations, folders, and projects provide places to attach an inherit roles. Permissions at a higher level in the hierarchy are inherited by lower-level entities. For example, giving a user a role in a folder provides those role permissions for any projects and resources the folder contains. All Google Cloud resources, like virtual machines, databases, and Apigee, are contained in a project. An Apigee organization is contained in a single customer project. Environments for that Apigee organization are contained in the organization. A Google Cloud Organization and an Apigee organization are different. In this course, when we refer to an organization, we are referring to an Apigee organization unless otherwise specified. The inheritance pattern for Apigee follows the inheritance of the resource hierarchy. Roles that are given in a project are automatically inherited for the Apigee organization, and any roles inherited by the Apigee organization are inherited by its environments. There are two locations in which Apigee roles are attached. The first location is at the project level. Any Apigee roles attached to the project are automatically available for the organization and all contained environments. The second location is in a specific environment. Within the Apigee console, environment-specific roles can be given to IAM users defined at the project level. The access given in an environment is the union of the access provided at the organization and the specific environment. There are several pre-defined roles created for Apigee users. An Organization Admin or Org Admin has full read-write access to the organization. A Read-only Admin has full read access. An API Admin has the correct privileges for a developer who creates and tests proxies. This role provides the ability to edit proxies, shared flows, and key value maps. A Developer Admin manages app developer access, editing API products, app developers, apps, and app keys. An Environment Admin manages API proxy deployments and environments, providing edit access to entities like shared flows, flow hooks, key value maps, and target servers. In addition, the Environment Admin can deploy and undeploy API proxies. Note that when you look at the list of IAM roles for a project, you may also see Apigee roles that are only used by Apigee hybrid services. Note that the owner of a project has full read-write access like an org admin. Google recommends the principle of least privilege, where a user is only given the minimum set of privileges necessary to complete their job. If one of the predefined roles does not provide the correct level of access, you can create a custom role containing only the permissions you need for that role. Use of the Apigee trace tool is vital for troubleshooting issues with your API. However, the user tracing live API traffic can by default see all of the fields that are being accessed during the API calls. This data can include sensitive user data, including names, passwords, or credit card numbers. The user can also see credentials that are being used to communicate with back end services. When you download a trace log, those values will also be in the trace file. Data masking can block configured data from being visible in live trace or trace files. You specify certain patterns or field or variable names and matching data will be masked using a series of asterisks. Data masking is a feature that cannot be controlled using the Apigee console. Data masks are set up using the DebugMask Apigee API. Data masks are configured at the environment level, and these masks will be active for all APIs in the environment. Data masks are not visible in the console, so API teams sometimes forget about them. Protecting data is an important part of your API security, so you should create data masks for your environments and ideally store the data masks in source control. A DebugMask is a singleton object in an Apigee environment. Data masks are created by patching the singleton object, which is named DebugMask. The payload for the DebugMask contains a list of variables and JSONPath or XPath expressions for API requests or responses. In this case, one of the masked fields is the login password at the root level of an incoming JSON request. When tracing, you will see the masked value replaced with asterisks. A downloaded trace file will also have the data mask.

### Video - [Apigee Platform Security (2)](https://www.cloudskillsboost.google/course_templates/255/video/466036)

* [YouTube: Apigee Platform Security (2)](https://www.youtube.com/watch?v=gPunCFQuNO8)

Another way to hide sensitive information while tracing is to use private variables. A private variable is created by using a prefix of "private dot" in the variable name. So private.password is a private variable. A private variable can be used like any other variable, ,but, when an API is traced, the data value of a private variable is automatically masked. Note that when you assign a private variable to another variable, the value will be visible when the non-private variable is accessed. Key value maps or KVMs, are used to store non-expiring configuration data for use by proxies at runtime. You can think of a KVM as a replacement for a property fire. Both the key and the value for a key value map entry must be a string. You can convert the value to another data type like a number inside the proxy. KVMs can be scoped to an organization, an environment or a specific proxy, but environment-scoped KVMs are the most common. The Apigee console only allows you to create environment-scoped KVMs. KVMs are ideal for environment-specific configuration. You can create or delete KVMs using the Apigee API or the Apigee console. You can only add, update or delete KVM entries using the KeyValueMapOperations policy or the Apigee API. You cannot modify KVM entries using the console. The key value map values are encrypted, so KVMs are safe for sensitive data like backend credentials. Because KVMs often do store sensitive data, you can only retrieve values into private proxy variables. The KeyValueMapOperations policy can be used to access and update KVM data from within a proxy. This policy can insert, update or retrieve data from KVMs. The MapName field specifies the KVM to access. The name can be specified from a variable or as a hardcoded value. In this case, the variable "kvmName" is checked first, and if the variable does not exist or is empty, then the string "defaultKVM" will be the name of the KVM. Scope can be used to select an organization, environment or API proxy-scoped key value map. The default scope, if not specified, is environment. Entries are added or updated using a Put element, and received by using a Get element. One or more parameter fields are specified as your key, and each of these fields can be hardcoded or read from a variable. In the example, the backend service name is coming from a variable, but password is a hardcoded string. Remember when retrieving data from a KVM, you must assign the KVM entry value to a private variable, or the policy will throw a runtime error. Expiry time in seconds specifies how long to cache the retrieved or updated entry. In this case, the entry is cached for 600 seconds. If the next Get for the matching entry happens within 600 seconds or 10 minutes, a cached value will be used rather than reading from the database. Cached reads are significantly quicker than those from the database, but database changes may not be picked up until the cache entry has expired. If the entry is read from cache, the expiration time will not be extended. Like a Key Value Map, a property set can be used to store a custom collection of key value pairs that can be used by API proxies. A property set is implemented using a . properties file. This standard format is used to specify key value pairs. Comments can be added to the file for readability. Property sets should be used for static, non-expiring data. Unlike the values in a key value map, property set values cannot be updated dynamically by an API proxy. Property sets can be specified at an environment or API proxy level. Environment-scoped property sets can be used to provide different values depending on the environment in which the API proxy is deployed. Changes to an environment-scoped property will be picked up by an API proxy without redeployment. For an API proxy-scoped property set, the keys and values can only be changed when the API proxy is redeployed. The values in a property set are accessed by referencing flow variables in the API proxy. For example, a property named loglevel in a property set named test.properties could be accessed using the flow variable propertyset.test.loglevel. Key Value Maps and property set serve similar purposes. They are both used to store configuration data, but there are key differences. KVM values are encrypted. This can be important when storing sensitive data like backend service passwords or API keys. Property set values are stored in plaintext. KVM values can be changed dynamically. The KeyValueMapOperations policy can be used to update a value during the execution of an API call. Property set values cannot be updated dynamically by an API proxy. Changes to values in KVMs are picked up by an API proxy without redeployment. API proxy-scoped property sets can only be changed by redeploying the API proxy. Even though KVMs have more features, property sets are usually better than KVMs for storing static, non-sensitive configuration data. Properly set keys and values are easier to create and maintain than KVM entries. Because are static and non-sensitive, it is often appropriate to check in . properties files to code repositories.

### Video - [Lab Intro: Internal Threat Protection](https://www.cloudskillsboost.google/course_templates/255/video/466037)

* [YouTube: Lab Intro: Internal Threat Protection](https://www.youtube.com/watch?v=DwYMGvoG8ic)

Hansel: In this lab, you protect backend credentials from being exposed in the Apigee management UI. You create a key value map and add the credentials to it. You will use those credentials in your proxy to create a basic authentication header for calls to the backend.

### Lab - [Apigee Lab 6: Protecting Against Internal Threats](https://www.cloudskillsboost.google/course_templates/255/labs/466038)

In this lab, you'll protect backend credentials by using a key value map to store them.

* [ ] [Apigee Lab 6: Protecting Against Internal Threats](../labs/Apigee-Lab-6-Protecting-Against-Internal-Threats.md)

### Video - [Lab Intro: Data Masking](https://www.cloudskillsboost.google/course_templates/255/video/466039)

* [YouTube: Lab Intro: Data Masking](https://www.youtube.com/watch?v=skzE8H3O2Yg)

Hansel: In this lab, you learn how to protect against internal access of sensitive data by using private variables and data mask.

### Lab - [Apigee Lab 6a: Masking Sensitive Data](https://www.cloudskillsboost.google/course_templates/255/labs/466040)

In this lab, you'll protect sensitive data by using data masking and private variables.

* [ ] [Apigee Lab 6a: Masking Sensitive Data](../labs/Apigee-Lab-6a-Masking-Sensitive-Data.md)

### Quiz - [Module Quiz](https://www.cloudskillsboost.google/course_templates/255/quizzes/466041)

#### Quiz 1.

> [!important]
> **Which of the following policies are used to protect against parsing attacks? Select two.**
>
> * [ ] XMLThreatProtection policy
> * [ ] RegularExpressionThreatProtection policy
> * [ ] AccessControl policy
> * [ ] JSONThreatProtection policy
> * [ ] MessageValidation policy

#### Quiz 2.

> [!important]
> **Which of the following data stores does Apigee use when proving the proxy's identity to the backend service?**
>
> * [ ] Truststore
> * [ ] Property sets
> * [ ] Keystore
> * [ ] Encrypted Key Value Maps (KVM)

#### Quiz 3.

> [!important]
> **Which of the following statements about KVMs are true? Select two.**
>
> * [ ] The Apigee API can be used to turn off encryption for an existing KVM.
> * [ ] Values can be retrieved from an encrypted KVM by using the Apigee API.
> * [ ] KVMs are only scoped to a specific environment.
> * [ ] Keys and values must both be strings.
> * [ ] When the KeyValueMapOperations policy is being used, values from a KVM may only be retrieved into private variables.

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/255/video/466042)

* [YouTube: Module Review](https://www.youtube.com/watch?v=o_UmcttnfyE)

Hansel: In this module, you learned how to protect your API proxies against content-based attacks and how to keep users from seeing sensitive data while tracing API calls in the Apigee console. You learned about transport security and how to use TLS for communicating between client apps, and Apigee, and backend services. You also completed labs using threat protection policies, key value maps, and data masking.

### Video - [Course Review](https://www.cloudskillsboost.google/course_templates/255/video/466043)

* [YouTube: Course Review](https://www.youtube.com/watch?v=GOpsoXUC9jU)

Hansel: Thank you for taking the API Security course. During this course, you learned about the different types of security concerns your APIs must protect against. We learned about many aspects of OAuth, including the OAuth grant type flows and when we would use each grant type. You learned about JWT tokens and federated security. We discussed content-based attacks and learned about the threat protection policies that can be used to protect against these attacks. And you learned about Apigee features that can limit internal access to features and mass data for the users of the Apigee console. Next, we recommend you continue with the next course in the series, API Development and Operations on Google Cloud's Apigee API Platform. In the API Development and Operations course, you learn about API mediation, traffic management, caching, and vault handling and add these to your retail API proxy. You will also create a developer portal and publish your API product for use by app developers. We will learn about message logging and analytics, CICD, and deployment options for Apigee. We hope to see you in the next course.

### Document - [Reading: Apigee X and Apigee Edge differences](https://www.cloudskillsboost.google/course_templates/255/documents/466044)

## Course Resources

PDF links to all modules

### Document - [Course Resources](https://www.cloudskillsboost.google/course_templates/255/documents/466045)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

---
id: 397
name: 'Preparing for Your Professional Cloud Security Engineer Journey'
datePublished: 2025-04-07
topics:
- Cloud Platform
- Google Cloud Services
- Cloud Computing
type: Course
url: https://www.cloudskillsboost.google/course_templates/397
---

# [Preparing for Your Professional Cloud Security Engineer Journey](https://www.cloudskillsboost.google/course_templates/397)

**Description:**

This course helps learners prepare for the Professional Cloud Security Engineer (PCSE) Certification exam. Learners will be exposed to and engage with exam topics through a series of lectures, diagnostic questions, and knowledge checks. After completing this course, learners will have a personalized workbook that will guide them through the rest of their certification readiness journey.

**Objectives:**

- Describe the domains covered on the Professional Cloud Security Engineer Certification exam.
- Identify gaps in your knowledge and skills for each domain and create a study plan.

## Introduction

Welcome to Preparing for the Professional Cloud Security 
Engineer Journey.

### Video - [Course Trailer](https://www.cloudskillsboost.google/course_templates/397/video/529550)

- [YouTube: Course Trailer](https://www.youtube.com/watch?v=LKmS_fs5M-U)

Shawn: Are you ready to start preparing for the professional security engineer certification exam? Well, in this course, you will assess your exam readiness and form a personalized workbook that will guide you for your certification journey. Hi, I'm Shawn, a technical curriculum developer at Google Cloud. And I'll introduce you to the professional security engineer certification and how to prepare for it. Now, this content is designed for experienced security engineers that are ready to become Google Cloud certified. Before taking this course, you should have experienced designing and managing security solutions in Google Cloud. In this course, you'll be exposed to and engage with exam topics through a series of lectures and quizzes. Upon completion of this course, you'll understand the domains covered on the exam and you'll be able to identify gaps in your knowledge and skills for each domain. Enroll in this course to prepare to become a certified Google Cloud security engineer.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/397/video/529551)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=hSUNfcMgOzc)

Welcome to Preparing for Your Professional Cloud Security Engineer Journey. In this course, you’ll learn more about the skills covered on the Professional Cloud Security Engineer certification exam. Each module points to one section of the exam guide. In this introduction module, we’ll learn more about the role of a Professional Cloud Security Engineer and this course structure. In module 2, we’ll be covering exam section 1, which is on configuring access. Module 3 will cover securing communications and establishing boundary protection. Module 4 will cover data protection. Module 5 will cover operations management. Module 6 will cover compliance. And finally, module 7 will discuss next steps. It’s important to clarify that this course by itself will not prepare you to take the certification exam. This is not a “cram session.” The exam is purposefully calibrated to test your ability to apply the knowledge required of a Professional Cloud Security Engineer, not merely repeat it. Cram sessions have minimal impact on your ability to pass the exam. Instead, the goal of this course is to help you better structure your preparation time for the exam. You’ll learn about the scope of each exam section, assess your current knowledge and skills through diagnostic questions, and review where to find additional tools and resources to include in your study plan. In this introductory module, you’ll learn about the role of a Professional Cloud Security Engineer, the types of resources available to support your study, and how you will use the workbook in this course to create your study plan.

### Video - [Introduction to the Professional Cloud Security Engineer role](https://www.cloudskillsboost.google/course_templates/397/video/529552)

- [YouTube: Introduction to the Professional Cloud Security Engineer role](https://www.youtube.com/watch?v=xu3nO5m7Pd4)

So, you’re preparing for the Professional Cloud Security Engineer certification, but what exactly is the role of a Professional Cloud Security Engineer? Let’s review the job role description: A Professional Cloud Security Engineer enables organizations to design and implement secure workloads and infrastructure on Google Cloud. Through an understanding of security best practices and industry security requirements, this individual designs, develops, and manages a secure solution by leveraging Google Cloud security technologies. The Professional Cloud Security Engineer should be proficient in all aspects of cloud security, including identity and access management, defining the resource hierarchy and policies, using Google Cloud technologies to provide data protection, configuring network security defenses, monitoring environments for threat detection and incident response, security policy as code, the secure software development lifecycle, and enforcing regulatory controls. A Professional Cloud Security Engineer should have 3+ years of industry experience, including more than 1 year designing and managing solutions using Google Cloud. For more information, visit the Professional Cloud Security Engineer certification page. In this course, you’ll examine the role of a Professional Cloud Security Engineer by putting yourself in the shoes of a Professional Cloud Security Engineer working for Cymbal Bank, a fictional company that is digitally transforming and in the process of designing and developing a secure Google Cloud system. As part of its digital transformation, Cymbal Bank needs to determine how to set up and secure operations within a hybrid cloud environment. As a Professional Cloud Security Engineer at Cymbal Bank, your role involves your role involves working with cloud architects and network engineers to design Cymbal Bank’s cloud environment, and using recommended security practices that are in compliance with industry regulations. You’ll be involved in configuring Identity and Access Management and helping define Cymbal Bank’s resource hierarchy and policies. You’ll also ensure that Cymbal Bank makes use of Google Cloud technologies for data protection, network security and defenses, logging, and managing incident responses. As you continue through this course, you’ll explore the role of a Professional Cloud Security Engineer as Cymbal Bank defines different aspects of security for its cloud environment. We’ll use this scenario to illustrate the types of considerations and tasks that correspond to each section of the exam guide. Cymbal Bank’s network will also provide context for many of the diagnostic questions you’ll encounter along the way.

### Video - [Certification value and benefits](https://www.cloudskillsboost.google/course_templates/397/video/529553)

- [YouTube: Certification value and benefits](https://www.youtube.com/watch?v=do7eWETjsjI)

Person: Now, why become a certified Professional Cloud Security Engineer? Well, certification value has skyrocketed. Becoming Google Cloud certified gives you industry recognition, it validates your technical expertise, and can be the starting point to take your career to the next level. You may be curious about what differentiates a Professional Cloud certification from an associate level one. The professional level certification expects the exam taker to know how to evaluate case studies and design solutions to meet business requirements, which is in addition to knowing about technical requirements that will be used for customer implementation. The Professional Cloud Security Engineer Certification Exam is based on the exam guide. In the following modules, you'll take diagnostic questions to assess your knowledge of each section of the exam guide. The exam guide is divided into five sections. Each section has several objectives. We'll focus on where you can find your resources at the section objective level. You can find the exam guide on the Google Cloud certification page.

### Video - [Certification process](https://www.cloudskillsboost.google/course_templates/397/video/529554)

- [YouTube: Certification process](https://www.youtube.com/watch?v=2rxRqV5TOrU)

Throughout this course, you’ll be pointed to specific resources and documentation that can help you fill the gaps you identify through the diagnostic questions. Let’s go over the types of resources you may want to include in your study plan. Google provides resources to help you develop your skills and experience with Google Cloud solutions. The learning path for this certification includes in-person or online courses, online practice labs, skill badges, and practice questions. The courses recommended for the Professional Cloud Security Engineer certification include Google Cloud Fundamentals: Core Infrastructure, Networking in Google Cloud, and Security in Google Cloud. You’ll learn more about how these courses relate to the sections of the exam guide as you complete the modules in this course. Keep in mind that Networking in Google Cloud is available in an on-demand format as a six-course series. You should take all six courses: Fundamentals, Routing and Addressing, Network Architecture, Network Security, Load Balancing, and Hybrid and Multicloud for equivalent content to the 3-day instructor-led course. Similarly, Security in Google Cloud is available in an on-demand format as a three-course series. You should take all three courses: Managing Security in Google Cloud, Security Best Practices in Google Cloud, and Mitigating Security Vulnerabilities in Google Cloud, for equivalent content to the 3-day instructor-led course. The skill badges provide hands-on experience working in Google Cloud. Skill badges are learning paths made up of labs that give you hands-on practice with Google Cloud services or solutions. Pass the challenge lab at the end of the skill badge and you will receive a shareable credential that recognizes your ability to solve real-world problems with your cloud knowledge. As we review the diagnostic questions in this course, you’ll also get recommendations for skill badges to include in your study plan. Sample questions are another resource you can use to prepare. The diagnostic questions in this course are designed to help you identify your knowledge gaps. On the certification page, Google provides a different set of sample questions that can help you familiarize yourself with the format of the exam questions. Once you complete the question set, you will receive feedback describing the rationale for the correct answers. The sample questions provide a good opportunity to practice taking the type of scenario-based, application-level questions on the exam. The exam questions present you with a scenario, explain the goal or what you are trying to achieve, and ask you what you would do in that situation. Remember these tips for multiple choice questions: Read the question stem carefully. Make sure you understand exactly what the question is asking. Try to anticipate the correct answer before looking at the options. You may be able to come up with the correct answer just from reading the question stem. You may find that more than one answer may be possible on multiple choice tests. Take questions at face value. If certain details are omitted, then they are unlikely to contribute to the selection of the best answer. Pay attention to qualifiers ("usually", "all", "never", "none") and key words ("the best", "the least", "except"). Google also supplies official public documentation for its products and services. This documentation can be found at cloud.google.com/docs. In each of the following modules, you’ll learn about specific documentation resources to help you study that section in preparation for the exam.

### Video - [Creating your study plan](https://www.cloudskillsboost.google/course_templates/397/video/529555)

- [YouTube: Creating your study plan](https://www.youtube.com/watch?v=YxjKlKU1bQ0)

Person: One of the primary goals for this course is to help you devise a study strategy that focuses on the areas you need to work on. Let's quickly explore how the course is set up. To help you craft a study strategy, you'll take diagnostic questions as part of each module. These will help you identify areas you need to study and resources to support you. Now, many of these questions relate to our Cymbal Bank scenario and ask you to apply concepts you will need to be familiar with as a professional cloud security engineer. Now, keep in mind that these diagnostic questions are meant to help you identify gaps in your knowledge, but they don't represent all possible topics on the exam. We'll review the answers to the questions related to each section objective. As we cover each objective, you'll learn more about where the key concepts appear in Google Cloud documentation, specific courses and modules, and/or specific skill badges. Now at the end of each section objective, you'll find a list of related resources. Mark or highlight the specific resources you need in your study plan. In the final part of your workbook, you'll find a template to help you identify weekly goals and study activities. We'll talk more about putting together weekly goals at the end of this course. Now that you know about the overall setup of this course and how to use the workbook, let's get started by exploring section 1 of the exam guide.

### Document - [Workbook](https://www.cloudskillsboost.google/course_templates/397/documents/529556)

## Configuring Access

Learn how to set up the Organization, Folder, and Project hierarchy. Epxlore Organization policies and defining service accounts, groups, and custom IAM roles and binding custom or predefined roles to users, groups, and service accounts.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/397/video/529557)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=e5Oi41MJPlU)

In this module, you’ll learn about defining a high level plan for an organization’s cloud identity and access management, which corresponds to the first section of the Professional Cloud Security Engineer Exam Guide. We’ll start by discussing some different aspects of Cymbal Bank’s identity and access management structure. Next, you’ll assess your skills in this section through 10 diagnostic questions. Then, we’ll review these questions. Based on the areas you need to learn more about, you’ll identify resources to include in your study plan.

### Video - [Planning Cymbal Bank’s cloud identity and access management](https://www.cloudskillsboost.google/course_templates/397/video/529558)

- [YouTube: Planning Cymbal Bank’s cloud identity and access management](https://www.youtube.com/watch?v=an65j3fBsQY)

Let's begin by exploring how a Professional Cloud Security Engineer would plan Cymbal Bank's cloud identity and access management. Cymbal Bank is extending its on-premise office and data center infrastructure to connect into Google Cloud to support a hybrid cloud model. As a Professional Cloud Security Engineer, you play an integral role in securing the cloud environment and the data stored therein. In the cloud, Cymbal Bank will leverage the shared responsibility model to secure its virtual infrastructure, workloads, and data on top of the hardware and physical infrastructure security provided by Google. You will help design their systems, incorporating security features provided by Google Cloud along with the recommended approaches and best practices to ensure a layered defense in depth. You will begin by helping them synchronize and federate their current identity management system to Cloud Identity. This will let employees use the existing Cymbal Bank authentication system to be granted access to Cymbal Bank’s Google Cloud resources via their user or group identities. You will also help Cymbal Bank define service account identities for their workloads, running both on-premise and in the cloud, to provide access to protected resources and data in Google Cloud. Those resources and data will be arranged in an organization hierarchy that aligns with their access control requirements and helps them achieve a least privileged access control and separation of duties. You will also help Cymbal Bank manage authentication, manage and implement authorization controls, and help define their resource hierarchy. Cymbal Bank will synchronize their on-premises Active Directory users and groups to Cloud Identity using the Google Cloud Directory Sync tool. This synchronization will be handled by a cron job, which will run on a daily schedule, right after updates are made to the Active Directory system. This will ensure any changes to organization users, groups, and group memberships are synchronized from the Active Directory system into Google Cloud. Cymbal Bank will then be able to continue to use their existing Active Directory authentication system, for which they have a long-term contract. This system is configured for multifactor authentication. Cymbal Bank will synchronize their on-premises Active Directory users and groups to Cloud Identity using the Google Cloud Directory Sync tool and configure Cloud Identity to use the corporate Active Directory as a SAML2 identity provider and Google Cloud as a service provider. This will allow Google Cloud roles to be bound to their existing Active Directory user and group identities, and they can continue to manage the users, groups, and group membership, as well as authentication for users and groups, in Active Directory. Cymbal Bank will create separate service accounts for all their Google Cloud workloads running in Compute Engine VMs and GK containers, as well as for any on-premises workloads that require access to Google Cloud resources. Cymbal Bank will primarily leverage Google Key Management for these service accounts to reduce risk of key exposure by using features such as GKE workload identity and workload identity federation. They will prevent users creating service account keys with rare exceptions, use automated rotation of such keys when they do, and carefully audit that usage. They will also carefully control who has access to which service accounts and audit how they are used to ensure alignment with security best practices. Cymbal Bank will create their organization in Google Cloud with a folder hierarchy aligning with their departments, teams, products, and shared services. They will utilize separate projects for development, QA, and production environments. Projects may or may not have standalone VPCs for workloads that require isolation, and there will be a set of development, QA, and production shared VPC host projects for cross-project communication. Cymbal Bank will utilize organizational policy constraints in multiple policies bound at different levels of the hierarchy to restrict activity across projects to approved and expected services and processes. They will set constraints on which services can be enabled in parts of the hierarchy, as well as which regions or zones can be used. They will also set constraints around which identities from which domains can be granted access and how service accounts can be used. Cymbal Bank will primarily assign access by binding predefined roles to groups, aligning with the principles of least privilege and separation of duties. They will always bind roles as low in the hierarchy as possible when the access is not required across multiple resources or projects. They will also partition access to minimize the damage any single actor can do. Providing access primarily via groups, rather than individuals, minimizes maintenance as individuals join or leave teams or the organization, and reduces effort and complexity for auditing activity. Cymbal Bank will utilize IAM conditions when binding roles to identities to restrict from which locations, agent types, and time frames access can be used. This will provide further flexibility and granularity on least privilege access control.

### Video - [Introduction: Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529559)

- [YouTube: Introduction: Diagnostic questions](https://www.youtube.com/watch?v=0Goljn7J39Y)

Person: Now, it's your turn to assess your experience and skills related to this section with some diagnostic questions. Remember, the purpose of these questions is to help you better understand what is involved in this section of the exam guide, and identify which areas you'll want to focus on in your study plan.

### Quiz - [Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/quizzes/529560)

#### Quiz 1.

> [!important]
> **Cymbal Bank has a team of developers and administrators working on different sets of Google Cloud resources. The Bank's administrators should be able to access the serial ports on Compute Engine Instances and create service accounts. Developers should only be able to access serial ports. How would you design the organization hierarchy to provide the required access?**
>
> - [ ] Deny Serial Port Access and Service Account Creation at the Organization level. Create an 'admin' folder and set enforced: false for constraints/compute.disableSerialPortAccess. Create a new 'dev' folder inside the 'admin' folder, and set enforced: false for constraints/iam.disableServiceAccountCreation. Give developers access to the 'dev' folder, and administrators access to the 'admin' folder.
> - [ ] Allow Serial Port Access and Service Account Creation at the organization level. Create a 'dev' folder and set enforced: true for constraints/iam.disableServiceAccountCreation. Create another 'admin' folder that inherits from the parent inside the organization node. Give developers access to the 'dev' folder, and administrators access to the 'admin' folder.
> - [ ] Deny Serial Port Access and Service Account Creation at the organization level. Create a 'dev' folder and set enforced: false for constraints/compute.disableSerialPortAccess. Create a new 'admin' folder inside the 'dev' folder, and set enforced: false for constraints/iam.disableServiceAccountCreation. Give developers access to the 'dev' folder, and administrators access to the 'admin' folder.
> - [ ] Deny Serial Port Access and Service Account Creation at the organization level. Create a 'dev' folder and set enforced: true for constraints/compute.disableSerialPortAccess and enforced: true for constraints/iam.disableServiceAccountCreation. Create a new 'admin' folder inside the 'dev' folder, and set enforced: false for constraints/iam.disableServiceAccountCreation. Give developers access to the 'dev' folder, and administrators access to the 'admin' folder.

#### Quiz 2.

> [!important]
> **Cymbal Bank publishes its APIs through Apigee. Cymbal Bank has recently acquired ABC Corp, which uses a third-party identity provider. You have been tasked with connecting ABC Corp's identity provider to Apigee for single sign-on (SSO). You need to set up SSO so that Google is the service provider. You also want to monitor and log high-risk activities. Which two choices would you select to enable SSO?**
>
> - [ ] Use openssl to generate public and private keys. Store the private key in an X.509 certificate, and encrypt using AES or DES for SAML. Sign in to the Google Admin console, and under Security, upload the certificate.
> - [ ] Use openssl to generate a private key. Store the private key in an X.509 certificate, and encrypt using AES or DES for SAML. Sign in to the Google Workspace Admin Console and upload the certificate.
> - [ ] Review Network mapping results, and assign SSO profiles to required users.
> - [ ] Review Network mapping results, and assign SAML profiles to required users.
> - [ ] Use openssl to generate public and private keys. Store the public key in an X.509 certificate, and encrypt using RSA or DSA for SAML. Sign in to the Google Admin console, and under Security, upload the certificate.

#### Quiz 3.

> [!important]
> **Cymbal Bank has acquired a non-banking financial company (NBFC). This NBFC uses Active Directory as their central directory on an on-premises Windows Server. You have been tasked with migrating all the NBFC users and employee information to Cloud Identity. What should you do?**
>
> - [ ] Run Configuration Manager on a Compute Engine instance. Copy the resulting configuration file from this machine onto a new Compute Engine instance to keep the production environment separate from the staging environment. Leave the channel unencrypted because you are in a secure Google Cloud environment. Deploy Google Cloud Directory Sync on this new instance. Connect to the on-premises Windows Server environment from the new instance, and migrate users to Cloud Identity.
> - [ ] Select an on-premises domain-joined Windows Server. Run Configuration Manager on the domain-joined Windows Server, and copy the resulting configuration file to a Compute Engine instance. Run Google Cloud Directory Sync on the Compute Engine instance over the internet, and use Cloud VPN to sync users from the on-premises Active Directory to Cloud Identity.
> - [ ] Use Cloud VPN to connect the on-premises network to your Google Cloud environment. Select an on-premises domain-joined Windows Server. On the domain-joined Windows Server, run Configuration Manager and Google Cloud Directory Sync. Use Cloud VPN's encrypted channel to transfer users from the on-premises Active Directory to Cloud Identity.
> - [ ] Run Microsoft System Center Configuration Manager (SCCM) on a Compute Engine instance. Leave the channel unencrypted because you are in a secure Google Cloud environment. Deploy Google Cloud Directory Sync on the Compute Engine instance. Connect to the on-premises Windows Server environment from the instance, and migrate users to Cloud Identity.

#### Quiz 4.

> [!important]
> **Cymbal Bank recently discovered service account key misuse in one of the teams during a security audit. As a precaution, going forward you do not want any team in your organization to generate new external service account keys. You also want to restrict every new service account's usage to its associated Project. What should you do?**
>
> - [ ] Navigate to Organizational policies in the Google Cloud Console. Select your organization. Select iam.disableServiceAccountKeyCreation. Under Policy Enforcement, select Merge with parent. Click Save. Repeat the process for iam.disableCrossProjectServiceAccountLienRemoval.
> - [ ] Navigate to Organizational policies in the Google Cloud Console. Select your organization. Select iam.disableServiceAccountKeyCreation. Customize the applied to property, and set Enforcement to 'On'. Click Save. Repeat the process for iam.disableCrossProjectServiceAccountUsage.
> - [ ] Run the gcloud resource-manager org-policies allow command with the boolean constraints iam.disableServiceAccountKeyCreation and iam.disableCrossProjectServiceAccountUsage with Organization ID.
> - [ ] Run the gcloud resource-manager org-policies enable-enforce command with the constraints iam.disableServiceAccountKeyCreation, and iam.disableCrossProjectServiceAccountUsage and the Project IDs you want the constraints to apply to.

#### Quiz 5.

> [!important]
> **Cymbal Bank's organizational hierarchy divides the Organization into departments. The Engineering Department has a 'product team' folder. This folder contains folders for each of the bank's products. One folder titled "analytics" contains a Google Cloud Project that contains an App Engine deployment and a Cloud SQL instance.**
>
> - [ ] Create custom roles for all three user types at the project level. For the team lead, provide all appengine.* and cloudsql.* permissions. For the developer, provide appengine.applications.* and appengine.instances.* permissions. For the code reviewer, provide the appengine.instances.* permissions.
> - [ ] Create custom roles for all three user types at the "analytics" folder level. For the team lead, provide all appengine.* and cloudsql.* permissions. For the developer, provide appengine.applications.* and appengine.instances.* permissions. For the code reviewer, provide the appengine.instances.* permissions.
> - [ ] Assign the basic 'App Engine Admin' and 'Cloud SQL Admin" roles to the team lead. Assign the 'App Engine Admin' role to the developer. Assign the 'App Engine Code Viewer' role to the code reviewer. Assign all these permissions at the analytics project level.
> - [ ] Assign the basic 'Editor' role to the team lead. Create a custom role for the developer. Provide all appengine.* permissions to the developer. Provide the predefined 'App Engine Code Viewer' role to the code reviewer. Assign all these permissions at the "analytics" folder level.

#### Quiz 6.

> [!important]
> **Cymbal Bank's organizational hierarchy divides the Organization into departments. The Engineering Department has a 'product team' folder. This folder contains folders for each of the bank's products. Each product folder contains one Google Cloud Project, but more may be added. Each project contains an App Engine deployment. Cymbal Bank has hired a new technical product manager and a new web developer. The technical product manager must be able to interact with and manage all services in projects that roll up to the Engineering Department folder. The web developer needs read-only access to App Engine configurations and settings for a specific product. How should you provision the new employees' roles into your hierarchy following principles of least privilege?**
>
> - [ ] Assign the Project Editor role at the Engineering Department folder level to the technical product manager. Assign the App Engine Deployer role at the specific product's folder level to the web developer.
> - [ ] Assign the Project Owner role in each individual project to the technical product manager. Assign the App Engine Deployer role in each individual project to the web developer.
> - [ ] Assign the Project Editor role at the Engineering Department folder level to the technical product manager. Create a Custom Role in the product folder that the web developer needs access to. Add the appengine.versions.create and appengine.versions.delete permissions to that role, and assign it to the web developer.
> - [ ] Assign the Project Editor role in each individual project to the technical product manager. Assign the Project Editor role in each individual project to the web developer.

#### Quiz 7.

> [!important]
> **Cymbal Bank is divided into separate departments. Each department is divided into teams. Each team works on a distinct product that requires Google Cloud resources for development. How would you design a Google Cloud organization hierarchy to best match Cymbal Bank's organization structure and needs?**
>
> - [ ] Create an Organization node. Under the Organization node, create Department folders. Under each Department, create Teams folders. Add Projects to the Teams folders.
> - [ ] Create an Organization node. Under the Organization node, create Department folders. Under each Department, create Product folders. Add Projects to the Product folders.
> - [ ] Create an Organization node. Under the Organization node, create Department folders. Under each Department, create a Teams folder. Under each Team, create Product folders. Add Projects to the Product folders.
> - [ ] Create an Organization node. Under the Organization node, create Department folders. Under each Department, create Product folders. Under each Product, create Teams folders. In the Teams folder, add Projects.

#### Quiz 8.

> [!important]
> **You are an administrator for Cymbal Bank's Mobile Development Team. You want to control how long different users can access the Google Cloud console, the Cloud SDK, and any applications that require user authorization for Google Cloud scopes without having to reauthenticate. More specifically, you want users with elevated privileges (project owners and billing administrators) to reauthenticate more frequently than regular users at the organization level. What should you do?**
>
> - [ ] Create a custom role for project owners and billing administrators at the organization level in the Google Cloud console. Add the reauthenticationRequired permission to this role. Assign this role to each project owner and billing administrator.
> - [ ] Open all Google Cloud projects that belong to Cymbal Bank's Mobile Development team. Find each project's Google Cloud session control setting, and configure a reauthentication policy that requires reauthentication. Choose the reauthentication frequency from the drop-down list.
> - [ ] In the Admin console, select Google Cloud session control and set a reauthentication policy that requires reauthentication. Choose the reauthentication frequency from the drop-down list.
> - [ ] Create a custom role for project owners and billing administrators at the organization level in the Google Cloud console. Add the reauthenticationRequired permission to this role. Create a Google Group that contains all billing administrators and project owners. Apply the custom role to the group.

#### Quiz 9.

> [!important]
> **
Cymbal Bank has certain default permissions and access for their analyst, finance, and teller teams. These teams are organized into groups that have a set of role-based IAM permissions assigned to them. After a recent acquisition of a small bank, you find that the small bank directly assigns permissions to their employees in IAM. You have been tasked with applying Cymbal Bank's resource hierarchy to the small bank. Employees will need access to Google Cloud services. What should you do?
**
>
> - [ ] Leave all user permissions as-is in the small bank's IAM. Use the Directory API in the Google Workspace Admin SDK to create Google Groups. Use a Python script to allocate users to the Google Groups.
> - [ ] Reset all user permissions in the small bank's IAM. Use Cloud Identity to create the required Google Groups. Upgrade the Google Groups to Security Groups. Use a Python script to allocate users to the groups.
> - [ ] Reset all user permissions in the small bank's IAM. Use Cloud Identity to create dynamic groups for each of the bank's teams. Use the dynamic groups' metadata field for team type to allocate users to their appropriate group with a Python script.
> - [ ] Reset all user permissions in the small bank's IAM. Use the Directory API in the Google Workspace Admin SDK to create Google Groups. Use a Python script to allocate users to the groups.

#### Quiz 10.

> [!important]
> **Cymbal Bank leverages Google Cloud storage services, an on-premises Apache Spark Cluster, and a web application hosted on a third-party cloud. The Spark cluster and web application require limited access to Cloud Storage buckets and a Cloud SQL instance for only a few hours per day. You have been tasked with sharing credentials while minimizing the risk that the credentials will be compromised. What should you do?**
>
> - [ ] Create a service account with appropriate permissions. Authenticate the Spark Cluster and the web application as a delegated request, and share the service account key.
> - [ ] Create a service account with appropriate permissions. Have the Spark Cluster and the web application authenticate as a direct request, and share the short-lived service account credentials as XML tokens.
> - [ ] Create a service account with appropriate permissions. Have the Spark Cluster and the web application authenticate as delegated requests, and share the short-lived service account credential as a JWT.
> - [ ] Create a service account with appropriate permissions. Authenticate the Spark Cluster and the web application as direct requests and share the service account key.

### Video - [Review diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529561)

- [YouTube: Review diagnostic questions](https://www.youtube.com/watch?v=J7lTyJeCsdQ)

Now let’s review how to use these diagnostic questions to help you identify what to include in your study plan. We’ll approach this review by looking at the key areas of this exam section and the questions you just answered about each one. We’ll talk about where you can find out more about each area in the learning path for this certification and/or where to find the information in Google Cloud documentation. As we go through each one, take notes on the specific courses (and modules!), skill badges, and documentation pages you’ll want to emphasize in your study plan.

### Document - [Study plan resources](https://www.cloudskillsboost.google/course_templates/397/documents/529562)

### Quiz - [Knowledge Check](https://www.cloudskillsboost.google/course_templates/397/quizzes/529563)

#### Quiz 1.

> [!important]
> **Which feature of Google Cloud will Cymbal Bank use to control the source locations and times that authorized identities will be able to access resources?**
>
> - [ ] Identity-aware Proxy
> - [ ] IAM Conditions
> - [ ] Service Accounts
> - [ ] IAM Roles

#### Quiz 2.

> [!important]
> **Which tool will Cymbal Bank use to synchronize their identities from their on-premise identity management system to Google Cloud?**
>
> - [ ] Service Accounts
> - [ ] Cloud Identity
> - [ ] Google Cloud Directory Sync
> - [ ] Active Directory

## Securing Communications and Establishing Boundary Protection

Learn how to deifne VPC architecture for the Organization to ensure appropriate resource isolation, firewall rules to control/restrict traffic flow into and out of these VPCs, and private IP connectivity to resources in VPCs.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/397/video/529564)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=v1QsIgT_ctA)

In this module, you’ll learn about another area of the Professional Cloud Security Engineer’s role at Cymbal Bank. Network security is a critical aspect of overall system security and helping secure networks and network resources will be an important part of the tasks performed by a Professional Cloud Security Engineer. This corresponds to the second section of the Professional Cloud Security Engineer Exam Guide. As in the previous module, we’ll begin by exploring what this aspect of your role looks like at Cymbal Bank. Next, you’ll assess your skills in this section through 10 diagnostic questions. Then, we’ll review these questions. Based on the areas you need to learn more about, you’ll identify resources to include in your study plan.

### Video - [Securing Cymbal Bank’s network resources](https://www.cloudskillsboost.google/course_templates/397/video/529565)

- [YouTube: Securing Cymbal Bank’s network resources](https://www.youtube.com/watch?v=rr91Zc8bNqY)

As in the previous module, we'll begin by exploring what this aspect of your role looks like at Cymbal Bank. In the previous module, we started with designing identity management and access control for Cymbal Bank. Now, your role as a Professional Cloud Security Engineer continues with helping to secure Cymbal Bank’s networks and network resources. Some general patterns can be applied to facilitate securing networks. Keeping most traffic private with limited or no direct exposure of most resources to the internet, ensures that attackers have very few attack points from the internet. Resources that are exposed to the internet are the most vulnerable, so configuring network segmentation is paramount. Protect these resources with a web application firewall, such as Cloud Armor in Google Cloud. This will allow you to monitor traffic for patterns indicating invalid or attack traffic and block or filter such traffic. Establishing private connectivity can leverage isolation or segmentation to restrict the type of communication that can happen internally in your organization. This means that ports and protocols used for standard workloads are not exposed to the public internet and potential bad actors. You can use service identity to ensure that only valid, authenticated traffic can travel within your private networks. Cymbal Bank expects attacks against any endpoints that are accessible from the public internet. Cloud Load Balancing can provide protection against Layer 3 (or Network layer) and Layer 4 (Transport layer) attacks. Google Cloud Armor provides a configurable managed service that is integrated with the external Application Load Balancer and the classic Application Load Balancer, and protects against Layer 7 (or Application layer) attacks. Google Cloud Armor protects against SQL injection, cross-site scripting injection, and similar attacks. You can also configure Google Cloud Armor to filter traffic based on request properties. Traffic through Google Cloud Armor can also be throttled with configurable rate limits or challenged with a reCAPTCHA for bot management or to further protect against DDoS. Cymbal Bank will attempt to ensure the majority of traffic arriving at Cymbal Bank services from the public internet, go through the load balancer and Cloud Armor to provide this extra protection. When Cymbal Bank users need to connect via the public internet to resources or services via HTTPS or any TCP protocol (which includes SSH) that require authenticated and authorized access, they will connect through the Identity-Aware Proxy, or IAP. IAP lets you manage access to any services deployed in Google Cloud with an authentication and authorization layer for your applications. You can use Google-managed identities with Google authentication, or SAML2 federated single sign-on. You can also use external identities and other types of single sign-on when combining the Identity-Aware Proxy with Identity Platform. Cymbal Bank will ensure security for their public DNS zones to prevent attackers from poisoning or manipulating DNS responses to DNS requests sent to these public zones by activating DNSSEC. Cloud DNS ensures authenticated DNS responses to DNS requests and automatically manages DNSSEC-related DNS records. DNSSEC is supported by Cloud DNS and also by Google domains, Google's domain registration and registry service. Cymbal Bank will activate DNSSEC in both services to ensure security of your public DNS. Cymbal Bank will utilize firewall rules to only allow valid and expected network traffic between IP addresses, ports, and protocols used by actual workloads. You will use firewall rules to block all other traffic. Stateful rules handle requests in either the ingress or egress direction. Wherever possible, you will define firewall rules to restrict traffic to specific source and target service accounts. You will also use hierarchical firewall rules to ensure uniform application of rules across projects. Cymbal Bank will use private IP address communication between all resources within Google Cloud. This will happen primarily inside shared VPC networks. Shared VPC provides centralized network administration and allows resources from a large number of projects to communicate via a single VPC. Some Cymbal Bank projects may also have standalone VPCs when running isolated ephemeral workloads. These isolated standalone networks can be VPC peered to the shared VPC networks if they need to communicate with standard workloads running in the shared VPC networks. VPC peering provides decentralized network administration and allows VPCs to be connected across projects or even organizations. Cymbal Bank will connect privately from on premises into Google Cloud to Google APIs or the wider internet. Cloud VPN and Interconnect provide private IP communication from on-premises networks to Google Cloud. Cymbal Bank will utilize private IP communication from office and data center networks into Google Cloud via Cloud VPN and Interconnect. Google private access enables private IP communication to Google APIs. You will use Google private access to make requests to Google APIs privately from inside Google Cloud or from office and data center private networks. Cloud NAT allows resources with only internal IP addresses to make requests to the public Internet. All Cymbal Bank workloads will make internet bound requests through Cloud NAT, allowing them to only be given internal IP addresses.

### Video - [Introduction: Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529566)

- [YouTube: Introduction: Diagnostic questions](https://www.youtube.com/watch?v=PUBZ_Aph8WE)

Person: Now it's your turn to assess your experience and skills related to this section with some diagnostic questions. Remember, the purpose of these questions is to help you better understand what is involved in this section of the exam guide, and identify which areas you'll want to focus on in your study plan.

### Quiz - [Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/quizzes/529567)

#### Quiz 1.

> [!important]
> **Cymbal Bank has published an API that internal teams will use through the Application Load Balancer. You need to limit the API usage to 200 calls every hour. Any exceeding usage should inform the users that servers are busy. Which gcloud command would you run to throttle the load balancing for the given specification?**
>
> - [ ] gcloud compute security-policies rules create priority     --security-policy sec-policy 	    --src-ip-ranges="<source range>" 	    --action=rate-based-ban                  --rate-limit-threshold-count=200     --rate-limit-threshold-interval-sec=3600     --conform-action=allow                --exceed-action=deny-500     	    --enforce-on-key=IP
> - [ ] gcloud compute security-policies rules create priority --security-policy sec-policy 	--src-ip-ranges=source-range	--action=throttle--rate-limit-threshold-count=200 --rate-limit-threshold-interval-sec=3600 --conform-action=allow       	--exceed-action=deny-429  --enforce-on-key=HTTP-HEADER
> - [ ] gcloud compute security-policies rules create priority     --security-policy sec-policy 	    --src-ip-ranges=source-range 	    --action=rate-based-ban                  --rate-limit-threshold-count=200     --rate-limit-threshold-interval-sec=3600     --conform-action=deny                --exceed-action=deny-403     	    --enforce-on-key=HTTP-HEADER
> - [ ] gcloud compute security-policies rules create priority     --security-policy sec-policy 	    --src-ip-ranges=source-range	    --action=throttle            	    --rate-limit-threshold-count=200     --rate-limit-threshold-interval-sec=60     --conform-action=deny                --exceed-action=deny-404     	    --enforce-on-key=HTTP-HEADER

#### Quiz 2.

> [!important]
> **Cymbal Bank is releasing a new loan management application using a Compute Engine managed instance group. External users will connect to the application using a domain name or IP address protected with TLS 1.2. A load balancer already hosts this application and preserves the source IP address. You are tasked with setting up the SSL certificate for this load balancer. What should you do?**
>
> - [ ] Create a Google-managed SSL certificate. Attach a global static external IP address to the global external Application Load Balancer. Validate that an existing URL map will route the incoming service to your managed instance group backend. Load your certificate and create an HTTPS proxy routing to your URL map. Create a global forwarding rule that routes incoming requests to the proxy.
> - [ ] Import a self-managed SSL certificate. Attach a global static external IP address to the external proxy Network Load Balancer. Validate that an existing URL map will route the incoming service to your managed instance group backend. Load your certificate and create a TCP proxy routing to your URL map. Create a global forwarding rule that routes incoming requests to the proxy.
> - [ ] Import a self-managed SSL certificate. Attach a global static external IP address to the external proxy Network Load Balancer. Validate that an existing URL map will route the incoming service to your managed instance group backend. Load your certificate and create an SSL proxy routing to your URL map. Create a global forwarding rule that routes incoming requests to the proxy.
> - [ ] Create a Google-managed SSL certificate. Attach a global dynamic external IP address to the internal Application Load Balancer. Validate that an existing URL map will route the incoming service to your managed instance group backend. Load your certificate and create an HTTPS proxy routing to your URL map. Create a global forwarding rule that routes incoming requests to the proxy.

#### Quiz 3.

> [!important]
> **You have recently joined Cymbal Bank as a cloud engineer. You created a custom VPC network, selecting to use the automatic subnet creation mode and nothing else. The default network still exists in your project. You create a new Linux VM instance and select the custom VPC as the network interface. You try to SSH into your instance, but you are getting a "connection failed" error. What answer best explains why you cannot SSH into the instance?**
>
> - [ ] You should have deleted the default network. When you have multiple VPCs in your project, Compute Engine can't allow you to connect because overlapping IP ranges prevent the API from establishing a root connection.
> - [ ] You did not set up any firewall rules on your custom VPC network. While the default VPC comes with a predefined firewall rule that allows SSH traffic, these need to be added to any custom VPCs.
> - [ ] You should have used custom subnet creation mode. Since the default VPC still exists, automatic mode created subnets in the same regions, which led to overlapping IP addresses.
> - [ ] You should have used the default network when setting up your instance. While custom networks support instance creation, they should only be used for internal communication.

#### Quiz 4.

> [!important]
> **An ecommerce portal uses Google Kubernetes Engine to deploy its recommendation engine in Docker containers. This cluster instance does not have an external IP address. You need to provide internet access to the pods in the Kubernetes cluster. What configuration would you add?**
>
> - [ ] Cloud NAT gateway, subnet primary IP address range for nodes, and subnet secondary IP address range for pods and services in the cluster
> - [ ] Cloud VPN, subnet secondary IP address range for nodes, and subnet secondary IP address range for pods and services in the cluster
> - [ ] Nginx load balancer, subnet secondary IP address range for nodes, and subnet secondary IP address range for pods and services in the cluster
> - [ ] Cloud DNS, subnet primary IP address range for nodes, and subnet secondary IP address range for pods and services in the cluster

#### Quiz 5.

> [!important]
> **
An external audit agency needs to perform a one-time review of Cymbal Bank's Google Cloud usage. The auditors should be able to access a Default VPC containing BigQuery, Cloud Storage, and Compute Engine instances where all the usage information is stored. You have been tasked with enabling the access from their on-premises environment, which already has a configured VPN. What should you do?
**
>
> - [ ] Use a Cloud VPN tunnel. Use Cloud DNS to create DNS zones and records for *.googleapis.com. Set up on-premises routing with Cloud Router. Use Cloud Router custom route advertisements to announce routes for Google Cloud destinations.
> - [ ] Use a Cloud VPN tunnel. Use your DNS provider to create DNS zones and records for private.googleapis.com. Connect the DNS provider to your on-premises network. Broadcast the request from the on-premises environment.  Use a software-defined firewall to manage incoming and outgoing requests.
> - [ ] Use Partner Interconnect. Configure an encrypted tunnel in the auditor's on-premises environment. Use Cloud DNS to create DNS zones and A records for private.googleapis.com.
> - [ ] Use Dedicated Interconnect. Configure a VLAN in the auditor's on-premises environment. Use Cloud DNS to create DNS zones and records for restricted.googleapis.com and private.googleapis.com. Set up on-premises routing with Cloud Router. Add custom static routes in the VPC to connect individually to BigQuery, Cloud Storage, and Compute Engine instances.

#### Quiz 6.

> [!important]
> **
The data from Cymbal Bank's loan applicants resides in a shared VPC. A credit analysis team uses a CRM tool hosted in the App Engine standard environment. You need to provide credit analysts with access to this data. You want the charges to be incurred by the credit analysis team. What should you do?
**
>
> - [ ] Add egress firewall rules to allow TCP and UDP ports for the App Engine standard environment in the Shared VPC network. Create either a client-side connector in the Service Project or a server-side connector in the Host Project using the IP Range or Project ID of the target VPC. Verify that the connector is in a READY state. Create an egress rule on the Shared VPC network to allow the connector using Network Tags or IP ranges.
> - [ ] Add ingress firewall rules to allow NAT and Health Check ranges for App Engine standard environment in the Shared VPC network. Create a server-side connector in the Host Project using the Shared VPC Project ID. Verify that the connector is in a READY state. Create an ingress rule on the Shared VPC network to allow the connector using Network Tags or IP ranges.
> - [ ] Add ingress firewall rules to allow NAT and Health Check ranges for the App Engine standard environment in the Shared VPC network. Create a client-side connector in the Service Project using the Shared VPC Project ID. Verify that the connector is in a READY state. Create an ingress rule on the Shared VPC network to allow the connector using Network Tags or IP ranges.
> - [ ] Add egress firewall rules to allow SSH and/or RDP ports for the App Engine standard environment in the Shared VPC network. Create a client-side connector in the Service Project using the IP range of the target VPC. Verify that the connector is in a READY state. Create an egress rule on the Shared VPC network to allow the connector using Network Tags or IP ranges.

#### Quiz 7.

> [!important]
> **Cymbal Bank needs to connect its employee MongoDB database to a new human resources web application on the same network. Both the database and the application are autoscaled with the help of Instance templates. As the Security Administrator and Project Editor, you have been tasked with allowing the application to read port 27017 on the database. What should you do?**
>
> - [ ] Create service accounts for the application and database. Create a firewall rule using:gcloud compute firewall-rules create ALLOW_MONGO_DB 	--network network-name 	--allow ICMP:27017 	--source-service-accounts web-application-service-account	 --target-service-accounts database-service-account
> - [ ] Create a user account for the database admin and a service account for the application. Create a firewall rule using:gcloud compute firewall-rules create ALLOW_MONGO_DB 	--network network-name 	--allow TCP:27017 	--source-service-accounts web-application-service-account 	--target-service-accounts database-admin-user-account
> - [ ] Create service accounts for the application and database. Create a firewall rule using:gcloud compute firewall-rules create ALLOW_MONGO_DB 	--network network-name 	--allow TCP:27017 	--source-service-accounts web-application-service-account 	--target-service-accounts database-service-account
> - [ ] Create user accounts for the application and database. Create a firewall rule using:gcloud compute firewall-rules create ALLOW_MONGO_DB 	--network network-name 	--deny UDP:27017 	--source-service-accounts web-application-user-account 	--target-service-accounts database-admin-user-account

#### Quiz 8.

> [!important]
> **
Cymbal Bank has designed an application to detect credit card fraud that will analyze sensitive information. The application that's running on a Compute Engine instance is hosted in a new subnet on an existing VPC. Multiple teams who have access to other VMs in the same VPC must access the VM. You want to configure the access so that unauthorized VMs or users from the internet can't access the fraud detection VM. What should you do?
**
>
> - [ ] Use target filtering. Create a tag called 'app', and assign the tag to both the source and the target. Create a firewall rule to allow all ingress communication on this tag.
> - [ ] Use subnet isolation. Create a service account for the fraud detection VM. Create one service account for all the teams' Compute Engine instances that will access the fraud detection VM. Create a new firewall rule using:gcloud compute firewall-rules create ACCESS_FRAUD_ENGINE 	--network <network name> 	--allow TCP:80 	--source-service-accounts <one service account for all teams> 	--target-service-accounts <fraud detection engine's service account>
> - [ ] Use target filtering. Create two tags called 'app' and 'data'. Assign the 'app' tag to the Compute Engine instance hosting the Fraud Detection App (source), and assign the 'data' tag to the other Compute Engine instances (target). Create a firewall rule to allow all ingress communication on this tag.
> - [ ] Use subnet isolation. Create a service account for the fraud detection engine. Create service accounts for each of the teams' Compute Engine instances that will access the engine. Add a firewall rule using:  gcloud compute firewall-rules create ACCESS_FRAUD_ENGINE 	--network <network name> 	 --allow TCP:80 	--source-service-accounts <list of service accounts> 	 --target-service-accounts <fraud detection engine's service account>

#### Quiz 9.

> [!important]
> **Cymbal Bank's Customer Details API runs on a Compute Engine instance with only an internal IP address. Cymbal Bank's new branch is co-located outside the Google Cloud points-of-presence (PoPs) and requires a low-latency way for its on-premises apps to consume the API without exposing the requests to the public internet. Which solution would you recommend?**
>
> - [ ] Use Partner Interconnect. Use a service provider to access their enterprise grade infrastructure to connect to the Google Cloud environment.
> - [ ] Use a Content Delivery Network (CDN). Establish direct peering with one of Google's nearby edge-enabled PoPs.
> - [ ] Use Carrier Peering. Use a service provider to access their enterprise grade infrastructure to connect to the Google Cloud environment.
> - [ ] Use Dedicated Interconnect. Establish direct peering with one of Google's nearby edge-enabled PoPs.

#### Quiz 10.

> [!important]
> **Your organization has a website running on Compute Engine. This instance only has a private IP address. You need to provide SSH access to an on-premises developer who will debug the website from the authorized on-premises location only. How do you enable this?**
>
> - [ ] Use Identity-Aware Proxy (IAP). Set up IAP TCP forwarding by creating ingress firewall rules on port 22 for TCP using the gcloud command.
> - [ ] Set up Cloud VPN. Set up an unencrypted tunnel to one of the hosts in the network. Create outbound or egress firewall rules. Use the private IP address to log in using a gcloud ssh command.
> - [ ] Use SOCKS proxy over SSH. Set up an SSH tunnel to one of the hosts in the network. Create the SOCKS proxy on the client side.
> - [ ] Use the default VPC's firewall. Open port 22 for TCP protocol using the Google Cloud Console.

### Video - [Review diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529568)

- [YouTube: Review diagnostic questions](https://www.youtube.com/watch?v=8oT_abPmdrM)

Now let’s review how to use these diagnostic questions to help you identify what to include in your study plan. We’ll approach this review by looking at the key areas of this exam section and the questions you just answered about each one. We’ll talk about where you can find out more about each area in the learning path for this certification and/or where to find the information in Google Cloud documentation. As we go through each one, take notes on the specific courses (and modules!), skill badges, and documentation pages you’ll want to emphasize in your study plan.

### Document - [Study plan resources](https://www.cloudskillsboost.google/course_templates/397/documents/529569)

### Quiz - [Knowledge Check](https://www.cloudskillsboost.google/course_templates/397/quizzes/529570)

#### Quiz 1.

> [!important]
> **Which tool will Cymbal Bank use to enforce authentication and authorization for services deployed to Google Cloud?**
>
> - [ ] Identity-Aware proxy
> - [ ] Google Cloud Armor
> - [ ] Firewall rules
> - [ ] Application Load Balancer

#### Quiz 2.

> [!important]
> **How will Cymbal Bank enable resources with only internal IP addresses to make requests to the Internet?**
>
> - [ ] Shared VPC
> - [ ] Cloud NAT
> - [ ] Dedicated Interconnect
> - [ ] Google private access

## Ensuring Data Protection

Learn how to define DLP and VPC service controls process for the Organization as well as the Encryption and key management scheme.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/397/video/529571)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=1XEAlXw52kA)

In this module, you'll learn about the third area of the Professional Cloud Security Engineer's role at Cymbal Bank. In addition to the network security we looked at in the previous module, the next security consideration is the data security for data stored and accessible in those networks. As a Professional Cloud Security Engineer, you play an integral role in ensuring that security, confidentiality, appropriate access control, and use of data. This corresponds to the third section of the Professional Cloud Security Engineer Exam Guide. As in previous modules, we'll begin by exploring what this aspect of your role, securing data, looks like at Cymbal Bank. Next, we'll assess your skills in this section through 10 diagnostic questions. Then, we'll review these questions. Based on the areas you need to learn more about, you'll identify resources to include in your study plan.

### Video - [Securing Cymbal Bank’s data](https://www.cloudskillsboost.google/course_templates/397/video/529572)

- [YouTube: Securing Cymbal Bank’s data](https://www.youtube.com/watch?v=mmw8sw3McN0)

Let’s explore how a Professional Cloud Security Engineer at Cymbal Bank ensures data security. In the previous module, you examined Google Cloud tools and practices to help facilitate secure communications and establish boundary protection. In this module, you’ll continue to explore the Professional Cloud Security Engineer’s role through an examination of the tools and techniques for ensuring data protection. Data security encompasses protecting sensitive data via encryption and appropriate least privilege access control. Data security also includes classifying the sensitivity of all stored data to define the data’s level of confidentiality. Data security further involves enforcing access and usage of data in a way that aligns with the data’s level of confidentiality. Data security also includes prevention of data exfiltration, or the invalid transfer, movement, or communication of data by malicious or invalid activities undertaken by users who correctly have access to that data, but violate the terms of its correct usage. Cymbal Bank will utilize Sensitive Data Protection to scan all your stored data to identify personally identifiable information (PII) and other sensitive or confidential data, such as names, addresses, phone numbers, email addresses, or credit card and other account numbers. Sensitive Data Protection has many built-in data patterns for global or country-specific types of sensitive data. You can customize Sensitive Data Protection and define new data patterns to scan, detect, and if needed, transform your data. Configuring scanning for custom patterns is referred to as custom info-types and discovered sensitive data can be transformed in various ways including pseudonymization, data shifting, and generalization and bucketing. Sensitive Data Protection can work with image and PDF files to perform optical character recognition (OCR). Cymbal Bank will apply appropriate metadata to sensitive data types that indicates the data’s level of confidentiality. Access to data will be controlled accordingly. In cases where data with sensitive portions should still be accessible and used, sensitive portions of the data can be redacted, obfuscated, or transformed to prevent exposure. You want to provide granular access to data, controlled at the organization, folder, project, or lower levels of Cymbal Bank’s resource hierarchy. You will ensure least privilege access to data by grouping associated data with identical or similar access control, and providing access to groups and service accounts at appropriate levels. For Cloud Storage, you will group objects with identical or similar access in buckets. For BigQuery, you will group tables with identical or similar access in datasets. Cymbal Bank will primarily access control Cloud Storage at the bucket level, with uniform bucket-level or object-level access. You will use IAM conditions to provide increased granularity when necessary with Access-control lists (ACL). BigQuery data will be primarily access controlled at the dataset level. You will occasionally control access at the table level, with some sensitive tables further protected at the sub-table level by row and column security or authorized views. Your role also involves helping Cymbal Bank store sensitive key-value data, such as passwords, connection strings, or keys. Using Google Cloud Secret Manager: Access control can be granted at the individual secret level. Secrets can be independently encrypted, versioned, rotated, and have expiry periods set. And changes to secrets can trigger notifications. At Cymbal Bank, you will grant access at the secret level, and typically only to the service accounts of workloads that require the secret. All data at rest is encrypted by default in Google Cloud using a multi-level encryption scheme. As a Professional Cloud Security Engineer, you also need to know how Cymbal can leverage additional options for data encryption in Google Cloud. You will primarily utilize customer-managed encryption keys to encrypt data at rest, and create and store keys in Cloud KMS with rotation periods appropriate to the level of sensitivity of the data. In cases where Cymbal Bank would like complete control over the keys, including storage outside Google Cloud, you will utilize customer-supplied encryption keys. You will also have the possibility to use externally managed keys. Cloud hosted security module—or HSM—is also available if you want to create and use HSM-protected encryption keys. Part of your role will be to help manage the data lifecycle. Cymbal Bank will use Cloud Storage features to enforce data lifecycle policies. Retention policies or object holds prevent accidental overwrite or deletion. Object versioning lets you read or recover past versions of objects. Configuration rules in lifecycle management automatically delete or change the storage class of objects based on age or other factors. Cymbal Bank will also protect data from accidental overwrite or deletion by applying retention periods or object holds and object versioning as appropriate and ensure data is deleted when required via object lifecycle management rules. Implementing security and privacy measures is crucial for organizations such as banks adopting Google Cloud AI (GCAI) solutions. To ensure the protection of sensitive customer data and compliance with regulatory requirements, the following guidelines should be carefully considered: Clearly define the sensitivity levels of different types of customer data and establish granular access controls to restrict access to only authorized personnel based on their roles and responsibilities. Employ role-based access control (RBAC) mechanisms to limit access to sensitive data and resources. Encrypt customer data at rest and in transit to safeguard it against unauthorized access, even if the underlying infrastructure is compromised. Utilize strong encryption algorithms and implement encryption keys management practices to protect the confidentiality of sensitive data. Employ Data Loss Prevention tools to detect, monitor, and prevent sensitive data from being inadvertently or intentionally leaked. DLP solutions can identify and flag sensitive data elements, restrict data transfers to unauthorized destinations, and block unauthorized access attempts. You can also utilize Identity and Access Management to manage and control user access to GCAI resources. Define fine-grained access policies based on user roles and enforce multi-factor authentication (MFA) for sensitive operations. Continuously monitor user activity and access patterns to detect anomalies and potential security breaches. Utilize audit logs to track all access attempts, data transfers, and changes made to GCAI resources. Regularly review audit logs to identify suspicious activity and investigate potential security incidents. You should also regularly conduct security assessments and penetration tests to identify and address vulnerabilities in GCAI deployments. Engage third-party security experts to perform comprehensive vulnerability scans and penetration testing to ensure the integrity and security of GCAI systems. You should also adopt a Zero Trust security model, which assumes that no user or device is inherently trusted and requires continuous authentication and authorization for access. Implement network segmentation, micro-segmentation, and least privilege access controls to further enhance your security posture. Don’t forget to integrate security best practices into the software development lifecycle (SDLC) and other deployment processes. You should employ automated security tools and practices to detect and remediate vulnerabilities early in the development process. Be sure to stay informed about the latest security threats, vulnerabilities, and emerging attack techniques. Regularly update GCAI software, libraries, and dependencies to patch known vulnerabilities and protect against emerging threats. And finally, you should engage external security consultants or auditing firms to conduct periodic security assessments of GCAI deployments. These assessments can provide valuable insights into potential vulnerabilities and help identify areas for improvement. By adhering to these guidelines and carefully considering these aspects, organizations can effectively protect customer data, maintain compliance with regulatory requirements, and enhance the overall security posture of their GCAI implementations.

### Video - [Introduction: Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529573)

- [YouTube: Introduction: Diagnostic questions](https://www.youtube.com/watch?v=8EHHWQgZYNU)

Person: Now, it's your turn to assess your experience and skills related to this section with some diagnostic questions. Remember, the purpose of these questions is to help you better understand what is involved in this section of the exam guide and identify which areas you'll want to focus on in your study plan.

### Quiz - [Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/quizzes/529574)

#### Quiz 1.

> [!important]
> **Cymbal Bank stores customer information in a BigQuery table called 'Information,' which belongs to the dataset 'Customers.' Various departments of Cymbal Bank, including loan, credit card, and trading, access the information table. Although the data source remains the same, each department needs to read and analyze separate customers and customer-attributes. You want a cost-effective way to configure departmental access to BigQuery to provide optimal performance.  What should you do?**
>
> - [ ] Secure data with classification. Open the Data Catalog Taxonomies page in the Google Cloud Console. Create policy tags for required columns and rows. Provide the bigquery.user role to each department's required users. Provide policy tags access to each department separately.
> - [ ] Create separate datasets for each department. Create authorized functions in each dataset to perform required aggregations. Write transformed data to new tables for each department separately. Provide the bigquery.dataViewer role to each department's required users.
> - [ ] Create an authorized dataset in BigQuery's Explorer panel. Write Customers' table metadata into a JSON file, and edit the file to add each department's Project ID and Dataset ID. Provide the bigquery.user role to each department's required users.
> - [ ] Create separate datasets for each department. Create views for each dataset separately. Authorize these views to access the source dataset. Share the datasets with departments. Provide the bigquery.dataViewer role to each department's required users.

#### Quiz 2.

> [!important]
> **Cymbal Bank has hired a data analyst team to analyze scanned copies of loan applications. Because this is an external team, Cymbal Bank does not want to share the name, gender, phone number, or credit card numbers listed in the scanned copies. You have been tasked with hiding this PII information while minimizing latency. What should you do?**
>
> - [ ] Use the Cloud Vision API to perform optical code recognition (OCR) from scanned images. Redact the text using the Cloud Data Loss Prevention (DLP) API with regular expressions.
> - [ ] Use the Cloud Vision API to perform text extraction from scanned images. Redact the text using the Cloud Natural Language API with regular expressions.
> - [ ] Use the Cloud Vision API to perform optical code recognition (OCR) from scanned images. Redact the text using the Cloud Natural Language API with regular expressions.
> - [ ] Use the Cloud Data Loss Prevention (DLP) API to make redact image requests. Provide your project ID, built-in infoTypes, and the scanned copies when you make the requests.

#### Quiz 3.

> [!important]
> **Cymbal Bank has a Cloud SQL instance that must be shared with an external agency. The agency's developers will be assigned roles and permissions through a Google Group in Identity and Access Management (IAM). The external agency is on an annual contract and will require a connection string, username, and password to connect to the database. How would you configure the group's access?**
>
> - [ ] Use Cloud Key Management Service. Use the destination IP address and Port attributes to provide access for developers at the external agency. Remove the IAM access after one year and rotate the shared keys. Add cloudkms.cryptoKeyEncryptorDecryptor role for the group that contains the external developers.
> - [ ] Use Secret Manager. Use the duration attribute to set the expiry period to one year. Add the secretmanager.secretAccessor role for the group that contains external developers.
> - [ ] Use Secret Manager. Use the resource attribute to set a key-value pair with key as duration and values as expiry period one year from now. Add secretmanager.viewer role for the group that contains external developers.
> - [ ] Use Secret Manager for the connection string and username, and use Cloud Key Management Service for the password. Use tags to set the expiry period to the timestamp one year from now. Add secretmanager.secretVersionManager and secretmanager.secretAccessor roles for the group that contains external developers.

#### Quiz 4.

> [!important]
> **Cymbal Bank needs to statistically predict the days customers delay the payments for loan repayments and credit card repayments. Cymbal Bank does not want to share the exact dates a customer has defaulted or made a payment with data analysts. Additionally, you need to hide the customer name and the customer type, which could be corporate or retail. How do you provide the appropriate information to the data analysts?**
>
> - [ ] Generalize all dates to year and month with bucketing. Use the built-in infoType for customer name. Use a custom infoType for customer type with regular expression.
> - [ ] Generalize all dates to year and month with bucketing. Use the built-in infoType for customer name. Use a custom infoType for customer type with a custom dictionary.
> - [ ] Generalize all dates to year and month with date shifting. Use a predefined infoType for customer name. Use a custom infoType for customer type with regular expression.
> - [ ] Generalize all dates to year and month with date shifting. Use a predefined infoType for customer name. Use a custom infoType for customer type with a custom dictionary.

#### Quiz 5.

> [!important]
> **You're building a machine learning model on Google Cloud. You're choosing between two options: managing the infrastructure yourself (IaaS) or using Google's managed services (PaaS). To ensure the best security posture for both the model and its data, which TWO factors should you prioritize when defining security requirements for each hosting option?**
>
> - [ ] Granular access controls and permissions
> - [ ] Physical server hardening and security patches
> - [ ] Compliance with internal security policies
> - [ ] Network traffic inspection and intrusion detection
> - [ ] Data location and residency restrictions

#### Quiz 6.

> [!important]
> **Cymbal Bank calculates employee incentives on a monthly basis for the sales department and on a quarterly basis for the marketing department. The incentives are released with the next month's salary. Employee's performance documents are stored as spreadsheets, which are retained for at least one year for audit. You want to configure the most cost-effective storage for this scenario. What should you do?**
>
> - [ ] Import the spreadsheets to Cloud SQL, and create separate tables for Sales and Marketing. For Table Expiration, set 365 days for both tables. Use stored procedures to calculate incentives. Use App Engine cron jobs to run stored procedures monthly for Sales and quarterly for Marketing.
> - [ ] Import the spreadsheets into Cloud Storage and create NoSQL tables. Use App Engine cron jobs to run monthly for Sales and quarterly for Marketing. Use a separate job to delete the data after 1 year.
> - [ ] Upload the spreadsheets to Cloud Storage. Select the Nearline storage class for the sales department and Coldline storage for the marketing department. Use object lifecycle management rules to set the storage class to Archival after 365 days. Process the data on BigQuery using jobs that run monthly for Sales and quarterly for Marketing.
> - [ ] Import the spreadsheets to BigQuery, and create separate tables for Sales and Marketing. Set table expiry rules to 365 days for both tables. Create jobs scheduled to run every quarter for Marketing and every month for Sales.

#### Quiz 7.

> [!important]
> **You are tasked with developing an AI system on Google Cloud for a telecommunications business. This AI system will conduct sentiment analysis on conversations agents have with customers, and provide conversational recommendations to improve customer satisfaction in the future. What AI/ML-specific security controls do you need to plan for when developing this system?**
>
> - [ ] AI systems are more interconnected than non-AI systems. Prepare for new attack vectors, as attackers can exploit vulnerabilities in one system to attack another.
> - [ ] Deploy your AI solution using managed instance groups (MIGs). These have baked in security controls specific to running AI workloads.
> - [ ] Select Google Cloud AI services that leverage a PaaS model. These are the only ones that can guarantee a secure-by-design foundation.
> - [ ] Leverage an AI model-specific threat detection scanner. Threats between AI systems and non-AI systems have very little in common.

#### Quiz 8.

> [!important]
> **
Cymbal Bank needs to migrate existing loan processing applications to Google Cloud. These applications transform confidential financial information. All the data should be encrypted at all stages, including sharing between sockets and RAM. An integrity test should also be performed every time these instances boot. You need to use Cymbal Bank's encryption keys to configure the Compute Engine instances. What should you do?
**
>
> - [ ] Create a Shielded VM instance with Customer-Managed Encryption Keys. In Cloud Logging, collect all logs for sevLaunchAttestationReportEvent.
> - [ ] Create a Shielded VM instance with Customer-Supplied Encryption Keys. In Cloud Logging, collect all logs for earlyBootReportEvent.
> - [ ] Create a Confidential VM instance with Customer-Supplied Encryption Keys. In Cloud Logging, collect all logs for sevLaunchAttestationReportEvent.
> - [ ] Create a Confidential VM instance with Customer-Managed Encryption Keys. In Cloud Logging, collect all logs for earlyBootReportEvent.

#### Quiz 9.

> [!important]
> **Cymbal Bank uses Google Kubernetes Engine (GKE) to deploy its Docker containers. You want to encrypt the boot disk for a cluster running a custom image so that the key rotation is controlled by the Bank. GKE clusters will also generate up to 1024 randomized characters that will be used with the keys with Docker containers. What steps would you take to apply the encryption settings with a dedicated hardware security layer?**
>
> - [ ] Create a new key ring using Cloud Key Management Service. Extract this key to a certificate. Use the kubectl command to update the Kubernetes configuration. Validate using MAC digital signatures, and use a startup script to generate random bytes.
> - [ ] Create a new key ring using Cloud Key Management Service. Extract this key to a certificate. Use the Google Cloud Console to update the Kubernetes configuration. Validate using MAC digital signatures, and use a startup script to generate random bytes.
> - [ ] Create a new GKE cluster with customer-managed encryption and HSM enabled. Deploy the containers to this cluster. Delete the old GKE cluster. Use Cloud HSM to generate random bytes and provide an additional layer of security.
> - [ ] In the Google Cloud console, navigate to Google Kubernetes Engine. Select your cluster and the boot node inside the cluster. Enable customer-managed encryption. Use Cloud HSM to generate random bytes and provide an additional layer of security.

#### Quiz 10.

> [!important]
> **You are building an AI model on Google Cloud to analyze customer data and predict purchase behavior. This model will have access to sensitive information like purchase history and demographics. To protect this data and prevent misuse of the model, what THREE security controls are most important to implement?**
>
> - [ ] Configure IAM roles to grant full access to the model for all Google Cloud users.
> - [ ] Store all model training data in BigQuery with public access for transparency.
> - [ ] Deploy the model in a region with the highest data security standards.
> - [ ] Enable Google Cloud Armor on your deployed model to block malicious requests.
> - [ ] Monitor the model's performance for anomalies and biases, then manually intervene if needed.

### Video - [Review diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529575)

- [YouTube: Review diagnostic questions](https://www.youtube.com/watch?v=YkLaakBPhv0)

Now let’s review how to use these diagnostic questions to help you identify what to include in your study plan. We’ll approach this review by looking at the key areas of this exam section and the questions you just answered about each one. We’ll talk about where you can find out more about each area in the learning path for this certification and/or where to find the information in Google Cloud documentation. As we go through each one, take notes on the specific courses (and modules!), skill badges, and documentation pages you’ll want to emphasize in your study plan.

### Document - [Study plan resources](https://www.cloudskillsboost.google/course_templates/397/documents/529576)

### Quiz - [Knowledge Check](https://www.cloudskillsboost.google/course_templates/397/quizzes/529577)

#### Quiz 1.

> [!important]
> **Which tool will Cymbal Bank use to scan for, detect, and optionally transform sensitive data to prevent exposure?**
>
> - [ ] Secret Manager
> - [ ] VPC service controls
> - [ ] Google Cloud Armor
> - [ ] Sensitive Data Protection

#### Quiz 2.

> [!important]
> **What feature will allow Cymbal Bank to delete or change the storage class of objects in Cloud Storage buckets?**
>
> - [ ] Retention policies
> - [ ] Rotation periods
> - [ ] Object versioning
> - [ ] Lifecycle management rules

## Managing Operations

Learn about automating Google Cloud security features into the organizational CICD flow and utilizing Logging and Monitoring for security forensics and alerting.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/397/video/529578)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=hcA1wJIGbVc)

In this module, you’ll learn about the fourth area of the Professional Cloud Security Engineer’s role at Cymbal Bank. Once the network and data security approaches have been defined, as a Professional Cloud Security Engineer, the next step will be to institute and automate ongoing security operations. This corresponds to the fourth section of the Professional Cloud Security Engineer Exam Guide. As in previous modules, we’ll begin by exploring what this aspect of your role, managing security operations, looks like at Cymbal Bank. Next, you’ll assess your skills in this section through 10 diagnostic questions. Then, we’ll review these questions. Based on the areas you need to learn more about, you’ll identify resources to include in your study plan.

### Video - [Cymbal Bank’s security operations](https://www.cloudskillsboost.google/course_templates/397/video/529579)

- [YouTube: Cymbal Bank’s security operations](https://www.youtube.com/watch?v=uV77r22XNiY)

After securing the network and data resources, your role as a Professional Cloud Security Engineer at Cymbal Bank shifts focus. You will design processes and automation to maintain security of software, infrastructure, and data, which are deployed and used to support business operations. You need to follow a secure software development and deployment process that includes scanning software and infrastructure for vulnerabilities and addressing those vulnerabilities. You also need to configure a logging and monitoring system to capture detailed information about any actions or events that may have a security impact. Your system needs to provide indications of attacks or compromised systems or data. All logs and metrics will require regular audits to detect and respond to security incidents. As a professional cloud security engineer, you will help Cymbal Bank automate security operations in CI/CD pipelines. Cymbal Bank will implement a DevOps model with automation to enable continuous integration and continuous deployment. You'll ensure security operations are included in this automation to ensure secure software deployment. Such security operations include confirming that most recent and secure versions of third-party software and dependencies are used, scanning code for security vulnerabilities, ensuring only software that passes checks and tests, and is built by approved CI/CD pipelines can be deployed into production systems, and finally, detecting errors in production deployments and rolling back to the last stable build. Cymbal Bank will use infrastructure as code for infrastructure creation and updates in CI/CD. Cymbal Bank will create an update all Google Cloud infrastructure in CI/CD pipelines using infrastructure-as-code tools like Terraform and Packer. Terraform can be used to create immutable infrastructure, which can be modified or deleted and recreated quickly in an automated response to incidents or attacks. Packer can be used to create baked images, so software and configurations of virtual machines can be immutable, which reduces the chance of insecure configuration. At Cymbal Bank, you will deal with infrastructure declaratively and immutably and update baked virtual machine images whenever upgrading or patching software or OS and then recreate the VMs with those new images. This process can mitigate the risks of ad hoc updates by fixing the software and configuration of VMs and reducing the likelihood of insecure configuration or software installation. Using this process ensures that Cymbal Bank has a running history and inventory of its virtual infrastructure, that infrastructure is created in an automated, secure, and approved way, and that you can destroy and recreate infrastructure quickly as necessary. Having a running history and inventory of your virtual infrastructure can be useful in failures and disaster recovery. You can also quickly replace compromised infrastructure and quickly update or correct system configurations to mitigate or respond to security incidents or attacks. Cymbal Bank will use binary authorization to enforce secure container image deployment. Cymbal Bank will build container images in CI/CD with Cloud Build and store them in Artifact Registry. When an image is built by Cloud Build on a tester, verifies that it was from a trusted repository, built by a specific pipeline, passed tests, and was scanned for vulnerabilities. Artifact Registry includes a vulnerability scanner that scans containers. And results can be used to apply attestations, allowing or blocking deployments. Cymbal Bank will use binary authorization to apply automated attestations to container images, which will show the CI/CD pipelines that built them, which testing they had undergone and passed, and what vulnerabilities were present. These attestations will automatically allow or block container images from being deployed into production systems. For example, only container images with attestations indicating that they were built from the valid CI/CD pipeline, passed all tests, and had no critical or high-level vulnerabilities discovered in scanning will be permitted for deployment. Cymbal Bank will only use shielded virtual machines for their workloads. Shielded VMs provide secure and measured boot to ensure operating system integrity. Secure boot prevents loading of malicious code during boot up. And measured boot checks for modified components during boot up. Shielded VM significantly reduce the risk of attackers injecting malware into the boot process or kernel. As a Professional Cloud Security Engineer, part of your role includes helping Cymbal Bank develop a security-monitoring and incident-response process. You will use Google Cloud Observability to capture, visualize, and alert on logs or metrics indicating security incidents. Patterns and metric visualizations can indicate security incidents or attacks. Logs, log-based metrics, or metric conditions can alert support to unusual events. Cymbal Bank will include logs and metrics related to security, security incidents, and potential attacks into its monitoring and incident-response process. You will develop and drill incidence response plans to deal with any such discovered incidents. You will periodically enable and forensically scan certain log types that are default disabled, such as VPC flow logs, firewall logs, packet mirroring traffic captures, and data access logs. Cymbal Bank will leverage Cloud Audit Logs to mitigate insider risk. Cloud Audit Logs provide a complete picture of administrative activity and should be periodically audited to ensure compliance. You can enable data access logs to capture reads and writes to manage data storage or export logs for long-term storage or analysis. At Cymbal Bank, you will regularly audit the logs to ensure compliance, detect malicious or invalid administrative activity, and take appropriate corrective actions. Cymbal Bank will subscribe to the premium tier of the Security Command Center, which provides access to organizational and project security configuration. You will regularly review and mitigate any discovered vulnerabilities, findings, or threats identified by the Security Command Center. You can access the Security Command Center from the Cloud console. The Security Command Center provides visibility into the resources used and their security state. The Security Command Center helps you prevent, detect, and respond to threats. Built-in features detect suspicious activity and can detect compromised virtual machines. For possible threats, a set of actionable recommendations is provided. Some of the features provided include asset discovery and inventory, sensitive data discovery, web application vulnerability detection, access control monitoring, real-time notifications, audit logs, and assessment of misconfigurations.

### Video - [Introduction: Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529580)

- [YouTube: Introduction: Diagnostic questions](https://www.youtube.com/watch?v=60pfqftKpqQ)

Person: Now, it's your turn to assess your experience and skills related to this section with some diagnostic questions. Remember, the purpose of these questions is to help you better understand what is involved in this section of the exam guide and identify which areas you'll want to focus on in your study plan.

### Quiz - [Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/quizzes/529581)

#### Quiz 1.

> [!important]
> **Cymbal Bank needs a secure, compliant DevSecOps solution on Google Cloud for vulnerability scanning, granular access control, and cryptographic key management. They also require dynamic artifact analysis triggered by metadata changes. Which Google Cloud services best meet these stringent requirements?**
>
> - [ ] Custom artifact storage on Compute Engine with Binary Authorization for policy enforcement, combined with independent vulnerability scanning tools deployed on Google Kubernetes Engine, and integrated with Cloud Logging for audit trails.
> - [ ] Cloud Storage with Object Lifecycle Management for artifact versioning, integrated with Cloud Functions triggered by object creation events for ad-hoc vulnerability checks, and secured with IAM roles based on least privilege.
> - [ ] Compute Engine instances running custom vulnerability scanning scripts, secured with VPC Service Controls, and managed using Cloud Deployment Manager with Terraform modules for infrastructure as code.
> - [ ] Artifact Registry with Artifact Analysis, leveraging IAM Conditions for fine-grained access control and Cloud KMS for Customer-Managed Encryption Keys, integrated with Cloud Build triggers based on Pub/Sub notifications from Artifact Registry.

#### Quiz 2.

> [!important]
> **Cymbal Bank has suffered a remote botnet attack on Compute Engine instances in an isolated project. The affected project now requires investigation by an external agency. An external agency requests that you provide all admin and system events to analyze in their local forensics tool. You want to use the most cost-effective solution to enable the external analysis. What should you do?**
>
> - [ ] Use Event Threat Detection. Trigger the IAM Anomalous Grant detector to detect all admins and users with admin or system permissions. Export these logs to the Security Command Center. Give the external agency access to the Security Command Center.
> - [ ] Use Cloud Audit Logs. Filter Admin Activity audit logs for only the affected project. Use a Pub/Sub topic to stream the logs from Cloud Audit Logs to the external agency's forensics tool.
> - [ ] Use Cloud Monitoring and Cloud Logging. Filter Cloud Monitoring to view only system and admin logs. Expand the system and admin logs in Cloud Logging. Use Pub/Sub to export the findings from Cloud Logging to the external agency's forensics tool or storage.
> - [ ] Use the Security Command Center. Select Cloud Logging as the source, and filter by category: Admin Activity and category: System Activity. View the Source property of the Finding Details section. Use Pub/Sub topics to export the findings to the external agency's forensics tool.

#### Quiz 3.

> [!important]
> **Cymbal Bank experienced a recent security issue. A rogue employee with admin permissions for Compute Engine assigned existing Compute Engine users some arbitrary permissions. You are tasked with finding all these arbitrary permissions. What should you do to find these permissions most efficiently?**
>
> - [ ] Use Event Threat Detection and configure Continuous Exports to filter and write only Firewall logs to the Security Command Center. In the Security Command Center, select Event Threat Detection as the source, filter by evasion: Iam, and sort to find the attack time window. Click on Persistence: IAM Anomalous Grant to display Finding Details. View the Source property of the Finding Details section.
> - [ ] Use Event Threat Detection and configure Continuous Exports to filter and write only Firewall logs to the Security Command Center. In the Security Command Center, select Event Threat Detection as the source, filter by category: anomalies, and sort to find the attack time window. Click on Evasion: IAM Anomalous Grant to display Finding Details. View the Source property of the Finding Details section.
> - [ ] Use Event Threat Detection and trigger the IAM Anomalous Grant detector. Publish results to Cloud Logging. In the Security Command Center, select Cloud Logging as the source, filter by category: anomalies, and sort to find the attack time window. Click on Persistence: IAM Anomalous Grant to display Finding Details. View the Source property of the Finding Details section.
> - [ ] Use Event Threat Detection and trigger the IAM Anomalous grants detector. Publish results to the Security Command Center. In the Security Command Center, select Event Threat Detection as the source, filter by category: iam, and sort to find the attack time window. Click on Persistence: IAM Anomalous Grant to display Finding Details. View the Source property of the Finding Details section.

#### Quiz 4.

> [!important]
> **Cymbal Bank uses Docker containers to interact with APIs for its personal banking application. These APIs are under PCI-DSS compliance. The Kubernetes environment running the containers will not have internet access to download required packages. How would you automate the pipeline that is building these containers?**
>
> - [ ] Create a Dockerfile with container definition and cloudbuild.yaml file. Use Cloud Build to build the image from Dockerfile. Upload the built image to Artifact Registry and Dockerfile to a Git repository. In the cloudbuild.yaml template, include attributes to tag the Git repository path with a Google Kubernetes Engine cluster. Create a trigger in Cloud Build to automate the deployment using the Git repository.
> - [ ] Create a Dockerfile with a container definition and a Cloud Build configuration file. Use the Cloud Build configuration file to build and deploy the image from Dockerfile to Artifact Registry. In the configuration file, include the Google Container Registry path and the Google Kubernetes Engine cluster. Upload the configuration file to a Git repository. Create a trigger in Cloud Build to automate the deployment using the Git repository.
> - [ ] Build an immutable image. Store all artifacts and a Packer definition template in a Git repository. Use Artifact Registry to build the artifacts and Packer definition. Use Cloud Build to extract the built container and deploy it to a Google Kubernetes Engine Cluster (GKE). Add the required users and groups to the GKE project.
> - [ ] Build a foundation image. Store all artifacts and a Packer definition template in a Git repository. Use Artifact Registry to build the artifacts and Packer definition. Use Cloud Build to extract the built container and deploy it to a Google Kubernetes Engine (GKE) cluster. Add the required users and groups to the GKE project.

#### Quiz 5.

> [!important]
> **Cymbal Bank's management is concerned about virtual machines being compromised by bad actors. More specifically, they want to receive immediate alerts if there have been changes to the boot sequence of any of their Compute Engine instances. What should you do?**
>
> - [ ] Set Cloud Logging measurement policies on the VMs. Use Cloud Logging to place alerts whenever actualMeasurements and policyMeasurements don't match.
> - [ ] Set an organization-level policy that requires all Compute Engine VMs to be configured as Shielded VMs. Use Secure Boot enabled with Unified Extensible Firmware Interface (UEFI). Validate integrity events in Cloud Monitoring and place alerts on launch attestation events.
> - [ ] Set an organization-level policy that requires all Compute Engine VMs to be configured as Shielded VMs. Use Measured Boot enabled with Virtual Trusted Platform Module (vTPM). Validate integrity events in Cloud Monitoring and place alerts on late boot validation events.
> - [ ] Set project-level policies that require all Compute Engine VMs to be configured as Shielded VMs. Use Measured Boot enabled with Virtual Trusted Platform Module (vTPM). Validate integrity events in Cloud Monitoring and place alerts on late boot validation events.

#### Quiz 6.

> [!important]
> **Cymbal Bank has Docker applications deployed in Google Kubernetes Engine. The bank has no offline containers. This GKE cluster is exposed to the public internet and has recently recovered from an attack. Cymbal Bank suspects that someone in the organization changed the firewall rules and has tasked you to analyze and find all details related to the firewall for the cluster. You want the most cost-effective solution for this task. What should you do?**
>
> - [ ] View the GKE logs in the local GKE cluster. Use Docker-explorer to explore the Docker file system. Filter and export the Firewall logs to Cloud Logging. Create a dataset in BigQuery to accept the logs. Use the command gcloud logging sinks create to export the logs to a BigQuery dataset. Query this dataset.
> - [ ] View the GKE logs in Cloud Logging. Use the log scoping tool to filter the Firewall Rules log. Create a Pub/Sub topic. Export the logs to a Pub/Sub topic using the command gcloud logging sinks create. Use Dataflow to read from Pub/Sub and query the stream.
> - [ ] View the GKE logs in the local GKE cluster. Use the kubectl Sysdig Capture tool to filter the Firewall Rules log. Create a Pub/Sub topic. Export these logs to a Pub/Sub topic using the GKE cluster. Use Dataflow to read from Pub/Sub and query the stream.
> - [ ] View the GKE logs in Cloud Logging. Use the log scoping tool to filter the Firewall Rules log. Create a dataset in BigQuery to accept the logs. Export the logs to BigQuery using the command gcloud logging sinks create. Query this dataset.

#### Quiz 7.

> [!important]
> **Cymbal Bank runs a Node.js application on a Compute Engine instance. Cymbal Bank needs to share this base image with a 'development' Google Group. This base image should support secure boot for the Compute Engine instances deployed from this image. How would you automate the image creation?**
>
> - [ ] Stop the Compute Engine instance. Set up Measured Boot for secure boot. Prepare a cloudbuild.yaml configuration file. Specify the persistent disk location of the Compute Engine instance and the 'development' group. Use the command gcloud builds submit --tag, and specify the configuration file path.
> - [ ] Prepare a shell script. Add the command gcloud compute instances start to the script to start the Node.js Compute Engine instance. Set up Measured Boot for secure boot. Add gcloud compute images create, and specify the persistent disk and zone of the Compute Engine instance.
> - [ ] Prepare a shell script. Add the command gcloud compute instances stop with the Node.js instance name. Set up certificates for secure boot. Add gcloud compute images create, and specify the Compute Engine instance's persistent disk and zone and the certificate files. Add gcloud compute images add-iam-policy-binding and specify the 'development' group.
> - [ ] Start the Compute Engine instance. Set up certificates for secure boot. Prepare a cloudbuild.yaml configuration file. Specify the persistent disk location of the Compute Engine and the 'development' group. Use the command gcloud builds submit --tag, and specify the configuration file path and the certificates.

#### Quiz 8.

> [!important]
> **Cymbal Bank wants to use Cloud Storage and BigQuery to store safe deposit usage data. Cymbal Bank needs a cost-effective approach to auditing only Cloud Storage and BigQuery data access activities. How would you use Cloud Audit Logs to enable this analysis?**
>
> - [ ] Enable Data Access Logs for ADMIN_READ, DATA_READ, and DATA_WRITE for Cloud Storage. All Data Access Logs are enabled for BigQuery by default.
> - [ ] Enable Data Access Logs for ADMIN_READ, DATA_READ, and DATA_WRITE at the service level for BigQuery and Cloud Storage.
> - [ ] Enable Data Access Logs for ADMIN_READ, DATA_READ, and DATA_WRITE at the organization level.
> - [ ] Enable Data Access Logs for ADMIN_READ, DATA_READ, and DATA_WRITE for BigQuery. All Data Access Logs are enabled for Cloud Storage by default.

#### Quiz 9.

> [!important]
> **The loan application from Cymbal Bank's lending department collects credit reports that contain credit payment information from customers. According to bank policy, the PDF reports are stored for six months in Cloud Storage, and access logs for the reports are stored for three years. You need to configure a cost-effective storage solution for the access logs. What should you do?**
>
> - [ ] Set up a logging export bucket in Cloud Storage to collect data from the Security Command Center. Configure object lifecycle management rules to delete logs after three years.
> - [ ] Set up a logging export dataset in BigQuery to collect data from Cloud Logging and Cloud Monitoring. Create table expiry rules to delete logs after three years.
> - [ ] Set up a logging export dataset in BigQuery to collect data from Cloud Logging and the Security Command Center. Create table expiry rules to delete logs after three years.
> - [ ] Set up a logging export bucket in Cloud Storage to collect data from Cloud Audit Logs.  Configure object lifecycle management rules to delete logs after three years.

#### Quiz 10.

> [!important]
> **Cymbal Bank uses Compute Engine instances for its APIs, and recently discovered bitcoin mining activities on some instances. The bank wants to detect all future mining attempts and notify the security team. The security team can view the Security Command Center and Cloud Audit Logs. How should you configure the detection and notification?**
>
> - [ ] Use Event Threat Detection's threat detectors. Export findings from 'Suspicious account activity' and 'Anomalous IAM behavior' detectors and publish them to a Pub/Sub topic. Create a Cloud Run function to send notifications of suspect activities. Use Pub/Sub notifications to invoke the Cloud Run function.
> - [ ] Enable the VM Manager tools suite in the Security Command Center. Perform a scan of Compute Engine instances. Publish results to Cloud Audit Logging. Create an alert in Cloud Monitoring to send notifications of suspect activities.
> - [ ] Enable the Web Security Scanner in the Security Command Center. Perform a scan of Compute Engine instances. Publish results to Cloud Audit Logging. Create an alert in Cloud Monitoring to send notifications for suspect activities.
> - [ ] Enable Anomaly Detection in the Security Command Center. Create and configure a Pub/Sub topic and an email service. Create a Cloud Run function to send email notifications for suspect activities. Export findings to a Pub/Sub topic, and use them to invoke the Cloud Run function.

### Video - [Review diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529582)

- [YouTube: Review diagnostic questions](https://www.youtube.com/watch?v=q-zLM2jhnxw)

Now let’s review how to use these diagnostic questions to help you identify what to include in your study plan. We’ll approach this review by looking at the key areas of this exam section and the questions you just answered about each one. We’ll talk about where you can find out more about each area in the learning path for this certification and/or where to find the information in Google Cloud documentation. As we go through each one, take notes on the specific courses (and modules!), skill badges, and documentation pages you’ll want to emphasize in your study plan.

### Document - [Study plan resources](https://www.cloudskillsboost.google/course_templates/397/documents/529583)

### Quiz - [Knowledge Check](https://www.cloudskillsboost.google/course_templates/397/quizzes/529584)

#### Quiz 1.

> [!important]
> **How will Cymbal Bank be able to determine who performed a particular administrative action and when?**
>
> - [ ] Audit logs
> - [ ] VPC flow logs
> - [ ] Cloud Monitoring
> - [ ] VPC service controls

#### Quiz 2.

> [!important]
> **Which feature of Google Cloud will Cymbal Bank use to prevent unauthorized container images from being deployed into production environments?**
>
> - [ ] Cloud Monitoring
> - [ ] Audit logs
> - [ ] Binary Authorization
> - [ ] Cloud Build

## Supporting Compliance Requirements

Explore organizational security design considerations to satisfy specific compliance/regulatory requirements (SOC2, PCI-DSS, HIPAA).

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/397/video/529585)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=-hsbQkOjo4o)

In this module you’ll learn about the final area of the Professional Cloud Security Engineer’s role at Cymbal Bank. Once the identity and access management, network, data, and operations security have been addressed, the final area of focus is on satisfying and maintaining security regulator compliance with a chosen set of standards. This corresponds to the fifth and final section of the Professional Cloud Security Engineer Exam Guide. As in previous modules, we’ll begin by exploring what this aspect of your role, managing regulatory compliance, looks like at Cymbal Bank. Next, you’ll assess your skills in this section through 5 diagnostic questions. Then, we’ll review these questions. Based on the areas you need to learn more about, you’ll identify resources to include in your study plan.

### Video - [Cymbal Bank’s  security regulatory compliance](https://www.cloudskillsboost.google/course_templates/397/video/529586)

- [YouTube: Cymbal Bank’s  security regulatory compliance](https://www.youtube.com/watch?v=lfrir5HXlXs)

Let’s explore how a Professional Cloud Security Engineer at Cymbal Bank helps ensure security regulatory compliance. The final area of concern for the Professional Cloud Security Engineer is ensuring compliance with a chosen set of security standards. An organization’s standards depend on the business and competitive landscape, and can include such standards as HIPAA, PCI-DSS, The ISO 27000 Series, The NIST cybersecurity framework, CIS critical security controls, FedRAMP, SOC1 and SOC2, and many others. These standards typically specify requirements related to: How authentication, authorization, and access control can be performed. How data is encrypted and otherwise secured, How key management is performed; and, How networks, computing, and storage resources are monitored, secured, and maintained. Google Cloud meets many third-party and government compliance standards worldwide. Cymbal Bank will be building on top of Google Cloud, and can leverage the compliance built into the infrastructure of Google Cloud. However, as a Professional Cloud Security Engineer, you will need to help ensure that the applications and services Cymbal Bank builds on top of this infrastructure are also compliant with your chosen standards. Google Cloud has been certified as secure, but that does not mean that applications built on Google Cloud are automatically certified. Google products undergo regular independent verification of security privacy and compliance controls. To help customers with compliance and reporting, Google shares information and best practices, and provides access to documentation. ISO/IEC 27001, HIPAA, FedRAMP, and SOC 1 are just a sample of the compliance offerings of Google Cloud. For the full set, visit https://cloud.google.com/security/compliance/offerings/#/. Cymbal Bank does not need to worry about getting Google Cloud tools and services certified, only those services you build on top of Google Cloud. It is important to note that when deploying services on Google Cloud, it is still necessary to ensure that you follow applicable standards. Guidelines are provided by Google for some standards. For example, Google provides you with documentation on how to set up a HIPAA-aligned project. See the link in the speaker notes for more details. In the cloud, an important concept is the shared responsibility model. The cloud provider (Google) is responsible for the shared physical infrastructure and managing its security. When working in an infrastructure as a service model, the customer (in this case, Cymbal Bank) is responsible for securing the virtual infrastructure built over top of the physical infrastructure, the workloads running in that virtual infrastructure, and data. When working in other more managed approaches Google can take over more responsibility for the virtual infrastructure and its security. Depending on how a customer works in the cloud, this can involve more or less security responsibility and effort to ensure security compliance. Google helps you by providing best practices, templates, products, and solutions. Cymbal Bank will use Google Cloud’s default encryption at rest where compliance does not require conflicting key control or storage requirements. Where there is such conflict, you can leverage customer managed encryption keys (CMEK), customer supplied encryption keys (CSEK), or externally managed keys (EKM). These options provide encryption at rest with varying degrees of control over keys and key storage. Where compliance requirements dictate, you can also store keys in hardware-based hardened key storage appliances via Cloud HSM. Cymbal Bank will use Google Cloud’s default encryption in motion for managed services or when data is transferred across physical boundaries controlled by Google Cloud. Where there are compliance requirements for auditable end-to-end encryption or encryption using a particular set of ciphers or protocols, you will help Cymbal Bank apply application layer encryption using TLS or similar protocols. Cymbal Bank will use Sensitive Data Protection to scan and classify data. You will have metadata applied to indicate sensitive data or data that requires special treatment, and optionally transform that data to allow it to be used without risk of exposure. Using this Sensitive Data Protection process will help Cymbal Bank satisfy compliance requirements related to dealing appropriately with sensitive data. The metadata that is applied as part of the Sensitive Data Protection scanning process can then be used to determine whether or not to grant access to data based on the sensitivity indicated by the metadata. You can apply granular access control to data to ensure correct access based on sensitivity. Cymbal Bank has compliance requirements related to data residency and from where and how data can be accessed. As a Professional Cloud Security Engineer, you help Cymbal Bank leverage VPC service controls to enforce data residency and location-based access requirements by limiting access to the data from specific VPCs that are located in approved locations. Cymbal Bank can limit access to only VMs in those VPCs that are hardened and have necessary software installed to ensure correct and secure processing of the data. VPCs can be configured with subnets in only certain regions, which when combined with VPC service controls can constrain access to data from only those locations. Cymbal Bank has compliance requirements that require you to classify networks by trust level. The highest trust networks have no direct connectivity to the internet and satisfy strict requirements about when and how they can be used, what sort of traffic can flow into them, and how that traffic is scanned. Cymbal Bank will use many isolated VPCs for different workloads to help satisfy such requirements. Having different VPCs for different workloads can also facilitate location-based access requirements when combined with VPC service controls. Cymbal Bank has compliance requirements which mandate policies that define, lock-down, and restrict what can be done in cloud environments to prevent unauthorized activity. Organization policy constraints can be applied to the organization, or any folder or project, and restrict how Google Cloud can be used. This lets you specify which Google Cloud services can be used in which projects, and the parameters of that usage. The principles of least privilege and separation of duties are commonly expressed in the requirements of security standards. Compliance may require auditable least privilege and separation of duties in access control policies. Google Cloud IAM policies, which allow roles to be bound to identities at any level of the hierarchy, with optional IAM conditions to provide fine-grained conditional access, let Cymbal Bank satisfy such requirements.

### Video - [Introduction: Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529587)

- [YouTube: Introduction: Diagnostic questions](https://www.youtube.com/watch?v=f5sq0MAEqAo)

Now, it's your turn to assess your experience and skills related to this section, with some diagnostic questions. Remember, the purpose of these questions is to help you better understand what is involved in this section of the exam guide and identify which areas you'll want to focus on in your study plan.

### Quiz - [Diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/quizzes/529588)

#### Quiz 1.

> [!important]
> **Cymbal Bank plans to launch a new public website where customers can pay their equated monthly installments (EMI) using credit cards. You need to build a secure payment processing solution using Google Cloud which should follow the PCI-DSS isolation requirements. How would you architect a secure payment processing environment with Google Cloud services to follow PCI-DSS? (Select the two correct choices)**
>
> - [ ] Deploy a Linux base image from preconfigured operating system images. Install only the libraries you need. Deploy using Terraform.
> - [ ] Create a new Google Cloud project with restricted access (separate from production environment) for the payment processing solution. Configure firewall rules, a VPN tunnel, and a proxy Network Load Balancer for a new App Engine flexible environment.
> - [ ] Create a new Google Cloud project with restricted access (separate from production environment) for the payment processing solution. Configure firewall rules, a VPN tunnel, and an Application Load Balancer for a new Compute Engine instance.
> - [ ] Deploy an Ubuntu Compute Engine instance. Install the libraries needed for payment solutions and encryption/decryption. Deploy using Terraform.
> - [ ] Create a new Google Cloud project with restricted access (separate from production environment) for the payment processing solution. Create a new Compute Engine instance and configure firewall rules, a VPN tunnel, and an internal load balancer.

#### Quiz 2.

> [!important]
> **Cymbal Bank's Insurance Analyst needs to collect and store anonymous protected health information of patients from various hospitals. The information is currently stored in Cloud Storage, where each hospital has a folder that contains its own bucket. You have been tasked with collecting and storing the healthcare data from these buckets into Cymbal Bank's Cloud Storage bucket while maintaining HIPAA compliance. What should you do?**
>
> - [ ] Create a new Project. Use the Google Cloud Healthcare Data Protection Toolkit to set up a collection bucket, monitoring alerts, audit log sinks, and Forseti monitoring resources. Use Dataflow to read the data from source buckets and write to the new collection buckets. Give the Insurance Analyst the 'Editor' role on the collection bucket.
> - [ ] Use the Cloud Healthcare API to read the data from the hospital buckets and use de-identification to redact the sensitive information. Use Dataflow to ingest the Cloud Healthcare API feed and write data in a new Project that contains the Cloud Storage bucket. Give the Insurance Analyst the 'Editor' role on this Project.
> - [ ] Create a new folder. Create a new Cloud Storage bucket in this folder. Give the Insurance Analyst the 'Editor' role on the new folder. Collect all hospital data in this bucket. Use the Google Cloud Healthcare Data Protection Toolkit to monitor this bucket.
> - [ ] Create a new Project. Create a new Cloud Storage bucket in this Project with customer-supplied encryption keys (CSEK). Give the Insurance Analyst the 'Reader' role on the Project that contains the Cloud Storage bucket. Use the DLP API to find and mask personally identifiable information (PII) data to comply with HIPAA.

#### Quiz 3.

> [!important]
> **You are designing a web application for Cymbal Bank so that customers who have credit card issues can contact dedicated support agents. Customers may enter their complete credit card number when chatting with or emailing support agents. You want to ensure compliance with PCI-DSS and prevent support agents from viewing this information in the most cost-effective way. What should you do?**
>
> - [ ] Use customer-supplied encryption keys (CSEK) and Cloud Key Management Service (KMS) to detect and encrypt sensitive information.
> - [ ] Use customer-managed encryption keys (CMEK) and Cloud Key Management Service (KMS)  to detect and encrypt sensitive information.
> - [ ] Detect sensitive information with Cloud Natural Language API.
> - [ ] Implement Cloud Data Loss Prevention using its REST API.

#### Quiz 4.

> [!important]
> **Cymbal Bank's lending department stores sensitive information, such as your customers' credit history, address and phone number, in parquet files. You need to upload this personally identifiable information (PII) to Cloud Storage so that it's secure and compliant with ISO 27018. How should you protect this sensitive information using Cymbal Bank's encryption keys and using the least amount of computational resources?**
>
> - [ ] Generate an AES-256 key as a 32-byte bytestring. Decode it as a base-64 string. Upload the blob to the bucket using this key.
> - [ ] Generate a customer-managed encryption key (CMEK) using RSA or AES256 encryption. Decode it as a base-64 string. Upload the blob to the bucket using this key.
> - [ ] Generate a customer-managed encryption key (CMEK) using Cloud KMS. Decode it as a base-64 string. Upload the blob to the bucket using this key.
> - [ ] Generate an RSA key as a 32-byte bytestring. Decode it as a base-64 string. Upload the blob to the bucket using this key.

#### Quiz 5.

> [!important]
> **You are a cloud engineer at Cymbal Bank. You need to share the auditing and compliance standards with your CTO that cover controls over financial reporting and both public and private controls over security, availability, and confidentiality. Which compliance standard covers this?**
>
> - [ ] GDPR
> - [ ] PCI-DSS
> - [ ] SOX
> - [ ] FIPs 140-2

### Video - [Review diagnostic questions](https://www.cloudskillsboost.google/course_templates/397/video/529589)

- [YouTube: Review diagnostic questions](https://www.youtube.com/watch?v=qHdw0pSsOYA)

Now let’s review how to use these diagnostic questions to help you identify what to include in your study plan. We’ll approach this review by looking at the key areas of this exam section and the questions you just answered about each one. We’ll talk about where you can find out more about each area in the learning path for this certification and/or where to find the information in Google Cloud documentation. As we go through each one, take notes on the specific courses (and modules!), skill badges, and documentation pages you’ll want to emphasize in your study plan.

### Document - [Study plan resources](https://www.cloudskillsboost.google/course_templates/397/documents/529590)

### Quiz - [Knowledge Check](https://www.cloudskillsboost.google/course_templates/397/quizzes/529591)

#### Quiz 1.

> [!important]
> **Cymbal Bank has a compliance requirement to have control over key lifecycle and rotation periods.  Which Google Cloud feature can they leverage to satisfy that requirement?**
>
> - [ ] CMEK with Cloud KMS
> - [ ] Audit logs
> - [ ] VPC service controls
> - [ ] PCI-DSS compliance

#### Quiz 2.

> [!important]
> **Cymbal Bank has compliance requirements to ensure certain data is stored, processed, and never transferred or used outside of Europe. Which Google Cloud feature can help them achieve this?**
>
> - [ ] VPC service controls
> - [ ] Audit logs
> - [ ] Sensitive Data Protection
> - [ ] Organization policy constraints

## Your Next Steps

Course review and next steps in your PCSE Journey.

### Video - [Your next steps](https://www.cloudskillsboost.google/course_templates/397/video/529592)

- [YouTube: Your next steps](https://www.youtube.com/watch?v=wMSu1EKOrpg)

In this module, you'll focus on creating your individualized study plan. In this module, you'll use the notes you've been taking throughout this course to put together a study plan for each week in your Professional Cloud Security Engineer journey. Now that you've explored all five sections of the exam guide, consider what you've learned about your knowledge and skills through the diagnostic questions in this course. You should have a better understanding of what areas you need to focus on and what resources are available. Think about the answers to these questions. When will you take the exam? How many weeks does that give you to prepare? How many hours can you realistically spend preparing for the exam each week? And how many total hours will you prepare? Be sure to leave enough time at the end of your plan to retake the diagnostic questions and the sample questions and fill in any gaps in your knowledge that may remain. Take a few minutes to think about how much time you will allocate to preparing for the exam and note your answers in the workbook. The number of weeks in your preparation journey will depend on a variety of factors, such as your prior experience with Google Cloud and how much time you have available to dedicate to studying each week. You might choose to focus on specific courses or skill badges each week, such as in this sample study plan, or instead focus your study on a specific topic, such as managing service accounts. Once you have a high level idea of how many weeks you have to study and how you want to determine your weekly focus, you'll want to build out a plan with weekly goals and study activities. Use the template in your workbook to plan your study goals for each week. Consider what exam guide sections or topic areas will you focus on? What courses or specific modules will help you learn more? What skill badges or labs will you work on for hands-on practice? What documentation links will you review? And what additional resources will use such as sample questions? You may do some or all of these study activities each week. Let's review an example. For example, if you've identified managing service accounts as a particular area you need to study, you might choose to structure your study for a week to include targeted modules from the on-demand training or related skill badge for hands-on practice and documentation. Alternatively, you might choose one week to complete an entire course and another week to focus on a skill badge. You can determine the approach that fits your existing skill set. Find the weekly study template at the end of your workbook. Duplicate the weekly template for the number of weeks in your individual preparation journey. Remember, you may need to adjust your plans based on the areas where you need to learn more. For more information about the resources that we have discussed in this course, refer to your notes in the student copy of the slides. To register for the exam, follow the link on the Professional Cloud Security Engineer certification information page. Congratulations on completing this course, preparing for your Professional Cloud Security Engineer journey. Throughout this course, you were exposed to and engage with exam topics through a series of lectures, diagnostic questions, and knowledge checks. Now that you've completed this course, you have your very own personalized workbook that will guide you through the rest of your certification readiness journey.

### Document - [Course Resources](https://www.cloudskillsboost.google/course_templates/397/documents/529593)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

---
id: 168
name: 'Managing and Securing the Apigee Hybrid API Platform'
type: Course
url: https://www.cloudskillsboost.google/course_templates/168
date_published: 2023-11-02
topics:
  - Scaling
  - Apigee Hybrid
  - API Gateway
---

# [Managing and Securing the Apigee Hybrid API Platform](https://www.cloudskillsboost.google/course_templates/168)

**Description:**

This course discusses how environments are managed in Apigee hybrid, and how runtime plane components are secured. You will also learn how to deploy and debug API proxies in Apigee hybrid, and about capacity planning and scaling.

**Objectives:**

* Discuss infrastructure security, user access management, data storage and encryption practices used in Apigee hybrid.
* Manage environments in Apigee hybrid.
* Discuss capacity planning.
* Scale runtime components in the hybrid runtime plane.

## Introduction

Introduction to the management and security course on Google Cloud's Apigee hybrid API platform.

### Video - [Course series introduction](https://www.cloudskillsboost.google/course_templates/168/video/419521)

* [YouTube: Course series introduction](https://www.youtube.com/watch?v=bn4Cqpp2-FI)

Hi, I'm Hansel Miranda, a course developer at Google. I’d like to welcome you to Managing Google Cloud’s Apigee API Platform for Hybrid Cloud. This is a series of three courses that teach you the concepts and skills required to install and manage the Apigee hybrid API management platform. In the first course, we discuss fundamental concepts, the hybrid architecture, and you learn how to install the Apigee hybrid platform. In the second course, you learn how to manage the platform, and about the practices used to secure the hybrid runtime components. The third course teaches you about upgrading, monitoring, and troubleshooting Apigee hybrid. These courses are intended for cloud architects and operations specialists who want to install, manage, and operate the Apigee API platform using the hybrid deployment model. You must be familiar with Linux commands and have a basic understanding of Google Cloud, Kubernetes Engine, and networking, as well as common web protocols and standards like REST and HTTP. Through presentations, demos, and a hands-on lab, you will learn how to install and operate the Apigee hybrid platform on Google Cloud. The course will cover the architecture, the installation process, and the techniques used to manage and monitor the hybrid runtime platform. Specifically, you will learn about the product fundamentals, the Apigee hybrid architecture, and how to install and operate Apigee hybrid. You will learn about API proxy deployment and environment management, how hybrid components are secured, and capacity planning and scaling the hybrid platform. You will also learn how to upgrade Apigee hybrid and how to use hybrid logging and monitoring to troubleshoot issues with the platform. The lab in this course will be done using Qwiklabs. Qwiklabs provisions you with Google account credentials, so you can access the Google Cloud Console for the lab at no cost. For each lab, Qwiklabs offers a free set of resources for a fixed amount of time and a clean environment with required permissions. This course provides you with the knowledge and skills needed to install and manage Apigee hybrid. Take time to understand the concepts introduced in the lectures and the techniques used in the lab. The lectures, together with the lab and demos, teach you how to install, manage, and perform common operational tasks like scaling, monitoring, and troubleshooting Apigee hybrid. We hope you enjoy the course.

### Video - [Course Introduction](https://www.cloudskillsboost.google/course_templates/168/video/419522)

* [YouTube: Course Introduction](https://www.youtube.com/watch?v=5VLFi5tKfSs)

Hi, I'm David Mehi, a Customer Success Engineer at Google. Welcome to Management and Security, the second course in the series on Managing Google Cloud's Apigee API Platform for Hybrid Cloud. In this course, you'll learn how to manage and secure hybrid run-time plane. You will learn how API proxies are deployed to an environment in Apigee hybrid. You will learn about the Trace tool and how it can be used to debug an API proxy. We will also discuss the developer portal solutions that are available for use with Apigee hybrid. You will learn how to manage environments in Apigee hybrid. We will discuss how the hybrid runtime plane components securely communicate with each other and with the management plane that runs in Google Cloud. We will also discuss how your runtime data is stored and secured and how you can use role-based access control to manage hybrid users. You will learn how to plan capacity for your hybrid installation and how to manually and automatically scale Apigee hybrid.

## Deployment and Environment Management

In this module, you learn about API proxy deployment and environment management on the hybrid platform.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/168/video/419523)

* [YouTube: Module Overview](https://www.youtube.com/watch?v=jGhsTl5GUVo)

In this module, you will learn about API proxy and environment management on the hybrid platform.

### Video - [Build and Deploy API proxies](https://www.cloudskillsboost.google/course_templates/168/video/419524)

* [YouTube: Build and Deploy API proxies](https://www.youtube.com/watch?v=SHeaS-LMnU8)

In this lecture we will discuss how to build and deploy API proxies to your hybrid runtime environment. In later lectures, you will learn how to debug your API proxies and learn about the various developer portal solutions that are available for use. We will discuss how to manage environments. You use the Apigee hybrid user interface or Apigee API to create an API proxy. The hybrid UI has a proxy creation wizard that guides you through the main steps to create the API proxy. You can use the wizard to set optional security policies and the target API endpoint, and then deploy the proxy to one or more existing hybrid environments. The UI also allows you to upload an API proxy bundle that you have already created. During API development, you iteratively make and save changes to your proxy. When development is complete, you use the hybrid UI or Apigee API to deploy the proxy. When you deploy a proxy to an environment, a proxy revision is generated. A proxy revision is immutable. Any future deployment of API proxy changes to an environment always generates a new proxy revision. The API proxy deployment process involves the management plane and some hybrid runtime plane components. The Synchronizer component in the runtime plane polls the management plane at regular intervals and downloads any new or modified API proxy and other configuration data from the management plane. This downloaded data is called a contract and is made available to the runtime plane. The runtime Message Processor component retrieves the contract from the Synchronizer component and deploys the proxy. It then sends deployment status data to the Watcher component in the runtime plane. Watcher forwards the deployment status to Google Cloud and to the management plane; from there you can use the hybrid UI to view proxy deployment status or use the Apigee API to retrieve the status information. Let's review the sequence of steps in the API proxy deployment process. An API developer deploys a proxy using the hybrid UI or API. The request is sent to the management server running in the Apigee hybrid Management plane on Google Cloud. The management plane generates a new configuration for the Message Processors and Ingress gateway. The Synchronizer component in the runtime plane polls the management plan at regular intervals for changes to the API proxies and related data. The Watcher component in the runtime plane also checks the management plane for configuration changes to basepath and virtual host information. The configuration data, including API proxy bundles, is retrieved by the Synchronizer and stored locally on the file system. It is also saved to the Cassandra datastore. In addition to the proxy bundles, the configuration data downloaded by the Synchronizer includes shared flows, flow hooks, shared resources, target server definitions, TLS settings, key-value map names and data masks. The Watcher component updates the Ingress gateway with the modified routing configuration. The Message Processor runtime components poll the Synchronizer at regular intervals to detect any changed bundles or configuration. The Message Processors then load the change proxy bundles and configuration from the Synchronizer and deploy them. The Message Processor runtime components then sends the status of the proxy deployment to the Watcher component in the runtime plane. Watcher reports the status of the Message Processor and Ingress gateway to the management plane and to Cloud Logging and Cloud Monitoring in Google Cloud. You use the hybrid user interface to deploy API proxies. The hybrid UI runs in the management plane. You can deploy a specific proxy revision to an environment by selecting it from the revision drop-down list in the proxy overview page. You can also deploy the proxy revision from the develop tab. The status column in the deployments section of the overview page provides details on the status of the proxy deployment. The status indicator provides information on the success or failure of the proxy deployment. If issues are encountered during the deployment, information about the cause of the issues is included in the status details. A warning or error indication may require you to further troubleshoot the issue with the proxy configuration or runtime plane components. In Apigee hybrid, proxy deployment is asynchronous, and the status may take some time to update in the UI and API. You can also use the Apigee API to deploy an API proxy. You deploy an API proxy revision to a specific environment in your Apigee organization by issuing a POST request to the deployments resource. The organization name, environment name, api proxy name, and proxy revision number must be passed in the request as path parameters. An OAuth token generated using your Apigee org admin credentials must be passed in as a bearer token header in the request. You can retrieve the deployment status of an API proxy in an environment by issuing a GET request to the deployments resource. As in the previous API call, the same path parameters and OAuth token must be provided in the request. An OAuth token generated using your Apigee org admin credentials must be passed in as a bearer token header in the request. The API response includes information about the API proxy revision and the deployment status as reported by the runtime pods. A few command-line tools are available that support API proxy deployment to Apigee hybrid. The Apigee maven deploy and config plugins enable you to deploy API proxies and configuration data. These tools can be used as part of a continuous integration and continuous delivery process in your API development project. The apigeecli tool is another command-line tool that can be used to create and manage API proxies, products and other entities used in Apigee hybrid. When developing API proxies in Apigee hybrid, try to limit the number of proxies deployed to the same runtime environment. Consider the Message Processor boot time that increases with the number of proxies deployed, thus affecting the time taken for scaling the runtime pods in your cluster. Another consideration is the noisy neighbor problem: when one proxy crashes a Message Processor, all of the proxies deployed to the same Message Processor become unavailable while it restarts. By limiting the number of proxies deployed to an environment, you minimize the impact of a single proxy crashing. Having multiple environments that share the same host alias allows you to divide up proxies by environment without causing additional friction for your API consumers.

### Video - [Tracing and Debugging](https://www.cloudskillsboost.google/course_templates/168/video/419525)

* [YouTube: Tracing and Debugging](https://www.youtube.com/watch?v=ZRfwbNLlG44)

In this lecture we will discuss how to debug your API proxy using the debug tool in Apigee hybrid. Debug is a tool for troubleshooting API proxies running on Apigee. Debug lets you probe the details of each step through an API proxy flow. Debug collects data from the request and response and proxy flow variables, allowing you to inspect the state of the API proxy as it executes policies at runtime. Debug is asynchronous in Apigee hybrid, so there is a slight delay in the availability of debug data in the hybrid UI or Apigee API. Let's review the steps involved when using debug in Apigee hybrid. When you start a debug session, two properties determine when it ends on a given Message Processor. timeout: The length of time that a session collects data for. The default is 300 seconds (or 5 minutes). The maximum value is 600 seconds (or 10 minutes). count: The maximum number of requests that are recorded in a single session per Message Processor. Because the number of Message Processors in most clusters is variable, the effects of the count can be unpredictable. API does not recommend customizing the setting. You cannot configure a debug session's timeout in the hybrid UI. You can configure this timeout with the debug APIs when you create a new session. You start a debug session via the Apigee hybrid UI or Apigee API. Using a Pub/Sub model, the management plane sends the debug request to the runtime plane. The Synchronizer runtime component subscribes to notifications about debug session requests. It receives a request and propagates it to the runtime Message Processor components. The Message Processor collects debug data for the API, and streams the debug data to the UDCA data collection pod in the cluster. The UDCA runtime component collects the debug data and sends it to the UAP service in the management plane, which makes it available to the hybrid UI and API. You can then view the debug session in the hybrid UI or use the Apigee API to retrieve trace session data. You can initiate debug sessions from the debug tab in the Apigee hybrid UI by selecting the environment and proxy revision. You can selectively debug API requests by applying an optional filter that uses conditions on request metadata and flow variables. For further troubleshooting and analysis, you can also download debug session data for viewing in the hybrid UI. Active debug session data can be viewed in the hybrid UI for a period of 24 hours. If further analysis is required, a debug session can be downloaded using the hybrid UI or Apigee API. Use the offline debug view to upload previously downloaded debug sessions for viewing in the hybrid UI. For troubleshooting purposes, Apigee support personnel must be added to the hybrid organization to view offline debug sessions. A filter is a conditional statement that is applied to API transactions to determine whether debug data should be captured in that session. You create a filter by using Apigee system or custom flow variables and combining them into logical expressions with boolean operators. Apigee hybrid provides a set of predefined filters that can be used in debug sessions. These filters use common data elements, such as response time and response code values, request header, and query and path parameter values, which can be applied to your debug sessions. You can initiate a debug session by sending a POST request to the debug sessions API. Identify the organization name, environment name, API proxy name, and revision by providing their values in the request path parameters. You can also optionally set the debug session's timeout and set a filter condition in the body of the request.

### Video - [Demo: Tracing in Apigee Hybrid](https://www.cloudskillsboost.google/course_templates/168/video/419526)

* [YouTube: Demo: Tracing in Apigee Hybrid](https://www.youtube.com/watch?v=6r7RLx_Y4Kk)

In this demo, you learn how to trace and debug an API proxy running on Apigee hybrid. Tracing is a method that enables you to debug your API proxy at runtime while it receives and processes requests and responses. Using the Trace Tool in the Apigee hybrid UI, you can view various aspects of the API request and response, including headers and payload, variables that you set and use in your policies, and a variety of other metadata information. This allows you to effectively debug your API proxy and fix any issues with its operation. This demo is part of the managing Google Cloud's Apigee API platform for hybrid Cloud course and assumes you have a working installation of Apigee hybrid, including the test install API proxy created in your hybrid organization. Login to the Apigee hybrid UI at apigee.google.com using your credentials. Click on "Develop", then "API Proxies". The TestInstall API proxy has been modified to implement API key verification. Click on the "Develop tab", as you can see, there is a verify API key policy that has been added to the pre flow of the proxy. Every request that is sent to this API will need to pass in a valid API key for it to be successful. The test app developer and API product used in this demo, were previously created in the hybrid organization using the UI. Click the "Trace tab" to start debugging your API proxy. First select the environment, in this case, our API proxy is deployed to the test environment. Then click "Start Trace session". Once you have a Trace session started, you will see requests show up as they are made to your API proxy. Switch to the Google Cloud Shell terminal window and first confirm that the ingress FQDN environment variable is set correctly. This is the host name assigned to the test environment and it's configured in the overrides our demo file that is used for installing Apigee hybrid. Also confirm that the external IP address or the istio ingress gateway load balancer has been set. As you can see, this environment variable has been set to the external IP address of these two ingress gateway load balancer. Let's send a request to our API proxy first without passing in the API key. As you can see, this request is made to our API proxy V1 tests install with a status code of 418 and it resolves the ingress FQDN to our external load balancer IP address. You should see an error message from the API indicating that there was a failure to resolve the API key variable. This is expected since this request did not pass in a valid value for the API key. This is the default error message from the verify API key policy when it throws a fault under error conditions like this one. You can change this message by handling faults in your API proxy. Switching to the hybrid UI, you can see now that the first request that was sent is available in your Trace Session window. Next, let's make a second request, but this time passing the value of the API key that is assigned to our application. This is a request with the API key passing as a query parameter. As you can see this request is successful. Let's go back to our Apigee hybrid UI. As you can see, there's a second request that came into our Trace session that is successful. In the first request, an error was generated by our verify API key policy. This policy indicates the error with a exclamation mark on the policy icon. If you click on the small vertical bar to the right of the policy, it shows the error details in the bottom potion of the Trace window. Let's select the second request in the Trace session that was successful. In this case, the policy succeeded. Clicking on the policy icon in the Trace session, can see that the bottom portion displays a list of variables that was read and assigned by the verify API key policy, as well as other metadata about the request. You can use the value of these variables to control the Proxy processing logic using conditional expressions, as well as reference them in downstream policies in the Proxy. Click the left most circle in the Trace session window. The bottom potion of the window displays information about the request received by the API Proxy, including any request headers and payload if any. Click the circle to the left of the factory icon. The bottom pane displays information about the response received from the back end, including any response headers and payload. Clicking on the other circles in the Trace session displays information about the request or response and associated data at that stage in the request response flow of the API Proxy. As you implement additional policies at various stages in the Proxy, you can see how those policies affect Proxy functionality and use the bottom potion of the Trace session to inspect the values in the variables read or assigned by those policies in an effort to debug them. Let's create a new Trace session with a filter. Filters enabled you to Trace only certain requests that satisfied the filter condition at runtime. This is a useful tool when debugging API Proxies in high volume environments where you need to debug only certain requests. Select the environment and select the header for the filter type. For the filter condition type request.header. X-Trace with the value of tt. This condition will only Trace requests that had the X-Trace header sent in the request. Click start Trace session. From the Cloud Shell terminal, we will send two requests with the test install API Proxy, one with the header and one without. Let's pass in the header to this request. The request was successful and let's send a second request. But this time without the header. We have two requests sent, one with the header and one without. If you go back to the Trace session window, you only see the single request that came into your API Proxy with the X-Trace header passed in with the value supplied in the request. This request can now be debugged as usual. This demo showed you how to debug your API Proxies using the Trace tool in the Apigee hybrid UI. It also used a filter feature to qualify the request to be traced, so you can easily debug the API Proxy in high volume environments.

### Video - [Developer Portal solutions](https://www.cloudskillsboost.google/course_templates/168/video/419527)

* [YouTube: Developer Portal solutions](https://www.youtube.com/watch?v=oTxtivwT-eI)

In this lecture, we will discuss the developer portal solutions you can use with Apigee hybrid. Application developers can be internal or external to your organization, or they can belong to partner organizations. Design your APIs based on what app developers need. App developers are customers of your APIs. Your APIs should have a consistent interface, be well-documented, and enable app developers to build great applications. A developer portal enables app developers to discover your API offerings and teaches them how to use your APIs by providing comprehensive documentation. It provides functionality to: easily self-register applications to use your API products and enables app developers to quickly build their applications. Apigee hybrid supports multiple developer portal solutions. The integrated developer portal enables simple self-service portal development and is hosted by Apigee in the management plane. The Drupal portal is a fully customizable portal that is based on the open source Drupal content management system and integrated with Apigee using modules. The do it yourself portal is also fully customizable and implemented using Apigee APIs. The Drupal and DIY developer portals are hosted by you and require a high level of effort to implement. A well-designed developer portal provides a great developer experience. To accomplish this a developer portal must have self-service registration features for developers and their applications, thus providing a seamless onboarding experience. It should include a catalog of your available API products that the app developer can browse and view documentation in. A developer portal can also include app analytics that help the developer view and analyze their application usage patterns. The Apigee integrated portal includes a set of tools that enable you to: Develop portal content in markdown or html. Customize the look and feel using CSS stylesheets. Publish your API product catalog. Generate interactive documentation for your APIs using open API specifications. Manage your images. Customize the portal menus. Configure Google Analytics, and extend functionality of the portal with custom scripts. Using Drupal modules developed by Apigee, you can build a fully customizable developer portal based on Drupal. The Apigee Developer Portal Kickstart is a Drupal distribution that enables you to quickly create an Apigee developer portal using Drupal. You are responsible for developing, hosting and managing the Drupal developer portal. To install the Drupal portal, you must have certain prerequisite software packages installed. The Apigee developer portal uses its own PostgreSQL database to store developer and application data, and other entities. A webserver to serve the portal content is required. The Apigee Drupal modules must be configured for registration and other portal functionality. Detailed installation instructions are on the Apigee developer portal documentation website.

### Video - [Managing Environments](https://www.cloudskillsboost.google/course_templates/168/video/419528)

* [YouTube: Managing Environments](https://www.youtube.com/watch?v=ECY5oglHtSc)

In this lecture, we will discuss managing environments in Apigee hybrid. An environment in Apigee hybrid provides a runtime execution context for API proxies. In order for an API proxy to receive and process API requests, it must be deployed to an environment. Environments provide you with a flexible way to group your proxies, such as by functional domain or API development lifecycle. You create an environment by using the Apigee hybrid UI or Apigee API and configuring the cluster in the runtime plane. You must assign an environment to an environment group before it can be used. You can deploy API proxies to the environment after it is assigned to a group and the runtime plane is configured. After you create an environment, you must assign it to an environment group. You add an environment to a group using the Apigee UI or Apigee API. You can add an environment to an existing group or to a new group by first creating the group. After you create an environment using the UI or Apigee API, you configure it in the runtime plane using the overrides.yaml file. The environment definition comprises the name of the environment, the service accounts of the synchronizer, and the UDCA and runtime components. The override file changes must then be applied to the cluster. An environment group must be configured to add or modify host aliases or domain names that are used to route requests to API proxies deployed to environments in the group. You can configure the group with more than one environment. The environment group is mapped to a virtual horse property in the overrides.yaml file. You then apply the changes to the overrides file to the runtime plane cluster. You can also create an environment by using the Apigee API. Issue a POST request to the /organization/environments API and pass in the name of your organization as a path parameter in the request. The environment name, description, and other attributes are passed in the body of the request. The create operation is asynchronous and returns a long-running operation object. You must then make a GET request to the /organization/operations API and pass in the value of the operation ID that was received in the response from the create operation. The response from the Operations API contains information about the status of the operation to create the environment. You may need to make multiple calls to the operation API until the status indicates that the operation has completed. To delete an environment, you must first delete it from all associated environment groups. You can do this using the Apigee UI or API. You then apply your overrides.yaml configuration that contains the environment to be deleted to the cluster, using the apigeectl delete command. This will remove the runtime components associated with the environment that is being deleted. It is a best practice to do a dry run first to check for any errors before deleting the environment. Next, delete the environment from the management plane using the Apigee hybrid UI or API. Finally, edit your overrides file to remove the deleted environment configuration. To delete an environment using the Apigee API, issue a POST request to the /organization/environments API and pass in the name of your organization and environment as path parameters in the request. The delete operation is asynchronous and returns a long-running operation object. You must then make a GET request to the /organization/operations API and pass in the value of the operation ID that was received in the response from the delete operation. The response from the operations API contains information about the status of the operation to delete the environment. You may need to make multiple calls to the operations API until the status indicates that the operation has completed. You can use the Apigee hybrid UI or API to update the display name and description of an environment. Issue a PUT call to the /organization/environment's API and pass in the name of your organization and environment as path parameters in the request. The body of the request must contain all the existing environment properties, in addition to the properties being updated. If this process is successful, the response from the API contains the updated environment object. As you operate and manage your hybrid runtime cluster, you may have to maintain multiple override.yaml configuration files over time. A good practice is to use a structure of multiple override files, where each file contains configuration information for a functional resource or set of resources used in hybrid. For example, you can have a common . yaml file that includes configuration for Cassandra, metrics, and logger resources. An organization.yaml file for any organization-scoped resources and configuration. An organization.yaml file for each hybrid runtime environment that contains configuration for the environment being added or updated in the cluster. You can initialize the cluster using the common.yaml file, and then apply the individual override config files, starting with the common resources, organization-level resources, and environments.

### Quiz - [Deployment and Environment Management](https://www.cloudskillsboost.google/course_templates/168/quizzes/419529)

#### Quiz 1.

> [!important]
> **Which one of the following is true regarding environments in Apigeehybrid:**
>
> * [ ] An environment is mapped to a single runtime deployment resource in the Kubernetes cluster.
> * [ ] An environment can have multiple host aliases or domain names defined.
> * [ ] The name of an environment can be modified after the environment iscreated.
> * [ ] An environment can be assigned to at most one environment group before it can be used.

#### Quiz 2.

> [!important]
> **How are API proxy changes made available in the runtime plane?**
>
> * [ ] The Message Processors poll the management plane for API proxychanges.
> * [ ] The Synchronizer polls the management plane for proxy changes and makes them available to the Message Processors.
> * [ ] UDCA collects changes in the API proxy from the management plane and sends them to the Message Processors.
> * [ ] API proxy changes are saved in Cassandra, and the Message Processors fetch the proxy bundles from the database.

#### Quiz 3.

> [!important]
> **Which one of the following is true regarding API proxy deployment in Apigee hybrid?**
>
> * [ ] A deployed proxy revision is immediately available on all Message Processors serving the environment in the runtime cluster.
> * [ ] There is no limit to the number of API proxies that can be deployed to an environment.
> * [ ] A saved proxy revision cannot be modified.
> * [ ] A deployed proxy revision is immutable.

#### Quiz 4.

> [!important]
> **When using the Trace feature in Apigee hybrid, you:**
>
> * [ ] Can view the trace session in the hybrid UI synchronously as the request is received by the runtime.
> * [ ] Cannot download a trace session from the hybrid UI for offlineviewing.
> * [ ] Cannot filter requests using the Apigee DebugSession API.
> * [ ] Cannot set breakpoints in the hybrid UI for API request or responseflows.

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/168/video/419530)

* [YouTube: Module Review](https://www.youtube.com/watch?v=TR0WNR1SMe4)

In this module, you learned how to deploy and manage API proxies and Apigee hybrid. You learned about the deployment process and how to check the status of a proxy deployment. You also learned about the various developer portal solutions available in Apigee hybrid. You learned about environment management, configuration, and how to use the hybrid UI and Apogee API to perform, create, update, and delete operations on the environment. In the next module, you will learn about hybrid security, RBAC and how the hybrid runtime components are secured.

## Security

This module discusses how the Apigee hybrid runtime plane infrastructure components and data are secured.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/168/video/419531)

* [YouTube: Module Overview](https://www.youtube.com/watch?v=a-uwWx20Jag)

This is the security module in the course on managing and securing the Apogee hybrid API platform. In this module, you will learn about the security features and role-based access control used in Apogee hybrid. You'll also learn how traffic is secured within the hybrid run time plane and with the management plane in Google Cloud.

### Video - [Infrastructure security](https://www.cloudskillsboost.google/course_templates/168/video/419532)

* [YouTube: Infrastructure security](https://www.youtube.com/watch?v=FIJpvE23J4w)

In this lecture, we will discuss the security features used in Apigee hybrid and how traffic within the runtime plane and with the management plane is secured. In later lectures, you will learn how data is collected and stored and how role-based access control is implemented in Apigee hybrid. Traffic between the Apigee hybrid runtime components and the management plane is over TLS and uses OAuth access tokens. Ingress traffic from client applications into the cluster and egress traffic from the runtime Message Processors to backend target servers can be secured using TLS and OAuth. All logging and metrics data sent from the hybrid runtime plane to Google Cloud Services goes over TLS. All internal communication between the hybrid runtime plane components uses TLS. In addition, components that connect to the runtime Cassandra data store use client authentication or mutual TLS. Intra-node Cassandra communication also uses mutual TLS. Apigee hybrid stores keys and certificates used by runtime components in Kubernetes secrets. When communicating with management plane services, the synchronizer and UDCA components use OAuth access tokens. Each component employs a sidecar authorization container that generates an OAuth 2.0 JTW token, which is signed using the component's service account private key. The service accounts are stored as Kubernetes secrets and made available to the runtime pods. The MART runtime component uses the authorization container to verify OAuth 2.0 tokens sent with API requests from the hybrid management plane to the runtime plane. To verify the token, the container uses the public key of a configured service account available from a Google Cloud endpoint. Apigee hybrid uses service accounts to perform various tasks that include sending logs and metrics data to Google Cloud and downloading proxy bundles from the management plane. A service account is a type of Google account that represents a system or application user that needs to be authenticated and be authorized to access Google APIs and services. Apigee hybrid requires you to create several service accounts during installation. Each service account requires a specific role or set of roles that enable it to perform certain functions. This is a list of service accounts used in Apigee hybrid. You create these service accounts when you install Apigee hybrid. The service accounts have a specific assigned role and are used by the runtime plane components to perform the function described. For example, the apigee-synchronizer or service account is used by the synchronizer component to download API proxy bundles and configuration data from the management plane. The Apigee hybrid distribution includes the create-service-account tool that you can use to create service accounts. You can also use the Google Cloud Console or the gcloud SDK. It is a good practice to use only one role for each service account in order to limit access for each runtime component. When installing the hybrid runtime plane, you configure the paths to the service account key files on your machine in the overrides.yaml configuration file. As an alternative, for non-production, test, and demo environments, you can use a single service account with all the roles assigned to it. This is not recommended for production environments. A hybrid environment must be assigned to an environment group. The environment group is configured with one or more host aliases or DNS names, and is mapped to a virtual host configuration in the overrides.yaml file. You configure the virtual host with the path to a TLS certificate and key that is used to secure that host. Client apps that send API requests to the host domain must be able to trust the certificate in order to establish the TLS connection. You can use a self-signed certificate for a development or test installation of Apigee hybrid. The synchronizer runtime component securely accesses the management plane using OAuth over TLS to download API proxy and configuration data to the runtime plane. It uses a service account whose key file path is configured in the runtime plane configuration file. In order to authorize the synchronizer account, you must call the setSyncAuthorization Apigee API as part of the hybrid installation process. To invoke the API, you must first generate an OAuth access token using your Apigee organization admin or gcloud authenticated user credentials. Apigee Connect allows the hybrid management plan to connect securely to the MART service in the runtime plane, without requiring you to expose the MART endpoint outside the cluster. To use Apigee Connect, you must enable the Apigee Connect API in the Google Cloud API library for your project. A service account with the Apigee Connect Agent role must be created and used to configure the Apigee Connect runtime component in the override.yaml configuration file. On startup, Apigee Connect uses the service account credentials to establish a secure bi-directional gRPC stream with the management plane. All communication between the management plane and Apigee Connect is encrypted using TLS. In addition, all MART API requests from the management plane use OAuth JWT tokens for authentication. To configure Apigee Connect for your hybrid installation, follow these steps: Enable the Apigee Connect API in the Google Cloud API library. Add the Apigee Connect Agent role to the MART service account. This is a pre-defined role with the apigeeconnect.endpoints.connect permission that is needed to set up the Apigee Connect agent. To enable Apigee Connect, update your overrides.yaml configuration file, specifying the path to the MART service account key file. To enable the Apigee Connect feature, update the Apigee hybrid organization by using an organizations.update Apigee API call. To apply the configuration changes to the cluster, use the apigeectl command, passing in the path to the overrides config file and supplying the organization flag. Apigee Connect is enabled by default for new installations of Apigee hybrid version 1.3.0 and newer. You are most likely to need these steps if you are upgrading from an older version of Apigee hybrid. In Apigee hybrid, TLS is enabled by default for any communication between Cassandra nodes and between clients and Cassandra nodes in the cluster. Any hybrid runtime component that communicates with Cassandra requires authentication. Apigee hybrid provides user accounts that are used by clients to communicate with Cassandra. The DML user account is used by the runtime components to read and write API runtime data to the Cassandra data store. The DDL user account is used by the MART runtime component for data definition tasks like keyspace creation, update, and deletion. The admin user account is used for any administrative activities performed on the cassandra cluster. Apigee hybrid provides default passwords for the Cassandra user accounts. You can change the default passwords in the overrides.yaml configuration file, and apply the change to your cluster using the apigeectl command. The Cassandra username and passwords can be stored in a Kubernetes secret and configured in the overrides file. You must first create the Kubernetes secret and apply it to your cluster. Then add the secret configuration to your overrides file for the Cassandra component, and apply the overrides file to the hybrid data storecomponent. You can use TLS to secure traffic to backend servers. You can also use OAuth access tokens in your API proxies to implement authentication and authorization. Use the Apigee hybrid UI or API to create a TargetServer definition. Configure it to use 1-way or 2-way TLS, depending on your requirements. To store TLS keys and certificates, create key stores and truststores in the hybrid UI or API. You can secure the Apigee hybrid Runtime plane by also implementing Kubernetes network policies in your cluster. A network policy is a specification of how groups of pods are allowed to communicate with each other and other network endpoints. A typical Apigee hybrid installation is made up of multiple pods that require access to specific ports, and not every pod needs to communicate with every other pod. Use network policies to restrict communication between pods and to pods that have access outside the Kubernetes network. You can further harden the security of your runtime cluster by following the recommended guidelines of your Kubernetes infrastructure provider.

### Video - [Data storage and encryption](https://www.cloudskillsboost.google/course_templates/168/video/419533)

* [YouTube: Data storage and encryption](https://www.youtube.com/watch?v=d8wzC95UPwI)

In this lecture, we will discuss the types of data entities used in Apigee hybrid and the mechanisms used to collect, store, and make that data available for use. Apigee hybrid stores API runtime data in the Cassandra data store in the Kubernetes cluster that you manage. This data includes KMS entities like developers, apps, API products, and API keys. It also includes key value map entries, cache objects, and quota counters. Apigee manages and stores API proxies, Target server configuration, TLS keys, and certificates in truststores and keystores in the management plane on Google Cloud. This data is downloaded by the synchronizer and made available in the runtime plane. Apigee hybrid also stores audit logs in the management plane. Apigee hybrid collects logging, metrics, analytics, and proxy deployment status data during its normal operation. Logging and metrics data is stored on Google Cloud under your project and accessed via the Cloud Logging and Cloud Monitoring user interfaces in Google Cloud console. Analytics, proxy deployment status, and trace data are stored in the Apigee management plane on Google Cloud. KVM, KMS, and cache data in the runtime plane are stored encrypted by default. Apigee hybrid provides a set of default Base64-encoded keys that are used to encrypt KVM, KMS, and cache data. The Apigee hybrid installer stores the keys in the runtime plane as Kubernetes Secrets and uses them to encrypt your data with AES-128 standard encryption. The keys are under your control and never used by the hybrid management plane at any time. The default data encryption keys can be replaced with your own keys by configuring them in your overrides.yaml configuration file when you initially install Apigee hybrid in a new cluster. If you change the encryption keys after the runtime is created in your cluster, previously encrypted data can no longer work (it cannot be decrypted); only new data added after the change will be encrypted and function as expected. We recommend that you use your own data encryption keys for production installations. Kubernetes Secrets let you store and manage sensitive information, such as passwords, OAuth tokens, and keys. A Secret is used with a pod as files in a volume mounted on its containers, or it can be exposed as an environment variable to the container. You can create Kubernetes secrets and access them in an API proxy as flow variables in Apigee hybrid.

### Video - [Demo: Implement API key verification in Apigee Hybrid](https://www.cloudskillsboost.google/course_templates/168/video/419534)

* [YouTube: Demo: Implement API key verification in Apigee Hybrid](https://www.youtube.com/watch?v=p3kDTdji8E4)

In this demo, you learn how to create an API product, an app developer, and an application and use these entities to implement API key verification in your API proxy that runs in Apigee hybrid. API products enable your APIs to be easily consumable by applications. By creating and using these Apigee entities, you validate that the hybrid runtime components Apigee Connect, MART and Cassandra are functioning as expected. This demo is part of the managing Google clouds Apigee API platform for hybrid cloud course. And assumes you have a working installation of Apigee hybrid including the test install API proxy created in your hybrid organization. Login to the Apigee hybrid ui@apIgee.google.com using your credentials. Let's add a new API product to our Apigee hybrid organization. In the left navigation menu, under Publish, click API Products. To add a new API product, click Add API Product. For the product name, type TestProduct. Use the same value for the display name. Check test to make this product available in the test environment. For access, select Public to make this product publicly available in the Apigee developer portal. Leave the automatically approved access requests checked to automatically generate API keys for this product. In the API resources section, click Add a proxy, check Test Install to bundle this proxy in the test product. You can have more than one proxy in an API product. Click Add. Click Save at the top right to save the API product. Now let's add a developer. Developer entities are normally created when they sign up to use API products on your Apigee developer portal. For the purposes of this demo, we create the developer administratively using the Apigee hybrid UI. In the left navigation menu on the Publish, click Developers. To add a new developer, click on +Developer, type values for the first name, last name, user name and email address fields. Then click Create to create the developer. Developers create and register the applications with one or more API products on the Apigee developer portal. For the purposes of this demo, we create an app using the Apigee UI. In the left navigation menu under Publish, click Apps. To create a new app, click on +App. For the app name, type TestApp. For Developer, click into the box and select the developer created earlier. Click Add product and select the test product created earlier. Click Add. You can set the apps API key credentials to never expire, expire after a certain duration or on a specific date. For this demo, leave the expiration to be Never. Click Create to create the application Once the app is created, on the app details page, click show to view the generated API key for the app. Copy and paste the key to a text file on your machine for use later. Now let's modify our test install API proxy to implement API key verification. Once the proxy is deployed, any request to the API proxy will need to include a valid API key query parameter. In the left navigation menu, Under Develop, click API Proxies. Click the TestInstall API proxy. Click on the DEVELOP tab to edit the proxy. In the navigator pane, select PreFlow under the default proxy endpoint. Click Add step in the request flow. Scroll down the list of policies in the Add step dialog and select verify API key. Click Add to add the policy to your proxy. This policy will execute for every request to the API and will validate the API key query parameter that is passed in the request. If you have other policies in your request flow and would like to make the verify API key policy the first one, so that it checks for the key before any other policy executes. Drag and drop the policy so that it is the leftmost or the first policy to execute in the request flow. Click Save to save the changes to the API proxy. Once the proxy is saved, click on deploy to test to deploy the proxy to the test environment. Click on deploy to confirm the deployment. We will return to the UI to confirm that the proxy has deployed before testing it. For now, let's go into the Google Cloud Shell of Google Cloud Console. Let's confirm that the Ingress FQDN environment variable is set correctly. This is the host name assigned to the test environment, and is configured in the overrides or YAML file that was used for installing the hybrid. Also, retrieve the external IP address of the istio ingress gateway load balancer and set it as the value of the lb external IP environment variable. As you can see, the environment variable lb external IP has already been set to the external IP address of the istio ingress gateway load balancer. Now let's verify that our API proxy has been deployed to the test environment. We'll go back into the apigee-hybrid UI, and confirm that the proxy revision eight has been deployed to the test environment. Let's make a call now to our test API proxy using code. This code command sends a request to the test install API proxy on our test environment hostname, whose value is stored in the Ingress FQDN environment variable. Sending this request generates an error message from the proxy. This indicates that there was a failure to resolve the API key variable since no API key was passing the request. This is a default error message from the verify API key policy when it throws a fault on the error conditions like this one. You can change this message by handling falls in your API proxy. Let's make another request, but this time pass in the value of the API key that was generated for our application. The API key has to be passed in as a query parameter to the API request. This is the value of the API key of our application. This request is successful since a valid API key was passed in to the API proxy. The response from the proxy is the response that was gen Created from our test back end. That is the response for the status code 418, which is the teapot. This demo showed you how to create Apogee entities to implement API key verification in your API proxy on Apogee hybrid. It also validates that the API product and other entities that were created in the hybrid UI, in the management plane was successfully sent to the hybrid runtime plane. Via Apogee connect and Mott and instantiated in the runtime Cassandra data store. This verifies that the hybrid runtime components are functioning as expected.

### Video - [RBAC](https://www.cloudskillsboost.google/course_templates/168/video/419535)

* [YouTube: RBAC](https://www.youtube.com/watch?v=o_0nEGaF9xQ)

In this lecture, we will discuss how role-based access control, or RBAC, is implemented in Apigee hybrid. We will also discuss Workload Identity with Apigee hybrid. An Apigee hybrid user is represented by an authenticated Google Cloud account. The user is granted access by using roles at the project level, which are inherited in all hybrid environments by default. You can refine a user's access by using the hybrid UI to specify one or more roles per environment in your hybrid organization. The user acts in that role only for the selected environment. You can federate user accounts between Active Directory and Google Cloud Identity or Google Workspace. A user inherits roles from the Google Cloud Project in the hybrid organization and environments. You typically assign roles with the least permissions to the user and the project, and then refine those roles in the hybrid organization and individual environments based on the functionality that the user can perform. It is a best practice to follow the principle of least privilege when assigning roles that allow users to access resources. The principle states that a user or resource should only have access to the exact set of resources needed to perform a given function. Avoid granting users broad, basic roles like Owner or Editor. To manage user attrition, assign roles to groups instead of to individual users. This makes it efficient to change user access by simply managing the user's group membership. Consider using predefined or custom roles to provide more granular access to resources. Apigee hybrid provides a set of predefined roles that you can assign to users based on their job function. The org admin role has full access privileges to all resources in the Apigee hybrid organization. API developers can be assigned the API Admin an Environment Admin roles, and a business user can be assigned the Analytics Viewer or Analytics Editor role. A user with the Developer Admin role has edit access to Apps, API keys, and App Developers in hybrid. A new user who is added to your project is granted one or more roles based on job function. By default, the new user inherits the same role for all the project resources, including the hybrid organization and environments. You can use the Apigee hybrid UI to refine the user roles for each hybrid environment. When defined for a hybrid environment, the user only functions in the specified role in that environment. You can use the Google Cloud Console, the Apigee API, or the gcloud tool to set a user's roles in Apigee hybrid. Use the getIamPolicy and setIamPolicy operations of the organizations/environments Apigee API to get and set a user's role in a hybrid environment. The API uses a Policy object that contains a collection of role bindings assigned to a set of user accounts. Apigee hybrid supports the creation of custom roles using Google's Identity and Access Management. You can use the Cloud Console to create a custom role from an existing Apigee hybrid role. In the IAM user interface of the Cloud Console, add or remove permissions for the custom role. After that, use the Cloud Console UI or gcloud API to assign the custom role to users in your project. Workload Identity is a way for applications running within Google Kubernetes Engine to access Google Cloud services in a secure and manageable way. Workload Identity allows workloads in your GKE clusters to impersonate Identity and Access Management service accounts to access Google Cloud services. A Google IAM service account is an identity that an application can use to make requests to Google APIs. Separately, Kubernetes also has the concept of service accounts. A service account provides an identity for processes that run in a Pod. Kubernetes service accounts are Kubernetes resources, while Google service accounts are specific to Google Cloud. From Apigee hybrid 1.4 and later, Apigee creates and uses a Kubernetes service account for each type of component. Enabling Workload Identity allows the hybrid components to interact with the Kubernetes service accounts. Before enabling Workload Identity for Apigee hybrid, Workload Identity must be enabled for the GKE cluster running Apigee. When running Apigee hybrid and GKE, the standard practice is to create and download private keys (.json files) for each of the service accounts. When using Workload Identity, you do not need to download service account private keys and add them to GKE clusters. Before enabling Workload Identity, you ensure Workload Identity is enabled per node pool and then initialize variables. You can enable Workload Identity for a fresh install or upgrade an existing install. For more information on configuring and using Workload Identity with Apigee hybrid, refer to the Enabling Workload Identity with Apigee hybrid documentation.

### Quiz - [Security](https://www.cloudskillsboost.google/course_templates/168/quizzes/419536)

#### Quiz 1.

> [!important]
> **Which one of the following statements about authentication between the hybrid management plane and runtime plane components is true:**
>
> * [ ] The MART runtime component uses a sidecar container to generate OAuth tokens used for securely communicating with the hybrid managementplane.
> * [ ] OAuth tokens are not used for communication between the hybrid management plane and the runtime plane components.
> * [ ] The Synchronizer runtime component uses a sidecar container to generate OAuth tokens used for securely communicating with the hybrid management plane.
> * [ ] The UDCA runtime component uses a sidecar container to verify OAuth tokens received when securely communicating with the hybrid managementplane.

#### Quiz 2.

> [!important]
> **To securely communicate between the API proxy running in Apigee hybrid and the target backend, as a best practice:**
>
> * [ ] Create a TargetServer configuration with TLS and client authentication enabled. Use references to a truststore and keystore in the configuration of the target server.
> * [ ] Use a keystore that contains the private key and certificate chain of the target backend server.
> * [ ] For 2-way TLS, only use a keystore that contains the private key and certificate chain of the runtime message processor.
> * [ ] Configure the virtualhost property with a TLS key and certificate in the overrides configuration file.

#### Quiz 3.

> [!important]
> **In Apigee hybrid, roles that are granted to a user at the Google Cloud project level are inherited at:**
>
> * [ ] The Apigee hybrid environment level for all environments in the Apigee hybrid organization by default.
> * [ ] The Google Cloud project level only.
> * [ ] The Google Cloud organization level.
> * [ ] The Apigee hybrid environment level for a specific environment in the Apigee hybrid organization.

#### Quiz 4.

> [!important]
> **In Apigee hybrid, the KMS, key-value map, and cache data are encrypted using organization- or environment-scoped encryption keys. Which one of the following is correct:**
>
> * [ ] KVM data is encrypted using only an environment-scoped encryption key.
> * [ ] Cache data is encrypted using an organization-scoped encryption key.
> * [ ] KMS data is encrypted using an organization-scoped encryption key.
> * [ ] The default Apigee-provided encryption keys cannot be changed.

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/168/video/419537)

* [YouTube: Module Review](https://www.youtube.com/watch?v=Ys70psy5x6k)

In this module, you learned how communications between the Apigee hybrid runtime and management plane components are secured. You also learned how components within the runtime plane are secured. You learned about the different types of data used in hybrid and their secure storage mechanisms. You also learned about role-based access control used for users of Apigee hybrid and about using Workload Identity with Apigee hybrid. In the next module, you will learn about capacity planning for Apigee hybrid and how the platform can be scaled to handle your API traffic.

## Capacity Planning and Scaling

This module discusses capacity planning for Apigee hybrid, and how the runtime components can be scaled to process increases in the volume of API traffic to your proxies.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/168/video/419538)

* [YouTube: Module Overview](https://www.youtube.com/watch?v=bpFmJ4wqCH4)

In this module, you will learn about capacity planning for Apigee hybrid and now you can scale the runtime plane to support higher throughput for your API proxies.

### Video - [Capacity Planning](https://www.cloudskillsboost.google/course_templates/168/video/419539)

* [YouTube: Capacity Planning](https://www.youtube.com/watch?v=BBa762vAfkk)

Let's discuss capacity planning for Apigee hybrid. You will learn how to scale the runtime plane in a later lecture and learn to scale your runtime plane components with a demo. One of the fundamental concepts when planning for capacity of your Apigee hybrid platform is to understand your business requirements. The business provides inputs into transaction volume and processing throughput for both current needs and future growth, taking into account any expansion plans. Business requirements typically drive service level agreements that you set with your customers. SLAs includes service availability in terms of up time percentage, response times, problem resolution time, and other factors. Business requirements and service level agreements drive your infrastructure requirements. This helps in capacity planning for your Apigee hybrid installation. It is important to understand your API traffic patterns when planning your hybrid runtime installation. The number of message processors or runtime pods will scale based on CPU usage and the amount of traffic processed. The Cassandra pods in your cluster might also need to scale to handle the increased traffic volume. As mentioned earlier, understanding your business strategy, growth plans, and target expectations is key to planning capacity for your hybrid installation. It's important to plan ahead when determining the amount of API traffic your runtime would be expected to handle. Also, consider rolling updates of the runtime components in your cluster. You must have sufficient cluster resources available to create new pods with the updated containers during rolling updates. When considering API throughput and latency for capacity planning purposes, you must have a good understanding of proxy logic. The number of API proxies in a hybrid environment and the complexity of the API processing logic may increase your response latency. Also, API proxies that require reading and writing to the runtime Cassandra data store increase proxy execution time. Policy types that involve Cassandra lookups and updates, such as OAuth, Quota, and KVM, will add to proxy latency. You can use cache policies in your API proxies to improve proxy latency. It is important to identify which Apigee hybrid components are in the critical path of execution of an API proxy. The runtime message processor receives requests from client apps via the ingress gateway and processes them by executing the logic in the API proxy. The Cassandra component also belongs on the critical path for API proxies that need read or write access to runtime data. Component failure must always be considered as a factor when planning your runtime capacity. You should test how your runtime plane handles your API traffic load under reduced capacity and adjust your cluster configuration accordingly. In a containerized environment like Kubernetes, the failed pods are recreated automatically and take some time to bootup before they are available to handle runtime traffic. Here are some general requirements for your Apigee hybrid runtime plane installation on Google Kubernetes Engine. Apigee recommends creating two nodepools: one for the runtime Cassandra data store, and the other nodepool for all of the other hybrid runtime components. The Cassandra data store requires a minimum of 200 to 500 gigabytes SSD storage per pod, depending on your proxy usage. A regional cluster with three availability zones is recommended. It is always a good practice to refer to the official hybrid documentation for the latest sizing recommendations. While determining your Cassandra storage requirements, take into account the usable disk capacity. This is typically around 50 to 70% of your allocated storage capacity that is available for use. This is because, during normal operations, Cassandra requires disk capacity for compaction and repair operations. Also note that, because data is replicated, the total usable disk capacity is a function of the number of nodes in the ring divided by the replication factor.

### Video - [Scaling](https://www.cloudskillsboost.google/course_templates/168/video/419540)

* [YouTube: Scaling](https://www.youtube.com/watch?v=oYKAOmPLiKA)

In this lecture, we will discuss how the Apigee hybrid runtime components can be scaled to handle your API runtime traffic. Scaling is an integral feature of Kubernetes that can be configured for your hybrid runtime cluster. You've seen this picture before in the context of capacity planning. Scaling allows you to handle increases in traffic volume by spinning up additional processing capacity in your cluster. It also conserves resources when they are no longer needed by removing the extra capacity. Based on your business requirements, expected API traffic and backend capabilities, you can configure your runtime cluster so that it can scale efficiently when needed. You can scale most services running in Kubernetes from the command line or in a configuration override. Scaling generally involves increasing or decreasing the number of replica pods that make up the service or application. The exact method of scaling and autoscaling hybrid runtime services depends on the type of service. The recommended method of scaling hybrid runtime services is by updating the appropriate properties in the overrides.yaml configuration file. This is usually done so any configuration changes are not overridden by future updates to the overrides file, or during hybrid software upgrades. The changes are applied to the cluster by using the apigeectl apply command. By default, scaling is defined at the organization level. You can override the default settings by specifying environment-specific scaling in the overrides.yaml file. The Cassandra runtime data store is deployed as a StatefulSet in your Kubernetes cluster on its own nodepool. StatefulSets do not support autoscaling but can be scaled manually. To scale up the Cassandra StatefulSet in your hybrid runtime, set the value of the Cassandra object's replicaCount property in the overrides.yaml configuration file. Because the default replication factor for all keyspaces is three, Apigee recommends that you scale the replicas to maintain the replication factor (3/6/9 etc.). Apply the changes to your cluster using the apigeectl apply command. The Cassandra runtime component can be scaled vertically to support higher CPU and memory requirements. To implement this, you create a new node pool in your Kubernetes cluster with the higher sizing requirements. Once the node pool is available, modify your hybrid runtime plane overrides configuration file to use the new node pool and update the Cassandra resource configuration with the new CPU and memory sizes. Apply the changes to your cluster using the apigeectl apply command. Depending on your current API traffic load, you may want to scale down the Cassandra ring in your runtime plane. Scaling down your Cassandra pods is a multi-step process. You must first confirm that the nodes in the Cassandra cluster are healthy, and there is enough storage to support your data requirements with the reduced number of Cassandra pods. To scale down, update the Cassandra replicaCount property in your overrides.yaml configuration file. Make sure to maintain the replication factor of 3. Use the apigeectl command to apply the change. The runtime cassandra pods are then scaled down in the cluster. Finally, delete the persistent volume claims that are no longer used. To manually scale the hybrid components, update the value of their corresponding Deployment's replicaCountMin and replicaCountMax properties in the overrides.yaml configuration file. Then run the apigeectl command to apply your changes to the cluster. To autoscale these components, set the Deployment object's targetCPUUtilizationPercentage property to the threshold for scaling up. When this value is exceeded, Kubernetes adds the required number of pods up to the value of replicaCountMax. Deployments use a Horizontal Pod Autoscaler for autoscaling.

### Video - [Demo: Scaling Apigee hybrid](https://www.cloudskillsboost.google/course_templates/168/video/419541)

* [YouTube: Demo: Scaling Apigee hybrid](https://www.youtube.com/watch?v=XFvnTtsedQg)

Welcome to this demo on scaling Apigee hybrid. As your API program grows and matures, the need for additional capacity to support your API throughput and response latencies increases. This translates to an increase in resource usage of the Apache hybrid runtime cluster. Your Kubernetes cluster will need to scale up to meet the additional demand and scale down when the demand for resources decreases. This demo uses simulated load conditions to demonstrate how the hybrid runtime components can be scaled to meet API demand. To complete this demo, there are some prerequisites required. Apigee hybrid 1.10 or later should be installed and running in a cluster on GKE. This demo does not perform the install of Apigee hybrid. If you do not have an existing Apigee hybrid installation, you can follow the task in the installing and managing Apigee hybrid lab in Qwiklabs. Another requirement is to have an Apigee hybrid environment named test and a properly configured environment group named test-group. The test environment must be added to the environment group. So access the Cloud Console in the browser, select GCP Project, and open Cloud Shell. Make sure your cluster is healthy and all the Apigee hybrid runtime plane components are running. You can check the status of the cluster and its workloads in the Google Cloud console and also by running the command kubectl get pods and provide the Apigee namespace. To test the runtime plane, we'll need to deploy a sample API to the Apigee hybrid environment test. Access the Apigee hybrid UI in an incognito browser window or switch to its tab if you have it open already. In the left navigation pane, click Develop, API Proxies. You might need to refresh the browser for the environments to display. Select the test environment, and click Create New to create a new API proxy. In the Create Proxy Wizard, select Reverse proxy and provide the information required for the API. We’ll name our proxy TestInstall and update the Base path accordingly. You need to provide a target URL for an existing backend API, which we will use the httpbin.org/status API. Click Next and accept the defaults for Security and Quota, as well as for the CORS headers. Click test to deploy the API proxy to the test environment. Then click Create and deploy. Now go to the proxy list and wait until the TestInstall API proxy is deployed to the environment as indicated in the status column. We switch back to the console, Cloud Shell, and set an environment variable for the Apigee ingress gateway external IP address. Verify that the LP external IP address environment variable is populated, and then make a curl call to test the API proxy. Standard Teapot EPA response is returned from the backend API, that is proxied through our TestInstall API on Apigee hybrid. Let's now scale the runtime component in the cluster. First, let’s determine the current number of runtime pods that are running for the test environment. We'll use the kubectl get pods command, parse in the Apigee namespace. The name of the app component is apigee-runtime and the environment test as labeled through the command. As you can see, we have one pod running. To manually scale the runtime pods, we'll edit the Apigee hybrid overrides yaml configuration file for the test environment to add a runtime section. We edit the Apigee override yaml file for the test environment that's located in the hybrid-files folder, under your Apigee installation directory. You will add the runtime section between the environments and the Cassandra section. We’ll set a replica minimum count of three and the maximum count of five pods. Make sure the file is saved, and apply this file to our cluster. We check to make sure that the pods are ready by running the check-ready command. And then use the kubectl get pods command for the runtime component to determine the number of pods. As you can see, there are three pods created based on our replica count minimum setting in the overrides.yaml file. Check it once more to make sure that all three pods are ready. In order to autoscale the Apigee hybrid runtime component, you can configure your cluster to enable Kubernetes to autoscale the runtime component based on CPU usage of the runtime pods. We’ll reedit the Apigee hybrid overrides yaml file to add the target CPU utilization percentage entry to the runtime section. The runtime has been configured with an artificially low target CPU usage percentage of 5%. This is done to easily verify that the number of runtime pods increases based on a small amount of load to the environment. We’ll save the file, and reapply our changes to the cluster. Once again, verify that the components are ready and check the number of pods. As before, there are three runtime pods available based on a minimum setting in the overrides file. To test the autoscaling, we’ll generate some load to the proxy in the test environment. We use a for-loop to call the API proxies in code. Once the for-loop completes, we'll check the status of the pods in the runtime cluster. As you can see now, the number of pods has increased from 3 to 5 based on the load that was received by the API. Five was a maximum setting in the overrides yaml file. We checked the number of pods again to see that all of them are ready and receiving traffic. The goal of this demo was to help you understand how components in the Apigee hybrid runtime plane can be manually and automatically scaled with configuration that is applied to a Kubernetes cluster. Thanks for watching.

### Quiz - [Capacity Planning and Scaling](https://www.cloudskillsboost.google/course_templates/168/quizzes/419542)

#### Quiz 1.

> [!important]
> **What is the recommended best practice to scale the Apigee hybrid runtimecomponent?**
>
> * [ ] Use the kubectl scale command.
> * [ ] Declare the min and max replica counts in the overrides.yaml file, and run the apigeectl apply command.
> * [ ] Create a Horizontal Pod Autoscaler.
> * [ ] The hybrid runtime component cannot be scaled.

#### Quiz 2.

> [!important]
> **What are three factors to consider when planning capacity for your hybrid runtime infrastructure?**
>
> * [ ] Testing requirements
> * [ ] API processing logic
> * [ ] Service level agreements
> * [ ] Business strategy

#### Quiz 3.

> [!important]
> **Which one of the hybrid runtime components cannot be autoscaled?**
>
> * [ ] Runtime (Message Processor)
> * [ ] Cassandra
> * [ ] Synchronizer
> * [ ] MART

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/168/video/419543)

* [YouTube: Module Review](https://www.youtube.com/watch?v=Op9YFYEXXXA)

In this module, you learned about capacity planning for Apigee hybrid and items to consider when planning your runtime plane installation. You also learned how to scale your runtime plane components using both manual and auto-scaling.

### Video - [Course Review](https://www.cloudskillsboost.google/course_templates/168/video/419544)

* [YouTube: Course Review](https://www.youtube.com/watch?v=DdWPZQASd3w)

Thank you for taking the course on management and security of Google Cloud's Apigee Hybrid API platform. In this course, you learned how API proxies are deployed to an environment in Apigee hybrid. You also learned about the trace tool and how it can be used to debug an API proxy. We discussed the developer portal solutions that are available for use with Apigee hybrid. You learned how to manage environments in Apigee hybrid and learned how the hybrid runtime plane components securely communicate with each other and with the management plane that runs in Google Cloud. We discussed how your runtime data is stored and secured in hybrid, and how role-based access control can be used to manage users of Apigee hybrid. Finally, we discussed capacity planning for your hybrid installation and how Apigee hybrid achieves manual and auto-scaling. Congratulations on completing this course on the management and security of Google Cloud's Apigee Hybrid API platform. We recommend you continue with the third course in this series, upgrading, monitoring, and troubleshooting Google Cloud's Apigee Hybrid API platform. In that course, you will learn the process to upgrade your Apigee hybrid installation to a new release of the software distribution. You also learn about logging and Apigee hybrid and how you can use Apigee metrics and analytics data to monitor and troubleshoot your hybrid runtime components.

## Course Resources

PDF links to all modules

### Document - ['Managing and Securing the Apigee Hybrid API Platform - Course Resources'](https://www.cloudskillsboost.google/course_templates/168/documents/419545)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

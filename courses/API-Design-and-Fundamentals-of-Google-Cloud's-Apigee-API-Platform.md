---
id: 254
name: 'API Design and Fundamentals of Google Cloud's Apigee API Platform'
type: Course
url: https://www.cloudskillsboost.google/course_templates/254
date: 2025-04-07
datePublished: 2022-11-24
topics:
- API Development
- API Gateway
- Apigee
---

# [API Design and Fundamentals of Google Cloud's Apigee API Platform](https://www.cloudskillsboost.google/course_templates/254)

**Description:**

In this course, you learn how to design APIs, and how to use OpenAPI specifications to document them. You learn about the API life cycle, and how the Apigee API platform helps you manage all aspects of the life cycle. You learn about how APIs can be designed using API proxies, and how APIs are packaged as API products to be used by app developers.

Through a combination of lectures, hands-on labs, and supplemental materials, you will learn how to design, build, secure, deploy, and manage API solutions using Google Cloud's Apigee API Platform. This is the first course of the Developing APIs with Google Cloud's Apigee API Platform series. After completing this course, enroll in the API Security on Google Cloud's Apigee API Platform course.

**Objectives:**

- Explore and put into practice API design, development and management concepts.
- Describe the fundamentals of REST API design.
- Describe API products, API product strategies, and how to publish APIs to a developer portal.
- Describe Apigee terminology and organizational model based on Apigee product capabilities.
- Interact with the Apigee API Platform.

## Introduction

Welcome to API Design and Fundamentals! This is the first course in the Developing APIs with Google Cloud's Apigee API Platform series.

### Video - [Course Series Introduction](https://www.cloudskillsboost.google/course_templates/254/video/347347)

- [YouTube: Course Series Introduction](https://www.youtube.com/watch?v=sYc68Qum0Hs)

Mike: Hi, I'm Mike Dunker, a course developer at Google. Hansel: And I'm Hansel Miranda, also a course developer at Google. Mike: We'd like to welcome you to Developing APIs with Google Cloud's Apigee API Platform. This is a series of three courses that will teach you API concepts and skills that will help you build great APIs. Hansel: We will teach you how to use Google Cloud's full featured API management platform Apigee to design, build, and secure your APIs. You will also learn about how Apigee's developer portal can allow app developers to discover your APIs and register apps to use them. We will also discuss how Apigee can help you manage and grow your API program. Mike: These courses are not just about how to use Apigee. These courses are also focused on the skills required of an API engineer. You will learn how to design APIs that follow best practices. You will learn about API security concerns and how to mitigate them. You will also learn how to productize your APIs. Hansel: These courses are intended for a technical audience. You will build an API from the ground up, completing a series of labs. Many of the labs build on each other, adding more features and security to your API. It is recommended that you take all three courses in order and complete the labs in order. Mike: These courses cover a wide range of topics, and the information may sometimes feel overwhelming. Take your time to absorb the content and make sure that you understand both the lectures and labs. When Hansel and I joined Apigee, we started with zero knowledge of Apigee and minimal knowledge of APIs. Hansel: We learned how to be API engineers during years of helping companies build their APIs and API programs. Mike: This course teaches you the skills, knowledge and best practices that we've found most important for API engineers.

### Video - [Course Introduction](https://www.cloudskillsboost.google/course_templates/254/video/347348)

- [YouTube: Course Introduction](https://www.youtube.com/watch?v=m8IBdX5VDq0)

Mike: Welcome to API Design and Fundamentals, the first course in developing APIs with Google Cloud's Apigee API platform. This course will introduce you to Apigee and its features. You will learn about the API development lifecycle. You will also learn about rest APIs and what to consider when designing them. We will discuss API-first development and how API specifications can be used to define an API interface. We'll also discuss the main sections of an Apigee API proxy, the proxy endpoint, target endpoint, route rules, and flows. You will learn how these are used when you create your APIs. You will also learn about the logic and modules that are used to build your proxies within proxy flows, conditions, variables, and policies. We'll learn about API products, how they're used to package your APIs for use by app developers, and see an example of how API products might evolve in a real world scenario. During this course, you will explore these topics in a series of labs in which you build and test API proxies. You will build a retail API proxy that calls a back end service, and you will protect your proxy so that it can only be called by an app that is registered to use the API. Other labs will explore providing different levels of service to different applications and using the Apigee proxy trace tool.

## Apigee Overview

This module introduces the Apigee platform, API management, and the API lifecycle.

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/254/video/347349)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=o89T_6FGyLY)

Mike: In this module, we'll introduce you to Apigee, Google Cloud's API management platform. You will learn about the API lifecycle, as well as Apigee organizations and the entities that they contain.

### Video - [Product Overview](https://www.cloudskillsboost.google/course_templates/254/video/347350)

- [YouTube: Product Overview](https://www.youtube.com/watch?v=_ksRtPo7cTY)

Mike: In this lecture, you will learn about Apigee, Google Cloud's API management platform. We'll discuss the business problems that can be solved using Apigee, see many of the features that Apigee provides, and introduce the components of Apigee, and deployment options for the Apigee platform. Before we discussed the role of APIs and API management in today's enterprise landscape, it is important for you to understand where we are and how we got here. Not too long ago, having a digital presence just meant you had a website. At the time, success was expressed in simple terms, such as the number of visits to the site, or the number of users registered over months or years. The relatively slow pace of change of the web channel allowed an IT organization to plan and execute changes to back-end systems. The pace allowed them to keep up with demand. What about today? The number of customer-facing applications has dramatically increased and diversified, opening the door to a new era of connected digital experiences. Today, most companies embrace multiple methods of interaction as part of their digital strategy. In addition to traditional web and mobile applications, companies are finding new channels for users to interact with data and services, powered by smart, connected devices. With all of these new apps and channels come new challenges, including securing communication and access for new channels and devices, increasing scale to handle higher traffic and usage, managing new channels, customers, partners, and apps, improving visibility of business and technical metrics to allow data-driven business decisions, and leveraging ecosystems and platforms to increase reach. All of these challenges add to the complexity and diversity of requirements that back-end systems need to handle while the pace of change gets faster and faster. Applications that power connected digital experiences tend to evolve at an accelerating rate. This need for speed is driven by business opportunities, competition, and evolving customer needs. Apigee's API management platform is designed to bridge the gap. By building APIs for connected experiences, you can create abstraction layers that help reduce the complexity required of back-end systems. APIs that are implemented on Apigee leverage a rich set of capabilities and features, including security, caching, transformation, and mediation. These features allow you to build APIs tailored to the needs of individual applications and react to changing business requirements, while reducing the need for customization and modification of back-end services. With all API calls passing through Apigee, you can gain insights into technical and business challenges. APIs also improve your ability to participate in or create ecosystems, driving even more business and success. The digital value chain allows us to visualize how connected digital experiences are realized. In a digitally connected world, you interact with customers or end users using applications. Applications range from web and mobile apps to large enterprise systems and connected devices. Some of these applications are built by developers at your company. Other applications may represent systems used by partners or customer-facing products that they've built. Application developers leverage the APIs offered by your company. These APIs are built and managed by a cross-functional team we call the API team. APIs built by the API team make use of back-end resources while shielding application developers from unnecessary complexity. Because some application developers using your APIs are generally external to your company, the apps they create are not actually under your control. The real boundary of a company's control over enforcement of policies and management of access to resources ends at the API layer. APIs are the digital products you present to app developers. As products, they should follow a lifecycle, and you should manage them as you would manage other products produced by the company, marketing them to internal and external audiences. The Apigee platform is composed of four core capabilities. Starting at the foundation, Apigee offers multiple deployment models for the API runtime. The API runtime is responsible for handling runtime API traffic. Apigee's enterprise-level platform can be run as a software-as-a-service offering running in Google Cloud, and fully managed by Google. API runtimes can also be deployed in customer private clouds or in an on-premises data center, with the runtime deployment managed by the customer, and the management services managed by Google and running in Google Cloud. The Apigee Adapter for Envoy is a lightweight API gateway that provides limited API management functionality that can be deployed close to back-end services. Mediation provides the ability to parse and manipulate the requests and responses of API calls passing through Apigee. Mediation allows API teams to perform enrichment, transformation, orchestration, enforcement of security, caching, handling of faults, and more. Every API call that passes through Apigee generates analytics data. Analytics data generated by the system can be used by operations teams and business users to make data-driven decisions about APIs and their API program. The developer ecosystem is an important factor in the success of your APIs. APIs built and deployed on Apigee are bundled into API products, which can be deployed to a developer portal. The developer portal facilitates the discovery and consumption of APIs, and offers developers access to API documentation. Let's introduce Apigee's logical components by looking at their capabilities and relationships. The runtime gateway sits in the critical path of runtime traffic. Gateway's main component is the message processor, which is responsible for executing APIs in response to API requests. Data used by APIs during runtime is stored in the runtime data store. This includes API keys, OAuth tokens, cache, and configuration. As APIs are executed by a message processor, analytics events are generated and processed asynchronously. These events reveal a wealth of information about APIs, apps, and back-end system calls and are used for Analytics reports and visualization. The Apigee API is used to manage the API platform. The API is used to deploy and un-deploy API proxy revisions, monitor APIs, configure environments, manage users, and more. The Apigee console, the developer portal, and other management processes use the Apigee API. The Apigee API is also fully documented and available to customers. Developers and operations teams make use of this API for automation, such as continuous integration, continuous deployment, or CICD. The management database stores configuration changes. The runtime will pull for changes and update itself when changes are detected. The Apigee console is the main web interface for administration and development. Developers can use it to create, develop, and manage APIs. Operations, security, and business users also access the Apigee console. The console can be used to view and control all aspects of your APIs, including controlling the API lifecycle and building and viewing analytics reports. The developer portal is a web interface dedicated to addressing the needs of application developers. The API team publishes documentation about your organization's APIs to the developer portal, where application developers can register their applications and sign up to use your API products. Apigee offers flexible platform deployment options. Apigee's Google-managed, software-as-a-service deployment simplifies customer adoption and dramatically accelerates time to market for new APIs. Developers can get started immediately building and running APIs at scale. This is the most popular deployment option. It allows customers to focus on addressing business needs, while letting Google manage the operational overhead of running the software at scale in a secure and reliable way. Customers who want or need to provide access to their APIs in multiple clouds or on premises can choose the hybrid deployment model. This model allows the customer to manage and deploy containerized versions of the API runtime on Kubernetes while delegating the management-plane operations to Google. During this course, you will use the Google Cloud hosted deployment for your labs. Operational management differs between the Google Cloud-managed and the hybrid deployments, but the experience you will have as an API developer is virtually identical.

### Video - [API Lifecycle](https://www.cloudskillsboost.google/course_templates/254/video/347351)

- [YouTube: API Lifecycle](https://www.youtube.com/watch?v=TqOLSzaUYp8)

person: During this lecture, we will discuss the API life cycle, and see how Apigee can help with development of your APIs and API programs. APIs can play a key role in your business and your ability to drive connected digital experiences. It is important to continually improve your APIs to adjust to changing customer and business needs. You may find it beneficial to think of your API development in terms of a life cycle. Start at the top with the design of the API, and move clockwise. After the design has been reviewed and approved by stakeholders, you can develop your APIs and build security into them. Your API is launched by deploying it into production and publishing it to app developers. When your API is in production, you must make sure to monitor the health and usage of your API. Analytics can be used to determine your API's level of adoption and how it can be improved. Depending on your business model, it may make sense to monetize your API, charging for its use or sharing revenue with app developers who are driving new business. With the feedback you receive from your app developers, and the insights you gain from monitoring and analyzing your API program, you will have an understanding of necessary and desired changes. You can design new features for your API, beginning the cycle again. Apigee has been designed to provide all of these capabilities, so you can manage the API life cycle for your APIs. Let's take a look at each stage of the life cycle and see how Apigee is used. One tool often used when designing a REST API is an open API specification. An open API spec can be used to define the interface and capabilities of your REST APIs without focusing on the implementation. The spec may then be used in a developer portal to allow app developers to explore and try out your APIs. An open API specification can also be used to generate an API proxy stub. The API proxy stub provides a template for building an API that adheres to the defined specification. Apigee allows you to build your API proxies using policies, which are pre-built functions that can be configured without code. Apigee also has built-in support for JavaScript or Java policies, which allow you to write custom code when needed for more complex use cases. Your proxies can be debugged using Apigee stress tool, so you can troubleshoot issues during development or in production. Apigee and Google provide multi-layer security for your APIs. Apigee proxies can utilize many built-in policies and features which allow you to create secure APIs even if your back-end APIs are not fully secured. Policies are available to add on SAML, JSON Web Token, and HMAC authentication and authorization to your APIs. Other policies provide threat protection against content-based attacks, detecting malicious request payloads and rejecting the requests before they are sent to your back-end services. Apigee allows sensitive data to be masked so that operations teams do not see user data or passwords when tracing live API traffic. Because Apigee is hosted in Google Cloud, Google Cloud security features can be leveraged to further protect your APIs. For example, Cloud Armor is a Google-grade web application firewall that protects web and API traffic against distributed denial of service attacks, allows rejection of traffic based on geographic origin or IP address, and provides firewall rules to protect against many common types of attacks. Cloud armor benefits from Google's extensive experience, protecting key Internet services like Google Search, Gmail, and YouTube. Identity platform is a customer identity and access management platform that helps organizations easily add identity and access management functionality to their APIs and applications. It protects users by supporting multi-factor authentication and provides support for many authentication methods, including SAML, OpenID Connect, email and password, or custom implementations. These are just a couple of examples of the Google Cloud security features you can leverage for your APIs. When your API has been built, you will need to deploy your API proxy into production. The deployment process should include testing and should be repeatable. This process can be built into a deployment pipeline, where changes to a proxy are automatically tested before being deployed. Apigee provides a management API that can be used to create and deploy proxies and configuration artifacts as part of a deployment pipeline, allowing you to build a repeatable process for deploying new or updated APIs. Apigee's developer portal helps your app developers discover your APIs and register apps to use them. Your open API specifications can be used to create the live documentation hosted in the developer portal, allowing app developers to try out your APIs. Apigee provides two types of developer portals, a Drupal-based portal that offers a full-featured customizable content management system, and a hosted integrated portal, which requires much less effort, but lacks some of the features and customization of the Drupal portal. After APIs are built and launched on Apigee, they need to be monitored to ensure that they are available and performing as expected. Apigee is API monitoring provides near-real-time insights into API traffic and performance by monitoring API performance and usage, automatically capturing API and back-end latencies, error rates, and call volume, among other types of operational metrics. Alerts can be used to keep you informed of unusual events or patterns, such as spikes in traffic or latencies. Alerted events can be analyzed in the console, and you can use notification channels in Google Cloud's operations suite to make sure the right people are notified quickly. API monitoring helps you diagnose issues before your app developers and users of your apps notice them. In addition to API and performance metrics, Apigee captures business metrics, tracking the apps and app developers using your APIs and the device types and geolocation of the users of those apps. Other metrics specific to your business can be captured by collecting custom data within your API proxies. Apigee includes a rich set of built-in reports to help gain insights into your APIs and API program. Custom reports can also be created to explore business-specific data. Apigee's analytics data can be integrated into your own enterprise systems by using the metrics API, or by extracting the data into Google's cloud storage or BigQuery. Companies with public API programs, or those offering digital products to partners, can use Apigee's monetization capability to create revenue streams based on API-powered digital products. Apigee monetization allows you to charge for API usage, or share revenue with app developers that drive your business. App developers can easily set up billing, choose rate plans, and process credit card payments from within the developer portal. APIs are key factors in today's digital businesses. Apigee can help you manage all aspects of the API life cycle, helping you to improve your APIs, create new APIs to address new opportunities, and grow your API program.

### Video - [Apigee Organizations](https://www.cloudskillsboost.google/course_templates/254/video/347352)

- [YouTube: Apigee Organizations](https://www.youtube.com/watch?v=kSlZm8teM1g)

Mike: This lecture will be a quick introduction to Apigee organizations and the entities they contain. You will learn more about all of these entities during this series of courses. An Apigee organization is the top-level entity for Apigee. When you use the Apigee console, you are working within the context of an organization. This Apigee organization is not the same as a Google Cloud organization. An Apigee organization is associated with a single Google Cloud project. An organization contains many types of entities. Some entities live inside environments, which are used as runtime execution contexts for your APIs. Let's quickly review organization and environment entities. Users can be granted access to one or more organizations. Users are associated with one or more roles within an organization. A role specifies a set of permissions that is granted to a user. Users and roles are managed using Google Cloud's identity and access management, or IAM. An Apigee organization admin has super user access within the organization. Other built-in roles specify permissions appropriate for other users of Apigee, including operations, business, and API development team members. An organization's API proxies are scoped at the organization level. APIs are exposed on Apigee by implementing API proxies. These proxies are built using policies, which are pre-built modules that provide features like security, rate limiting, message transformation, or mediation within the request and response flows of your proxy. Policies allow your APIs to provide rich functionality without your having to write lots of code. Shared flows can be used to combine a set of policies into a common pattern, allowing reuse of proxy logic in multiple APIs. An environment is a runtime execution context for your APIs. API proxies and shared flows are deployed to environments. API requests are handled by a proxy deployed in a specific environment. Environments may be used to model and enforce your API development life cycle. An organization might have three environments: development, test and production. An API developer would work on a new proxy, or changes to an existing proxy, in the development environment. When the API developer is confident that the proxy is working as intended, that revision of the proxy can be deployed to the test environment, where more formal testing could occur. Finally, the tested revision of the proxy can be moved into the production environment. Users can be given different permissions in each environment. A developer might need full access in the development environment, but should have no write access in production. The support team might have read-only access in development, but could trace proxies in production. Before publishing your APIs to the developer portal, you group and productize your APIs by creating API products. API products provide a mechanism for access and authorization for a group of APIs. App developers access the developer portal to discover your APIs and experiment with them. Within the developer portal, app developers may register apps with API products to allow access to your APIs. Apps present API keys, and OAuth tokens to access APIs. When an API key or OAuth token is verified in an API proxy, the app making the request is identified, as is the associated API product. This allows proxies to control functionality based on API product or app. API keys and tokens are stored at the organization level, but are generally associated with a single environment. The API product associated with the app specifies which environment or environments can be used. Organization-scoped key value maps, or KVMs, can store organization-wide configuration. KVMs are encrypted, so they are appropriate for storing passwords or other sensitive information. Environment groups are used to create a mapping from host names to one or more Apigee environments. For example, the host name api.example.com could be mapped to the production environment, and test.example.com could be mapped to the test environment. When an API request is received with the host name api.example.com, the request would be routed to a proxy in the production environment. Data collectors are defined locations used to store data collected during the processing of an API call. A data capture policy may be used to store a value in the data collector. The data collected may be used in custom reports. Analytics data provides visibility for all API traffic from an application through Apigee to your back-end services, and back. Operational and business metrics are automatically captured for each API call, ad a wide range of provided reports allows you to gain insight into your APIs. Customer reports can also be created to allow visualizations of custom data captured in data collectors, or to provide new ways of looking at your data. Environments provide a runtime execution context for API proxies. A proxy only accepts API requests when deployed to an environment. Environments may be used to represent different stages of the API development life cycle. For example, a revision of a proxy could be promoted from a development environment to the testing environment, and eventually into production. A proxy revision can be deployed to an environment where it can start taking traffic. A shared flow revision can also be deployed to an environment, making it available for use by proxies in that environment. A deployed revision of an API proxy or shared flow is immutable. Further edits to the API proxy or shared flow must be made in a new revision. Target servers are used to decouple back-end URLs from the API proxy code. This allows the proxy to connect to environment-specific back ends without changing proxy code. Key stores and trust stores store certificates and private keys to allow point-to-point encryption from Apigee to back-end servers. Debug sessions capture requests and responses that are received while tracing an API proxy deployment. Flow hooks are used to automatically attach shared flows to every proxy in an environment. This allows admins to enforce that security, logging, or other common policies are executed for all proxies. Resource files allow proxies within an environment to share code libraries. Caches may be used to eliminate unnecessary traffic to back ends or third-party services, resulting in improved latency, reduced costs, and better scalability. Cache data should not be shared between proxies in separate environments, so caches are only scoped at the environment level. Environment-scoped key value maps can be used to store configuration items that change between environments, like back-end credentials. I've taken you through a very quick tour of organizations and environments. Don't worry if organizations and environments, as well as all the entities they contain, don't make sense yet. You will learn more about these entities and how they all fit together throughout this series of courses.

### Quiz - [Module Quiz](https://www.cloudskillsboost.google/course_templates/254/quizzes/347353)

#### Quiz 1.

> [!important]
> **Which of the following entities is sometimes used to represent a phase of API development, such as staging or production?**
>
> - [ ] API Product
> - [ ] Application
> - [ ] Flow hook
> - [ ] Environment

#### Quiz 2.

> [!important]
> **When a customer uses the hybrid deployment model, which part of the deployment infrastructure is managed by Google?**
>
> - [ ] Neither the management plane nor the runtime plane
> - [ ] Only the management plane
> - [ ] Both the management plane and the runtime plane
> - [ ] Only the runtime plane

#### Quiz 3.

> [!important]
> **Which are core capabilities of the Apigee API Management Platform?**
>
> - [ ] Database and file storage
> - [ ] Application management and catalog
> - [ ] Container and cluster management
> - [ ] Mediation and analytics

#### Quiz 4.

> [!important]
> **Which of the following Apigee entities are only scoped to a single environment?**
>
> - [ ] Caches
> - [ ] API proxies
> - [ ] Key value maps
> - [ ] Environment groups

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/254/video/347354)

- [YouTube: Module Review](https://www.youtube.com/watch?v=WDiD-487AKw)

Mike: You've learned about Apigee, Google Cloud's API management platform, and the business challenges it can help you overcome. You learned about the API life cycle and how Apigee helps with the development of your APIs. You also learn about Apigee organizations and environments and the entities they contain.

## API-First and OpenAPI Specifications

This module introduces the basic concepts of REST API design, API first development, and OpenAPI specifications

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/254/video/347355)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=XsFjqNTr9Xg)

Hansel: In this module, you'll learn about the basics of REST APIs and how we design them. This module will teach you about API-first development, which recommends that you design APIs with the app developer in mind. You'll also learn about OpenAPI specifications, which are used to document APIs and provide live documentation in an Apigee developer portal.

### Video - [REST API Design, Part 1: Basics (1)](https://www.cloudskillsboost.google/course_templates/254/video/347356)

- [YouTube: REST API Design, Part 1: Basics (1)](https://www.youtube.com/watch?v=ywbD8ulZhl4)

Hansel: This lecture is the first of three on REST API design. We'll discuss the primary features of REST APIs. And you'll learn how to leverage HTTP concepts for those APIs. Before we get into the basics of designing REST APIs, let's explore what we mean by the term REST. REST was defined in Roy Fielding's 2000 doctoral dissertation at the University of California Irvine. At this time, SOAP, or simple object access protocol, was a popular way to implement APIs. SOAP, however, is not very simple. In order to make an API call using the SOAP protocol, a developer needs to craft a complex XML payload by referencing an even more complex definition document called WSDL, which stands for web services description language, Fielding and his colleagues designed the REST architectural style while version 1.1 of HTTP was being designed. They saw an opportunity to use HTTP concepts to create a simpler and more familiar pattern for APIs. REST APIs leverage common web HTTP concepts like URLs, verbs, and status codes. Message payloads for REST APIs are generally specified using simple JavaScript Object Notation, or JSON. The JSON payload of a well-written REST API is simpler and more human readable than the complex XML used for SOAP services. The use of common web patterns and simple payloads makes REST APIs easy for app developers to learn and use. Due to its simplicity and ease of use, REST has become the predominant style of web APIs today. When an API is designed using the REST style, we call it a RESTful API. RESTful APIs are resource oriented, focusing on the resources being acted upon instead of focusing on a list of operations or actions. Resources are specified in API URLs by using resource names and IDs. For example, to access a list of orders, you would make a request to /orders. To access order 1234, you would make a request to /order/1234. The request HTTP verb or method specifies the type of operation that has being performed on the resource or list of resources. Normal browser requests to retrieve web pages use the verb get. A get request for a RESTful API therefore retrieves details about the resource or resources specified in the URL. Post is used to create a new entity. Posting to /orders would typically create a new order with an auto-generated ID Put or patch to /order/ID is used to update an existing order, and delete on /order/ID would remove the order. Let's try an example. See if you can figure out what this API request means. What do you think this request is trying to achieve? Pause the video if you'd like to think about it before you see the answer. If you said that this URL retrieves a list of customers, you'd be correct. Look at the beginning of the request URL. This API request is using the domain name api.example.com, and the beginning of the URL path is /sales. For a REST API, the first part of the URL specifies the particular API that is being called. So this is example.com/sales API. After /sales, we see /customers. This follows the resource pattern we saw earlier. /customers represents a list of customers. We are using the get verb, so this request is fetching a list of customers. On the right is a typical response for the get customers call. 200 is the response status code, and OK is the reason phrase. The status code indicates the success or failure of the request, as well as the type of failure if the request failed. Since the API return 200, OK, the API call succeeded. The next two lines are headers. The content type header specifies the type of data returned in the payload, JSON in this case. The cache control header specifies how long the requester can cache and use this response instead of having to make the same request again. After the headers is the response payload. The JSON response is showing a list of customers with an ID, a name, and reference for each. The href reference is a URL that can be used to retrieve more details about that customer. We also see additional metadata about the response, the offset of the first customer retrieved, and the number of customers in the payload. According to the count, 100 customers were returned. The response is truncated to show only a few entries. The offset to the first customer is one. So this response is listing the first 100 customers. The total number of customers according to the metadata is 542. Remember that REST is an architectural style, not a standard. The payloads of REST responses do not have a required format. But you should try to keep responses consistent for all of your APIs, and especially within an API. Okay, here's another one. We know from the previous example that https://api.example.com/sales is the root URL of example.com sales API. When we are specifying calls in the context of an API, we often shorten this by removing the root URL. We would call this a get on /customers/C72. What would get on /customer/C72 signify? This retrieves information for a specific customer. In this case, Joe Apigeek, who has an ID of C72. In this example, we retrieve much more than just the name, ID, and a reference, since we are requesting the details of a single customer instead of up to 100 of them. This response also includes links, which allow us to easily retrieve the orders or wishlist of Joe Apigeek. When you design your own APIs. think about how your app developers would want to consume your APIs and what data would be useful to them. Remember, your app developers are your customers. A core part of designing your APIs is identifying your resources. Resources typically use concrete names instead of abstractions. In an employee's API, your resources might include employees, buildings, and reporting relationships. Each resource type typically has two primary URLs. /employees would be a collection of employees, and /employees/1234 would be the specific employee with the unique ID 1234. We use plural nouns for resource names in the URL. Use the plural noun for the collection name, /employees, as well as for a specific employee, /employees/1234. Remember also that you are designing your resources to be understood by app developers who may not have knowledge of internal names and concepts used within your company. You should always use terminology that makes sense to your app developers and is meaningful to them. For example, employees of the Apigee team at Google are sometimes called Apigeeks. This term could likely be confusing to most app developers, including app developers within Google. It would make more sense to name the resource "employees."

### Video - [REST API Design, Part I: Basics (2)](https://www.cloudskillsboost.google/course_templates/254/video/347357)

- [YouTube: REST API Design, Part I: Basics (2)](https://www.youtube.com/watch?v=XT78w2it_s4)

Hansel: As we saw before, HTTP verbs are used to specify the type of operation being performed on a resource. Using dogs as a resource, let's discuss how we should map HTTP verbs for the required operations. We can map these HTTP verbs to the four basic functions of persistent storage: create, read, update, and delete. We typically refer to these as CRUD operations. CRUD is an acronym for create, read, update, and delete. Remember that we have two primary URLs. For our resources, /dogs refers to a collection of dogs. And /dog/1234 is the specific dog with the ID 1234. Let's see what CRUD operations can be performed on dogs using these HTTP verbs. Get is the verb used to retrieve information about a collection of resources or a single resource. When you retrieve a web page in your browser, you are using the get verb. Get should not update the state of the resource at all. An operation that does not update the state is known as a safe method. Unless another API call has modified the state of your resource between calls, repeating the same get call will always produce the same result. We call this being idempotent. HTTP specifies that get should be safe and idempotent, so make sure your API adheres to these rules. Post on /dogs is used to create a new dog. No ID is provided in the URL. The ID for the new dog should be automatically generated by the API. The post method modifies the state of resources, creating a new resource in the dogs collection. Therefore, post is not a safe method. Repeating the same post call will result in multiple dogs being created, so post is also not idempotent. Posting to a specific dog by ID does not have a specific CRUD meaning. For update, we have two methods listed, put and patch. We will focus on the differences between put and patch later. Put /dog/1234 should update Toto, the dog with ID 1234. If appropriate for your API, you can have put create a new resource with the specified ID if one doesn't already exist. This is somewhat rare. Typically, this would only be used when the ID of a resource is a unique number or string, like a product ID. Put /dogs will bulk update all dogs or matching dogs if your request included a search or filter. Do not allow this operation unless it is necessary, because it might be too easy to accidentally bulk update lots of dogs. Put is not a safe method, because it is meant to update resources. Put, however is specified by HTTP as an idempotent method. A second identical put call should therefore leave the resource or resources in the same state. The delete method is used to delete a resource. Delete /dog/1234 would delete a specific dog. Delete /dogs would delete all dogs, or all dogs that match the search or filters provided. Most APIs don't allow a delete on a collection because it would be too easy to accidentally delete everything in the collection. Delete updates the state by removing resources, so it is unsafe. A second, identical, delete has no effect since the resource was already deleted, so delete is idempotent. If you have focused on SOAP services in the past, you may not be used to thinking first about resources and then choosing operations that can be performed upon them, as we recommend for REST APIs. SOAP specifies operations in the URL. But this is an anti-pattern for REST APIs. Operation names in URLs tend to have inconsistent patterns, making the calls difficult to remember, and the API hard to use and learn. For CRUD operations, we recommend that you use the primary HTTP verbs to operate on the resource. Operations will occasionally not fit into the CRUD model. For these cases, you can consider using post with an action or operation query parameter to specify the operation on the resource. For example, post /dog/1234, with an action parameter set to walk, could represent walking the dog. Here's the updated operation matrix. Post /dog/1234 with an action or operations query parameter can be used for non-CRUD operations. The HTTP put and patch verbs are both used to update resources, but for HTTP, they have different behaviors. Put completely replaces a resource with the provided payload. Patch should only be used to modify a subset of the resource. The JSON merge patch specification specifies how patch can be used for partial updates. Fields with the value are added or modified, and fields specified as null are deleted. Fields not mentioned in the patch request are not modified. Let's look at an example. Performing a get on the widget with ID of 1, we see that the widget's name is Bob and its count is 14. The patch call updates resource 1, setting the size field to large and removing the count field, since it is null. The name field is unchanged. The put call replaces the entire resource with the request payload. When you look at public REST APIs, most tend to use the put verb even though they are actually using the semantics of HTTP patch. The fields that are not present in the request payload are not modified. Although this is not the standard HTTP use of put, it is very common in REST APIs. When you are creating your own APIs, consider using patch for partial updates. However, it helps your app developers if you maintain consistency for your APIs. So you may decide to use put for partial updates if other APIs are also using put in this way. When we offer complex functionality in our APIs, we need to think about the app and developer experience. For example, we need to find dogs based on factors like color, location, and action being performed. A simple design using only standard URL resources would allow this ability, but what would the app developer experience be? To find brown dogs running in the park, the developer would first need to get all parks. Depending upon how many parks there are, it might take many API calls. Once she had all the parks, the developer would make a request for each park to find all dogs in the park. She would then need to retrieve each dog found in each park and keep a list of only those dogs that are running and are brown. Obviously. this solution would require lots of programming for the developer. Even worse, it could result in a huge number of round trips as she retrieved all the dogs one by one. The user would have to wait a long time to get the results. Now look at the bottom request, which can be viewed as "give me all the dogs that are in a park and are brown and are running." Which pattern would you rather use, and which is more likely to perform well? Coming up with the second solution requires the API developer to think like the app developer. And think about the experience of a user of an app that consumes your API. It is worth your time to think and design your APIs using this mindset. Also, APIs may be used by apps in ways you didn't originally expect. You can add features to your APIs to address needs as you learn of them, either when requested by your app developers or by analyzing API call patterns. Another way to deliver an optimized experience to your app developers is to allow the selection of partial responses. Instead of returning the entire response every time, you can give the developer control over which fields to return. This feature should definitely be considered for APIs that are designed for usage in low bandwidth apps, like mobile apps, or for APIs with large response payloads. In this example, a list of comma-separated fields is specified using a query parameter, and only the requested fields are returned in the response.

### Video - [API-First Development](https://www.cloudskillsboost.google/course_templates/254/video/347358)

- [YouTube: API-First Development](https://www.youtube.com/watch?v=Dhz_NqnsRcE)

Hansel: This lecture introduces the concept of API-first development. First, the obvious question, what is API-first development? API-first development is a strategy where your APIs are designed by first focusing on the needs of the app developers who will consume your APIs. Your API will be more successful if your app developers enjoy using your API, and it solves their problems. By focusing on the needs of your app developers, you may find that your API design should differ significantly from the design of your backend APIs. It may be useful to think of your backend APIs as building blocks for the API you want to create. Your API interface should also be designed before you start implementing your APIs. This helps you avoid making questionable design decisions based on what happens during the implementation process. Let's return to the digital value chain. App developers build apps that deliver connected experiences for end users. These experiences drive value for the company. APIs built by the API team will be used to power those applications. API-first development recognizes that your app developers will be most effective if those APIs are crafted specifically for their needs. Traditional API development has often been driven by inside-out thinking: build services first and then worry about how to expose them to the customer. A traditional goal may sound something like "There are 20 APIs we use in our company and we want to expose them to the world." This is focusing on the implementation of the API first, instead of focusing on the needs of the application developers, who will be the customers of your APIs. Even though you may be able to check a box saying you made 20 APIs available, you run the risk of having APIs that no one wants to use, or that perform poorly when using applications. In contrast, if you adopt an API-first approach, you are basing your API design decisions on the needs of your potential customers. This is outside-in thinking: designing with value for the customer as your primary focus, and then building something to deliver that value. If you understand what your app developers want, and can design an API that solves their problems, and is enjoyable to use, your API has a much better chance of being successful. Concentrate your API design efforts on how your API will be consumed by your app developers and their applications. Back to the digital value chain. If your primary focus is on simply exposing what you already have, or you are designing your APIs based on your existing backend implementation, you aren't designing with the customer in mind. When your design is primarily informed by the needs and desires of your app developers, and the app's end customers, focusing on usability, and customer use cases, your APIs have a better chance to succeed. There are other benefits that come with adopting an API-first approach. By designing your API contracts before you implement the APIs, you can have customers and stakeholders uncover business and technical gaps in your APIs before you develop them. You won't spend time building features that are not needed. And you won't design backend systems without understanding how they will be used. This early review cycle also allows your APIs to be reviewed for consistency, usability and best practices. Consistency across your APIs tends to increase adoption and give app developers confidence in your API program. Designing the API contract early also increases the ability to do parallel development. Apps using the APIs can be designed and use cases can be validated while your API implementation is in progress.

### Video - [OpenAPI Specs](https://www.cloudskillsboost.google/course_templates/254/video/347359)

- [YouTube: OpenAPI Specs](https://www.youtube.com/watch?v=tj9f9ZSjzNg)

Hansel: This lecture will introduce the OpenAPI specification, the preferred way to document your RESTful APIs. We will learn about the benefits of OpenAPI specifications, as well as how OpenAPI specs can be used with Apigee. In the early days, JSON-based APIs were documented using WADL, which stands for "web application description language." WADL served a purpose similar to WSDL, or web services description language, which is used to describe SOAP-based services. Like WSDL, WADL is relatively difficult to use. It is XML based, complex, and not very human readable. Swagger, introduced in 2010, was a big step in the right direction, specifying JSON-formatted files to describe the interface for RESTful APIs. This format was easier to understand and build. Swagger 2.0 introduced support for the YAML format. YAML is a recursive acronym which stands for "YAML ain't markup language." YAML is more human readable than JSON. Swagger 2.0 also provided the ability to describe all aspects of a RESTful API within a single file. Swagger is a proprietary format, but the format was donated to the OpenAPI initiative so that the format could be fully open sourced. This became OpenAPI version two. OpenAPI three further improved the structure and reusability of the components in an OpenAPI specification, and also added features like examples and callbacks. Apigee currently supports OpenAPI version two and three. OpenAPI specifications are a great way to document your REST APIs. OpenAPI specs describe the API interface, or contract, that defines how apps can use the API. OpenAPI specs can be made available on the Apigee developer portal as live documentation, which makes it easier for the developers to learn and explore your APIs. An OpenAPI spec is laid out in a format that promotes readability and editability. OpenAPI specs define the available paths to resources, and the allowed operations for each path. The request and response formats for all API calls should be documented in the spec, including success and failure response codes, and payload formats for all failure types. Authentication details for the API should also be described in the spec. OpenAPI specifications are used to provide interactive documentation for application developers in the developer portal. Being able to try your API streamlines the learning process for your app developers. We'll learn more about the developer portal in a future lecture. OpenAPI specifications can also be used to generate Apigee API proxy stubs. The generated proxy stubs will include flows for all resources and operations documented in the API specification. You can also use an OpenAPI spec validation policy in your API proxy to validate incoming requests against an OpenAPI specification. Any requests that do not match the spec could be rejected. We will learn more about API proxies in the next lectures.

### Quiz - [Module Quiz](https://www.cloudskillsboost.google/course_templates/254/quizzes/347360)

#### Quiz 1.

> [!important]
> **API-First development specifies that APIs should be designed and documented before they are implemented. Why is API-First development a recommended practice? Select two.**
>
> - [ ] It is hard to design your backend services if you don't know how your API will work.
> - [ ] API-First development eliminates the need for an OpenAPI specification.
> - [ ] API-First development allows issues to be found by technical and business stakeholders earlier in the API lifecycle.
> - [ ] API-First development allows app developers to directly call backend services until the API is fully implemented.
> - [ ] API-First development increases the ability to do parallel development.

#### Quiz 2.

> [!important]
> **For a REST API, which API request would best represent updating an existing student?**
>
> - [ ] PUT /student/15
> - [ ] POST /students/15
> - [ ] PUT /students/15
> - [ ] PUT /student?id=15

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/254/video/347361)

- [YouTube: Module Review](https://www.youtube.com/watch?v=hV2LILoLWVI)

Hansel: You have learned about restful APIs and what we should consider when designing them. We discussed API-first development, which tells us to design our APIs from the outside in, focusing on app developers and their needs. And you learned about OpenAPI specifications and how they are used to document APIs.

## API Proxies

This module introduces API proxies, proxy and target endpoints, environment groups, route rules, target servers, conditions, flows, and policies

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/254/video/347362)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=IfUyXxxd6rU)

Mike: In this module, we'll learn about API proxies. We'll learn how API calls are routed to a specific API proxy in an organization and environment, how backend services are called from your API proxies, and how we use flows, variables, conditions, and policies to control the functionality of our API proxies. You'll also create a retail API proxy during this course using a series of labs. You will use an open API specification to generate an API proxy step and use a target server to configure the backend service for your proxy. You'll also explore the trace tool and use route rules to route requests to multiple backend services.

### Video - [Apigee API Proxies](https://www.cloudskillsboost.google/course_templates/254/video/347363)

- [YouTube: Apigee API Proxies](https://www.youtube.com/watch?v=yR82iz6l56w)

Mike: This lecture discusses Apigee API Proxies, explains why we need them, and introduces proxy and target endpoints. The first step in understanding API proxies is to recognize what a proxy does. A proxy is an intermediary that sits between requesters and providers and acts on behalf of the provider. A request is forwarded, or proxied, to one or more providers. When the proxy has a response from the provider, the request can be fulfilled. Let's look at this from the requester's point of view. As far as the requester is concerned, she got the information from the proxy. The requester does not know or need to know that the proxy got the information from someone else. From the provider's perspective, the request came from the proxy. The provider does not need to know that someone other than the proxy originally requested the information. We'll see that this concept of a proxy has benefits for APIs. So, what is an API proxy? An API proxy provides a facade layer that separates API consumers, typically applications, from backend services and resources. The API consumer does not connect directly to those backend services. Instead, the API consumer connects to the API proxy, and the API proxy provides the required functionality by calling the backend services. The proxy provides consumer-facing APIs. These APIs can be designed specifically to address the needs of app developers and their apps. The advantage of this decoupling is that app developers do not need to worry about the complexity or usage patterns of backend services. The API proxy itself can deal with authentication, authorization, data manipulation, removing sensitive data, and other related concerns. Your backends can all use different API patterns or methods of access, and the API proxy can avoid passing that complexity on to app developers. This pattern also allows us to make changes in our backends, such as modernizing backend services or moving services from a data center to the cloud, all without having any effect on the apps that are using the proxy APIs. This is a diagram of Apigee's version of an API proxy. At a high level, what does an Apigee API proxy do? The proxy receives API requests from the app consuming the API. A particular proxy receives that request based on the scheme, hostname, and URL. An API developer can add features like security, scalability, and rate limiting to API proxies by attaching policies to flows. We will learn more about policies and flows later. Proxies can call multiple backend services during an API call. The API response can be built by combining and transforming backend responses. Analytics data is also captured for each call. This helps you gain visibility into all of the requests, responses, and the backend services called, even when the services are not capturing analytics data themselves. We will learn much more about each of these features of Apigee API proxies later. A common objection is, but what about the extra network hop for the API proxy? Doesn't that make everything slower? The answer is that the proxy layer does add incremental latency to some calls, but the benefits of using the API proxy typically outweigh the costs. We've discussed the high-level benefits of API proxies in previous slides, but let's dig a bit deeper. By using an API proxy layer, you gain control and insight over your API calls. This is extremely important. When you expose an API, you are allowing indirect access to its backend services. You need to secure incoming requests, especially if your API is accessible from the internet. Your API should only allow access to information that is appropriate for the consumer. You may need to add security to the API proxy for backend services that don't have enough security built in or remove sensitive fields before returning responses. You may need to limit the rate of requests to your backend so it doesn't receive more traffic than it can handle or handle certain errors at the proxy layer to reduce the load to the backend. You can also use an API proxy to serve requests from cache, which can reduce unnecessary traffic to backend services. With Apigee's built-in analytics, you gain insight into API calls and backend service performance. Control and insight can be difficult to manage at the individual service level. A second benefit you get from adding an API proxy is the decoupling of apps from backend services. This allows you to create APIs tailored to your app developers as opposed to directly exposing the APIs of backend services. You can create APIs that combine multiple services, including those from third parties. Features can be added to APIs and API interfaces can be improved without having to modify backend services. You can also move services between data centers or completely change backend services and how they are used without changing the calls being made by apps. When required changes are handled in the API proxy, apps consuming your API will continue to work as expected. An Apigee API proxy is split into two parts: the proxy endpoint and the target endpoint. The proxy endpoint is on the left of the diagram, closer to the API consumer. The target endpoint is on the right of the diagram, closer to the backend service, which is also called the target. The proxy developer attaches policies to flows to build the API proxy's functionality. We'll discuss the specifics of policies and flows in later lectures. The concerns of the API consumer are generally handled by the proxy endpoint. An incoming request is sent to a specific proxy based on the protocol, host alias, and base URL of the request. The proxy endpoint parses and validates the request. Policies are usually attached in the proxy endpoint request to rate-limit traffic and protect against invalid and malicious requests, blocking the request from reaching the backend service. The proxy endpoint also typically builds the API response to be sent back to the caller. The target endpoint handles the calling of the backend service. The URL of the backend service is specified in the target endpoint. The target endpoint generally builds a request for calling the backend service. Parameters like connection and I/O timeouts are specified in the target endpoint so that the API call won't hang indefinitely when the backend is not responding. The response from the backend is also generally parsed and validated in the target endpoint. We will learn much more about the flow of API calls during the next few lectures.

### Video - [Lab Intro: Generating an API proxy using an OpenAPI spec](https://www.cloudskillsboost.google/course_templates/254/video/347364)

- [YouTube: Lab Intro: Generating an API proxy using an OpenAPI spec](https://www.youtube.com/watch?v=DcnnJAghTic)

Mike: In this lab, you'll create an API proxy for a retail API. Many of the labs in these courses will add features to the same proxy, like security, traffic management, and caching. Later, you will also create API products and deploy them to a developer portal to allow application developers to use your API. In this first lab, you will use an open API specification for a backend service to create a new API proxy using the Apigee Proxy Wizard. You will explore the configuration for the new proxy and trace calls you make to it. We will be modifying the same API proxy during the labs. When you start building your own proxies, you will likely follow a similar incremental approach as you add functionality to your APIs. If you are having problems getting your proxy to work, try to use the trace tool to debug and fix the issue.

### Document - [Reading: Labs in this course](https://www.cloudskillsboost.google/course_templates/254/documents/347365)

### Document - [Reading: REST clients](https://www.cloudskillsboost.google/course_templates/254/documents/347366)

### Lab - [Apigee Lab 1: Generating an API Proxy Using an OpenAPI Specification](https://www.cloudskillsboost.google/course_templates/254/labs/347367)

In this lab, you'll use an OpenAPI specification to create an API proxy for a retail API.

- [ ] [Apigee Lab 1: Generating an API Proxy Using an OpenAPI Specification](../labs/Apigee-Lab-1-Generating-an-API-Proxy-Using-an-OpenAPI-Specification.md)

### Video - [Proxy Endpoints and Environment Groups](https://www.cloudskillsboost.google/course_templates/254/video/347368)

- [YouTube: Proxy Endpoints and Environment Groups](https://www.youtube.com/watch?v=6Fv_JcJmlRU)

Mike: In this lecture, we explore the proxy endpoint side of the API proxy. We'll see how environment groups and base paths cause a request to be delivered to the correct proxy endpoint. The Apigee runtime handles your API traffic. There are typically many API proxies running within an organization, and Apigee must be able to route traffic to the correct proxy. Each organization can have multiple environments. Environments are often used to control the life cycle of an API. For example, an API revision may start out in the development environment, be promoted to the test environment, and eventually be promoted to the production environment. The Apigee runtime can receive traffic using different hostnames. For example, api.example.org might be for a production API and test-api.example.org might be for a test environment. How does traffic get routed to the correct proxy? Before we answer the routing question, let's look at the high-level architecture for Apigee on Google Cloud. Apigee consists of two primary components: Apigee services and Apigee runtime. Apigee Services provides the APIs that you use to create, manage, and deploy your API proxies. Apigee runtime is a set of containerized runtime services running in a Kubernetes cluster that is managed by Google. All runtime API traffic passes through and is processed by these runtime services. In addition, Google uses other components. Google Cloud Services used by Apigee include features like identity management, logging, analytics, and metrics. These services are the same services you can leverage in your Google Cloud projects. Your admins can manage these services directly in the Google Cloud console. The Apigee runtime also allows your API proxies to call backend services. Now let's look deeper at the runtime architecture for Apigee on Google Cloud. The first step when creating an Apigee organization is to create a Google Cloud project. A Google Cloud project can be associated with one and only one Apigee organization. Likewise, an Apigee organization is associated with only one customer project. Deleting the customer project will delete the associated Apigee organization. The customer creates a virtual private cloud, or VPC network. Resources on this network are accessible using private IP addresses. The customer also creates a peering connection for use by the Google-managed Apigee runtime. An Apigee organization can now be created. The Apigee runtime containing the runtime services will be created in a tenant project that is unique for the organization. A private IP address on the peer network may be used to call the Apigee runtime instance. All inbound API calls will travel through the customer project and into the tenant project via this IP address. The Apigee runtime can directly call backend services. The customer has full control over the networking in the customer project. Resources within the project, like virtual machines, can make API calls using the internal network. Apigee can also call resources in the peered VPC network. You can also use Cloud VPN, or Cloud Interconnect, to connect your on-premises network with your Google Cloud virtual private network. Apigee can then call services on your on-premises network without ever leaving the private network. If the customer wants to expose the APIs outside the network or outside Google Cloud, a load balancer can be created to provide secure access to Apigee within the peer network. Whether the request comes from the internal network or from outside of Google Cloud, we now know that all requests enter the runtime service via a single IP. How does a request get routed to the correct API proxy? The first part of the answer is environment groups. An Apigee organization can contain one or more environments. Environment groups are used to map hostnames to environments. The Apigee runtime can receive API calls that use different hostnames. For example, api.example.org might be for a production API and test-api.example.org might be for a test API. A hostname can only be assigned to a single environment group in an organization. If a request comes in with that hostname, the request can only be handled by an environment in that environment group. Multiple hostnames may be assigned to an environment group. An environment group can contain one or more environments. Finally, an environment can be in more than one environment group. The hostname in the environment group determines the environment or environments to receive the traffic. A base path is configured in a proxy endpoint to indicate the request starting with the base path should be routed to that endpoint. The base path is the first part of the URL following the hostname. In this example, /orders/v1 is the base path, which corresponds to version one of the orders API. A proxy endpoint has exactly one base path, which is specified in the HTTPProxyConnection element of the proxy endpoint. Only traffic with that base path can be routed to the proxy endpoint. When you deploy an API proxy revision to an environment, all base paths of the proxy endpoints in the proxy must be unique within that environment. The proxy revision will not be deployed if the same base path already exists in a proxy deployed to that environment. Note that you can have multiple proxy endpoints that match an API request within an environment with each endpoint having a different base path. For example, in this case, you can also have proxy endpoints with base paths of /orders, or even just /. If there are multiple base paths that match a request, the longer base path match will be chosen. Within an environment group, you may have more than one deployed proxy with identical base paths. You will be warned of the routing conflict and can optionally abort the deployment. If you do deploy the proxy, the second deploy proxy will not take traffic until the first proxy is undeployed. This may be used to move a deployed proxy from one environment to another environment without any downtime. If you are familiar with API requests, you might wonder how HTTP and HTTPS are handled within Apigee. API calls may be sent by HTTP, which is unencrypted, or by HTTPS, which is encrypted using a transport layer security, or TLS, certificate. For the Google Cloud-hosted deployment, an Apigee runtime instance accepts only HTTPS requests. The runtime instance uses a self-signed certificate. When you use HTTPS-encrypted traffic for an API, the API generally identifies itself using a domain certificate. This certificate should be hosted on a load balancer in the customer project. The encrypted TLS connection with the client is terminated at the load balancer before the request reaches the Apigee runtime. HTTP requests must also be terminated at a load balancer in the customer project since the runtime instance only allows HTTPS traffic. However, it is strongly recommended that you only accept HTTPS requests for your APIs. We will discuss HTTPS in a future lesson. Here's an example of environment groups used for the API life cycle. In this case, we have three environment groups, one each for development, test, and production. The hostnames are all different, as they must be for different environment groups. If a request comes in for dev-api.example.org, the request is meant for a proxy in the development environment group. API proxies in the order system and inventory environments will typically have different base paths. If separate teams work on the order system and inventory products, this environment group and environment scheme allows for separation. Apigee allows you to provide different users access to different environments. We might also decide to add a new environment group for our partners. We have two partners, Ace and Zap, and they get their own hostnames. In addition, we don't allow our partners to track inventory, only create orders, so we do not give them access to the prod-inventory environment. How you choose to design your environments and environment groups is up to you. Remember, within a specific organization, many proxies are generally deployed to a given environment. Proxies often have just one proxy endpoint, but they may have more than one. A proxy endpoint is the entry point into a proxy for an API call. Now you know how traffic is routed to a specific API proxy endpoint in an organization and environment.

### Video - [Conditions, Flows, and Policies (1)](https://www.cloudskillsboost.google/course_templates/254/video/347369)

- [YouTube: Conditions, Flows, and Policies (1)](https://www.youtube.com/watch?v=b6SGXG_x6so)

Mike: We've learned how traffic is routed to a proxy endpoint in an Apigee API proxy. In this lecture, we will learn about the features of proxies. We will learn about variables, operators, and conditions, which you can use to dynamically control the execution of your proxies. And we'll learn more about flows and policies. Apigee API proxies allow the use of variables. Variables can be used to control the functionality of your proxies. Apigee has predefined variables that are set for each API call. Some variables give us information about the incoming request. For example, all of the incoming request headers and query parameters are populated as variables. If a request contains a query parameter called ACTION, the variable request.queryparam.action is available for use in your proxy, containing the value of the request's action query parameter. request.verb contains the verb, and request.content contains the payload. There are variables for the API response too. Setting these variables will modify the API response. For example, by setting the value of the variable response.header.foo, you can create a header called Foo in the response with the value you have specified. There are many other predefined variables. system.time returns the time the variable was read. target.url can be modified to change the URL used to call the target. You can also create your own custom variables. Your custom variables can contain any information you need to build requests and responses, log to analytics, or control the processing flow. Policies will also create and use variables. The variable set by policies will be used to customize the flow and behavior of your APIs. An example of a variable that you will use quite often is proxy.pathsuffix. proxy.pathsuffix is automatically set to the part of the incoming URL following the base path, not including the query parameters. For a RESTful API, the request's proxy path suffix and verb indicate the operation being performed. Let's look at an example request. The verb, GET, and the URL are shown here. The hostname of the request specifies which environment group receives the traffic. In this case, api.example.org corresponds to an environment group named Production. The base path is /orders/v1, which is routed to the proxy endpoint, named Default, inside the orders-v1 proxy that is deployed to the prod-ordersystem environment. The proxy.pathsuffix variable contains the rest of the URL following the base path. In this case, that is /carts/1234. The request.verb variable contains GET from the verb and path suffix, GET/carts/1234. The request should retrieve the shopping cart with ID 1234. Conditions allow dynamic handling during the API calls. Conditions are like "if statements" in other programming languages and must always evaluate to true or false. Variables and literals may be used in conditions, and conditions may be chained using the AND and OR operators. Let's look at some examples. This condition is true if the query parameter named ACTION exists. The second condition is true when the variable, response.status.code, is greater than or equal to 500. The third condition is true when the incoming request is a GET and the proxy path suffix matches /orders/*, which is true for a path suffix like /orders/1234. Conditions always have an operator. Most operators are similar to the operators you'll recognize from other programming languages, like =, ≠, or >. Apigee also has multiple pattern-matching operators. The first pattern matching operator is Equals. It is represented by a single or double equal sign. Note that conditions can never assign values to the variables being used, so using the single equal sign would never result in a value being assigned. In this example, proxy.pathsuffix would have to be exactly equal to /orders for this condition to be true. The Matches operator adds a wild card to the comparison, indicated by an asterisk. This condition would match any string that started with /files. The JavaRegex operator allows you to use regular expressions with the same semantics as are used in the Java programming language. In this example, the square brackets section of the search pattern matches any single character inside the brackets, so this JavaRegex would match /cats and /hats, but not /[ch]ats. Regular expressions are very powerful. It is worth your time to learn them if you do not already use them. The MatchesPath operator is used often when trying to match the URL patterns. This operator is typically used with the proxy.pathsuffix variable. /* will match a single segment of a URL and /** will match one or more segments of a URL. Note that all of these pattern-matching operators are case sensitive.

### Video - [Conditions, Flows, and Policies (2)](https://www.cloudskillsboost.google/course_templates/254/video/347370)

- [YouTube: Conditions, Flows, and Policies (2)](https://www.youtube.com/watch?v=6uk_fNGwczI)

Let's look at the flows in an API proxy. API call processing proceeds through the flows shown in the diagram. Any policies attached to the evaluated flows are executed in order. The evaluation order of flows is as follows: When the API request is received by the proxy endpoint, it is first handled by the proxy endpoint request flows. It is here that the request is typically validated and parsed. Next, route rules are evaluated to determine which target, if any, should continue with the processing. Route rules will be discussed in the next lecture. Next, the target endpoint request flows are processed, the request to be sent to the backend is generally built in these flows. Next, the request is sent to the backend target service, which returns a response. The next set of flows to handle processing is the target endpoint response. We generally parse the backend response here. Finally, processing continues to the proxy endpoint response. It is here we typically build the API response and log any necessary information. After these flows, the responses returned to the API consumer. You can see that all four of the sections here look very similar. Let's explore how the flows work within each section. Within each section, policies in the preflow are executed first. Policies in the preflow are always evaluated. After the preflow are the conditional flows. The conditional flow section contains zero or more flows, each with an optional condition. These flows are evaluated in order, and only the policies in the first conditional flow with a condition that evaluates to true are executed. If no flow conditions are true, none of them are executed. After at most one conditional flow is evaluated, policies in the postflow are executed. Like the preflow, policies in the postflow are always evaluated. We've been talking about policies quite a bit, but haven't really explained what they are. Policies are pre-built modules that implement specific functionality. They allow features like security, rate limiting and payload manipulation. These features are controlled using simple XML configuration and without writing any code. However, when you need code for a complex use case, there are also policies that allow you to run custom code. A policy can also be conditionally executed. If the condition for a policy evaluates to false, policy execution is skipped. Let's take a quick tour of the policy types available in your toolbox, starting with the traffic management policies. Don't worry if some of these policies are confusing now, we will discuss the policies in much greater detail in later lectures. The SpikeArrest policy limits the rate of requests that an app or user can make against your API. The Quota policy limits the number of calls allowed over a specified period of time. Policies for standard caches allow look up, population and invalidation of cache entries. A special cache policy called ResponseCache caches entire responses and can eliminate unnecessary traffic to your backends. Several security policies are available for securing your proxies. VerifyAPIKey identifies and validates the application making an API request. The OAuthV2 policy enables OAuth version 2.0 functionality, providing the ability to generate, verify, refresh and invalidate OAuth tokens. There are also policies to set, delete and retrieve custom attributes associated with OAuth tokens. The RevokeOAuthV2 policy is used to revoke OAuth tokens for an app or end user. The BasicAuthentication policy builds and parses Authorization headers when used for basic authentication. There are policies to support creation, decoding and verifying of JSON Web Tokens, also known as JWT or "jot" tokens. You can also perform the same operations on JSON Web signatures. You can support SAML assertions in your APIs by using the Generate and ValidateSAMLAssertion policies. The HMAC policy generates and verifies cryptographic hash-based message authentication codes. The CORS policy is used to specify cross-origin resource sharing policies for web applications that consume your API. Apigee provides JSON and XMLThreatProtection policies to protect against malicious JSON and XML payloads. The RegularExpressionThreatProtection policy can detect malicious patterns in incoming requests. The AccessControl policy allows or blocks incoming IP addresses and ranges. Mediation policies allow you to manipulate data, usually in your payloads. AssignMessage is a very common policy used to create, modify and remove HTTP message elements and variables. ExtractVariables extracts information from message elements and variables into new variables. Key value maps, or KVMs, are usually used to store configuration data. The KeyValueMapOperations policy reads, writes and deletes key value map entries. Using the RaiseFault policy is similar to throwing an exception in many programing languages. The JSONtoXML and XMLtoJSON policies convert payloads between XML and JSON formats. These policies can be especially useful when you are creating a JSON RESTful API that uses a SOAP service backend. The XSL transformation policy transforms XML using XSLT or Extensible Stylesheet Language Transformations. The MessageValidation policy validates XML against XSD schemas or SOAP messages against WSDL definitions. The OpenAPI spec validation policy, OASValidation, enables you to validate an incoming request against an OpenAPI specification, rejecting requests that do not match the specification. Extension policies provide other specialized functionality for your proxies. The JavaScript and JavaCallout policies allow execution of custom JavaScript and Java code. ServiceCallout calls an external service or third party API, or calls into another proxy in your environment. This allows you to call more than one service during an API call. Shared flows specify a sequence of conditional policies that can be used within multiple proxies. The FlowCallout policy is used to call a shared flow. The MessageLogging policy logs custom information to a syslog server. And finally, the DataCapture policy allows you to add custom data to the analytics record that is captured for each call. As you can see, there are many out of the box policies that can be used when building your proxies. These policies will help you build powerful and efficient proxies using much less effort than if you had to code all of this functionality yourself. Policies are created within a proxy, each policy contains its own configuration written in XML. Proxies can contain multiple policies of the same policy type, and a policy can be attached to one or more flows within a proxy. When a policy is attached to a flow, it is called a step. Each step can be associated with a condition. If the condition evaluates to true, the policy is executed during the step. When a flow is run, steps are evaluated in order. The diagram shows the proxy endpoint request flows. The policies are shown at the bottom. They are attached to flows as steps. When an API call comes in, the steps in the preflow would be run in order, followed by steps in the first matching conditional flow, if any, and ending with any steps in the postflow. Let's look at an example of flows within a proxy endpoint. Within the request preflow for the proxy endpoint, there is a step with the name VAK-VerifyKey. This is the name of a policy that is defined in a separate policy configuration XML file. There is no condition for this step, so the verify key policy is always exectued. That is the only step in the proxy endpoint request preflow. So now we look at the request conditional flows. The first conditional flow has a name of GetOrders. It executes if the proxy pathsuffix is /orders and the request verb is GET. Assuming that compound condition is true, we look at the first step containing the policy EV-ExtractFilter. This step contains a condition. The policy only runs if there is a query parameter named filter. Other conditional flow and postflow steps are not shown. As we saw from the previous example, it might not be easy to determine what policy type is specified in a step without some sort of naming convention. The policy type is shown in the policy definition, not the flow. One common convention for a policy name is to use an abbreviation for the policy type, followed by a descriptive name, separated by a hyphen. The policy type is usually not enough information to understand what the policy is meant to do. For example, we might have one assign message policy that is meant to remove headers from a message, and another that builds a request to send to a backend service. Naming the policies assign message 1 and assign message 2 would not tell you what they do. However, if you name the first policy A M hyphen remove headers, and the second policy A M hyphen build request, it is clear that they are both assign message policies with specific purposes. We will use this policy naming convention in the labs.

### Video - [Target Endpoints, Route Rules, and Target Servers](https://www.cloudskillsboost.google/course_templates/254/video/347371)

- [YouTube: Target Endpoints, Route Rules, and Target Servers](https://www.youtube.com/watch?v=1AxFLdmycyA)

Mike: We've learned how traffic is routed to a proxy, and we've explored proxy features like variables, conditions, flows, policies, and steps. In this lecture, we will learn about target endpoints. We'll see how we select a target endpoint using route rules. And we'll also look at how we invoke backend targets and how we can use an Apigee feature called target servers to support our API development life cycle. Finally, we'll look at endpoint properties, which can help us control our communication with remote servers. Just like proxy endpoints, multiple target endpoints can exist within a single proxy. And just like proxy endpoints, only a single target endpoint can be called during an API request. We can also choose to call no target endpoint if the processing of the API call does not require calling a backend target. Proxies sometimes have no target endpoints. We learned that routing to proxy endpoints is determined by a combination of environment groups, environments, and base path. If there can be multiple target endpoints, how do we determine which one is used? Target endpoints are chosen based on a proxy's route rules. After the PostFlow for the proxy endpoint request completes, the proxy's configured route rules are evaluated. As with Conditional Flows, the route rule conditions are evaluated, in order, to determine which target endpoint to use, if any. The first matching route rule indicates which target endpoint should be used. The request processing would continue with the specified target endpoint request flows. The request would be sent to the backend target. And then, processing would continue with the target endpoint response flow, followed by the proxy endpoint response flow. The same target and proxy endpoints that handle the request path would also handle the response path. A match route rule might specify that no target endpoints should be used. In this case, the processing would continue with the proxy endpoint response. It would be up to the proxy endpoint response flows to build their correct response for the API call. Each route rule has an optional condition. The route rule is a match if the condition is true. If there is no condition on a route rule, the route rule is always a match. The target endpoint for a route rule specifies which target to use if the route rule is a match. If there is no target endpoint specified, no target endpoint will be used and processing will continue in the proxy endpoint response. For your ordered list of route rules, it is a best practice to have the last route rule with no condition so it always matches if none of the other route rules do. Let's look at the route rule example here. The first route rule, auth-notarget, has a condition, but no target endpoint. If the path suffix is /auth, no target endpoint will be used and processing will continue with the proxy endpoint response flows. The second route rule, test-store-server, matches if there is a test query parameter in the request. If there is, the test-store-backend target endpoint is selected. The third route rule, default, has no condition. If the first two route rules are not a match, this route rule is an automatic match and will select the store-backend target endpoint. The backend destination is specified in the HTTPTargetConnection element. In this example, the target URL for the backend is hardcoded. The proxy path suffix is typically appended to the configured target URL to determine the full backend URL. In this example, the original request was to the store's v1 proxy. The proxy path suffix is /orders/12. The proxy path suffix is appended to the URL configured in the HTTPTargetConnection. The original verb, GET, would also be used for the backend request, unless you change it. Say this proxy code is deployed to our test environment. Assuming our test and prod backends are different, how would we promote the code to the production environment? We'd need to change the hardcoded URL in the code. The code validated in the test environment would need to be changed before putting it into production. This is an anti-pattern! We shouldn't put untested code into production. However, there is a solution for this. We can create a target server in all environments, each with the same name. The host name, port, and any required certificate information in the target server configuration can be different for each environment. We can use the same target server name in each environment, and the environment-specific target servers can have different host names. In the example, the target server name, store-backend, routes to the test backend for the test environment and to the prod backend for the prod environment. Now we can use the same proxy code, regardless of the environment. We replaced the URL with the target server name. The host name and port is taken from the target server configuration for the current environment in which the proxy is deployed. The part of the URL following the host name is configured with a path element. Now, the HTTPTargetConnection configuration does not mention test or prod. No change to the code is required when promoting the proxy into production because the target server contains the environment-specific information. Notice the Load Balancer element in the new code. We aren't doing any load balancing here, because we only have one backend, but target servers do have to be specified inside a Load Balancer element. Apigee provides a load balancing feature for distributing traffic among multiple backend servers. Backends need to be configured as target servers. Load balancing algorithms, like round robin and least connections, can be used to distribute traffic between the backends. You can use the Max Failures element to specify the maximum number of consecutive failures that are allowed before a backend is automatically taken out of service. The Server Unhealthy Response element specifies backend response codes, which indicate that the backend is unhealthy. If you don't specify a response code as an unhealthy response, it will be treated as healthy and reset the number of consecutive failures seen to zero. Configured TCP, or HTTP health checks, can detect when a backend is healthy again and bring the backend back into rotation. When you use the Max Failures or Server Unhealthy Response elements, you should always include a health check. If you don't, backends removed from service will never be put back into service. Apigee's load balancing feature is not intended to replace the use of load balancers and backend data centers. You can use endpoint properties to change many transport settings for your connections to the backend. In most cases, you should reduce the default connection and socket read/write timeouts. At the time this course is being recorded, the default socket I/O timeout for target endpoints is 55 seconds, and the default connection timeout is three seconds. These default timeouts could result in unreasonable latencies when the backend is not responding.

### Video - [Lab Intro: Target Servers](https://www.cloudskillsboost.google/course_templates/254/video/347372)

- [YouTube: Lab Intro: Target Servers](https://www.youtube.com/watch?v=tUod1vMY-L4)

Mike: In this lab, you build upon your retail proxy, replacing the hardcoded target URL with a reference to a target server. This allows you to deploy your proxy to different environments without making any code changes even though the URL for the backend service is different for each environment. You will create and configure the target server in the test environment and update your retail proxy to use the target server instead of the hardcoded URL. After you complete this change, you will test your proxy to make sure that requests are still being proxied successfully to the backend.

### Lab - [Apigee Lab 2: Using Target Servers](https://www.cloudskillsboost.google/course_templates/254/labs/347373)

In this lab, you'll replace the hardcoded target URL in your proxy with a reference to a target server.

- [ ] [Apigee Lab 2: Using Target Servers](../labs/Apigee-Lab-2-Using-Target-Servers.md)

### Video - [Lab Intro: Route Rules and the Trace Tool](https://www.cloudskillsboost.google/course_templates/254/video/347374)

- [YouTube: Lab Intro: Route Rules and the Trace Tool](https://www.youtube.com/watch?v=rMD8enMGRl8)

Person: In this lab, you create a new proxy that has two target endpoints. Your first target endpoint sends traffic through to the retail back end. Your second endpoint calls a different back end service. This pattern may be used to create a single API that is made up of multiple back end services. The trace tool is used to troubleshoot and debug your proxies. In this lab, you explore features of the trace tool, including the filtering of requests, which allows you to capture matching requests, and ignore other live API traffic. Finally, you learn how to save trace sessions for future investigation.

### Lab - [Apigee Lab 2a: Route Rules and the Debug Tool](https://www.cloudskillsboost.google/course_templates/254/labs/347375)

In this lab, you'll learn about route rules and the features of the debug tool.

- [ ] [Apigee Lab 2a: Route Rules and the Debug Tool](../labs/Apigee-Lab-2a-Route-Rules-and-the-Debug-Tool.md)

### Quiz - [Module Quiz](https://www.cloudskillsboost.google/course_templates/254/quizzes/347376)

#### Quiz 1.

> [!important]
> **Which of the following combinations of proxy and target endpoints is not legal for an API proxy?**
>
> - [ ] Zero proxy endpoints and one target endpoint
> - [ ] One proxy endpoint and more than one target endpoint
> - [ ] One proxy endpoint and zero target endpoints
> - [ ] More than one proxy endpoint and one target endpoint

#### Quiz 2.

> [!important]
> **Which parts of a REST API request together typically represent the operation being performed? Select two.**
>
> - [ ] The message body
> - [ ] The HTTP verb
> - [ ] The path suffix
> - [ ] The base path
> - [ ] The headers

#### Quiz 3.

> [!important]
> **Which of the following is not configured for an environment group?**
>
> - [ ] Base path
> - [ ] Name
> - [ ] Hostnames
> - [ ] Environments

#### Quiz 4.

> [!important]
> **Which part of a proxy determines the target endpoint that will be used?**
>
> - [ ] HTTPTargetConnection
> - [ ] Post flow
> - [ ] Target server
> - [ ] Route rule

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/254/video/347377)

- [YouTube: Module Review](https://www.youtube.com/watch?v=V_RGnWkcJ_0)

Mike: You've learned about API proxies, proxy and target endpoints, route roles, environment groups, target servers, flows, variables, and conditions. We also introduced policies, prebuilt functions that are used within your API proxies. We will learn more about the different policies in later lectures. You also completed three labs, including two labs in which you started building your retail API proxy. You will add more features to the API proxy during this series of courses.

## API Products

This module introduces REST API response design, API products, app developers, apps, API keys, and API product strategies

### Video - [Module Overview](https://www.cloudskillsboost.google/course_templates/254/video/347378)

- [YouTube: Module Overview](https://www.youtube.com/watch?v=4bTg9gJsFQo)

Hansel: In this module, we'll learn about API products. API products are used to package APIs for use by app developers in their applications. You learn how API keys can be used to protect your API from unauthorized access. You will also learn about API product strategies, and we'll use an example scenario showing how API products can evolve over time. And you will learn about REST API responses, and how you should use HTTP status codes in your REST APIs. In a lab that adds API key protection to your retail API proxy, you will create an app developer and an app and call the retail API using the app's credentials. Another lab will show you how you can control the functionality of an API proxy using custom attributes attached to an API product.

### Video - [API Products, Developers, Apps, and API Keys](https://www.cloudskillsboost.google/course_templates/254/video/347379)

- [YouTube: API Products, Developers, Apps, and API Keys](https://www.youtube.com/watch?v=2r-CWNkJfws)

Hansel: In this lecture, you will learn about four entities that are vital to providing control access to APIs on Apigee, API products, app developers, apps, and API keys. We've already learned about API proxies, which are used to implement the APIs that are used by app developers within the apps. You've heard about developers and apps. API products are how we provide API access to our apps. And API keys are used by apps to gain access to those APIs. Let's start with API products. What is an API product? Stated another way, in the context of APIs, what is a product? In Apigee, an API product is a bundle of API operations. These API operations are typically packaged together with the needs of application developers and applications in mind. For example, we might create an API product for selling items online. This API product might contain several API operations, including getting the product catalog, getting and updating a shopping cart, and completing an order. We can decide to document and market these API operations together as a bundle as an API product. We also use API products to control access to our APIs. We may want to block public access to our APIs, or track the apps using our APIs. We can grant access to our APIs at the API product level. We might also want to allow different apps to access the same selling API operations but with different levels of access, or different levels of service. API products are a great way to do this. This can be as simple as allowing read-only or read-write access to the same APIs. Another example is internal versus public. A company's internal apps are usually given more access to sensitive data than apps developed for the public. Or maybe free versus standard versus premium. We could allow free use of our APIs, but provide better features and more capacity for standard and premium customers. We will look at more API product design strategies in the next lecture. When you're designing API products, an important feature is custom attributes. An API product custom attribute is a name value pair that will automatically be populated as a variable when the app makes a request. This allows your proxies to dynamically grant access and service levels that are appropriate for each app based on the custom attribute of the API product associated with the app. Remember the digital value chain? APIs are published for use by app developers. App developers build the apps that create the connected experiences that will engage customers using those apps. So how do we publish APIs on the Apigee platform? The first step is to package APIs and API operations as API products, so they can be consumed by app developers. You can allow access to an entire API, or only to selected operations within that API. Custom attributes may be attached to the API product. Attributes may also be attached to individual operations or proxies within the API product. App developers typically sign up on the API provider's developer portal to get access to the APIs. Here, they can explore the APIs and API operations bundled in API products. App developers can register their apps to use API products, which gives them access to the corresponding APIs and API operations. Apps are given credentials that are associated with one or more API products. The credentials are called the consumer key and consumer secret. These credentials are unique to the app. The consumer key can be used as an API key. The API key is sent with request to the API. Any custom attributes attached to the API product or operation will be available as variables in the API proxy when the API key is verified. Requests without a valid API key that has access to the corresponding API or API operation can be rejected. In Apigee, app developers are configured with a name, email address, and username. Custom attributes can be attached to a developer, and like the attributes attached to the API product. these attributes will be available as variables in the proxy when the API key is verified. Apps are created for an app developer. Like app developers, and API products, apps can have custom attributes, which become available as variables in your proxy. One or more sets of credentials can be created and attached to an app. The credentials or consumer key and consumer secret can be associated with one or more API products. The credentials can also be deleted by the app developer or revoked by the API team, which removes access to the associated API and API operations. The consumer key can be sent with an API request, acting as an API key that identifies the app. The Verify APIKey policy validates the key and allows or denies access. If access is allowed, any custom variables configured for the API product, API operation, application, and developer will be populated. Note that if your credentials are associated with more than one API product, the attributes for only one of the API products will be populated. The VerifyAPIKey policy is almost always attached in the ProxyEndpoint request PreFlow. Verification of the API key should occur very early in the proxy processing. If the caller does not send in an API key, or the key is not valid, the policy will reject the request. This is the XML configuration for the VerifyAPIKey policy. Policies are always defined in their own XML files. The name field in the XML root element specifies the policy name. The policy name VK-VerifyKey is specified in the step in the ProxyEndpoint PreFlow code. Most policies have several configuration elements, but the VerifyAPIKey policy typically only have the APIKey element. The APIKey element specifies the variable where the API key is found. By default, the VerifyAPIKey policy looks for the API key in a query parameter named APIKey. The example is configured to look for the API key in an HTTP header named APIKey. Note that HTTP headers are case insensitive, unlike query parameters, so any capitalization of "APIKey" will work. When the policy is being executed, the variable request.header. APIKey will be checked for a valid API key. If the API key does not exist, or is not valid, or the associated API product does not allow access to this API, the VerifyAPIKey policy will raise a fault. Raising a fault causes processing to stop and an error message to be returned. We will learn more about faults later. If the API key is valid, variables will be created and processing will continue to the next step. Variables are formatted like this. The first segment, verifyapikey, is the type of policy. The second segment is the name of the policy. In this case, the name is VK-VerifyKey. The remaining text is the name of the variable or custom attribute. You can see here some examples of the variables that will automatically be populated by the VerifyAPIKey policy.

### Video - [API Product Strategies (1)](https://www.cloudskillsboost.google/course_templates/254/video/347380)

- [YouTube: API Product Strategies (1)](https://www.youtube.com/watch?v=6Ve3eMkjcn8)

Hansel: You've learned the basics of API products, and how they are used to package APIs. Let's explore the strategies you can use to design your API products. Before we discuss API products, let's look at some characteristics of a traditional product. First, a product is a good or a service that attempts to meet the needs of a specific audience. If there isn't anyone who wants the product, there isn't much point in creating it. Second, products typically have documentation explaining the features of the product, and how to use it. Documentation is required and important for helping the customer get the most out of the product. Third, unless you're giving the product away for free, products have a price. Some products provide value to a company in other ways. So the product's price might be subsidized or free to make it more attractive to a consumer. Okay, so let's look at API products. What are some characteristics of an API product? It turns out that API products are very similar to a traditional product. Like a traditional product, an API product attempts to meet the needs of a specific audience, the app developers who will use the API product. Documentation explaining the features and usage of your APIs is also important. We use open API specifications to allow app developers to discover and try out our APIs. Great API documentation can result in higher developer satisfaction. In some cases, we might want to charge for our APIs. Many APIs drive revenue directly or indirectly, just by being used. So APIs are often provided at no cost to app developers. However, we can choose to charge for our APIs if we are providing a valuable service to the app developer. Or we might even provide revenue sharing. By paying developers a percentage when they sell our products through their apps. If you want to charge or pay app developers, API products and Apigee API monetization can help you do that. Apigee API monetization provides an easy and flexible way to monetize your APIs that allows an API provider to charge for API usage, or pay back developers who generate new business revenue. Monetization helps to provide a simple way for your app developers to sign up, set up billing, choose rate plans, and process credit card payments using your developer portal. Monetization also provides reports on usage, billing, and transaction activity for your app developers. Monetization leverages API products to provide specific bundles of functionality to your app developers. One important concept to remember is that a product is not the same as a project. You are probably familiar with how projects typically work. When we think about projects, we typically think of a project's deliverables and the delivery date. Just from those names, we understand that projects are all about delivery. We begin a project by creating an ordered list of steps we need to complete before the project is finished. We then assign people to different tasks for the project and try to lay out a timeline. Sometimes the delivery date is given to us even before we begin that process. Hopefully we are given enough resources to deliver the project within the requested timeline. Sometimes we choose to remove deliverables from the project in order to meet our deadline. Delivering the project allows us to move on to the next project. We no longer focus on the completed project. Products on the other hand, focus on the outcome, not the delivery. While the project is often represented by a scheduled list of activities that are required to solve the problem, products should be designed based on business requirements. The person or team designing a product may have no idea how the product will be implemented. But that's okay. A product focus will be more likely to lead to a successful outcome. Since we are focusing on the requirements of the API product, rather than the process used to create it, products also need to adapt to market needs as they change. This means that we should be willing to modify our product over time. It can also mean that the new product you envisioned a few months ago might not be what you need now. This is one of the problems we often see with IT projects. When we design large projects upfront for delivery months later, the team locks down requirements to avoid scope creep, and give the team a chance to meet the delivery date. But the project often has reduced value when it is eventually delivered. The need to have a product meet current business requirements means that products do not have a completion date. We're not saying that you never deliver a product. Rather, we don't think of products as something with an end date. We should keep thinking about how market and business changes affect our ideal product and make changes to our product as necessary. It is rare to have a product that does not need some changes over time, so it's best not to think of your products as ever being truly complete. For these reasons, we strongly recommend that you adopt a product mindset for your APIs and API products instead of thinking of them as projects. Our experience tells us that a product mindset leads to better adoption and customer satisfaction for your APIs and a more successful API program.

### Video - [API Product Strategies (2)](https://www.cloudskillsboost.google/course_templates/254/video/347381)

- [YouTube: API Product Strategies (2)](https://www.youtube.com/watch?v=3C_ehKooxu0)

Hansel: Let's discuss a scenario where multiple API products might be created for a company over time. Imagine a company that sells household items at its stores around the world. The inventory team is responsible for creating inventory tracking and restocking apps for running the business. The inventory team has APIs it uses to manage its work. The inventory API can view and update inventory in the stores. The restocking API can view, place, and track restocking orders for the stores. The inventory team is currently the only consumer of the APIs, so the API Product Manager responsible for inventory creates a single API product that the inventory team can use for all its apps. Soon, other internal teams see the valuable data that can be available using the inventory team's APIs, and want access to the APIs to view the current state of inventory and restocking orders in stores. The API team would love to have other teams use their APIs, but worry about giving other teams the ability to adjust inventory or create restocking orders. The API Product Manager agrees that full read-only access for the rest of the company makes sense. A second read-only inventory product is created for internal use. The first product allows access to all operations in the APIs and the second product only allows GET calls to be performed. Internal team apps given access to the new product can now check the current inventory and restocking orders but attempts to update state like creating a restocking request are rejected when the API key is verified before the request is sent to the backend. The company is growing in popularity and now external app developers want to provide their users in stock information for popular products. The API Product Manager decides that providing this access will have a positive effect on sales, and decides to give external developers access to information about whether a product is in stock at a particular store, but not the stock levels. A third product is created to provide this external access. In this case, we want to make sure that external apps are never granted access to anything sensitive. Only GET for the in stock operation is allowed in this third product. A custom attribute is also created, which indicates whether the product is for internal or external access. The new product's custom attribute is set to external and the other two products are set to internal. This can be used to provide a reduced set of fields in the in stock response when being called by an app using the external product. The API team also realizes that there isn't an in stock API call on the back end. The new call is created in the API proxy by calling the backend inventory API and returning that the item is in stock if the inventory level is greater than zero. This new API product is successful but some key partners want to be able to provide their users with expected dates that products will be back in stock. Instead of giving all apps this ability, the API Product Manager decides to create a new API product that provides this access. At this point, the external API products are also rebranded as the silver and gold products. The restocking API operation is allowed in the gold product. You can imagine that other teams will want to productize their APIs as well. Remember that our product mindset focuses on the needs of the app developer, not the API development teams. As other teams add their APIs, we should focus on how app developers will want to use them. API and API operations from many different teams may be combined into a single API product. App developers don't care which development team or business unit created the API. So your API product design should generally not be based on the implementation team. We've seen that Apigee provides controlled access to APIs through the use of API products. Note that all of these API products have been rolled out, including changes to levels of access and even new API calls, without making any changes to your back end APIs. This is the power of Apigee. Apigee allows your API team to be agile and provide new features even when your back end service teams can't roll out features quickly enough.

### Video - [Lab Intro: API Products, Developers, Apps, and API Keys](https://www.cloudskillsboost.google/course_templates/254/video/347382)

- [YouTube: Lab Intro: API Products, Developers, Apps, and API Keys](https://www.youtube.com/watch?v=lC2TzinlcQs)

Hansel: In this lab, you add a VerifyAPIKey policy to your retail proxy requiring client apps to supply a valid API key. You will create an API product, an app developer, and an app. You will associate the API product with your proxy and associate the app with the API product. Then you test your API to confirm that API requests are only allowed when they supply a valid API key that is associated with your API product.

### Lab - [Apigee Lab 3: Publishing APIs as Products](https://www.cloudskillsboost.google/course_templates/254/labs/347383)

In this lab, you'll learn how API products, apps, and developers are used to identify the caller of an API.

- [ ] [Apigee Lab 3: Publishing APIs as Products](../labs/Apigee-Lab-3-Publishing-APIs-as-Products.md)

### Video - [REST API Design, Part 2: Responses (1)](https://www.cloudskillsboost.google/course_templates/254/video/347384)

- [YouTube: REST API Design, Part 2: Responses (1)](https://www.youtube.com/watch?v=tq9hTb1TrPY)

Hansel: This lecture is the second of three lectures on REST API design. The first lecture introduced REST APIs, and explained how to design restful APIs. This lecture will teach you about API responses from REST APIs. We'll learn how HTTP status codes should be used in your REST APIs, and how we return responses that are useful for the app developer but don't expose too much information. We'll also explore how we can use pagination for returning results across multiple calls to our APIs. If you use web browsers, you probably have at least some idea what HTTP status codes are. You may also recognize some of the status codes shown here. In web requests, as well as REST APIs, status codes should be used as the primary signal indicating whether an operation succeeded or failed. Some other types of APIs, like SOAP, return operation success or failure in the payload, but this is an antipattern for REST APIs. Status codes have specific defined meanings. Part of the reason REST has been so successful is that it leverages common patterns and conventions of HTTP. You should adhere to the defined meanings when returning status codes for your APIs. It is also important to be consistent with how you use status codes across all of your APIs. An app developer will find the second and third API easier to learn if those APIs follow the patterns of the first API. Listed here are seven status codes that are very common for REST APIs. If you have some experience with web development, you may have a good idea what these status codes mean. Even if you are not a web developer, you will probably recognize some of these. An HTTP status code has an associated reason phrase that indicates what the status code means. If you want to test your knowledge, pause the lecture now and try to guess the meaning of the status codes. Let's start. 200 is okay. This means that the request was successful. The resource was found and the requested action was taken. The rest of the status codes on this page indicate some form of failure. 400 is bad request. The request made by the client didn't satisfy one or more requirements. However, the app developer should be able to repair the request and resubmit. 401 is unauthorized. This actually means that the call requires authentication, and the user has not successfully authenticated. This reason phrase is slightly confusing, since the error indicates a lack of authentication, not authorization. 403 is forbidden. In this case, the user has successfully authenticated but the user is not allowed to perform the request for the specified resource or resources. If you are unsure what authentication and authorization mean, don't worry, we'll be discussing them in more detail in a later lecture. 404 is not found, and everyone who uses a web browser has probably seen this error. For REST APIs, 404 means that the resource specified in the URL does not exist, or at least is not accessible to the current user. 429 is too many requests. This error is returned when the request is being rejected because the user or all users have made too many requests recently. We will see that this error is used by Apigee for the spike arrest and quota policies. More on those policies later. 500 is server error. This should be used for an unexpected error on the server side. The expectation is that the caller might try the request again at a later time. Many, if not most, of the REST APIs you use or create should return these status codes. Here are some status codes that you should also consider using for your APIs. As before, pause the video now if you want to test your knowledge. 201 is created. Like 200 Okay, this status code indicates success. It is used when a resource is successfully created, generally using a post. Most APIs use 200 Okay, for successful creation of a resource. Whether you choose to use 200 or 201, be consistent across your APIs. 204 is no content. 204 is a success code that indicates that there is no content to return in the response payload body. The request was successful, but there is nothing for the API to return. When returning a 204, the response cannot contain a message body. 304 is not modified. 304 is a success code that indicates that the version of the resource the caller already has is the most up to date version, so no payload response is necessary. This can be returned when you use cache headers. We will discuss this further in a later lecture. 405 is method not allowed. This should be returned when the resource being requested is valid, but the requested verb isn't allowed for the resource. 406 is not acceptable. This should be returned when an incoming accept header is asking for a response format that is not supported by the API. 409 is conflict. This indicates that the request cannot be completed because there is a conflict. For example, when you read a resource, and then attempt to update it, 409 could be returned if the resource was changed after the original read. 503 is service unavailable. This may be used when a service is temporarily unable to handle the request. For example, the service is down for maintenance. This should be used when the error is known to be temporary and service will be restored. You may decide not to use these status codes and there may be other status codes that you decide to use for your APIs. Just make sure that you are not using status codes in a way that conflicts with the established HTTP meanings. You may have noticed that the status codes had values like 200, 400, and 500. Status code ranges have defined meanings. Status codes in the 100s are informational. Neither success nor failure. Processing is not complete. Status codes in the 200s indicate success. The request was received, understood, and accepted. Status codes in the 300s indicate redirection, The client must take further action to fulfill the request. In the case of 304, the client would redirect to or use the cached value. Status codes in the 400s are client errors. These indicate that the client is the source of the problem. If the client fixes the request, it can be successful. Status codes in the 500s are server errors. Through no fault of the client, the server cannot service the request. Note the 400 and 500 ranges. 400 says that the error is the fault of the client and 500 says that the error is the fault of the service. It is important to use status codes in the correct ranges. Apps will sometimes choose how to notify the user based on the value of the status code. This also means that the backend status codes are sometimes not appropriately returned to the client. Say the backend service is returning a status code of 400. Bad request. It may be the API proxy is not formatting the request correctly. And this might be happening even though the app sent in the correct format, as expected by the proxy. So returning a 400 to the app would indicate that the app could fix the problem, which is not the case. Make sure you always think about the meaning of the status code being returned to the app developer when you are designing your APIs.

### Video - [REST API Design, Part II: Responses (2)](https://www.cloudskillsboost.google/course_templates/254/video/347385)

- [YouTube: REST API Design, Part II: Responses (2)](https://www.youtube.com/watch?v=lXHbJjH8CSo)

Hansel: Let's look at some bad responses. Look at this response. Try to figure out what is wrong with the API response, and how it could be improved. Pause the video if you'd like to think about it a bit before we reveal the answer. The 400 status code for this response indicates that the error is due to the requester. But the response gives no information indicating how to fix the problem. If you were the app developer, imagine trying to fix the issue without having any information about what was wrong with the request. The improved solution tells the app developer that a required query parameter is missing and gives the developer a link with information about how to make the request. Look at these two requests. We are only showing the status codes, not the responses. What's the issue here? These responses leak information that could be useful for someone trying to compromise the API. There is no reason to leak the information that user 456 exists. If the caller does not have the authorization to access the resource, it is better to return 404 if the user cannot access the resource, whether the resource exists or not. Okay, one more. This one should be easy. This response is leaking information about what kind of systems are being used in the backend, as well as an internal IP address. You don't want to help hackers know what is running in your backend/ They could try to exploit known vulnerabilities with this information. The better solution returns information to the user with a correlation ID, which is used when logging information in the backend service. This would allow your engineers to debug a reported issue without unnecessarily exposing sensitive information to the caller. Note that this type of error response may be returned through your API if you don't take care to block it at the API proxy layer. The backend service may have been originally designed to be used only on the company's internal network. This type of error will be useful for quickly resolving issues with the API. Do not return backend error messages from your API proxy unless you are sure they are returning safe information. Pagination is a way to return a subset of data at a time. We call the subset a page. These results are ordered so the next set of results according to the order should be returned with the next page. When an API call is a search or query that can return multiple resources, we generally expect to receive paginated results. If we've chosen our ordering correctly, the most useful information should be in the earliest pages retrieved If there are potentially many matching resources, pagination can make sure we don't return responses that are too large. Pagination can be very useful. If the resources being returned are unusually large, or network bandwidth is important, as is the case for mobile apps. Here is an example of how our pagination response might be implemented. Note the query parameters being passed into the request. Offset indicates the first resource to retrieve, the 21st in this case. Limit=10, indicating that the next ten resources should be returned. You can imagine that a search or filter could also be used to select a subset of the resources. And then the limit and offset would be used to iterate to that subset. The list of entities or resources is generally implemented as an array of objects. Each object contains the fields for the resource that would be needed for presenting a list of resources with the ability to select a resource and retrieve more details for that resource. In this case, you see the ID, the first name and last name for the resources. Other use cases might need additional fields. In addition, the objects in this response contain a link or reference that could be used with GET to retrieve the details for the specific resource. This response also has a pagination section that returns information about the resources returned, and the total number of resources in the results. The example response we just saw was using offset and limit to page through the results. This method works very well for UI based use cases where you are letting the user of an app page through the results based on the type of sorting used in your results. Though, you might not consistently page through all the results, as updates to the resources could cause them to be seen again on a later page, or be skipped altogether if the changes to the resource moved it to a previously seen page. For use cases where we might want to allow the caller to retrieve all of the results, we might implement value-based page. Value-based paging returns a field that can be returned with the next call to retrieve the next group of resources. An example is using a last parameter, which might return the creation timestamp or ID of the last resource retrieved. Passing this last parameter into the next request would retrieve the next set of resources that follow the last parameter from the previous request. This can result in the caller predictively seeing every resource in the list. If the user requires traversing through all of the resources, you might choose to use value-based paging.

### Quiz - [Module Quiz](https://www.cloudskillsboost.google/course_templates/254/quizzes/347386)

#### Quiz 1.

> [!important]
> **Which of the following statements are benefits of using a VerifyAPIKey policy in an API proxy? Select two.**
>
> - [ ] Any custom attributes associated with the developer, app, and API products will be populated as variables and can be used to control the behavior of the API.
> - [ ] Only apps that have been registered to use the API will be allowed access.
> - [ ] The VerifyAPIKey policy enforces the rule that an API key should be stored in a header.
> - [ ] API requests for a specific app will be automatically rate-limited.
> - [ ] The caller is forced to present the consumer key and consumer secret to gain access to the API.

#### Quiz 2.

> [!important]
> **Which of the following statements about API products are true? Select two.**
>
> - [ ] Apps should only be associated with a single API product.
> - [ ] API products may be used to control access or service levels for APIs.
> - [ ] APIs bundled in one API product cannot be bundled in another API product.
> - [ ] API products should be designed based on the needs of app developers.
> - [ ] API products are APIs that are sold on the open market.

#### Quiz 3.

> [!important]
> **Which status code range indicates an error caused by an issue with the client's request?**
>
> - [ ] 5XX
> - [ ] 1XX
> - [ ] 4XX
> - [ ] 2XX

#### Quiz 4.

> [!important]
> **Which type of developer is configured in the Publish section of the Apigee console?**
>
> - [ ] Portal developer
> - [ ] App developer
> - [ ] Backend developer
> - [ ] API developer

### Video - [Module Review](https://www.cloudskillsboost.google/course_templates/254/video/347387)

- [YouTube: Module Review](https://www.youtube.com/watch?v=oFABqoPU_Vk)

Hansel: You have learned about API products, app developers, apps, and API keys. We discussed API product strategies, and REST API responses, and HTTP status codes. You also completed a lab that added API key protection to your retail API and a lab that used API product custom attributes to control an API proxy.

### Video - [Course Review](https://www.cloudskillsboost.google/course_templates/254/video/347388)

- [YouTube: Course Review](https://www.youtube.com/watch?v=1bjF8yR25Jk)

Mike: Thank you for taking the API Design and Fundamentals course. I hope you've become more comfortable and knowledgeable about creating and designing APIs using Apigee. During this course, you learned about Apigee and the API lifecycle. We discussed REST API design, API first design, and open API specifications. You learned about API proxies and policies. Finally, you learned about API products, which are used to package APIs for use by app developers. You did several labs, in which you created and tested API proxies. We recommend you continue with the next course in this series, API Security on Google Cloud's Apigee API platform. In the API Security course, you'll learn about API security concerns, and how Apigee will help secure against them. You'll learn about Oauth, an authorization framework for APIs. You'll also learn how to protect your APIs against content based and internal security threats. And you will complete labs to add security to retail API proxy. Please join us in the next course.

### Document - [Reading: Apigee X and Apigee Edge differences](https://www.cloudskillsboost.google/course_templates/254/documents/347389)

## Course Resources

PDF links to all modules

### Document - [Course Resources](https://www.cloudskillsboost.google/course_templates/254/documents/347390)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

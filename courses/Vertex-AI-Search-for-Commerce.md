---
id: 391
name: 'Vertex AI Search for Commerce'
datePublished: 2025-03-07
topics:
- Recommender System
- Alerts
- Discovery AI
type: Course
url: https://www.cloudskillsboost.google/course_templates/391
---

# [Vertex AI Search for Commerce](https://www.cloudskillsboost.google/course_templates/391)

**Description:**

This on-demand course provides partners the skills required to design, deploy, and monitor Vertail AI Search for Commerce solutions including retail search and recommendation AI for enterprise customers.

**Objectives:**

- Describe the Vertail AI Search for Commerce workflow
- Gain hands on experience with Vertail AI Search for Commerce
- Identify product catalog data and user event data sources
- Evaluate and select an appropriate data ingestion method
- Differentiate the four recommendation models and articulate the purpose of each model
- Quantify the sales benefits of Vertail AI Search for Commerce via attribution tokens
- Use eCommerce placements to retrieve product recommendations
- Interpret key metrics and configure alerts

## Introduction

This introductory module outlines what this course will cover and provides an overview of the Vertex AI Search for Commerce  solution and its benefits.

### Video - [Course Introduction](https://www.cloudskillsboost.google/course_templates/391/video/526479)

- [YouTube: Course Introduction](https://www.youtube.com/watch?v=Dq5V_gORu9E)

SPEAKER: Welcome to the course on Vertex AI Search for Retail. In this module, you'll first discover the learning objectives and prerequisites for this course. After that, you'll have an overview of Vertex AI Search for Retail solution and its benefits. Finally, you'll explore what Retail API is. Let's start with the learning objectives for this course. At the end of this course, you'll be able to describe the reference architecture used for building Vertex AI Search for Retail solutions, identify the necessary data sources, select an appropriate data ingestion method and troubleshoot common data ingestion problems, describe the various types of models and the purpose of each model and then how to customize the model to optimize your business objectives, embed recommendations and search results in your website and make them available to your website visitors, interpret key metrics and quantify the series benefits of Vertex AI Search for Retail via attribution tokens, and monitor and manage Vertex AI Search for Retail deployments and troubleshoot common operational problems. It's important that you meet specific prerequisites before completing this course. This course is especially useful for individuals who are using Google Cloud for retail solutions. Main audiences of this course are software engineers, cloud architects, cloud administrators, and SysOps or DevOps engineers. Therefore, the course assumes good understanding of Google Cloud and various services available as part of Google Cloud. The course also assumes that you have a good amount of hands-on experience in software development. To get the most out of this course, it is recommended that you have completed Google Cloud Fundamentals, Core Infrastructure and Big Data and ML Fundamentals courses before attending this course. In addition to the prerequisites mentioned in the previous slide, this course assumes that you are familiar with the product. It's assumed that you have attended or gone through the contents of the courses on Vertex AI Search for Retail, such as Sales Introduction or Vertex AI Search for Retail Sales L200. This course will help you start building production-ready applications for your clients. Let's start with a quick overview of Vertex AI. Search for Retail to refresh your memory. First, let's recall the goal of Vertex AI Search for Retail. The goal of Vertex AI Search for Retail is to significantly enhance the shopping experience of an individual buyer on your e-commerce website. The key to enhancing the shopping experience is to provide highly relevant and personalized product recommendations and search results. Vertex AI Search for Retail draws on Google's experience and expertise in machine learning to deliver personalized results tailored to each customer's preferences in all digital touchpoints. Vertex AI Search for Retail helps retailers solve their product discovery challenges with a multi-modal approach. Therefore, Vertex AI Search for Retail has multiple components. Recommendations AI-- With Recommendations AI you can deliver highly personalized product recommendations for your visitors at scale. Retail Search-- Google is a world leader in search technology. With retail search, you can enable search functionality on your website that has Google-quality search capabilities. And Vision API Product Search-- with Vision API product search, customers can search for a product by providing an image as a search query. You'll study Recommendations AI and Search Retail as part of this course. Vision Product API Search is not covered in this course. Let's start with Recommendations AI first. Recommendations AI uses advanced machine learning technology to deliver intelligent personalization. Your visitors will get product recommendations that are highly relevant to them. These personalized and relevant recommendations are crucial to enhance the shopping experience of your buyer. As a result, you can expect dramatic improvements to meaningful metrics, like click-through rate, conversion rate, and revenue. Recommendations AI looks at multiple factors before providing recommendations. First, it considers the previous browsing behavior of the buyer on your website. Second, it looks at the present context, or in other words, it looks at what the buyer is currently looking for. Third, it considers the various products and SKUs currently available in your product catalog. Let's move on to Retail Search. Google Cloud Retail Search allows you to leverage Google's advanced capabilities and search technology on your own website and mobile applications. Retail Search can provide personalized and relevant search results by correctly understanding the search intent of the user and the context. Retail Search provides multiple features. Advanced query understanding-- the ability to return both product listings and category pages for broad queries, including non-product searches, semantic search, extract product attributes and match with website content to classify products and groupings of information. Optimize and control-- optimize results based on user interaction and ranking models. Then optimize results to meet your business goals. And security and privacy-- retailer data, catalog events, queries, and logs, and customer data is isolated and will not be available to competitors or to other parts of Google. Before we move on to the next section, it's important to understand that you need to know about Retail API first in order to use Recommendations AI and Retail Search. So what is Retail API? Retail API is a common endpoint for both Recommendations AI and Retail Search. Retail API has two unique capabilities. First, it allows you to ingest and manage the necessary input data. Second, it allows you to request predictions based on the available data. It has the following features-- it supports unified data integration. This means that after you ingest the necessary input data, the same data can be used for generating both recommendations and search results. You don't have to upload data twice. It's a fully managed service, which means less maintenance overhead. It's a global scale service and can be easily scaled to handle large workloads, and your data is yours and remains private. Product catalog data and user events data are isolated and will not be available to competitors or to other parts of Google.

## Architecture Overview

This module explores the most common use cases for Vertex AI Search for Commerce. It also explains the reference architecture for implementing the solution.

### Video - [Architecture Overview](https://www.cloudskillsboost.google/course_templates/391/video/526480)

- [YouTube: Architecture Overview](https://www.youtube.com/watch?v=11e_Uw42VAc)

SPEAKER: Welcome to the first module of the Vertex AI Search for Retail course. In this module, you will explore how Vertex AI Search for Retail works, overview the project preparation and most common use cases, and then study the reference architecture for implementing Vertex AI Search for Retail solution. Before we review the Vertex AI Search for Retail architecture, it's important to understand how Vertex AI Search for Retail works. Google Cloud's Vertex AI Search for Retail helps retailers make products easy to find for their shoppers. In order to build machine learning models with Vertex AI Search for Retail, you need to provide two sets of information, data and intelligence. The first piece of information is data, which includes product catalog, user events, and inventor and pricing updates. The Retail API uses the same data for both Recommendations AI and Retail Search in browse. Therefore, if you use both, you don't need to ingest the same data twice. Product catalog refers to the information about the products being recommended to customers. This includes the product title, description, in-stock availability, and pricing. User events refer to the end user behavior on your website. This includes events such as when a user views or purchases a specific item or when your website shows the user a list of products. Inventory and pricing updates refer to the current state of your inventory and prices, which are actually part of your product catalog. And finally, query refers to a request for data results from your database or website. The second piece of information is business intelligence, which includes your business and configuration rules, along with your optimization goals. The third piece is offered by Google Cloud. Thanks to query understanding, product understanding, or knowledge graph, learn to rank models and personalize and, lastly, web and structured index capabilities of Google Cloud. Vertex AI Search for Retail helps retailers solve their product discovery challenges with a multi-modal approach. With Retail Search, recommendations AI, and vision product search, retailers can offer fast, accurate, and high-quality text and image search, browse, recommendations, and autocomplete capabilities to their customers. Before you start any Vertex AI Search for Retail project, you need some preparation. For this, first, you need to be familiar with the timeline of events and the approximate duration of each phase of your project. Second, you need to understand the amount and the type of data required. And finally, you need to be familiar with the types of models and service configurations. The next slide gives the average project timeline and summarizes the various steps you need to complete before you start your project. Therefore, you can use it as a reference when starting your first project. You will study each phase in detail in the remaining modules of this course. The project timeline includes various steps in building a complete solution using any Vertex AI Search for Retail solution. The first step is to collect the input data that is essential for generating quality predictions. The second step is to ingest that data into the tool. You will study both these steps in detail in module 2. After the input data is successfully ingested, you can start training your models. The tool provides various options to tweak your model so that it can meet your business goals. You will know more details about this step in module 3. When the model is ready, you can integrate it into your website and start showing predictions to your visitors. You can monitor the performance and start improving it over a period of time. You will study these things in more detail in modules 4 and 5. Now, let's review the most common use cases for Recommendation AI and Retail Search. First, let's look at a Recommendation AI use case. A typical buyer journey for an online shopping customer will include the following steps. First, the customer signs into the retailer's website from their laptop. The customer browses sports apparel. Then the retailer's website tracks the browsing behavior and a purchase history within the retailer's own site. After a while, the customer returns to the retailer's website and logs into their account using their mobile device. Based upon the previous browsing history, as well as the pages the user is currently viewing, which is the current context, the retailer's website recommends various products under the section entitled "Others you may like." For example, one of the recommended products may be shoes. Let's say that the customer is interested in buying shoes and decides to click on the recommended product. The customer then views the details of the product page for shoes. The website immediately provides a list of products in the "Frequently bought together" section of the web page. For example, the recommended product might be a pair of socks. The customer adds both shoes and socks to the shopping cart. However, the customer does not complete the purchase transaction and abandons the shopping cart. Three days later, an email marketing campaign sends an email with a list of products recommended for you. This includes the shoes and socks the customer had previously viewed. The customer checks the email, looks at the product details one more time, and finally completes the purchase. Next, let's look at a typical use case for Retail Search. The user is browsing the website, but isn't able to find the desired product. The user decides to use the search option. As they start typing the search query, the website provides highly relevant autocompletions. When the user hits Enter, the website comes back with a list of personalized search results. The user finds the product they are looking for and clicks on the product for more information. They are delighted that it was so easy to find the exact product they were looking for. This is how Retail Search greatly enhances the shopping experience of the user. Now, we can take a look at the reference architecture for Vertex AI Search for Retail. Understanding the reference architecture is really helpful for implementing any Vertex AI Search for Retail solution. The Vertex AI Search for Retail reference architecture includes three essential parts. The first part includes collecting the necessary data and ingesting the data into Retail API. The second part involves processing the data and building models to provide recommendations and search results. The third part includes embedding the models in your website. The rest of this module explores each of these functions in more detail. As you've just discovered, the first part of the Vertex AI Search for Retail reference architecture is all about inputs, which refers to the data collection and ingestion. The journey of data begins at data sources. You will see later in this course that there are two data sources. The first one is your product catalog. And the second one is the record of user-generated events on your website. The data in its original form is rarely useful. So you need to perform Extract, Transform, and Load, or ETL, operations on this original data. Retail API provides multiple options to do these operations. When the data is properly formatted for the specified schema, you can ingest it into Retail API. The next section focuses on data collection and ingestion. You'll learn more about the data sources, the data formats, and the various possible ways of ingesting data into Retail API in that section. When you have ingested data into Retail API, you can start using that data to build models. Retail API supports two types of models. The first is for product recommendations. And the second is for Retail Search. Please note that Retail API uses the same data for both Recommendations AI and Retail Search. This means there is no need to ingest data twice. The third section of this course focuses on building models using ingested data. You will study the types of models, possible optimizations for these models, and allowed customization options in that section. The last function in the reference architecture is embedding these models in your website. After you've done this, you can start generating highly relevant, personalized recommendations and search results. There are various serving configurations, which include different pages and devices on which you will place these models. Retail API provides Representational State Transfer, or REST APIs, to get recommendations and search results. You need to call these APIs from your website's source code. The fourth section of this course focuses on integrating models into your website. Now, you're familiar with the reference architecture and the three functions performed by this architecture. You will study those functions in more detail in the remainder of this course.

## Data Ingestion

This module discusses the data required to create recommendations and search models.

### Video - [Gather Data](https://www.cloudskillsboost.google/course_templates/391/video/526481)

- [YouTube: Gather Data](https://www.youtube.com/watch?v=z8H5ulr7eg0)

SPEAKER: Welcome to module 2 of the course. In this module, you'll learn about the data required to create recommendations and search models. To start, here's a quick reminder of the architecture for ingesting data into Retail API. The first step in the architecture is to ingest the necessary type and amount of data into Retail API. Please remember that your machine learning model is only as good as your input data. This is a very crucial step. In any machine learning project, the most time-consuming step is collecting and ingesting the necessary data. Typically, developers spend around 80% of their time in collecting, cleaning, and ingesting data. The data originates from a data source. Here, we have two data sources, product catalog and visitor actions on an e-commerce website. The final destination of the data is in the data sink. In this case, it is Retail API. You will need some tools and flows to take the data from data source, convert it into useful form, and then ingest it into the final destination. You'll use Google Merchant Center, Dataflow, Google Tag Manager, BigQuery, Google Cloud Storage, and GA360 for this task. Before looking at the tools and flows to ingest data, it's important to consider a few important questions about the data itself. The first question you must ask yourself is, what type of data do I need? For Retail API, you need data about your product catalog and data that represents user behavior on your website. To capture the online behavior of users on your website, you'll record user events. You probably already captured this data. And if so, you can use it after some processing. However, if you're not capturing this data, then you first need to put tools and processes into place to start capturing it. The next thing to consider is, how much data do you need? The best answer is, as much as possible. The quality of a machine learning model improves as you train it with larger data sets. But practically, you need to have some minimum amount of data to come up with meaningful machine learning models. The Retail API specifies the minimum amount of data required to build recommendation and search models. The minimum data requirements are based on recommendation model type, optimization objective, and user event types. You'll look at these requirements in more detail later in this course. Finally, what format should the data be in so that it can be ingested into Retail API? Retail API specifies the schema for data to be ingested, for example, JSON format for describing a product and JSON format for describing a user event. If the input data doesn't follow this format, it will probably be ignored and will not contribute towards improving your machine learning model. You will study these data formats later in this module. The next few slides consider each of these questions in more detail. So what type of data do you need? Any system which provides personalized recommendations and search results needs the following two inputs. Catalog data is data about the company's product catalog, meaning, information about the products that the company sells to its customers. A detailed understanding of each product is essential so that the model can judge if a product would be useful to a particular customer. The product catalog data is typically stored in a customer-managed database connected to the customer's storefront website. You must export this data, transform it as needed to conform to the appropriate Retail API schema, and then import the transformed product catalog data via the Retail API. You should plan to regularly update the product catalog information via the Retail API. This will help ensure that changes in product offerings, new or obsolete, are reflected in the model and its recommendations. You will learn how to update the product catalog data and how frequently you should update it later in this module. User event data is data about end-user behavior on your website, meaning, information about the browsing behavior of every unique visitor on your website. The best way to collect this information is to capture visitor actions on your website. For example, which product pages were viewed by this particular user? Which products were purchased by this particular user? Retail API allows you to specify different types of user events and the information required for each type of event. You need information about historical events to analyze the past behavior of the user. You also need live, real-time events to understand the present context. Now let's look at each data type a bit closer. The catalog is a collection of product objects. The catalog data you import into Retail API has a direct effect on the quality of the resulting model and therefore on the quality of the results that Retail API provides. In general, the more accurate and specific catalog information you can provide, the higher quality your model. If you use Retail Search, you can use catalog branches to test new data that you've uploaded offline before making it live on your website. The Retail API supports up to three branches, identified as 0, 1, and 2. Your live website points to default branch for its catalog data. It's set to branch 0 by default, but you can change that value if required. As an example, say default branch is currently set to branch ID 0. This means that your site is using the catalog data that you've uploaded to that branch. You can upload new catalog data to branch 1 and preview it. When you've confirmed that the catalog has been uploaded correctly, you can switch to branch 1 as the live default branch. All product information you provide can be used to improve the quality of recommendations and search results. Be sure to provide as many fields as possible. Product ID, product title, and product name are required fields. You must provide values for them when you create product items in your catalog. They should also correspond with the values used in your internal product database and should accurately reflect the product represented because they are included in training your models. In some cases, other fields might also be required. For the complete list of all product fields, always check the product reference page. Product attributes are key-value pairs you can associate with the product-- for example, store name, vendor, style, or color. These attributes act as strong signals for the recommendation model. And so it's highly recommended that you add these attributes. Product attributes can have different default settings and allowed options, depending on their type. There are three product attribute types. System attributes-- predefined system attributes are existing product fields that provide more information about the product. These include product attributes like brand, availability, color, and size. For all available system attributes for products, see the Product Reference documentation. Custom attributes-- custom attributes are extra attributes that you define using the Product Attributes field. For example, this could include store names, vendors, or style. For examples and limits for custom attributes, see the Product Attributes Reference documentation. Inventory-level attributes-- system or custom attributes that provide store-level information about the product. You might use inventory-level attributes for products whose properties vary significantly between stores and regions, such as grocery items or products that have store-specific promotions. Product levels determine the hierarchy in your catalog. Typically, you need to choose between a single-level catalog or a two-level catalog. There are three product-level types. Primary items are what the Retail API returns in prediction or search results. Primaries can be individual SKU-level items and groups of similar items, SKU groups. Variant items are versions of a SKU group primary product. Variants can only be individual SKU-level items. For example, if the primary product is V-neck shirt, variants could be brown V-neck shirt, size extra large, and white V-neck shirt, size small. Primaries and variants are sometimes described as parent and child items. Collection items are collections of products. Collections are bundles of primary products or variant products. For example, a collection might be a jewelry set with a necklace, earrings, and ring. Collections are only available in Retail Search and are not widely used. The first step in selecting a product level for your catalog is to differentiate a primary product from your variant product. The catalog allows you to create a hierarchy of products. You can create a catalog with all primary products and add variants later, or you can remove variants and make it all primaries. The important note here is that a product type is immutable. You cannot change the type of a product, for example, from variant to primary or from primary to variant. If you do need to change the type of a product, delete the product, and recreate a product with a different type. Before you can delete a primary product, the associated variants must also be deleted. Setting product level is crucial when you are importing catalog data. But how do you select the best possible product level? The following points will help you to make that decision. How is your existing catalog data structured? Does it only have one level of items? Or do you have both primaries and variants in your catalog? For Retail API, you also need to capture user event data. As part of the event data, you also need to provide the product ID. How is your website logic? What product ID is available to when you capture user event data? If the website logic only enables you to pass primary product ID as part of the user event, then you will end up using only a single-level product catalog. If your website logic allows you to pass variant product ID, then you need to consider how many user events will be recorded for each variant ID. Your model will not be optimal if you don't have enough user events for each variant product. What product IDs would be most useful when returned with recommendations and search results, at the primary product level or at the variant level? The answers to the above questions will help you decide which product level to use. For Retail API, product inventory encompasses price, both the current and original prices; availability, such as in stock, out of stock, back-ordered, and pre-ordered; quantity available; and fulfillment information, such as pickup in store, ship to store, and next-day delivery. There are two levels of inventory, product level and local. Product-level inventory-- for retailers who only sell online, inventory is specified at the product level. Price, availability, and other inventory data is set for each product in the catalog. Local inventory-- retailers who have brick-and-mortar stores and an online store need to keep inventory information on a per-store basis. They use local inventory to do this. For more information about product and local inventories, see Update Inventory for details. Retail API specifies the JSON format for describing your product information. It's crucial to adhere to these specifications so that all of your data gets imported without issues. Name, ID, and title are the required fields. The rest of the fields are optional. Please note that the list of fields on the slide is not comprehensive. And you should refer to the documentation for complete details. When importing a catalog from BigQuery, use the retail product schema to create a BigQuery table with the correct format, and load it with your catalog data. Then import the catalog. Product catalog data isn't the only data you need to capture. It's also important to capture user behavior on your e-commerce site. For example, which product pages were viewed by this particular user? Which products were purchased by this particular user? This allows the model to create personalization in its recommendations and search results. You can record a user's behavior on your website by capturing the user events, for example, the links clicked, pages viewed, and items added to the shopping cart. These events give a strong indication of what the user is really looking for. You're interested in getting personalized recommendations and personalized search results. That means you must start capturing visitor IDs to uniquely identify every visitor. You'll find out how to do this over the next several slides. There are several user event types that you can record as users browse your retail site. Add-to-cart, category-page-view, detail-page-view, and home-page-view are some of the user event types. For a detailed information about the user event object, see User Event. For the highest quality results, we recommend that you record user events for all event types. You must log the highest priority user events to achieve quality data models. For example, add-to-cart, detail-page-view, purchase-complete, home-page-view for Recommendations AI, and search for Retail Search are required for initial live experiment. However, category-page-view, search, and shopping-cart-page-view are important for improving Recommendations AI model quality over time. For user events, eventType and visitorId are required fields. The rest of the fields are optional. Always check user event requirements to generate quality results. The user event JSON format has a visitorId field. The provided visitor ID should uniquely identify the visitor. The visitorID is very important because it's required by every event. It's also important to note that a visitorID is used to join the same visitor session across devices or different sessions. This step is crucial to providing personalized recommendations and search results. It is also important to note that you should avoid creating visitorIDs manually. Putting the same visitorID for all events would defeat the purpose of this field and cause a lot of problems. There are a couple of ways that you can implement visitorID in your event data schema. If you have a sign-in feature on your website, your website application can assign a unique identifier to every signed in user. Even if the user accesses your website from multiple devices, for example, a laptop and a cell phone, your website application can assign the same unique identifier to the signed-in user. This helps to track user behavior across multiple devices. If you have a new user or the user has not signed in, you can use Session ID as visitorID. If you are using Google Analytics, you can use client ID in Google Analytics. This ID uniquely identifies a visitor on a single device. So all the hits coming from that device are attributed to this session ID. That means, if the user visits your website from a laptop and then from a mobile device, the system will have two separate session IDs and so will treat the visitor as two separate users. Another important point to note is that you cannot use any Personally Identifiable Information, or PII, in your visitorID. That means you can't use the user's email or mobile number as a unique visitorID. Retail API specifies JSON format for importing user events. EventType and visitorId are the required fields. The rest of the fields are optional. Please note that the list of fields shown in this slide is not comprehensive. And you should refer to the online documentation for complete details. When you have decided what type of data is required, the next step is to figure out how much data is required for satisfactory results. The minimum data requirements change depending on recommendation model type, for example, others you may like or recommended for you, and optimization objective, for example, click-through rate or conversion rate. You will learn more about these model types and optimization objectives in the next module. Please refer to Google's official documentation to know the exact minimum data requirements for each combination. There are no requirements, as such, on the minimum number of products in the product catalog. However, very small catalog sizes-- less than 100 items-- may not see much benefit from the recommendations due to there being very few different products to recommend. The models work best with at least three months of product page views, home page views, and add-to-cart events for all models and, ideally, one to two years of purchase history for the frequently-bought-together model. If you provide data for the whole year, it will help the models to take advantage of seasonality and trends. The final question to consider is, what format should the data be in to be ingested? There are multiple predefined schemas that you need to use to import data into Retail API. It's important to understand the schema and follow it while importing the data. Specifying the wrong schema can lead to errors or data getting dropped. This slide lists a few important predefined schemas that you need to be aware of. The schema shown match the various methods of importing data that you'll learn about later in this module. If you are using Google Merchant Center, you need to follow Google Merchant Center product schema. If you are importing catalog data from BigQuery, use BigQuery Recommendations AI schema to create a BigQuery table with the correct format and load it with your catalog data. If you want to describe product items in JSON format, please use product item JSON schema format. If you are importing user events, refer to UserEvent object format to understand the JSON structure. After you identify what data you need, how much data you need, and in what format, you need to select the product level and set the visitor ID.

### Video - [Import Catalog Data](https://www.cloudskillsboost.google/course_templates/391/video/526482)

- [YouTube: Import Catalog Data](https://www.youtube.com/watch?v=kMw9TwFr47c)

SPEAKER: You've looked at what type of data you need and how much data you need. You also looked at JSON data formats for specifying the data. The next step is to discuss the tools and processes to ingest your data into Retail API. So how do you import your product catalog? You can import catalog data into Retail API in multiple ways. Google Merchant Center. Google Merchant Center allows you to upload your product information into Google and then makes it available to shoppers when they search on a Google property. If you're already using Google Merchant Center, then it's easy to import your catalog data from it to Retail API. BigQuery. You can directly read catalog data stored inside a BigQuery table and import it inside of Retail API. Google Cloud Storage. Retail API allows you to import catalog data in JSON format. These JSON files need to be stored inside Google Cloud Storage. Inline request. Make a POST request to products.import method. You need to provide a JSON file for your product and call it. Based on the method you are using to import catalog data-- Google Merchant Center, BigQuery, Google Cloud Storage, inline-- you can select the tool that is supported for your method. Rest API are supported for all methods. You can also use Cloud Console UI for some methods. Please check the official documentation for the full list of supported tools. In addition, client libraries too will be provided as an alternative to curl command. You will get hands-on experience with these tools as part of your labs. As you've discovered, there are various ways for importing product catalogs. The next few slides explore each of these methods in more detail, starting with using Google Merchant Center. If you're using Google Merchant Center, then it's easy to import catalog data from Merchant Center. It allows easy integration of the catalog so that you don't have to do any development or integration work. However, oftentimes, the Merchant Center data may be incomplete. It may lack some important attributes, especially for search facets, or these important attributes may not be updated. As a result, large websites may end up using a direct import-- API, Google Cloud Storage, or BigQuery-- because it allows you to add more custom fields and more data that isn't usually in Merchant Center. The steps to import catalog from Google Merchant Center are-- set up a data transfer from Merchant Center into BigQuery. You can use BigQuery Data Transfer Service to do this transfer. The BigQuery Data Transfer Service automates data movement into BigQuery on a scheduled managed basis. Configure your transfer to repeat daily. You need to use Google Merchant Center Products table schema for your BigQuery table. Import your catalog data from BigQuery data set into the Retail API. You can do this through Cloud Console UI or by executing a curl command to call products.import method in Retail API. Note that Merchant Center import is only available for Recommendations AI. The second way to import your product catalog is to use BigQuery. This method is great if you already have data in BigQuery or data that can be easily exported to BigQuery from your original source of catalog data. If you have your data in BigQuery, you can import from BigQuery into Retail API. Please note that BigQuery data needs to follow the Retail Schema format. So you may have to map your existing BigQuery table into a table with Retail Schema. It can be tricky to get this formatting right. You should be familiar with nested fields, arrays, records, et cetera in BigQuery. Use the following steps. Create an empty table in BigQuery by using the Retail Schema. Convert your existing catalog data into the format specified by Retail Schema. And then load the above empty table with your catalog data. Import your catalog data from BigQuery data set into the Retail API. You can do this through Cloud Console UI or by executing a curl command to call products.import method in Retail API. You will need to automate the above steps so that you can transfer the catalog data on a regular basis. You can use this option if it's easy for you to export your catalog data from an existing database into JSON files. You can then upload these JSON files to Google Cloud Storage and then import from Google Cloud Storage into the retail API. This method tends to be the easiest, because writing out text files and pushing them to Google Cloud Storage is fairly simple. This method is preferred if you're not using Google Merchant Center or you don't have product catalog data readily available in BigQuery. This method is also useful if you want to try out the product quickly by adding a subset of your product catalog. Please note that the file itself is not a JSON file. It is a text file with one JSON structure per line. So each line describes one product instance. The JSON should follow the specified JSON product schema format. Also, remember that newlines are not allowed inside of the JSON. Steps. Export your existing catalog data into JSON files. You need to follow the product item JSON data format as defined by Retail API. According to this format, each product item should be on its own line. You need to provide the entire description of the product item on a single line, without using any line breaks. A few fields are required, and the remaining fields are optional. Upload the JSON files to Google Cloud Storage bucket. Import your catalog data from Google Cloud Storage bucket into the Retail API. You can do this through Cloud Console UI or by executing a curl command to call products.import method in Retail API. You can import your catalog information to the Retail API inline by making a POST request to the products.import method. You need to specify your catalog data in the described JSON product item format. This format allows you to include multiple products inside a single JSON file. It uses the same JSON format as Google Cloud Storage, but newlines are allowed. This method is useful if you want to update your catalog quickly. For example, if a new product is added to your catalog, you can use this method to quickly add it to the Retail API. You don't have to wait until the next scheduled update of the complete catalog. There is a limit on the number of items that can be imported at once. So this method is not suitable for very large imports. Follow the following steps to import your product catalog via direct ingest API. Use POST for products.import method. Use the productInlineSource object to specify your catalog data.

### Video - [Import User Event Data](https://www.cloudskillsboost.google/course_templates/391/video/526483)

- [YouTube: Import User Event Data](https://www.youtube.com/watch?v=15STh_prrJM)

SPEAKER: So now you are familiar with importing the product catalog data. Next, you'll discover how to import user event data. You need to collect and ingest two types of user events, recording user events in real time-- this gives information about what the user is looking for now-- and importing historical user events. This gives you information about the past behavior of the user. Historical user event data is also very useful to meet the minimum data requirements for building your model. Retail AI allows you to import historical user event data in bulk. There are five ways to import historical user event data in Retail API in bulk. Import from cloud storage-- upload files in the Google Cloud Storage bucket containing your user event data. Import your event's information to the Retail API by making a POST request to the user event's import method. Import from BigQuery. If you are storing your past event data in BigQuery, you can directly import it into Retail API. Import from Google Analytics 360. This is a good option if you're using Google Analytics to capture website analytics. If you have integrated Google Analytics 360 with BigQuery and use Enhanced Ecommerce then you can import Google Analytics 360 events into Retail API. Import user events inline. You can directly call userEvents.import method and provide a JSON file with your user event data. This method is useful if you want to quickly import a handful of new events. This method is also useful if you want to add new events in real time. Import Google Analytics for user events with BigQuery. You can import Google Analytics for user events if you have integrated Google Analytics 4 with BigQuery and use Google Analytics Ecommerce

### Video - [Record Real Time User Events](https://www.cloudskillsboost.google/course_templates/391/video/526484)

- [YouTube: Record Real Time User Events](https://www.youtube.com/watch?v=0s36jvkzph8)

SPEAKER: Now you'll look at ways to record real-time user event data and ingest it into Retail API. There are three ways to record your ongoing events-- JavaScript, Google Tag Manager, or via the API. You can use a JavaScript pixel to record a user event. This code must be added to your front-end application. Therefore, every time you want to update this pixel, you must also update your front-end application. If you are using Google Tag Manager to configure and fire tags on your website, you can use this same tool for recording user events. Google Tag Manager enables you to update your tags without updating the code of your front-end application. You can call the userEvents.write method to send user events directly from your backend server.

### Video - [Data Ingestion Considerations](https://www.cloudskillsboost.google/course_templates/391/video/526485)

- [YouTube: Data Ingestion Considerations](https://www.youtube.com/watch?v=2CJd2ww5i9E)

SPEAKER: There are a few other issues and caveats you need to consider about the data ingestion process. Retail API specifies JSON Schema format for describing products and events. It's vital to understand and follow this format. Any deviations can result in data getting dropped and not being used to develop the model. Retail API has some restrictions on the amount of data that can be ingested. For example, for bulk import from Google Cloud Storage, there is a limit on the maximum file size. There is also a limit on the number of files that can be imported in a single bulk import request. Please refer to the online documentation to find out the exact limits. Be sure to set the original timestamps correctly. Visitor ID, user ID, and all other data must match what's in the real-time events. Retail API has a list of best practices to follow while importing Data Catalog. Please follow as many as possible. Retail API also has a list of best practices to follow while recording user event data. Please follow as many best practices as you can. Getting events as soon as possible is also crucial. For search, personalization based on events is less than an hour. But recommendations are much faster. Therefore, batch imports are not generally ideal. And it's best to send events in near real time when possible. Don't import dummy data for products and user events. Customers often want to try out the products quickly. To do that, they import dummy data and check out how Retail API works. Please note that the dummy data is not a good choice to check the prediction capabilities of Retail API. To check the prediction capabilities, always use real live data. If you have uploaded some dummy data into Retail API, remember to delete it afterwards. When the system is live, it should contain only the real data. If you are using Google Cloud Storage, then follow the best practices for uploads and downloads. For example, while uploading, it's better to use a resumable upload than a single request upload. This is especially important for large files. You need to ensure that the application has proper Identity and Access Management, IAM, permissions to work with Google Cloud Storage buckets. For example, storage.objects.create permission allows you to create objects. If you specify the storage.objectCreator role to a member for a specific bucket, they can only create objects in that bucket.

### Video - [Common Problems](https://www.cloudskillsboost.google/course_templates/391/video/526486)

- [YouTube: Common Problems](https://www.youtube.com/watch?v=VjpECeGj06s)

SPEAKER: Finally, here are some common problems and doubts you may face while ingesting the data. To troubleshoot any problems, you can start by checking the Data, Catalog page in the console. It will show the number of catalog items, the last time the catalog was updated, et cetera. Check for any errors or warnings there. Next, you can check Data, Events page in the console. It will show the number of events, unjoined events, et cetera. Next, you can check Monitoring and Analytics. Look for user event errors, predict errors, and model errors. From there, you can go to Cloud Logging to see the exact error and response. If you're not getting any events, then more debugging needs to be done on the front-end side. If you are using Google Tag Manager, you can use Preview mode and see if tags are firing as expected. When you record user events, the product ID included in the user event is connected with the current catalog in Retail API. If you record an event for a product ID that is not in the current Retail API catalog, it cannot be used by the Retail API for training your models. This type of event is called an unjoined event. It's expected that you will always have a few unjoined events. But do check if the percentage of unjoined events is steadily increasing. If the percentage of unjoined events reaches 5% of your total user events, then you definitely need to take some corrective action. As you will see later, you can set automatic alerts to track the percentage of unjoined events. Here are a few ways to handle unjoined events. Check if unjoined events are happening for newly added products. This means your Retail API catalog is not up-to-date. To correct this, you would need to update your Retail API catalog frequently to reduce unjoined events. Check if unjoined events are happening for some special products which are not included in the catalog intentionally. For example, websites may have a free sample product that is not included in the official catalog. Check if the recorded events happened before your catalog was completely imported and updated. You can rejoin the events that were recorded during the import update. Check your program to see if you are providing correct product ID inside the user event request. You may be having a primary variant product ID mix-up. For example, imagine you are storing primary product IDs in a product catalog that you've imported into Retail API. However, when you are adding user events, you are using variant product IDs. In this case, both the IDs will always mismatch. And all of your events will be unjoined. In today's world, security is always a priority. So it's important to consider how you can ensure security while using Retail API. Cloud IAM is an ideal solution for making your application secure. It provides fine-grained access control and visibility across all the Google Cloud resources. Cloud IAM can be used to manage security for all Google Cloud Services, including Retail API. Retail API provides you various options when defining user roles through IAM. A set of predefined roles designed to help you easily control access to your retail resources-- examples of predefined retail roles are retail editor, retail viewer, and retail admin. Please note that the roles specific to retail provide only retail permissions. The older basic roles-- editor, viewer, and owner-- are also available to you. The basic roles provide permissions across Google Cloud. You can also create your own custom roles if the predefined roles do not provide the sets of permissions you need. If you're using Google Cloud Storage or BigQuery for data import, you need to provide the necessary permissions for Google Cloud Storage and BigQuery, too. Make sure the service account you created has necessary access to Google Cloud Storage buckets and BigQuery. Retail API needs a minimum amount of data to create useful models. The minimum data requirements change depending on recommendation model type-- for example, "others you may like" or "recommended for you"-- and optimization objectives-- for example, click-through rate and conversion rate. You will not be able to create a model unless you have the minimum data specified. You can solve this problem by importing past data. Retail AI allows you to import historical user event data in bulk. Using this feature, you can ensure that you meet the minimum data requirements for your recommendation model. This information is only applicable if you started using Recommendations AI when it was in beta. Recommendations AI now uses the Retail API. So all users should be using retail.googleapis.com. The old Recommendations AI, version V1beta1, remains available. But it will not be updated in the future. Please note that many changes were made to the REST and RPC paths while moving away from beta to Retail API. Similarly, the schemas for catalog and user events have changed in the Retail API. Please refer to the official guide on migrating to the Retail API. To get high-quality recommendations, it's vitally important to keep your product catalog up-to-date and keep recording user events successfully. Even if your initial import and event recording is successful, you should keep monitoring a few important performance indicators. Cloud Monitoring alerts help you to constantly monitor these important performance indicators. Cloud Monitoring has predefined alerts for many common issues. They can be activated from Cloud Console UI. A few important error indicators are alert for user event recording reduction. If you are not receiving user events for a prolonged period of time, there could be issues with your user event recording code. The event recording reduction alert is automatically triggered if you don't record any events for a specified period of time. High events unjoined ratio-- you will probably get a few unjoined events. But it's a concern if your percentage of unjoined events keeps increasing over a period of time. This alert is designed to inform you about this potential problem. You can also create a custom alert by using Cloud Monitoring Service.

### Video - [Introduction to Lab 1](https://www.cloudskillsboost.google/course_templates/391/video/526487)

- [YouTube: Introduction to Lab 1](https://www.youtube.com/watch?v=Eot1XvEQZXo)

SPEAKER: It's now time for a lab, where you will get hands-on experience of ingesting data into retail API. You will ingest both catalog data and user event data.

### Lab - [Product Discovery - Ingesting Retail Catalog and User Event Data](https://www.cloudskillsboost.google/course_templates/391/labs/526488)

Product Discovery - Ingesting Retail Catalog and User Event Data

- [ ] [Product Discovery - Ingesting Retail Catalog and User Event Data](../labs/Product-Discovery-Ingesting-Retail-Catalog-and-User-Event-Data.md)

## Training the Models

This modules explains how to build and manage Recommendations models. 

### Video - [Build Recommendation Models](https://www.cloudskillsboost.google/course_templates/391/video/526489)

- [YouTube: Build Recommendation Models](https://www.youtube.com/watch?v=M33LUtkj2-Y)

SPEAKER: Welcome to module 3 of the course. In the first module, you saw that Retail API provides two types of models, Recommendations model and Retail Search model. In this module, you'll learn how to build and manage recommendations models. In module 4, you'll learn how to manage and customize Retail search results. This module starts with a quick review of the top-level architecture. In the last module, you saw how to ingest data into Retail API. You need detailed and up-to-date information about product catalog and user events. You also need a minimum amount of data as specified by the Retail API. When you have this data, you are ready to build models. Retail API supports two types of model. The first is for product recommendations. And the second is for Retail Search. After the models have been created, you can use them on your website. Please note that Retail API uses the same data for both Recommendations AI and Retail Search. So there is no need to ingest data twice. In this section, you'll learn more about various available recommendation models and how to build and use them. First, you'll review the various components you need to consider to build your recommendation models. You should start by choosing your model. The first thing you need to decide before building your model is what type of model you want. The Retail AI supports the following recommendation model types. Others you may like-- this model predicts the next product that a user is most likely to engage or convert with. The model considers previous user interactions with the website and their relevance to the current specified product. For example, if you're browsing a laptop page, the model can show you similar configurations from other brands, newly arrived models, et cetera. Therefore, it's displayed on the detail page view page. The "Others You May Like" model predicts the next product that a user is most likely to engage or convert with. The prediction is based on the shopping and viewing history of the user and the candidate product's relevance to a current specified product. The default optimization objective for this model is click-through rate. This means the model will aim to increase engagement, the number of clicks on the recommended product. If you want, you can change the objective to conversion rate. With this objective, the model will try to increase the number of items added to the cart per session. You need to select the objective before you build the model. If you change the objective, you will need to build a new model. The model supports advanced configuration options of diversification and price reranking. These can be enabled through serving configurations. You need to provide a user event object to initiate the recommendation request. The supported user event object types are detail-page-view, add-to-cart, and shopping-cart-page-view. Frequently bought together-- this model predicts items that are frequently bought together along with a specified product. This model is not personalized but looks at the co-purchase data. The model tries to increase the number of items in a shopping cart by suggesting products that are highly complementary to the existing products in the cart. This model works with a single product as well as with a list of products. For example, if you're browsing for a new laptop, the website can show you matching laptop bags. The goal of this model is to increase the revenue for that session. And hence, it is displayed on Add to Cart and Shopping Cart pages. This model predicts items that are frequently bought together with a specified product. The goal of this model is to increase the number of items in a shopping cart. This model is also known as shopping cart expansion. The default optimization objective is revenue per order. The recommended products are selected in such a way that revenue earned by an individual order is maximized. Diversification is supported, but it is not recommended for this model type. Multiple user events are supported to call recommendations using this model. Although the list includes detail-page-view, add-to-cart, shopping-cart-page-view, and purchase-complete, this recommendation is commonly displayed on the Add to Cart page or on the Shopping Cart or Registry pages. Recommended for you-- this model predicts the next product that a user is most likely to engage with or purchase. The prediction is based on shopping history of that user and contextual information of requests, such as timestamps. Please note that this model is the most personalized model. The recommendations from this model are typically used on the Home page so that the user will see products immediately after signing in. In addition to the Home page, this model can also be used on category pages. A category page is similar to a home page, but all the products shown on the page belong to a specific category. To support category pages, you need to add a customized filter tag to all the items in a particular category. When you send the prediction request, you need to specify the filter tag for that particular category. If the filter is on, only products from that category will be shown. The default optimization objective for this model is click-through rate. You can change the optimization objective to conversion rate. You can use advanced configuration options like price reranking and diversification. The model supports all pages for the deployment. Recently viewed-- this is not a machine-learning-based model. It is simply a list of products that the user has browsed before. The model provides the IDs of products. And the IDs are provided in a chronological order, with the most recent products first. The recently viewed is not actually a recommendation. It simply provides the IDs of products that the user has recently interacted with. The IDs are provided in a chronological order, with the most recent products first. The model is supported for all user event types and pages. Similar items-- the similar-items recommendation predicts other products that have mostly similar attributes to the product being considered. This recommendation is typically used on a product detail page or when a recommended product is out of stock. The similar-items model requires only information from the product catalog. No user events are required. Additionally, similar-items models cannot be tuned. The default optimization objective is click-through rate for similar-items model type. It's recommended to create only one similar-items model per project. Since similar-item models are not customizable, creating multiple similar-item models based on the same user events does not produce different recommendations and can incur unnecessary costs. This recommendation model supports detail, add-to-cart, and purchase-complete pages. Therefore, detail-page-view event, add-to-cart event, and purchase-complete event are supported. Buy it again-- the buy-it-again model encourages purchasing items, again, based on previous recurring purchases. This personalized model predicts products that have been previously bought at least once and that are typically bought on a regular cadence. The buy-it-again model cannot be tuned. And it uses purchase-complete user events. Similar to similar-items models, buy-it-again models are not customizable. Therefore, creating multiple buy-it-again models based on the same user events does not produce different recommendations and can incur unnecessary costs. Recommendations from this model can be used on any page type. On sale-- the on-sale model type is a personalized, promotions-based model that can recommend on-sale products. You can use this model type to encourage users to purchase discounted items. The default optimization objective for this model is click-through rate. You can change the optimization objective to conversion rate. This model type is typically used on the home page, details, add-to-cart page, shopping-cart page, purchase-complete page, and category page. Page-level optimization-- page-level optimization extends Recommendations AI from optimizing for a single recommendation panel at a time to optimizing for an entire page with multiple panels. The page-level optimization model automatically selects the contents for each panel and determines the panel order on your page. For more information about model types, please check the documentation. Please note that these model types are recommendation model types. There are no model choices or options for Retail Search. It's all automatic behind the scene. Machine learning models are created to optimize a particular objective. So before you start building a machine learning model, you need to finalize your business objective or optimization objective. Each model has a default optimization objective. But you can request a different optimization objective to support your business goals by contacting your support representative. Retail API supports the following optimization objectives. Click-through rate, CTR-- choose this option if user engagement is your primary business objective. This option will maximize the likelihood that the user will interact with the generated recommendation, meaning, they click on the item and view the product details. Conversion rate, CVR-- choose this option if you want to increase the number of items added to a cart per session. This option will recommend products that maximize the likelihood that the user adds the recommended item to the cart. Revenue per session-- the goal of this option is to maximize the revenue per session. This objective is the default optimization objective for the frequently-bought-together recommendation model type. This objective can't be specified for any other recommendation model type. Please refer to the official online documentation for more information on optimization objectives. Each recommendation model supports a list of optimization objectives. One of the supported objectives is a default option. For example, the recommended-for-you model supports click-through rate and conversion rate as an optimization objective. But the click-through rate is the default objective. Please note that, after you have trained a model, you cannot change the optimization objective. You must train a new model to use different optimization objectives. This step can take up to two days to complete. This is why it's crucial that you finalize your optimization objective before you start building the model. Depending on the model type, there are some other model configurations you can use to change the behavior of your model. Before you can request predictions from your model, you must create at least one serving config for it. A serving config is a serving entity that associates a model or a set of controls that are used to generate your recommendation or search results. Note that a Recommendations AI serving config can have a single model associated with it. However, any model can be associated with multiple serving configurations, enabling you to deploy the same model on different pages via different serving configs. Retail API supports the following serving configuration options for Recommendations AI. Diversification-- this is useful if you want recommendation results to come from different categories of your product catalog. By default, diversification is disabled. That means multiple recommended products can come from a single product category. Diversification can limit this behavior. But this risks some good recommendations being removed. You can select different levels of diversification, which determines the maximum number of items per category based on your business needs. Two types of diversification are available, rule-based diversity and data-driven diversity. Rule-based diversity relies on categories on your product catalog. Use rule-based diversity to recommend products from a variety of categories. Use data-driven diversity to produce recommendations results that balance relevance and diversity. Price reranking-- if price reranking is enabled, Retail API will look for items with a similar recommendation probability and then sort that group based on the price. So when items from this group are listed, the highest priced items will be displayed first. Please note that this is not the same as sorting by price. It also looks at relevance and not just price to order the items returned. Price reranking is disabled by default. If you enable it, you have the option to balance conversion rates and average order values. Category matching-- if the serving config includes a similar-items model for Recommendations AI, you can enable category matching. When category matching is used, the Retail API returns only product results that share at least one category with the context product. If your categories have deeply nested hierarchies, the Retail API truncates them using heuristics to improve the possibility of a match. Category matching can be used in combination with other filtering options, such as price, availability, and filter tags. For more information about serving configurations for Recommendation AI, please check Advanced Model Configuration Options documentation. The great thing about the latest Retail API that you can change advanced model configurations, like price ranking and diversification, even after you have created your model. That means, you don't need to build a new model if you decide to change these options. These options can be changed through a serving configuration. Recall that a serving configuration is a serving entity that associates a recommendation model when making predictions. When you request a recommendation, you need to provide a corresponding serving configuration. The model will look at the information in the serving configuration and then tweaks the results accordingly. Serving configurations allow you to edit diversity and price reranking options and have them take effect in near real time. You can enable these options for all the recommendations, or you can selectively turn it on for a single recommendation request. Note that serving configurations for Retail Search will be covered in the next module.

### Video - [Additional things to consider](https://www.cloudskillsboost.google/course_templates/391/video/526490)

- [YouTube: Additional things to consider](https://www.youtube.com/watch?v=UqxEycersKM)

SPEAKER: Please keep a few other things in mind while building the model. Each model needs to be built separately. Recently reviewed items is not really a model and is created automatically. There are minimum data requirements to build a particular model type. You need to ensure that you have enough data before starting to build a model. There are limitations when you build a model, including limit on number of models per project, limit on number of active models, and a limit on the number of operations per minute. Typically, the operations per minute can be increased through quota. For more information on quotas, please refer to the documentation. Each model allows you to make customizations to best fit your need. Here are a few useful tips for building recommendation models. If you train your model with dummy or sample data sets or incomplete data, you won't get the best results from your model. You need to provide really good production data in order to get good results back. Remember, the machine learning model is only as good as your training data. The training phase for most of the models will be completed in two to three days. Very large catalogs or event data can cause models to take a bit more time to train, but the increase in time is not linear. If the training does not finish in three days, you need to start investigating. UI reports if there are any errors in the training. Usually, if the model training cannot complete, it's due to poor data quality. This problem happens more frequently if small sample data sets are used for training instead of real and complete production data. After you have ingested product catalog and user event data, indexing for search results happens automatically. You do not have to build any separate models to enable Retail Search. Remember that you will only get good search results if you have ingested quality input data. After you have trained your first model, you'll want to deploy it on your website. However, it's always a good idea to test the model thoroughly before going live. This is when recommendation preview can be particularly helpful. You'll learn more about this in module 4.

### Video - [Introduction to Lab 2](https://www.cloudskillsboost.google/course_templates/391/video/526491)

- [YouTube: Introduction to Lab 2](https://www.youtube.com/watch?v=uiqycGnER-s)

SPEAKER: In this lab, you will implement and use a recommendations AI model. You will create a serving configuration, configure a retail recommendations AI model, perform test predictions, and finally, call the Recommendations AI API from the command line.

### Lab - [Product Discovery - Implementing and Using Recommendations AI models](https://www.cloudskillsboost.google/course_templates/391/labs/526492)

Product Discovery - Implementing and Using Recommendations AI models

- [ ] [Product Discovery - Implementing and Using Recommendations AI models](../labs/Product-Discovery-Implementing-and-Using-Recommendations-AI-models.md)

## Serving Configurations

This module outlines how to integrate the Recommendations model and Retail Search model within your website.

### Video - [Serving Configurations](https://www.cloudskillsboost.google/course_templates/391/video/526493)

- [YouTube: Serving Configurations](https://www.youtube.com/watch?v=nAC78JByo84)

SPEAKER: Welcome to module 4 of the course. In this module, you'll learn how to integrate the Recommendations model and Retail Search model within your website. After these models are successfully integrated, your visitors will start getting highly personalized and relevant recommendations and search results. After you've deployed these models on your website, it's important to ensure that they are achieving the business goals. So you will study the different methods and tools to measure the model performance and improve it further. Let's start with a review of the top-level architecture. By now, you are familiar with how to ingest data into Retail API. You are familiar with different types of models and how to build them. The last step is to place these models on the actual website and start generating great results. The rightmost block shows the various pages and devices on which you will place these models. For example, imagine you've built the "recommended for you" model. When a user visits your website, the user will land on the homepage of your website. So you would like to call this "recommended for you" model from your homepage and show the products returned by this model. Similarly, you would like to remind the user about the recently viewed products. Here's another example. Imagine you have built the "frequently bought together" model. The model looks at items inside the shopping cart and suggests the best complementary items for that particular user. You want to call this model from various web pages, such as the product details page and cart checkout page. You would also like to add search options on every page to help the user to find the right product. Finally, you want to ensure that the models work on the website as well as on native mobile apps. In this module, you'll discover the various ways to implement these models. To integrate these models on your website, you need to understand more about serving configurations. You have briefly reviewed serving configurations in module 3. But in this module, you will study them in more detail. Serving configurations are used for both recommendations and Retail Search. However, Recommendations AI and Retail Search serving configs have different requirements and options. Recommendations AI serving configs require a model. If you plan to attach an existing model to a new serving config, get the ID of the model you plan to use, required when using the servingConfig.create method. If creating the serving config using the console, you can create a new model during the creation process instead of attaching an existing model. You can switch models later as long as it is of the same model type. Retail Search can use serving controls. But they are not required. If you plan to attach existing controls to a new serving config, get the IDs of the controls you plan to use. If creating the serving config using the console, you can also create new controls during the creation process. You can switch or add serving controls to your serving config after you create it. You'll learn more about both of these in this module, starting with serving configurations for Recommendations AI. When you create a serving configuration for recommendations, you attach an already created recommendation model to it. So you can consider the serving configuration as a logical reference to a recommendation model. When you make an API call to get recommendations, you provide information about the serving configuration. This then describes the model to be used. This means the API references the model associated with the serving configuration at the serving time to determine recommendations. Previously, Recommendations AI used placements to determine which model was used to return recommendations. Placements are still supported. But Google now recommends using serving configurations instead. Multiple serving configurations can be associated with a single model. These will deploy the same model on different pages via different serving configurations. However, you can't have multiple models inside a single serving configuration. A Recommendations AI serving config can have a single model associated with it. The serving configurations in the underlying model, therefore, have a many-to-one relationship. Typically, you will create a separate serving configuration for every unique placement on your site. Optimization objectives and advanced configurations allow you to tweak the model performance as per your business requirements. But there is one important difference between how they can be enabled. You need to specify optimization objective at the time of creating the model. There is a default optimization objective for each model type. You can also select a different objective from a list of objectives allowed for that model type. But remember, you can't change the optimization objective after you've created the model. If you really want to change the objective, you need to train and create another model. This process can take two to three days. You can specify advanced configuration options inside a serving configuration. If you do not specify these options, the default values will be used. The important point to remember is that you can change these values even after the model is built. This means you don't have to build a new model if you decide to change advanced configuration options. You can simply change them inside your serving configuration. The API will use this serving configuration at the serving time. And you will get results depending on the selected options. This means you can get new results in near real time. This is an improvement from the previous version of Recommendations AI, which used placements to return model results. In the previous version, you had to rebuild the model if you wanted to change the advanced configuration options. In the latest Retail API, you can change them inside serving configuration without rebuilding the model. There are also various serving configuration for Retail Search. When you create a serving configuration for Retail Search, you attach serving controls to it. A serving control is a rule consisting of a condition-action pair, where the condition dictates when the serving control will execute and the action specifies what behavior the serving control will enact. Therefore, serving controls enable you to create rules that customize how your serving configurations serve search results. You can also consider serving configuration as a logical entity that groups together multiple serving controls. When you make an API call to get search results, you provide information about the serving configuration. This then decides the rules to be used. This means these rules are applied at the serving time to determine the search results that need to be generated. You can have multiple serving configurations pointing to a single serving rule. In Retail Search, you can have multiple serving controls inside a single serving configuration. Serving configurations in the underlying serving rules, therefore, have a many-to-many relationship. Because of this relationship between serving configurations and underlying serving rules, you need to be careful while deleting a serving rule. If you delete a serving rule, it will get deleted from all serving configurations that are using it. Now, you know how to make a basic search request. But what if you want to tweak the default output of your search results? What if you wanted to customize the way search results are served? Is that supported? The answer is yes. And the way to do it is to use serving controls. Serving controls enable you to create rules that customize how your search results are served. The following serving controls are available for you to fine-tune Recommendations AI and Retail Search. Boost/bury affects results ranking and order in the returned result list, available for Recommendations AI and Retail Search. Filter removes results that do not pass the filter from the returned result list, available for Retail Search only. Redirect redirects your users to a specific page depending on the search query, available for Retail Search only. Linguistic customizes search query linguistics, available for Retail Search only. Several types of linguistic controls are available. Several types of linguistic controls are also available. Synonym expands considered synonyms for a search query. One-way synonym expands considered synonyms undirectionally for specific terms. Ignore prevents a term from being used in searches. "Do not associate" prevent terms from being used in searches when specific terms appear. Replacement replaces terms in the search query. Here's an example for boost/bury serving control. Imagine you're reviewing the order of search results returned by a user search query. After analyzing the results, you think that you should prioritize the cheaper products and deprioritize the expensive ones. You believe that doing so will boost your business and profit goals. Using a boost/bury rule, you can specify which products to boost in results and how much boost to apply. Boost can have a value between negative 1 to plus 1. In the rule shown here, you are applying a boost of plus 0.5 to all products that are less than $95. Similarly, you are applying a negative boost of 0.5 to expensive products, products higher than $95. Retail Search will consider this rule while serving search results. In the code window, the e in the expression price-- in parentheses, 95.0e, comma, asterisk-- which means you can add the letters e or i after the number to denote exclusive or inclusive-- indicates that the lower bound of the price range excludes 95.0. If both rules are present, neither rule will be triggered if the price is exactly 95.0 because both rules exclude that value. To include the value in one of the ranges, swap the e for an i. As such, in parentheses, 95.0e, comma, asterisk, which means you can add the letters e or i after the number to denote exclusive or inclusive-- The serving control inside a serving configuration is invoked whenever you use that particular serving configuration inside your API call. In addition to these controls, you can also use site-wide controls. Site-wide controls enable you to manage settings globally across all serving configurations. Site-wide controls apply to all search results or all recommendation results, depending on what type of site-wide attribute control you apply. Site-wide attribute controls are available for your catalog's product attributes, such as brand, color, and size. You can enable or disable site-wide controls for individual attributes. Retail Search uses the following attribute settings. Indexable-- Retail Search can filter and facet using this attribute. Dynamic faceting-- Retail Search can automatically use this attribute as a dynamic facet based on past user behavior, such as facet clicks and views. Searchable-- this attribute is searchable by Retail Search queries. You can edit site-wide controls by visiting Retail Controls page and then clicking on the Site-wide Controls tab. For more information, please refer to our official online documentation on managing controls. Retrievable-- if set to True, Retail Search returns this attribute in response to search queries. If all attributes have a retrievable set to False, the search results contain only the product name or, for variants, the product name and color information. Recommendations AI uses the following attribute settings. Filterable, public preview-- this attribute can be used in Recommendations AI filter expressions. This control is applicable only for text attributes. Creating a new serving configuration is fairly simple. Use the following steps. Go to the Retail API page. Select Serving Configs. Then click on Create Serving Config. When you create a new serving configuration, you need to select the product you want serving configuration to be used for, either Recommendation or Search. For recommendations, choose or create a model you want the serving configuration to provide recommendations for. Similarly, for Retail Search, choose or create controls to optimize your searches with. Generally, you will create a separate configuration for each different placement on your website. You can create a separate configuration for each option if you're doing experiments like A/B testing. In a project, you will need a limited number of serving configurations to cover these use cases. For more information on creating a serving configuration, you can refer to our official documentation about creating a service configuration. You can see the details of a serving configuration by going to the Details tab. It includes information about models in use, advanced configuration options used, et cetera. You can also edit these options from the Details page. You can get detailed analytics about the serving configuration by visiting the Analytics tab. You can see the historical data on click-through rate, conversion rate, recommender-engaged revenue, et cetera. You don't have to update the serving configuration if Recommendations API or Search API gets upgraded. You can easily delete a serving configuration from the same Serving Config Detail page if you don't need it.

### Video - [Introduction to Lab 3](https://www.cloudskillsboost.google/course_templates/391/video/526494)

- [YouTube: Introduction to Lab 3](https://www.youtube.com/watch?v=f7O7dm2qyoQ)

SPEAKER: In this lab, you will configure and use Retail Search. You will configure a Retail Search Serving Configuration, perform test searches using Retail Search console, configure the Boost/Bury control, and finally, call the Retail Search API from the command line.

### Lab - [Product Discovery - Configuring and Using Retail Search](https://www.cloudskillsboost.google/course_templates/391/labs/526495)

Product Discovery - Configuring and Using Retail Search'

- [ ] [Product Discovery - Configuring and Using Retail Search](../labs/Product-Discovery-Configuring-and-Using-Retail-Search.md)

### Video - [Access Model Results](https://www.cloudskillsboost.google/course_templates/391/video/526496)

- [YouTube: Access Model Results](https://www.youtube.com/watch?v=_fQ3rWXXnDs)

SPEAKER: When you've created the serving configuration, you're then ready to call the Retail API to get recommendations or search results. You can use the Serving Config Detail page to preview the recommendations from your models. Depending on the model being tested, you may wish to include the visitor ID to see recommendations for that user. Some models, such as frequently purchased together, do not require a visitor ID to display prediction results. These are the steps in using recommendation preview. Create a serving configuration for Recommendations AI. Visit the Retail Evaluation page. Select the serving configuration you want to preview. Optionally, enter a visitor ID to preview recommendations for that user. Then preview the predictions and ensure they are as expected. After you have configured a retail search inside Retail API, it's important to test it thoroughly. You should do this before you deploy it on the live website. Search preview provides you with the test mode, in which you can provide a search query and then evaluate the results returned by the model. When you are satisfied with the results, you can deploy the model on the live website. Follow these steps to use Search Preview. Go to Retail menu in Cloud Console. Click Evaluate. You will see a list of available serving configurations. Select a serving configuration you want to preview. You may have one or more controls already added to that serving configuration. Select the branch number. By default, branch 0 will be selected. Enter the search query you want to try out. You can also add visitor ID to see how results are personalized for that particular visitor. Click Preview and analyze the results. Check whether the conditions and various controls are properly applied. When you're happy with the performance of search model, you can deploy it on your live website. You can also get recommendations results via website API call. To do this, you need to make a POST request to the predict REST method. The API needs an appropriate request body in JSON format. Here are a few important inputs you need to provide in this request body. Access Token-- Access Token is essential to prove that you are authorized to make this request. It needs to have a role of retail viewer or above. SERVING_CONFIG_ID-- as you discovered earlier, serving configuration is like a logical name to refer to the actual model. This means SERVING_CONFIG_ID tells the API which model to use for recommendations. UserEvent-- you need to provide a userEvent object for the user action that initiated the recommendation request. It will include event type, visitor ID, user ID, et cetera. Note that this user event is not recorded. It is only used to provide context for this recommendation request. ExperimentId-- if you're running A/B experiment, you need to set this field to ID of the experiment group. You will learn more about A/B experiments in the later section of this module. Filter-- Filter is used to narrow down the list of potential products returned. This is optional. ValidateOnly-- this field is useful if you are just testing the method. If this field is set to True, the call returns a dummy result. You will not be charged for the API calls if validateOnly flag is set to True. You will get practical experience of using this API while doing the labs. Here are a couple of points to note about Retail API. The API calls to get results from Retail API are typically made from your backend. Frontend app, mobile apps don't want to make a direct API call since you don't want to have service account credentials as part of the app. Retail API calls are synchronous. That is, results are returned as part of API response. Currently, it does not support webhooks. Most of the time, you'll be using recommendations for your website. But Retail API also allows you to provide recommendations in emails. This feature is useful if you are running email marketing campaigns to engage with your website visitors over emails. You can include recommendations in the emails in two ways. Static prediction-- in this method, you call Predict API and insert those recommendations into email templates. It's important to call this API as close in time as possible to when the email is sent. That way, you can have the most up-to-date recommendations. This method is simple to implement. However, there is a time difference between when the API call is made and when the user actually reads the email. This means these recommendations may be outdated by the time the user sees them. Dynamic prediction-- this method ensures that your recommendations are always up-to-date. You can add dynamic content by including a reference to an image in an HTML email. Getting the recommendations back can be done with a Google Cloud function or any server-side app that can make the prediction request. The prediction results then need to be turned into an image that is shown as dynamic content in the email. So this method is more complicated than the static prediction. But you can always show the up-to-date recommendations to your user. As you studied earlier, a serving configuration allows you to attach serving controls to it. Serving controls enable you to create rules that customize how your serving configurations serve search results. To do this, you need to make a POST request to the search REST method. The API needs an appropriate request body in JSON format. There are a few important inputs you need to provide in this request body. The access token is required and proves that you are authorized to make this request. SERVING_CONFIG_ID is required. It tells the API which rules to use for generating search results. The QUERY_STRING is required and contains the text string to be passed to the search API. PAGE_SIZE is a variable used to control the pagination of the results. This field indicates how many search results should be displayed in one page. Pagination decreases the lookup time and the size of the responses being sent over the wire. Google, therefore, recommends enabling pagination by specifying the page size. VISITOR_ID is an optional field that identifies the user for whom the results should be tailored. You will practice using this API when doing the labs. Retail AI supports a few other options to enhance search results. Query expansion-- this setting is useful for long-tail queries which return very few search results. Using query expansion, you can increase the recall for query terms with few results. For example, if you search Google Pixel 5 without query expansion, you might only get Google Pixel 5 in the result. With query expansion, you might also get Google Pixel 4a with 5G, Google Pixel 4a, and Google Pixel 5 case. Filters-- you can add text filters to modify the search results returned by the query, for example, price, in parentheses, asterisk, 100.0e, which means you can add the letters E or I after the number to denote Exclusive or Inclusive. Filter will return products cheaper than $100. Order-- you can specify the field by which to order the results. By default, the order is ascending. You can also order by multiple fields.

### Video - [Measure Performance](https://www.cloudskillsboost.google/course_templates/391/video/526497)

- [YouTube: Measure Performance](https://www.youtube.com/watch?v=j5zpL16fa74)

SPEAKER: After you have deployed these models on your website, you then want to ensure that they are achieving great results. For an e-commerce website, there are different ways of measuring performance. You can track how many people clicked on the links, how many products got added to a shopping cart, how much revenue was generated per transaction, et cetera. It's very important to measure the performance and keep improving it over time. In the rest of this module, you'll discover the various methods and tools to measure performance and how to continually improve it. You will study five ways to measure performance of Retail API results. The first method is attribution tokens. Attribution tokens are unique IDs which are generated by Recommendations, AI, and associate Retail API results, both recommendations and search, with the subsequent user actions. So with the help of attribution tokens, you can judge if the provider results were relevant to the user and if the user was further interacting with those results. This data is very useful to train reranking models to improve the results quality. This is why attribution tokens provide a good way to improve Retail API performance over time. So how do you use attribution tokens? When you make an API request with a predict or a search method, the response returns a unique attribution token in its response body. Note that this token is automatically returned when you call the API. And you don't have to do any additional settings. A sample response is shown on the slide. Along with the results, you see the attribution token returned by the API. When you show results returned by Retail API, recommendations, or search, you are encouraging the user to take some further action. The user can interact with those results by browsing the product details, adding the product to a favorites list, adding the product to a shopping cart, et cetera. When you record this user event, you need to include the attribution token returned by the API in the previous step. The slide shows a sample user event that needs to be recorded. You can use attributionToken field to associate this user event with a particular recommendation or search result. Retail AI provides site-wide metrics in the Analytics tab on the Monitoring and Analytics page. By clicking on the Product Dropdown list, you can see data for both recommendations and search metrics for that type of Retail API product. The next slides explore recommendations data in more detail. The following data points are included in Recommendations AI summary. Total revenue-- the total revenue from all recorded purchase events. This value includes shipping and tax. Recommender-engaged revenue-- the revenue for purchase events that include at least one product that was selected from a recommendation panel. This value includes shipping and tax and any discount applied. Average order value-- the average value of orders from all purchase events. It is calculated as total revenue divided by the number of orders. Recommender-engaged AOV, Average Order Value-- the average value of orders that include at least one product selected from a recommendations panel. This is calculated using the recommender-engaged revenue divided by the number of orders with at least one product that was selected from a recommendation panel. There's also a range of data that you can analyze regarding search results. A marketing funnel depicts the user journey through the various stages of purchase. A user will start with searching for a product, then study the details of the product, express a desire to purchase the product, and, finally, purchase the product after making a payment. The following data points are included to highlight this customer journey. Searches-- the total number of searches performed site-wide. Click-through rate-- the number of clicks from search results divided by the total number of site-wide searches. Add-to-cart rate-- the number add-to-cart events occurring from search results divided by the total number of searches. Conversion rate-- the number of purchase events occurring from search results divided by the total number of searches. You can see configuration-specific metrics which are specific to serving configuration on the Serving Configs page. Please note that configuration-specific metrics are currently available for Recommendations AI only. The following metrics are provided. Click-Through Rate, CTR-- the number of product detail views from a serving configurations recommendation panel divided by the total number of predict queries for this serving configuration. In short, it tells you what percentage predict queries ended up in a user clicking the product details. Conversion Rate, CVR-- the number add-to-cart events from a serving configurations recommendation panel divided by the total number predict queries for this serving configuration. In short, it tells you what percentage predict queries ended up in a user adding the product to a cart. Recommender-engaged-revenue-- the total revenue from the recommendations for this serving configuration. Finally, you'll learn about A/B testing methodology. You can use A/B experiments to understand how Retail API is impacting your business. An A/B experiment consists of a randomized experiment with two groups, an experimental group and a control group. An experimental group receives the predictions or search results from the Retail API. The control group does not receive any predictions or results. At the end of the experiment, you compare the results and judge the effectiveness of the results provided by Retail API. The following steps are required to run A/B experiments for Retail API results. First, you will need a third-party experiment platform to set up the experiments. You can use Google Optimize, Optimizely, or any other third-party tool. The platform will generate a unique ID for the experimental group and a separate unique ID for the control group. When you record user events, you need to provide information about which group each user is in. You need to log events for both groups. To do this, you need to use the Experiment IDs field in the events schema to pass the unique group ID. Analyze the results of A/B experiment and evaluate if the recommendations are effective. The Retail API uses the information generated from A/B experiments. You must design and implement the experiment correctly to get an accurate measure of the impact. So it's important to follow below best practices for A/B testing. Before setting up your A/B experiment, use prediction or Search Preview to ensure that your model is behaving as expected. When you're satisfied with the results, you can use A/B experiments for the detailed comparison. Ensure that the behavior of your site is identical for the experimental group and the control group. Site behavior includes latency, display format, text format, page layout, image quality, and image size. This is extremely important. If the site behavior is different for the two groups, then your results will be skewed and won't be reliable. Ensure that the catalog data is the same for both groups. You should not run an experiment where full catalog data is used for the control group and only a subset of products is used for the experimental group. Add attribution tokens to user events. You have already studied attribution tokens in this module. Accept and display results as they are returned from Retail. You should also display them in the same order as they are returned without any additional filtering or ordering. Filtering or ordering results based on your business rules will add extra parameters and complicate the comparison.

## Operations

This module discusses the various features of Retail API that help you with continuous monitoring and management of the system.


### Video - [Monitoring](https://www.cloudskillsboost.google/course_templates/391/video/526498)

- [YouTube: Monitoring](https://www.youtube.com/watch?v=UTMq-iXBm2g)

SPEAKER: Welcome to module 5 of the course. So far in this course, you have seen how to ingest the necessary input data, how to build models using this data, how to deploy the models on your website, and how to measure and improve the performance of these models. After you've successfully deployed these models on your website, it's important to monitor the system for any errors or warnings. In this module, you'll learn various features of Retail API that help you with continuous monitoring and management of the system. You'll look at four features of Retail API that will help you monitor the system. This module will look at Admin Console and Dashboard first. Dashboard provides a quick summary of all important parameters that you want to monitor. It's the first place to look when you're monitoring operations. Dashboard has various fields. Getting Started-- this provides quick links for importing product data, importing user event data, and creating serving configurations. Credentials-- this includes a list of active API keys with access to that project's Retail API. Catalog-- this includes summary information about the total number of products in your catalogs. It shows total stock and products in stock. Event-- this displays summary information about event data over the past 90 days. Errors-- this shows a summary of Retail API errors for catalog updates, events, and Recommendations AI models. Recommended Alerts-- this is a link to help you create useful alerts. You will learn how to set up alerts later in this module. Models-- this shows status information for the active Recommendations AI models. Analytics-- this is a summary of analytics data from the last 24 hours of event data. And Serving Configs-- this includes quick links for evaluating or deploying active serving configs. You can view the Monitoring and Analytics page next. If you click the View API Metrics button in the top navigation bar, you'll see a graph of API errors over time. These are displayed by method name. It displays visualizations of traffic, errors, and latency by API method. At the bottom of the page, you can view errors related to the product catalog, user events, Recommendations AI predictions, Retail search results, and models. You can click on an individual error to see the logs for that error in Cloud Logging. To get high-quality results, it's important to keep your catalog data up-to-date. Similarly, it's important to keep recording user events successfully. Even if your initial setup is successful, you may start getting errors due to unexpected environmental issues, such as network connectivity failures. This is why it's very important to constantly monitor the various error rates during operations. Cloud Monitoring alerts are very useful when you need to take prompt action-- for example, when there are issues with user event recording, predictions, or search results. The next slide explores how you can set up these Cloud Monitoring alerts. You can set up Cloud Monitoring to alert on a large number of triggers. When you visit Recommended Alerts Policy page, you can see several alerts suggested by Retail API. So you can start by setting up alerts for those error types. These are some important alerts you can set. Alert for user event recording reduction-- if you see a drop in user event recording for a prolonged period of time, there might be issues with your user event recording code. You can specify the time period to wait before raising an alert. You can also select notification channel, like email or mobile number. Alert for prediction errors-- it's rare to get an error after calling predict method of Retail API. If you do start getting multiple errors while using predict method, it means something is wrong and you need to debug it further. You can set a threshold for the error ratio in predictions. If the number of errors returned by the predict method stay above this threshold for more than five minutes, alert is automatically generated. Alert for search errors-- it's rare to get an error after calling search method of Retail API. You can adjust the error threshold to suit your requirements. An alert is triggered when the error ratio stays above the threshold for more than five minutes. You can also create a custom alert by using Cloud Monitoring. Google Cloud Services write audit logs to help you answer the questions of who did what, where, and when within your Google Cloud resources. Audit logs are crucial for operations, monitoring, and troubleshooting. Retail API supports audit logs. And the following types of audit logs are available for Retail. Admin activity audit logs-- admin activity audit logs contain log entries for API calls or other actions that modify the configuration or metadata of resources. Admin activity audit logs are always written. You can't configure, exclude, or disable them. These logs are free. Data access audit logs-- this includes admin read operations that read metadata or configuration information. These logs also include data read and data write operations that read or write user-provided data. These logs are disabled by default and you need to explicitly enable them. These logs are chargeable. There are several ways to view audit logs generated by Retail API. Cloud Console-- in the Cloud Console, you can visit Logging and then Logs Explorer page. In the Query Builder pane, you can select resource type and the type of audit logs to view. gcloud command line-- the gcloud command line tool provides a command line interface to the Cloud Logging API. You can use gcloud logging read parameters command to read project-level, folder-level, and organizational-level audit log entries. APIs and client libraries-- the Cloud Logging API lets you programmatically read and write log entries. You can invoke the API by using a command line interface or a client library written to support a high-level programming language. Exporting logs-- you can export audit logs so that you can keep them for a longer period of time. Typically, you will store them inside Cloud storage, BigQuery, et cetera. This will enable you to use the more powerful search capabilities that these tools provide. Any API call that returns a warning or error is available in Cloud Logging. But there can be cases where the API call was successful, but you still had errors. For example, imagine you're doing a batch import of data from Google Cloud Storage. The output of this process is stored in the error bucket in Google Cloud Storage. Since the API call is successful, you will not see any errors in Cloud Logging. So in this case, it's important to check the Google Cloud Storage error bucket for any issues with data importing.

### Video - [Management](https://www.cloudskillsboost.google/course_templates/391/video/526499)

- [YouTube: Management](https://www.youtube.com/watch?v=zRA3aqFkFik)

SPEAKER: There is some important management tasks that you should perform regularly. Your models are dependent upon your data, which means you need to keep your data up-to-date. Please follow these best practices for updating your data. For product catalog data, you can set up a reoccurring schedule task that updates your product catalog data. You can set this task to occur daily or weekly, depending upon how frequently you expect your catalog data to change. Select a frequency that suits your use case. In addition to these scheduled updates, you should have a flow in place to support incremental updates to product catalog data. For example, changes in price and availability should be updated as close to real time as possible. You can set up a function that is automatically triggered whenever the database gets updated for these important fields. For user events, the data should be sent in real time whenever possible. Don't follow a practice of collecting data from multiple events and then uploading it in a batch. Imagine you have built your model, tested it using Recommendation Preview, and deployed it on your website. The model is providing great recommendations and you are very satisfied with the results. That's great, but the job doesn't end here. After you've deployed your model, you need to continuously manage it. This is an ongoing process and is crucial for the continued success of your model. To manage your models, you need to perform these four activities. However, you can only start a limited number of model operations per minute. Please refer to the documentation to check the exact limit that is applicable. The first activity to consider is model tuning. Tuning is an essential part of model maintenance. Throughout the year, your data will keep changing. And the customer behavior will also differ. So it's important to tune your model periodically and keep it up-to-date. In addition, some internal major model upgrades can be applied only after the model has been tuned. When you create your model, you can set it to tune automatically after every three months. You can also choose to tune it manually. You can change the tuning preference at any time. Tuning process can take two to four days. Please note that the existing model continues to work as usual while you are tuning it in the background. Next, you'll consider model retraining. There is a limit to how many models per project can be active at any time. If your model is active, the model is retrained at least once a week. Maximum is once per day. It's good practice to upload your user event data no more than 24 hours after that event occurs. You can pause your model to stop retraining. You can also restart a paused model at any time. Some common reasons for pausing the model are you have imported bad data, and so you don't want your model to learn from that data, or you have exceeded the limit on maximum number of active models per project at a given time. Another key activity when managing your models is to see all active models. You can review a list of all of your models on the Google Cloud platform under Retail/Models. The page will also show other details, such as model type, training status, and optimization objective. If you want, you can change the settings from that page. Finally, you might need to delete a model. If you don't need the model anymore, you can delete it. But please note that this action is permanent and can't be undone. Additionally, there is no way to take a model back up or export the model. So if you delete the model by mistake, you have to recreate the model. It will take two to three days again. And there will be costs involved.

### Video - [Lab4 Lab Intro](https://www.cloudskillsboost.google/course_templates/391/video/526500)

- [YouTube: Lab4 Lab Intro](https://www.youtube.com/watch?v=qiQKJBdRmGk)

SPEAKER: In this lab, you will practice monitoring and managing recommendations, AI, and retail search.

### Lab - [Product Discovery- Monitoring and Managing Recommendations AI and Retail Search](https://www.cloudskillsboost.google/course_templates/391/labs/526501)

Product Discovery- Monitoring and Managing Recommendations AI and Retail Search

- [ ] [Product Discovery- Monitoring and Managing Recommendations AI and Retail Search](../labs/Product-Discovery--Monitoring-and-Managing-Recommendations-AI-and-Retail-Search.md)

## Conclusion

This module reviews the key concepts that have been discussed in the course. It also presents a step-by-step process for implementing Retail API solution.

### Video - [Course Conclusion](https://www.cloudskillsboost.google/course_templates/391/video/526502)

- [YouTube: Course Conclusion](https://www.youtube.com/watch?v=qS64keMWjsI)

SPEAKER: Welcome to the last module of the Vertex AI Search for Retail course. So far in this course, you have studied various important concepts in the Vertex AI Search for Retail product suite. You will not learn any new concepts in this module. But we will quickly review the concepts you have already learned. The module will tie up various concepts and present a step-by-step process for implementing Vertex AI Search for Retail solution. The first step is to create a Google Cloud project and create authentication credentials, including an API key and an OAuth token. You can either use a user account or create a service account. If you are familiar with Google Cloud, you should know how to complete this step. The second step involves uploading the necessary data for Retail API. You need to import your product catalog data and then start recording user events. There are many ways to import product catalog data into Retail API. If you're using Google Merchant Center, then you can import catalog data directly from it. If you're not using Merchant Center, then you can import product catalog data from BigQuery or JSON files or by using the APIs provided by Retail service. You can use the products.import method for importing large catalogs in a single step, or you can use the products.create method to add product items individually. When you have imported the product catalog, you then need to start capturing user events. User events track user actions such as clicking on a product, adding an item to a shopping cart, or purchasing an item. User events play a crucial role in personalizing the results. It's important to capture user events in real time to accurately reflect the behavior of your users. There are a variety of ways to record user events. You can use JavaScript pixel. If you are using Google Tag Manager, you can configure it to track user events. Alternatively, you can use REST API to send user events from your website back end. You studied these steps in detail in module 2. The third step involves importing historical user events data. When you start recording real-time user events, you will start collecting data to build your model. But your model needs sufficient training data before it can provide quality results. This means you might have to wait for months to collect sufficient data to build your model. Importing historical user events enables you to start model training without having to wait for months. There are several ways to import historical user events data. You can import it from Cloud storage or from BigQuery. If you are using Google Analytics 360, you can import data directly from it. You can also import user events inline by using REST API provided by Retail service. You looked at various ways of importing user event data in module 2. Recall that these ways include importing from Cloud storage, BigQuery, Google Analytics 360, importing user events inline, and importing Google Analytics for BigQuery export. The next step is to create your model, controls, and serving configuration. You can create a recommendations model by selecting the model type, deciding the optimization objective, and enabling the advanced model configuration options. You can create serving controls that enable you to create rules for customizing your search results. A serving configuration is a serving entity that associates settings with a model or a set of controls that are used to generate your recommendation or search results. Module 3 presented details on how to complete step 4. When you're building a Recommendations model, the initial model training and tuning can take two to three days to complete. Very large catalogs or event data can cause models to take a bit more time to train. However, this increase in time is not linear. After model training is complete, you will want to deploy it on your website. But it's always a good idea to test the model thoroughly before going live. You can use the Preview feature of your serving configuration to test the Recommendations model. You can also use the Preview feature to test how the search results are served. When you're satisfied with the recommendations and search results, your model is ready for deployment. The next step is to set up an A/B experiment. This is an optional step. But it's very useful if you want to compare the performance of your website when using a Retail API to a baseline version that doesn't use Retail API. You covered these concepts in module 4 of the course. After you have deployed the models on your website, it's important to measure and improve the performance of these models. Retail API provides various reports and metrics to help with this task. Finally, it's important to continuously monitor the system to ensure that there are no errors or warnings. Retail API provides various ways to help you with continuous monitoring and management of the system. Module 5 of the course described how to monitor and manage the performance of the product discovery solution. If you want to quickly try out Retail API and see how the whole flow works, you can refer to the Creating Personalized Movie Recommendations tutorial on our official online documentation. The tutorial uses the MovieLens data set to demonstrate how to upload your product catalog and user events into the Retail API and train a personalized product recommendation model. The MovieLens data set contains a catalog of movies, products, and user movie ratings, user events. This means the input data is readily available in this data set. And so it enables you to quickly try out the various steps. Hopefully, you found this training useful. Please take the survey to provide feedback.

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

---
id: 35
name: 'Networking in Google Cloud: Fundamentals'
datePublished: 2025-01-10
topics:
- Cloud Networking
- VPC Networking
- Networking
type: Course
url: https://www.cloudskillsboost.google/course_templates/35
---

# [Networking in Google Cloud: Fundamentals](https://www.cloudskillsboost.google/course_templates/35)

**Description:**

Networking in Google cloud is a 6 part course series. Welcome to the first course of our six part course series, Networking in Google Cloud: Fundamentals.

This course provides a comprehensive overview of core networking concepts, including networking fundamentals, virtual private clouds (VPCs), and the sharing of VPC networks. Additionally, the course covers network logging and monitoring techniques. 

**Objectives:**

- Explain the concept of multiple network interfaces (NICs) and why they’re useful in a VPC network.
- Connect two or more VPC networks.
- Differentiate between Standard and Premium Network Service Tiers.
- Use Network Intelligence Center, Cloud Logging, and Cloud Monitoring to troubleshoot network problems.

## Welcome to Networking in Google Cloud

Welcome to the Networking in Google Cloud: Fundamantals course.

### Video - [Networking in Google Cloud Introduction](https://www.cloudskillsboost.google/course_templates/35/video/520448)

- [YouTube: Networking in Google Cloud Introduction](https://www.youtube.com/watch?v=hLWsXC17A94)

Google Cloud makes it easy to manage, scale, and secure your networks. In the networking and Google Cloud course series, learn how to implement load balancing and content delivery, and optimize your network for performance and costs. Hi, I'm Barry, a certified trainer at Google, and today I'm here to teach you about the wide variety of networking options and design patterns on Google Cloud. In this series of courses, you'll explore and deploy Google Cloud networking technologies, including VPC networks, subnets, and Firewalls. You'll learn about load balancing, cloud DNS, cloud CDN, and cloud NAT. This series of courses is designed for network engineers and administrators who are either using or planning to use Google Cloud and any other individuals who are interested in software-defined networking solutions in the cloud. Before enrolling in this series, it's recommended that you complete Google Cloud fundamentals core infrastructure, and the networking fundamentals in Google Cloud quests. This series also requires you to have prior understanding of the seven layer OSI model, IPv4 addressing, and prior experience managing IPv4 routes. Through a series of courses featuring videos, quizzes, and hands-on labs, you'll gain the knowledge you need to configure, maintain, and troubleshoot network components. You'll configure Google VPC network, subnets, and routers, control administrative access to VPC objects and network access to endpoints in VPCs. In addition, you'll learn to interconnect networks among Google Cloud projects, interconnect networks among Google Cloud VPC networks, and on-premises or other cloud networks. Configure traffic management among load balancer backend services, use cloud CDN to reduce latency and save money, optimize network spend using network tiers. Configure private connection options to provide access to external resources and services from internal networks. Design networks to meet common customer requirements, and configure monitoring and logging to troubleshoot network problems. Ready? Let's get started.

## VPC Networking Fundamentals

This module reviews some basic VPC networking concepts - and also covers multiple network interfaces and Network Service Tiers.

### Video - [VPC networks](https://www.cloudskillsboost.google/course_templates/35/video/520449)

- [YouTube: VPC networks](https://www.youtube.com/watch?v=ABJDJJb49ec)

A virtual Private Cloud VPC network is a virtual version of a physical network that provides connectivity for your Compute Engine virtual machine VM instances, including Google Kubernetes Engine GKE clusters, App Engine Flexible environment instances, and other Google Cloud products built on Compute Engine VMs. Offers built-in internal pass-through network load balancers and proxy systems for internal application load balancers. A VPC network connects to on-premises networks by using Cloud VPN tunnels and Cloud interconnect attachments. It distributes traffic from Google Cloud external load balancers to back ends. By default, every network has routes that let instances in a network send traffic directly to each other, even across subnets. In addition, every network has a default route that directs packets to destinations that are outside the network. Although these routes cover most of your normal routing needs, you can also create special routes that override these routes. Just creating a route does not ensure that your packets will be received by the specified next hop. Firewall rules must also allow the packet. The default network has preconfigured firewall rules that allow all instances in the network to talk with each other. Manually created networks do not have such rules, so you must create them. Projects can contain multiple VPC networks. Unless you create an organizational policy that prohibits it, new projects start with a default network, and auto mode VPC network that has one subnetwork, subnet in each region. An auto-mode VPC network can be useful when you start learning about Google Cloud. However, it's a best practice to create a custom mode network and include subnetworks only in desired regions.

### Video - [Multiple network interfaces](https://www.cloudskillsboost.google/course_templates/35/video/520450)

- [YouTube: Multiple network interfaces](https://www.youtube.com/watch?v=ZaQDJqVFx1Q)

In conventional networking, devices can use multiple network interfaces to communicate with multiple networks. Next, let's discuss using multiple network interfaces in a Google Cloud VPC network. Sasha is a network engineer at Symbol Corporation. Symbol is rolling out a new web-based customer portal. This portal will give access to sensitive account data and the capability to initiate transactions. The environment also has a management network that connects to the on-premises environment using a VPN. For compliance and security purposes, Sasha is looking to filter control plane traffic from data plane traffic. She is thinking of using a security virtual appliance to route traffic between VPC networks to an on-premises environment and to the Internet. This means she needs a mechanism to interconnect multiple networks to a single virtual appliance. Let's look into how we can solve this use case. VPC networks are isolated private networking domains by default. As we mentioned earlier, VM instances within a VPC network can communicate among themselves by using internal IP addresses as long as firewall rules allow it. However, no internal IP address communication is allowed between networks unless you set up mechanisms such as VPC peering or VPN. Every VM instance within a VPC network starts with a built-in default network interface. When you add more interfaces, you must choose a VPC network and a subnet within it for each new interface. Importantly, each additional interface has to connect to a different VPC network than the others. This multi-interface setup lets you establish configurations where a single instance directly connects to multiple VPC networks. Use multiple network interfaces when you need a single instance to act as a network appliance for tasks like load balancing, intrusion detection, prevention, IDS, IPS, and web application firewalls, WAF. In the diagram, VM1 communicates with VM2 through an internal IP address. VM1 communicates with VM3 through an external IP address. VM appliance communicates with VM1 and VM3 through NIC. Multiple network interfaces let you create configurations in which an instance connects directly to several VPC networks. Each of the interfaces must have an internal IP address and each interface can also have an external IP address. For example, in this diagram, you have two VM instances. Each instance has network interfaces to a subnet within VPC1, VPC2, VPC3, and VPC4. For some situations, you might require multiple interfaces. For example, to configure an instance as a network appliance for load balancing. Multiple network interfaces are also useful when applications running in an instance require traffic separation such as separation of data plane traffic from management plane traffic. Also, you cannot add or remove NIC to an instance once the instance is created so make sure to add the required NIC when you create the instance. Going back to the use case, the simplest way Sasha can connect multiple networks to a VM appliance is by using multiple network interfaces. This diagram shows multiple VPC networks connecting through a virtual appliance using multiple network interfaces. Each interface connects to one of the VPC networks. The diagram also shows Internet and on-premises connections over separate network interfaces including an Internet connection through an untrusted interface. By configuring multiple interfaces, you can apply separate firewall rules and access controls to each interface separately and enforce security functions in communications from the public to a private domain. When creating VM instances with multiple network interfaces, note these caveats. You can only configure a network interface when you create an instance. Each network interface configured in a single instance must be attached to a different VPC network. Each interface must belong to a subnet whose IP range does not overlap with the subnets of any other interfaces. The additional VPC networks that the multiple interfaces will attach to must exist before you create the instance. You cannot delete a network interface without deleting the instance. When an internal DNS, domain name system, query is made with the instance host name, it resolves to the primary interface nic0 of the instance. If the nic0 interface of the instance belongs to a different VPC network than the instance that issues the internal DNS query, the query will fail. You will explore this in the upcoming lab. The maximum number of network interfaces per instance is eight, but this depends on the instances machine type as shown in this table. Instances with less than are equal to two VCPU can have up to two virtual NICs. Examples include the f1-micro, g1-small, n1- standard-1, and any other custom VMs with one or two VCPUs. Instances with more than two VCPU can have one NIC per VCPU with a maximum of eight virtual NICs.

### Video - [Lab Intro: Working with Multiple VPC Networks](https://www.cloudskillsboost.google/course_templates/35/video/520451)

- [YouTube: Lab Intro: Working with Multiple VPC Networks](https://www.youtube.com/watch?v=G3pMFUE3rM4)

In this lab, you create several VPC networks and VM instances and test connectivity across networks. The lab tasks are to: create custom mode VPC networks with firewall rules, create VM instances by using Compute Engine, explore the connectivity for VM instances across VPC networks, create a VM instance with multiple network interfaces.

### Lab - [Working with multiple VPC networks](https://www.cloudskillsboost.google/course_templates/35/labs/520452)

In this lab, you create several VPC networks and VM instances and test connectivity across networks.

- [ ] [Working with multiple VPC networks](../labs/Working-with-multiple-VPC-networks.md)

### Video - [Network Service Tiers](https://www.cloudskillsboost.google/course_templates/35/video/520453)

- [YouTube: Network Service Tiers](https://www.youtube.com/watch?v=mOHkslBjGMg)

Next, let's talk about how network service tiers help boost your network performance. To illustrate this, consider the following scenario. Sarah, a network engineer at Symbol Corporation, is facing a challenge. Their video streaming platform is experiencing high latency and inconsistent performance, especially during peak hours. The current network infrastructure struggles to keep up with the growing number of global users. The user request traverses the Internet. Finally, the request arrives at the load balancer in Google Cloud. Google Cloud cannot control the user experience on the Internet, so the provider has no way to deliver low latency and great user experience. What can Sarah do to reduce latency and optimize performance? Network service tiers enable Sarah to optimize your Cloud network for performance by choosing premium tier or for cost with the new standard tier. What is the difference between these two tiers? The premium tier delivers traffic on Google's global network, providing high performance routing. If Sarah uses Google Cloud today, Sarah already uses the powerful premium tier. The standard tier alternatively offers an attractively priced network with a performance comparable to that of other major public Clouds. There are other differences between the two tiers. The SLA is 99.99% for premium and 99.9% for standard tier. Premium tier also supports regional and global external IPv4 addresses and standard tier supports regional external IPv4 addresses. Premium also allows for Google Cloud networking features and the standard tier provides a wide variety of foundational feature sets such as Cloud NAT, external application load balancer, and external pass through network load balancer. Why would Sarah choose the standard tier? Well, it all comes back to optimizing the Cloud network for performance by choosing premium tier or for cost with the standard tier. In other words, network service tiers allows Sarah to design the Cloud network her way. Let's explore each feature in network service tiers to better understand network performance and cost differences. Refer to the documentation for a detailed list. Premium tier delivers traffic on Google's premium backbone, while standard tier uses regular ISP networks. As you can see on this map, this network consists of an extensive global private fiber network with over 100 points of presence across the globe. Let's explore each network service tier to better understand network performance and cost differences. This information is subject to change. For more accurate and current details, please visit the link. See www.gcpn.com for information on latency displayed by region. In premium tier, inbound traffic from the end user to the video streaming application in Google Cloud enters Google's private high performance network at the pop closest to your end user, and Google Cloud delivers this traffic to your application over this network. Similarly, Google Cloud delivers outbound traffic from the application to end users on Google's network and exits at the pop closest to them, wherever the end users are across the globe. This means that most of this traffic will reach its destination with a single hop to the end users ISP, so it enjoys minimum congestion and maximum performance. Sarah could also use standard tier. Standard tier provides network quality that is comparable to other public Cloud providers, but lower than premium tier. Also, regional network services such as regional load balancing have one VIP per region. Standard tier is priced lower than premium because your traffic between Google Cloud and your end user is delivered over ISP networks instead of Google's Network. Now that you understand the differences in performance, let's get into cost. Premium tier pricing is based on both source and destination of traffic. This is because the cost of network traffic varies depending on the distance your traffic travels over Google's network. In contrast, standard tier traffic is source-based because it does not travel much over Google's network. This map illustrates that network service tiers categorizes all countries and continents into the listed geolocations. Depending on the origin and destination of traffic, costs will vary. We have gone over both the performance and cost differences between network service tiers. The decision tree will help Sarah decide on the tier that best meets the organization needs. For your specific workload or resource, what holds higher priority? Exceptional performance or cost optimization? The premium tier is the clear choice for performance. If cost is the main consideration, remember that the standard tier has other restrictions in addition to network performance. If you want to deploy your back ends, have users in multiple regions, but don't want to use the public Internet instead of Google's network for intercontinental and cross-regional traffic, you want to choose the premium tier. Also, if you want global load balancing or Cloud CDN, you need to use the premium tier. The standard tier is a great choice if you don't need any of those services and are okay using the public Internet instead of Google's network.

### Video - [Debrief](https://www.cloudskillsboost.google/course_templates/35/video/520454)

- [YouTube: Debrief](https://www.youtube.com/watch?v=ltMJBacJAwY)

If you're still not sure where to start and how, you can always lean on Gemini, an AI-powered collaborator in Google Cloud for some help. Wondering how? Ensure that Gemini is set up for your Google Cloud user account and project, and then you are all set to simply chat with Gemini to get help. Using the Gemini pin, you enter prompts, which are questions or statements that describe the help you want, and Gemini returns responses. In the Google Cloud console toolbar, click chat_spark, open Gemini, and type, 'how can I use gcloud to create my first VPC network in Google Cloud?' This response will cover instructions to create a simple VPC and a subnet. You can adjust to ask advanced steps by refining the prompt. For example try, 'how can I adjust the gcloud command provided to create a subnet to ensure the subnet is dual stack?' In this module, you learned about some fundamental Google Cloud VPC networking concepts. We began with an overview of Google Cloud VPC networks. Then we discussed using multiple network interfaces on compute engine VMs, as well as some important caveats. After that, we discussed network service tiers options, and a use case. We concluded the module with a lab exercise and a brief quiz to test your knowledge of what you've learned. Thank you.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/35/quizzes/520455)

#### Quiz 1.

> [!important]
> **You are designing a virtual machine in the cloud to act as a network gateway between an external public network and a private internal network. To ensure strong security and traffic separation, what technology can you implement?**
>
> - [ ] Cloud VPN
> - [ ] Multiple Network Interface Cards (NICs)
> - [ ] Premium Tier IPs
> - [ ] VLAN tagging within a single NIC

#### Quiz 2.

> [!important]
> **You want to lower cloud networking cost and have no problem leveraging the public internet for cross-region traffic. Which network service tier is best for you?**
>
> - [ ] Premium tier
> - [ ] Pro version
> - [ ] Prime tier
> - [ ] Standard tier

#### Quiz 3.

> [!important]
> **You want to improve network performance. You are not comfortable using the public internet to route traffic. Which service tier is the best fit?**
>
> - [ ] Prime tier
> - [ ] Standard tier
> - [ ] Pro version
> - [ ] Premium tier

## Sharing VPC Networks

This module covers two configurations for sharing VPC networks across Google Cloud projects: Shared VPC and VPC Network Peering. You will learn the benefits of each type of configuration and how to choose between them.

### Video - [VPC Network Peering](https://www.cloudskillsboost.google/course_templates/35/video/520456)

- [YouTube: VPC Network Peering](https://www.youtube.com/watch?v=BaNTe-C0fBc)

Welcome to the Sharing VPC Networks module of the Networking in Google Cloud course. This covers more details on sharing a VPC network. You will learn how to connect isolated Virtual Private Clouds (VPCs) using VPC Network Peering, enable centralized network management with Shared VPC, and migrate virtual machines (VMs) between networks. Through hands-on labs and practical examples, you'll gain a understanding of these essential networking concepts, ensuring optimal performance, security, and resource utilization. Let us start with a usecase. Lucian, a network engineer at Cymbal Corporation, faces a new challenge: seamlessly connecting and establishing a direct connection between their two organizations by consumer and producer. Public internet peering introduces unacceptable latency and security risks, while dedicated VPNs are proving cost-prohibitive. Lucian needs a solution that's private, secure, and scales with their evolving needs. Lucian opts to use VPC Network Peering. VPC Network Peering allows private connectivity across two VPC networks. Even if both VPC networks belong to the same project or the same organization, you can still peer them. Remember that each VPC network will have firewall rules that define what traffic is allowed or denied between the peered networks. For example, in this diagram, two organizations represent a consumer and a producer, respectively. Each organization has its own organization node, VPC network, VM instances, Network Admin, and Instance Admin. To successfully establish VPC Network Peering, two peering relationships must be created. The producer network administrator must peer the producer network with the consumer network. The consumer network administrator must peer the consumer network with the producer network. When both peering connections are created, the VPC Network Peering session becomes active and routes are exchanged. The peering relationships let the VM instance use their internal IP addresses to communicate privately. VPC Network Peering is a decentralized or distributed approach to multi-project networking. Each VPC network may remain in the control of separate administrator groups and maintains its own global firewall and routing tables. Historically, such projects would consider external IP addresses or VPNs to facilitate private communication between VPC networks. However, VPC Network Peering does not incur the network latency, security, and cost drawbacks that are present when you use external IP addresses or VPNs. Let’s talk about a few points to remember when using VPC Network Peering. First of all, VPC Network Peering works with Compute Engine, Google Kubernetes Engine, and App Engine flexible environments. You need to have the network administrator role to perform peering. Peered VPC networks remain administratively separate. In other words, routes, firewalls, VPNs, and other traffic management tools are administered and applied separately in each of the VPC networks. These tools are not managed centrally for all network peers. Each side of a VPC Network Peering association is set up independently. Peering will be active only when the configuration from both sides matches. This arrangement allows either side to delete the peering association at any time. A subnet CIDR prefix in one peered VPC network cannot overlap with a subnet CIDR prefix in another peered network. For example, two auto mode VPC networks that only have the default subnets cannot peer. Google Cloud returns an error if any of the following operations result in an overlap. Only directly peered networks can communicate, which means that transitive peering is not supported. Let me explain this with an example. Suppose VPC network CymbalBank1 is peered with CymbalBank2 and CymbalBank3. In that scenario, CymbalBank2 and CymbalBank3 are not directly connected. VPC network CymbalBank2 cannot communicate with VPC network CymbalBank3 over a peered connection. If CymbalBank1 offered SaaS services to CymbalBank2 and CymbalBank3, this situation could be critical. Next, let's explore the steps involved in initiating a VPC peering connection. Before you begin, you must have the name of the VPC network to which you will peer with. If that VPC network is located in another project, you must also have the project ID and network name. A peering configuration establishes the intent to connect to another VPC network. The VPC networks are not connected until each one has a peering configuration for the other. After the other network has a corresponding configuration to peer with your network, the peering state changes to active in both networks. At that point, the VPC networks are connected through VPC Network Peering. After peering is established, the two networks automatically exchange subnet routes. The peering state remains inactive. An inactive peering state indicates that there is not yet a full VPC Network Peering connection. Suppose you want to peer the two VPC networks shown on the slide. Let’s begin with the Cymbal-Rahway VPC network. You must know the name of the other VPC network, which is Cymbal-Kampala. Because Cymbal-Kampala is not in the same project as Cymbal-Rahway, you must also have the project ID. Cymbal-Kampala is in the Cymbal-bank2 project, whose project ID is cymbal-10101. Custom routes help achieve a desired granularity that cannot be achieved with a default route. Sharing custom routes and dynamic routes with peered VPC networks let networks learn routes directly from their peered networks. For example, if a custom route in a peered network is updated, your VPC network automatically learns and uses the updated custom route. You are not required to configure any additional settings in your VPC network. When you create or modify a peering configuration, you can choose to import routes, export routes, or both. The peer network administrator must similarly configure their peering configuration before routes are exchanged. This process ensures that both network administrators explicitly agree to exchange custom routes before they are exchanged. Let’s consider a sample scenario. Consider you are connecting your on-premises environment through a VPN tunnel or a Cloud Interconnect connection. Cloud Interconnect establishes direct, private connections between your on-premises network and your Google Cloud Virtual Private Cloud (VPC) network. VPN on the other hand provides a secure remote access that establishes an encrypted connection over the public internet. When using either of these connections, you can share dynamic routes. Sharing these routes enables peered networks to reach your on-premises network, as shown in the graphic. For dynamic routes, you must add Cloud Router custom route advertisements in your VPC network. These advertisements announce peered network subnets to your on-premises network. Local routes are always preferred over dynamic routes that are learned by using VPC Network Peering.

### Video - [Shared VPC](https://www.cloudskillsboost.google/course_templates/35/video/520457)

- [YouTube: Shared VPC](https://www.youtube.com/watch?v=iWMkVR3dtOs)

In this module, we are going to cover two configurations for sharing VPC networks across Google Cloud Projects. First, we will go over shared VPC, which allows you to share a network across several projects in your Google Cloud organization. Then we will go over VPC Network Peering, which allows you to configure private communication across projects in the same or different organizations. Let's start by talking about shared VPC. Kim is a network administrator at Symbol Corporation. Symbol has four networks that belong to the Web application servers project, namely the recommendation, personalization, analytics, and web. The recommendation service, the personalization service, and the analytics service are each hosted on a different VPC. In this model, Kim is facing challenges such as time consuming management of network, difficulty scaling, and limitation communicating between networks. In addition to this, it is a constant turn to set up access policy, new projects, billing, etc. Kim would like to centrally manage the VPC networks while still segregating workloads that use these networks. What should Kim do? Kim can benefit by implementing shared VPC among these networks. When you use shared VPC, you designate a project as a host project and attach one or more other service projects to it. In this case, the web application servers project is the host project, and the three other projects are the service projects. The overall VPC network is called the Shared VPC network. Shared VPC makes use of Cloud IAM roles for delegated administration. Let me walk through how to provision shared VPC by focusing on the required administrative roles. The first required role is the organization administrator. The organization resource represents an organization, for example, a company, and is the root node in the Google Cloud Resource hierarchy. The Google Workplace or Cloud Identity Super administrators are the first users who can access the organization, and they assign the organization Admin role to users. The organization Admins role in provisioning shared VPC is to nominate shared VPC admins by granting them appropriate project creation and deletion roles, and the compute.xpnAdmin role for the organization. Note that shared VPC is also referred to as XPN in the API and command line interface. Next, the shared VPC administrator performs various tasks necessary to set up shared VPC, such as enabling shared VPC on the host project, attaching service projects to the host project, and delegating access to some or all of the subnets in shared VPC networks to service project Admins by granting the compute.networkUser role. Typically, a shared VPC administrator is also the project owner for a given host project. In addition to being a network user, service project administrators also maintain ownership and control over resources defined in their service projects. The service project administrators must at least have the compute.instanceAdmin role to the corresponding service project. However, typically, the service project administrators are project owners of their service projects. This allows them to create and manage resources in the shared VPC. These resources could be VM instances, instance templates and groups, static internal IP addresses, and load balancers. Let's come back to our original example that had one host project and three service projects. In this diagram, the Shared VPC administrator, which was nominated by an organization administrator, configured the web application project to be a host project with subnet-level permissions. Doing so allowed the shared VPC administrator to selectively share subnets from the VPC network. Next, the shared VPC administrator attached the three service projects to the host project and gave each project owner the network user role for the corresponding subnets. Each project owner then created VM instances from their service projects in the shared subnets. By the way, billing for those VM instances is attributed to the project where the resources are created, which are the service projects. Shared VPC administrators have full control over the resources in the host project, including administration of the shared VPC network. They can optionally delegate the network administrator and security administrator roles for the host project. Overall, shared VPC is a centralized approach to multi-project networking because security and network policy occurs in a single designated VPC network.

### Video - [Demo: Shared VPC](https://www.cloudskillsboost.google/course_templates/35/video/520458)

- [YouTube: Demo: Shared VPC](https://www.youtube.com/watch?v=dxQcSS5LEpw)

Next, let's watch a demo that describes how to set up SharedVPC. We'll see what must be done to configure the host project and service projects. At the organization level, my login Stephanie. Wong currently has org admin and SharedVPC admin privileges. I can also assign the SharedVPC admin role to somebody else in my org. Switching over to my host project, I created a custom VPC called vpc1 and two subnets development and production. I also created two fireball rules, one to allow SSH to all instances in the network and one to allow ICMP traffic between instances in these subnets. In the SharedVPC page, first enable host project to be the host project by clicking set up SharedVPC. I'm going to select sharing individual subnets. This option allows you to share specific subnets in the host project VPC with your service project. Then select the vpc1 dev and prod subnets. Let's attach two service projects, development and production. Make sure the compute engine API has been enabled in each service project before attaching them. Here, you can edit the default permissions given to this service project. Then click save. We can now see host project is the SharedVPC host with two subnets and it has two attached service projects. This is also where you can add additional host project users and admins. Now I'm going to log into my development project owner account, John, who only has permission to that project. Switching to the development project, create a new VM. And add a development tag. Then select network shared with me from the host project so that you can select the dev subnet. Once it's done creating, copy the internal IP of the instance since you'll need it just in a second. Next, I'll switch to Mary's account, who is the owner of the production project. Create a new VM in the production subnet and add a production tag. Making sure to change the zone to the one in the production subnet region, select the prod subnet. When both VMs are done creating, you can see I can SSH into the prod instance and ping the dev instance's internal IP address since I've created the right firewall rules in the host project SharedVPC.

### Video - [Shared VPC versus VPC Network Peering](https://www.cloudskillsboost.google/course_templates/35/video/520459)

- [YouTube: Shared VPC versus VPC Network Peering](https://www.youtube.com/watch?v=R-7_jF-DJ5o)

Let's compare both of these configurations to help you decide which one is appropriate for a given situation. If you want to configure private communication between VPC networks in different organizations, you must use VPC network peering shared VPC only works within the same organization. If you want to configure private communication between VPC networks in the same project, you must use VPC network peering. The VPC networks can be in the same project, but it's not required. Shared VPC only works across projects. In our opinion, the biggest difference between the two configurations is the network administration models. Shared VPC is a centralized approach to multi project networking because security and network policy occurs in a single designated VPC network. In contrast, VPC network peering is a decentralized approach. Each VPC network is controlled by administrator groups in that VPC networks organization. Each VPC network can maintain its own global firewall and routing tables. For more information about the limits of VM instances per VPC network, see per network on the quotas and limits page of the Google Cloud documentation. Now that we've compared both of these configurations to share VPC networks across Google cloud projects, lets look at one last use case. In Google Cloud you can peer with a shared VPC network. Here you can see an example of a shared VPC network called network SVPC. Network SVPC is in host project P One. Service projects P3 and P4 can attach VM instances to network SVPC, which enables private communication between VMs 1, 2, and 4. If we establish a peering session between Network A and network SVPC, all VM instances will have private internal IP connectivity. Each VPC network has firewall rules that define which traffic is allowed or denied between the networks. You can also set up VPC network peering between two shared VPC networks.

### Video - [Let's ask Gemini](https://www.cloudskillsboost.google/course_templates/35/video/520460)

- [YouTube: Let's ask Gemini](https://www.youtube.com/watch?v=QHDdxDK99nU)

If you're still not sure where to start and how, you can always lean on Gemini, an AI-powered collaborator in Google Cloud, for some help. In the Google Cloud console toolbar, click Chat_Spark. Open Gemini, and type your prompt. In this case, let's ask a peering question. I need VM instances in Network A Org1, to access services from two different external organizations, Org2 and Org3, using internal IP addresses. Is this possible with peering? Gemini will guide you through the process and also provide steps. How cool is that?

### Video - [Lab Intro: Configuring VPC Network Peering](https://www.cloudskillsboost.google/course_templates/35/video/520461)

- [YouTube: Lab Intro: Configuring VPC Network Peering](https://www.youtube.com/watch?v=GJ1JhTPk1lc)

In this lab, you will learn how to perform the following tasks. Explore connectivity between non-peered VPC networks. Configure VPC network peering. Verify private communication between peered VPC networks. Delete VPC network peering. On the screen, you can see a general topology of my network and private net. Once VPC network peering is implemented, VMs in each VPC network will be able to communicate using internal IP addresses.

### Lab - [Configuring VPC Network Peering](https://www.cloudskillsboost.google/course_templates/35/labs/520462)

In this lab, you configure VPC Network Peering between two networks. Then, you verify private communication between two VMs in those networks.

- [ ] [Configuring VPC Network Peering](../labs/Configuring-VPC-Network-Peering.md)

### Video - [Migrating a VM between networks](https://www.cloudskillsboost.google/course_templates/35/video/520463)

- [YouTube: Migrating a VM between networks](https://www.youtube.com/watch?v=jA-XuubXS-E)

Finally, we discuss how to migrate a VM instance from one network to another. When a VM is connected to more than one network using multiple interfaces, the migration process updates one of the interfaces and leaves the rest in place. Luca needs to migrate a VM from one VPC network to another. What can she do? Before she migrates it, it is important that she is aware of the supported migration requirements and limitations, so let's go over them. Before you migrate a VM, you must meet the following requirements. The migration is a cold migration. The VM must be stopped before it can be migrated. The VM must not be in an instance group or network endpoint group NEG. If the VM is in an unmanaged instance group or NEG, you must take it out of the group before migrating it. VMs in managed instance groups cannot be migrated. Instead, you must copy your instance template to the new network and use it to rebuild the managed instance group. A target pool is a group of Google compute engine instances that receive incoming traffic from a load balancer. You can move instances and target pools without removing them first. The target pool expands to cover both networks. The migrations supported from Legacy network to a VPC network in the same project, from one VPC network to another VPC network in the same project. From one subnet of a VPC network to another subnet of the same network, from a service project network to the shared network of a shared VPC host project. In all cases, the VM stays in the region and zone where it was before only the attached network changes. There are limitations to migrating that you should consider. You cannot migrate a VM interface to a legacy network. The MAC address allocated to the network interface will change during the migration. This could have an impact on services tightly coupled with MAC addresses such as third-party license agreements. If you are migrating the VM to a network or subnet with a different IP range, the internal IP address of your instance must change. If you are migrating to a subnet with the same IP range, you can keep the old IP address as long as it is not already in use at the destination by specifying it during the migration. You can keep the VMS existing external IP address in the new location. However, to do this, you must have the compute.subnetworks.use external IP permission on the target network. And the target network cannot have external IP addresses disabled by the constraints/compute.vm externalip access constraint.

### Video - [Debrief](https://www.cloudskillsboost.google/course_templates/35/video/520464)

- [YouTube: Debrief](https://www.youtube.com/watch?v=8KHUXZwugaE)

In this module, we looked at shared VPC and VPC network peering, which are two configurations for sharing VPC networks across Google Cloud projects. You got to explore VPC network peering in a lab, and we compared both configurations and their network administration models to help you decide when to choose which. Google Cloud's flexibility to support multiple approaches to network administration allows organizations like yours to more carefully map resource policies, administrative controls, and related accounting to existing structures. In addition, administrators can carefully control the manner in which environments interact with each other, on premises networks, and the public Internet. Thank you.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/35/quizzes/520465)

#### Quiz 1.

> [!important]
> **Which of the following approaches to multi-project networking uses a centralized network administration model?**
>
> - [ ] Shared VPC
> - [ ] VPC Network Peering
> - [ ] Cloud VPN
> - [ ] Cloud VPN and Shared VPC

#### Quiz 2.

> [!important]
> **Which of the following statements about VPC Network Peering is correct?**
>
> - [ ] Both sides of a peering association are set up in one single step.
> - [ ] Subnet IP ranges can overlap across peered VPC networks.
> - [ ] Peered VPC networks do not remain administratively separate.
> - [ ] Transitive peering is not supported.

#### Quiz 3.

> [!important]
> **How does VPC Peering exchange routing information between two peered VPCs?**
>
> - [ ] It relies on the default route table to forward traffic between the VPCs.
> - [ ] It requires manual configuration of static routes in each VPC's route table.
> - [ ] It uses Border Gateway Protocol (BGP) to dynamically exchange routes.
> - [ ] It automatically discovers and propagates routes through the Google Cloud Router.

## Network Monitoring and Logging

This module covers network monitoring and logging features that can help you troubleshoot your Google Cloud network infrastructure.

### Video - [Module intro](https://www.cloudskillsboost.google/course_templates/35/video/520466)

- [YouTube: Module intro](https://www.youtube.com/watch?v=s-fTcvP-qAk)

Welcome to the Network Monitoring and Logging module of the Networking in Google Cloud Fundamentals course. In this module, we will cover Google Cloud network monitoring and logging features that can help you troubleshoot your Google Cloud networking services. You implement monitoring and logging in two separate lab exercises. At the end of the module, you will test your knowledge by taking a brief quiz.

### Video - [Monitoring](https://www.cloudskillsboost.google/course_templates/35/video/520467)

- [YouTube: Monitoring](https://www.youtube.com/watch?v=KEv9svAc1P0)

Before we dive deep into monitoring, let's take a look at a scenario. Tal is a Cloud network engineer at Cymbal, where networks are incredibly large and complex. There are multiple VPCs and multiple interconnections used and monitored by various teams. Tal faces challenges with maintaining visibility into the network, ensuring optimal network performance, identifying bottlenecks and connectivity issues, analyzing and viewing network insights. With growing complexity, Tal can benefit from a solution to streamline network monitoring and gain actionable insights. Let's explore the comprehensive set of tools that Tal can utilize to monitor the network. To have visibility into the network, Tal can use Google Cloud monitoring to create custom dashboards that contain charts of the metrics that he wants to monitor. For example, Tal can create charts that display instances CPU utilization, the packets or bytes sent and received by those instances, and the packets or bytes dropped by the firewall of those instances. In other words, charts provide visibility into the utilization and network traffic of your VM instances, as shown on this slide. These charts can be customized with filters to remove noise, groups to reduce the number of time series and aggregates to group multiple time series together. For a full list of supported metrics, please refer to the documentation. Now, although charts are extremely useful, they can only provide insight while someone is looking at them, but what if Tal server goes down in the middle of the night or over the weekend? Tal is not always available to look at dashboards and determine whether the servers are available, or of enough capacity or bandwidth. To solve that, Tal can create alerting policies that notify when specific conditions are met. An alerting policy describes the circumstances under which you want to be alerted and how you want to be notified about an incident. The alerting policy can monitor time series data stored by Cloud monitoring, or log stored by Cloud logging. When that data meets the alerting policy condition, Cloud monitoring creates an incident and sends the notifications. Tal can create an alerting policy when the network egress of your VM instance goes above a certain threshold for a specific time frame. When this condition is met, you or someone else can be automatically notified through email, SMS, or other channels in order to troubleshoot this issue. There are also uptime checks that Tal can configure to test the availability of public services from locations around the world, as you can see on this slide. The type of uptime check can be set to HTTP, HTTPS, or TCP. The resource to be checked can be an app engine application, a compute engine instance, a URL of a host, or an AWS instance or load balancer. For each up time check, you can create an alerting policy and view the latency of each global location. Checking up time time helps in monitoring and maintaining service level indicator, service level agreement, and service level objective for availability. Seventy five percent of network outages happen due to misconfiguration. More often than not, these misconfigurations are discovered in production. Not knowing the impact of making a configuration change in firewall rules or routing rules, makes network monitoring reactive rather than proactive, introducing risk and extending mean time to resolution. Network intelligence center enables Tal to prevent networking outages and performance issues before they happen. Centralized monitoring cuts down troubleshooting time and effort, increases network security, and improves the overall user experience. Network intelligent center modules offer network topology, visualization, network connectivity tests, a performance dashboard, and firewall insights. When a virtual machine is unreachable, Tal may need to diagnose the connectivity issue quickly to prevent any issues. For example, there may be an issue between source and destination endpoints in your VPC network. Using the network intelligence center connectivity tests, Tal can self diagnose connectivity issues within Google Cloud or Google Cloud to an external IP address, which could be on premises or on another Cloud, helping to isolate whether the issue is in Google Cloud or not. Tal can create, save, and run tests to help verify the impact of configuration changes and ensure that network intent captured by these tests is not violated proactively preventing network outages. These tests also help assure network security and compliance. Connectivity tests have been used internally by the Google Cloud Support team to resolve customer issues. How can Tal diagnose if the application or the underlying network is the root cause of the issues? Network intelligence centers performance dashboard can show you real-time performance metrics, latency and packet loss between the zones where you have VMs, enabling you to quickly troubleshoot where the packet loss is happening, and indeed, if it's a networking issue at all. Performance dashboard now shows customer project information and also Google Cloud general information. Firewall configuration can be daunting. How can Tal verify that firewall rules are being used in the intended way? Firewall insights enables you to better understand and safely optimize firewall configurations. Firewall insights provides reports that contain information about firewall usage and the impact of various firewall rules on your virtual Private Cloud, VPC network. Make sure to enable firewall rules logging to view the reports. Firewall Insights uses Cloud monitoring metrics and recommender insights. Cloud monitoring collects measurements to help you understand how your applications and system services are performing. A collection of these measurements is generically called a metric. The applications and system services being monitored are called monitored resources. Measurements might include the latency of requests to a service, the amount of disk space available on a machine, the number of tables in your SQL database, the number of wig its sold, and so forth. Recommender is a service that provides recommendations and insights for using resources on Google Cloud. These recommendations and insights are per product or per service, and are generated based on heuristic methods, machine learning, and current resource usage. You can use insights independently from recommendations. Each insight has a specific insight type. Insight types are specific to a single Google Cloud product and resource type. Firewall insights metrics let Tal analyze the way firewall rules are being used. Firewall insights metrics are available through Cloud Monitoring and Google Cloud Console, metrics are derived through firewall rules logging. With firewall insights metrics, you can perform the following tasks. Analyze firewall rule usage, determine if firewall rules are functioning as expected. Track connection behavior. Verify that firewall rules are permitting or blocking the correct traffic over defined time intervals. Diagnose dropped connections. Investigate connections that may be unintentionally blocked by firewall rules. Identify potential threats. Detect anomalies in firewall rule hit counts, which could indicate malicious network activity. Network analyzer automatically monitors your VPC network configurations and detects misconfigurations and suboptimal configurations. It provides insights on network topology, firewall rules, routes, configuration dependencies, and connectivity to services and applications. It identifies network failures, provides root cause information, and suggests possible resolutions. Network analyzer runs continuously and triggers relevant analysis based on near real-time configuration updates in your network. If a network failure is detected, it tries to correlate the failure with recent configuration changes to identify root causes, whenever possible, it provides recommendations to fix the issues. In the example above, an insight of the type error, a GKE node to control plane connectivity is generated. The insight page also describes the following. The root cause. An ingress firewall rule is blocking the connection between the node and the plane. This indicated that the default firewall rules were modified, removed, or shadowed by another firewall rule. A solution. If the root of the problem is a deleted firewall, create a new firewall rule. If it's a shadowed firewall rule that increase the priority, you can use Gemini if you are unsure of where to find a particular performance metric. For example, you can ask Gemini how to find out the average latency between my VMs in US East 4 and US Central 1. Gemini assists you with the dashboard name and its purpose.

### Video - [Lab Intro: Resource Monitoring](https://www.cloudskillsboost.google/course_templates/35/video/520468)

- [YouTube: Lab Intro: Resource Monitoring](https://www.youtube.com/watch?v=FlUAREQ98zw)

In this lab you learn how to: explore Cloud monitoring, add charts to dashboards, create alerts with multiple conditions, create resource groups, create uptime checks.

### Lab - [Resource Monitoring](https://www.cloudskillsboost.google/course_templates/35/labs/520469)

In this lab you learn how to use Cloud Monitoring to gain insight into applications that run on Google Cloud Platform.

- [ ] [Resource Monitoring](../labs/Resource-Monitoring.md)

### Video - [Logging](https://www.cloudskillsboost.google/course_templates/35/video/520470)

- [YouTube: Logging](https://www.youtube.com/watch?v=ZF9W9BXuZsE)

Next, let's talk about logging. Now, you've already been exposed to Cloud logging throughout this course. In this module, we'll focus on VPC flow logs and exporting your logs to BigQuery and Looker Studio so that you can analyze and visualize your logs. VPC flow logs records a sample of network flows sent from and received by VM instances, as you can see in this animation. These logs can be used for network monitoring, forensics, real-time security analysis, and expense optimization. Google Cloud is unique for its near real-time visibility, providing log updates every five seconds. Also, there is no extra delay and no performance penalty in routing the logged IP packets to their destination. DNS provides a look up for sites on the Internet. You can think of it as a phone book. But instead of using the name of an organization to look up its phone number, you use the name of an organization to find an IP address. A DNS service is provided by your ISP, Internet Service Provider. For example, suppose a request comes from a client computer to access symble.com, to direct the client computer to the symble.com site. The Internet service provider needs the IP address of symble.com. The ISP connects to get this information from its DNS service. The DNS service recursive resolver issues a request to look up the IP address of symble.com from one of its name servers. The name server responds with the ISP. You can enable or disable VPC flow logs per VPC subnet. Once enabled for a subnet, VPC flow logs collect data from all VM instances in that subnet. Each log entry contains a record of different fields. For example, this table illustrates the IP connection information that is recorded. This consists of the source IP address and port, the destination IP address and port, and the protocol number. This set is commonly referred to as five Tuple. Other fields include the start and end time of the first and last observed packet, the bytes and packet sent, instance details, VPC details, and geographic details. For more information on all data recorded by VPC flow logs, please refer to the documentation. VPC flow logs capture traffic from both ends of a VM to VM conversation within the same VPC network. To use this feature, ensure both the communicating VMs reside in subnets with VPC flow logs enabled. In this example, VM 10.10.0.2 sends a request with 1224 bytes to VM 10.50.0.2, which is also in a subnet that has logging enabled. In turn, 10.50.0.2 responds to the request with a reply containing 5,342 bytes. Both the request and the reply are recorded from both the requesting and responding VMs. Packet mirroring clones the traffic of specific instances in your virtual private Cloud, VPC network, and forwards it for examination. It also captures all ingress and egress traffic and packet data, such as payloads and headers. The mirroring happens on the virtual machine, VM instances, not on the network. Consequently, packet mirroring consumes additional bandwidth on the hosts. Packet mirroring is useful when you need to monitor and analyze your security status. It exports all traffic, not only the traffic between sampling periods. For example, you can use security software that analyzes mirror traffic to detect all threats or anomalies. Additionally, you can inspect the full traffic flow to detect application performance issues. Cloud NAT logging allows you to log NAT connections and errors. When Cloud NAT logging is enabled, one log entry can be generated for each of the following scenarios; when a network connection using NAT is created, when a packet is dropped because no port was available for NAT. You can choose to log both events or only one. Created logs are sent to Cloud logging. Cloud NAT logging handles TPC and UDP traffic only. Cloud NAT logging only logs dropped packets if they are egress, outbound, TCP and UDP packets. It does not log incoming packets. For example, if an inbound response to an outbound request is dropped for any reason, no error is logged. Although Tale can explore each log entry within Google Cloud logging, we recommend exporting logs to BigQuery. BigQuery runs blazing fast SQL queries on gigabytes to petabytes of data. This allows Tale to analyze network traffic, to better understand traffic growth to forecast capacity, analyze network usage to optimize network traffic expenses, or analyze network forensics to examine incidents. For example, in this screenshot, we queried my logs to identify the top IP addresses that have exchanged traffic with the web server. Depending on where these IP addresses are and who they belong to, we could relocate part of my infrastructure to save on networking costs or deny some of these IP addresses if we don't want them to access my web server. If Tale wants to visualize logs, we recommend connecting big query tables to Looker Studio. Looker Studio transforms raw data into the metrics and dimensions that Tale can use to create easy to understand reports and dashboards.

### Video - [Lab Intro: Analyzing Network Traffic with VPC Flow Logs](https://www.cloudskillsboost.google/course_templates/35/video/520471)

- [YouTube: Lab Intro: Analyzing Network Traffic with VPC Flow Logs](https://www.youtube.com/watch?v=u21wjkvFbBg)

In this lab you learn how to: configure a custom network with VPC flow logs, create an Apache web server, verify that network traffic is logged, export the network traffic to BigQuery, to further analyze the logs, set up VPC flow log aggregation.

### Lab - [Analyzing Network Traffic with VPC Flow Logs](https://www.cloudskillsboost.google/course_templates/35/labs/520472)

In this lab, you configure a network to record traffic to and from an apache web server using VPC Flow Logs. You will then export the logs to BigQuery to analyze them.

- [ ] [Analyzing Network Traffic with VPC Flow Logs](../labs/Analyzing-Network-Traffic-with-VPC-Flow-Logs.md)

### Video - [Debrief](https://www.cloudskillsboost.google/course_templates/35/video/520473)

- [YouTube: Debrief](https://www.youtube.com/watch?v=6H-69VkZ6wA)

In this module, we covered Google Cloud network monitoring and logging features that can help you troubleshoot your Google Cloud networking services. Monitoring is important to Google because it is at the base of site reliability engineering or SRE. SRE is a discipline that incorporates aspects of software engineering and applies that to operations whose goals are to create ultrascalable and highly reliable software systems. This discipline has enabled Google to build, deploy, monitor, and maintain some of the largest software systems in the world. Thank you.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/35/quizzes/520474)

#### Quiz 1.

> [!important]
> **In regards to VPC Flow Logs, which of the following statements is correct?**
>
> - [ ] Logs can be used for network monitoring, forensics, real-time security analysis, and expense optimization.
> - [ ] There is a delay and performance penalty in routing logged IP packets.
> - [ ] Log updates are provided every 5 minutes.
> - [ ] Logs cannot be analyzed in BigQuery or visualized in Looker Studio.

#### Quiz 2.

> [!important]
> **Sort the following steps for provisioning Shared VPC in Google Cloud:**
>
> - [ ] Uptime checks
> - [ ] Ops Agent
> - [ ] Dashboards
> - [ ] Alerting policies

## Course Resources

Student PDF links to all modules

### Document - [Networking in Google Cloud: Fundamentals Course Resources](https://www.cloudskillsboost.google/course_templates/35/documents/520475)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

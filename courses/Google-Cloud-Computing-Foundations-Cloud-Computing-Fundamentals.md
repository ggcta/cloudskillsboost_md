---
id: 153
name: 'Google Cloud Computing Foundations: Cloud Computing Fundamentals'
type: Course
url: https://www.cloudskillsboost.google/course_templates/153
date_published: 2024-12-04
topics:
  - Machine Learning
  - Databases
  - Google Cloud Services
---

# [Google Cloud Computing Foundations: Cloud Computing Fundamentals](https://www.cloudskillsboost.google/course_templates/153)

**Description:**

The Google Cloud Computing Foundations courses are for individuals with little to no background or experience in cloud computing. They provide an overview of concepts central to cloud basics, big data, and machine learning, and where and how Google Cloud fits in.

By the end of the series of courses, learners will be able to articulate these concepts and demonstrate some hands-on skills.

The courses should be completed in the following order:
1. Google Cloud Computing Foundations: Cloud Computing Fundamentals
2. Google Cloud Computing Foundations: Infrastructure in Google Cloud
3. Google Cloud Computing Foundations: Networking and Security in Google Cloud
4. Google Cloud Computing Foundations: Data, ML, and AI in Google Cloud

This first course provides an overview of cloud computing, ways to use Google Cloud, and different compute options.

**Objectives:**

* Discuss what the cloud is and why it’s a technological and business game changer.
* Describe the different ways a user can interact with Google Cloud.
* Discover the different compute options in Google Cloud.

## Course introduction

In this introduction, you'll explore the course goals and preview each section.

### Video - [Course Introduction](https://www.cloudskillsboost.google/course_templates/153/video/515726)

* [YouTube: Course Introduction](https://www.youtube.com/watch?v=_GUSra2blCI)

Welcome to the Google Cloud Computing Foundations course. The goal of this course is to introduce people with little to no background or experience in cloud computing, to the basic concepts of cloud computing, big data and machine learning, and then help them understand where and how Google Cloud fits in. This course consists of ten modules and is followed by an opportunity to earn four different digital Google Cloud skills badges to demonstrate your growing skillset. Each module in this course has a specific learning objective. In the first module, titled “So, what's the cloud anyway?,” you'll identify what the cloud is and the effect it's had on both technology and business. In module two, titled “Start with a solid platform,” you'll learn about different ways to interact with Google Cloud. In module three, titled “Use Google Cloud to Build your Apps,” you'll see how to leverage Google Cloud resources and serverless managed services to build applications. In module four, titled “Where do I store this stuff?,” you'll explore how to implement structured and unstructured storage models. In module five, titled “There's an API for that!,” you'll learn about the different application-managed service options that are available in the cloud. In module six, titled “You can't secure the cloud, right?,” you'll see how security is administered in Google Cloud. In module seven, titled “It helps to network,” you'll explore how secure networks are built on the cloud. In module eight, titled “Keeping an eye on things,” you'll identify tools that support cloud automation and management. In module nine, titled “You have the data, but what are you doing with it?,” you'll discover the managed big data services available in the cloud. Finally in module ten, titled “Let machines do the work,” you'll get an introduction to machine learning. In addition to the lecture content, this course includes 25 hands-on labs and four final challenge labs. This adds up to nearly 24 hours of experiential learning. These publicly available labs are hosted on Google Cloud Skills Boost. Skills Boost provides an online learning environment, along with a set of instructions, so you can walk through a live, real-world and scenario-based use case without needing an account on Google Cloud. In each lab, you have access to the actual environment you want to learn about, not a simulation or demo environment. You can access the lab environments using a standard web browser. As part of your course enrollment, Google has provided you with the credits required to cover the lab costs. Access cloud.google.com/edu to request Skills Boost credits. These can be requested by an instructor and/or by a student and distributed in class. When you're ready to start, click the Start Lab button. The screen will update to display an ‘Open Google Cloud console’ link and temporary sign-in credentials for the lab. Click the ‘Open Google Cloud console’ link. A new browser window will open and sign-in credentials will be requested. You'll use the temporary username and password provided in the Skills Boost window to complete the credentials in the Google Cloud console window. For ease of use, a copy functionality is provided. If you insert the credentials correctly, you'll be prompted to accept the terms of the temporary Google Account. This Google Account is temporary for the duration of the lab, so don't update any recovery details when the option is provided. The Google Cloud console will open. Agree to the Terms of Service and follow the instructions to complete the lab. After you complete a lab, sign out of the Google Cloud console. The Google Cloud console will close and you'll be signed out of the temporary Google Account. Close the tab. Return to the Skills Boost tab and click the End Lab button. When you complete the course and the associated knowledge assessment, you'll have the opportunity to earn four different digital Google Cloud Skill badges to demonstrate your growing skillset. Implement Load Balancing on Compute Engine, Set Up an App Dev Environment on Google Cloud, Build a Secure Google Cloud Network, and Prepare Data for ML APIs on Google Cloud. Each skill badge consists of a set of hands-on labs, and these will be completed during the course. However, these are only stepping stones to prepare you for the final Challenge Lab of each skill badge!

## So, what is the cloud anyway?

Cloud Basics: Discuss what the cloud is and why it's a technology and business game changer

### Video - [Introduction](https://www.cloudskillsboost.google/course_templates/153/video/515727)

* [YouTube: Introduction](https://www.youtube.com/watch?v=VnCwyJvlZgI)

Welcome to Module 1 of the Google Cloud Computing Foundations course, So what's the cloud anyway? After completing this first module, you should be able to identify what the cloud is and the effect it has on both technology and business. This means that you'll: Explore cloud computing. Compare and contrast physical, virtual, and cloud architectures. Differentiate infrastructure as a service (IaaS), platform as a service (PaaS), and software as a service (SaaS). Be introduced to Google Cloud compute, storage, big data, and ML services. And examine the Google network and how it powers cloud computing. The module begins with the definition of cloud computing, followed by a comparison between cloud and traditional architecture. And then you'll examine IaaS, PaaS, and SaaS. And finally, you'll explore the Google Cloud architecture. The module concludes with a short quiz and a recap of the topics covered.

### Video - [Cloud computing](https://www.cloudskillsboost.google/course_templates/153/video/515728)

* [YouTube: Cloud computing](https://www.youtube.com/watch?v=H7BlRA341d4)

Let's get started with cloud computing. The cloud is a hot topic these days, but what exactly is it? The US National Institute of Standards and Technology created the term cloud computing, although there's nothing US-specific about it. Cloud computing is a way of using information technology, or IT, that has these five equally important traits. First, customers get computing resources that are on demand and self-service. Through a web interface, users get the processing power, storage, and network they need with no need for human intervention. Second, customers get access to those resources over the internet, from anywhere they have a connection. Third, the provider of those resources has a large pool of them and allocates them to users out of that pool. That allows the provider to buy in bulk and pass the savings onto the customers. Customers don't have to know or care about the exact physical location of those resources. Fourth, the resources are elastic, which means that they can increase or decrease as needed, so customers can be flexible. If they need more resources, they can get more, and quickly. If they need less, they can scale back. And finally, the customers pay only for what they use or reserve as they go. If they stop using resources, they stop paying. That's it. That's the definition of cloud computing. An infrastructure is the basic underlying framework of facilities and systems. So it might be helpful to think about IT, or information technology, infrastructure in terms of a city's infrastructure. In a city, the infrastructure includes transportation, communications, power, water, fuel and other essential services. Comparing it to IT infrastructure, the people in the city are like ‘users,’ and the cars, bikes, and buildings are like ‘applications.’ Everything that goes into creating and supporting those services is the infrastructure. In this course, you'll explore the IT infrastructure services provided by Google Cloud. You'll become familiar enough with the infrastructure services to know what the services do, and you'll start to understand how to use them.

### Video - [Cloud vs. traditional architecture](https://www.cloudskillsboost.google/course_templates/153/video/515729)

* [YouTube: Cloud vs. traditional architecture](https://www.youtube.com/watch?v=oIhmNJQ52SI)

Now that you have a better understanding of what cloud computing is, and the infrastructure that supports it, let’s transition to cloud architecture. In this section, we’ll explore how the cloud compares to traditional architecture. To understand this, we need to look at some history. The trend toward cloud computing started with a first wave known as colocation. Colocation gave users the financial efficiency of renting physical space, instead of investing in data center real estate. Virtualized data centers of today, which is the second wave, share similarities with the private data centers and colocation facilities of decades past. The components of virtualized data centers match the physical building blocks of hosted computing—servers, CPUs, disks, load balancers, and so on—but now they’re virtual devices. With virtualization, enterprises still maintained the infrastructure; it’s still a user-controlled and user-configured environment. Several years ago, Google realized that its business couldn’t move fast enough within the confines of the virtualization model. So Google switched to a container-based architecture—a fully automated, elastic third-wave cloud that consists of a combination of automated services and scalable data. Services automatically provision and configure the infrastructure used to run applications. Today, Google Cloud makes this third-wave cloud available to Google customers. Google believes that, in the future, every company—regardless of size or industry—will differentiate itself from its competitors through technology. Increasingly, that technology will be in the form of software. Great software is based on high-quality data. This means that every company is, or will eventually become, a data company. The virtual world, which includes Google Cloud’s network, is built on physical infrastructure, and all those racks of humming servers use huge amounts of energy. Together, all existing data centers use roughly 2% of the world’s electricity. So, Google works to make data centers run as efficiently as possible. Just like our customers, Google is trying to do the right things for the planet. We understand that Google Cloud customers have environmental goals of their own, and running their workloads in Google Cloud can be a part of meeting them. Therefore, it’s important to note that Google's data centers were the first to achieve ISO 14001 certification, which is a standard that maps out a framework for improving resource efficiency and reducing waste. This is Google’s data center in Hamina, Finland. The facility is one of the most advanced and efficient data centers in the Google fleet. Its cooling system, which uses sea water from the Bay of Finland, reduces energy use and is the first of its kind anywhere in the world. In our founding decade, Google became the first major company to be carbon neutral. In our second decade, we were the first company to achieve 100% renewable energy. By 2030, we aim to be the first major company to operate carbon free.

### Video - [IaaS, PaaS, and SaaS](https://www.cloudskillsboost.google/course_templates/153/video/515730)

* [YouTube: IaaS, PaaS, and SaaS](https://www.youtube.com/watch?v=xKAK7w7qfBs)

Now let's shift our focus to IaaS, PaaS, and SaaS. The move to virtualized data centers introduced customers to two new types of offerings: infrastructure as a service commonly referred to as IaaS, and platform as a service, or PaaS. IaaS offerings provide raw compute, storage, and network capabilities, organized virtually into resources that are similar to physical data centers. PaaS offerings bind code to libraries that provide access to the infrastructure applications need. This allows more resources to be focused on application logic. In the IaaS model, customers pay for the resources they allocate ahead of time. In the PaaS model, customers pay for the resources they actually use. As cloud computing has evolved, the momentum has shifted toward managed infrastructure and managed services. Leveraging managed resources and services allows companies to concentrate more on their business goals and spend less time and money on creating and maintaining their technical infrastructure. It allows companies to deliver products and services to their customers more quickly and reliably. Serverless is yet another step in the evolution of cloud computing. Serverless computing allows developers to concentrate on their code, rather than on server configuration, by eliminating the need for any infrastructure management. Serverless technologies offered by Google include Cloud Run, which allows customers to deploy their containerized microservices based application in a fully managed environment, and Cloud Run functions, which manages event-driven code as a pay-as-you-go service. You might have also heard about software as a service, or SaaS, and wondered what it is and how it fits into the cloud ecosphere. SaaS applications are not installed on your local computer. They run in the cloud as a service and are consumed directly over the internet by end users. Google's popular applications like Gmail, Docs, and Drive, collectively known as Google Workspace, are all classified as SaaS.

### Video - [Google Cloud architecture](https://www.cloudskillsboost.google/course_templates/153/video/515731)

* [YouTube: Google Cloud architecture](https://www.youtube.com/watch?v=W5_6Gq85aSQ)

Next, let's focus on Google’s specific offerings in the cloud. You can think of the Google Cloud infrastructure in three layers. At the base layer is networking and security, which lays the foundation to support all of Google’s infrastructure and applications. On the next layer sit compute and storage. Google Cloud separates, or decouples, as it’s technically called, compute and storage so they can scale independently based on need. And on the top layer sit the big data and machine learning products, which enable you to perform tasks to ingest, store, process, and deliver business insights, data pipelines, and machine learning models. And thanks to Google Cloud, you can accomplish these tasks without needing to manage and scale the underlying infrastructure. Organizations with growing data needs often require lots of compute power to run big data jobs. And as organizations design for the future, the need for compute power only grows. Google offers a range of computing services, which includes: Compute Engine, Google Kubernetes Engine, App Engine, Cloud Run, and Cloud Run functions. Google Cloud also offers a variety of managed storage options. The list includes: Cloud Storage, Cloud SQL, Spanner, Bigtable, and Firestore. Cloud SQL and Spanner are relational databases, while Bigtable and Firestore are NoSQL databases. And then there’s a robust big data and machine learning product line. This includes: Cloud Storage, Dataproc, Bigtable, BigQuery, Dataflow, Firestore, Pub/Sub, Looker, Spanner, AutoML, and Vertex AI, the unified ML platform. As we previously mentioned, the Google network is part of the foundation that supports all of Google’s infrastructure and applications. Let’s explore how that’s possible. Google’s network is the largest network of its kind, and Google has invested billions of dollars over the years to build it. This network is designed to give customers the highest possible throughput and lowest possible latencies for their applications by leveraging more than 100 content caching nodes worldwide (locations where high demand content is cached for quicker access) to respond to user requests from the location that will provide the quickest response time. Google Cloud’s infrastructure is based in five major geographic locations: North America, South America, Europe, Asia, and Australia. Having multiple service locations is important because choosing where to locate applications affects qualities like availability, durability, and latency, which measures the time a packet of information takes to travel from its source to its destination. Each of these locations is divided into several different regions and zones. Regions represent independent geographic areas, and are composed of zones. For example, London, or europe-west2, is a region that currently contains three different zones. A zone is an area where Google Cloud resources are deployed. For example, let’s say you launch a virtual machine using Compute Engine (more about Compute Engine in a bit) it will run in the zone that you specify to ensure resource redundancy. Zonal resources operate within a single zone, which means that if a zone becomes unavailable, the resources won’t be available either. Google Cloud lets users specify the geographical locations to run services and resources. In many cases, you can even specify the location on a zonal, regional, or multi-regional level. This is useful for bringing applications closer to users around the world, and also for protection in case there are issues with an entire region, say, due to a natural disaster. A few of Google Cloud’s services support placing resources in what we call a multi-region. For example, Spanner multi-region configurations allow you to replicate the database's data not just in multiple zones, but in multiple zones across multiple regions, as defined by the instance configuration. These additional replicas enable you to read data with low latency from multiple locations close to or within the regions in the configuration, like The Netherlands and Belgium. Google Cloud currently supports 121 zones in 40 regions, though this is increasing all the time. The most up to date information can be found at cloud.google.com/about/locations.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/153/quizzes/515732)

### Video - [Summary](https://www.cloudskillsboost.google/course_templates/153/video/515733)

* [YouTube: Summary](https://www.youtube.com/watch?v=6EEgqUcRLOc)

This brings us to the end of the first module of the Google Cloud Computing Foundations course. Let's do a quick summary. You started by exploring cloud computing. Cloud computing is a way of using information technology that has these five equally important traits: on demand self-service, broad network access, resource pooling, rapid elasticity, and measured service. Next, you compared and contrasted physical, virtual, and cloud architectures. You explored how cloud computing is a continuation of a long-term shift in how computing resources are managed, looking back through three different waves - co-location, virtualized data centers, and container-based architecture - and Google's distinct positioning to propel organizations into the next wave of cloud computing. After that, you learned to differentiate between infrastructure as a service, platform as a service, and software as a service. From there, you were introduced to Google Cloud compute, storage, big data, and ML services. And finally,you examined the Google network and how it powers cloud computing.

## Start with a solid platform

User interface: Describe the different ways a user can interact with Google Cloud

### Video - [Introduction](https://www.cloudskillsboost.google/course_templates/153/video/515734)

* [YouTube: Introduction](https://www.youtube.com/watch?v=C1nEbE70y6A)

Welcome to Module 2 of the Google Cloud Computing Foundations course: Start with a solid platform. In this section of the course, we’ll explore different ways that you can interact with Google Cloud. This means that you’ll: Explore the Google Cloud console. Examine how projects are the basis for enabling and using Google Cloud services. Identify how billing works in Google Cloud. Install and configure the Google Cloud SDK. Recognize the different use cases for using Cloud Shell and the Cloud Shell code editor. Explore how APIs work. And manage Google Cloud services from a mobile device. The module agenda follows the objectives. It begins with the Google Cloud console, then continues on to explore projects, Google Cloud billing options, installing and configuring the Google Cloud SDK, Cloud Shell, two hands-on labs, the Google Cloud APIs, and the Cloud Mobile App. The module concludes with a short quiz and a summary of the topics covered. Let’s get started!

### Video - [The Google Cloud console](https://www.cloudskillsboost.google/course_templates/153/video/515735)

* [YouTube: The Google Cloud console](https://www.youtube.com/watch?v=SJfWtjeqPVA)

Let’s begin with the Google Cloud console. There are actually four ways to access and interact with Google Cloud. The list includes the Google Cloud console, the Google Cloud SDK and Cloud Shell, the APIs, and the Cloud Mobile App. We’ll explore all four of these options in this module, but focus on the console to start. The Google Cloud console, which is Google Cloud’s Graphical User Interface (GUI), helps you deploy, scale, and diagnose production issues in a simple web-based interface. With the console, you can easily find your resources, check their health, have full management control over them, and set budgets to control how much you spend on them. The console also provides a search facility to quickly find resources and connect to instances through SSH, which is the Secure Shell Protocol, in the browser. To access the console, navigate to console.cloud.google.com.

### Video - [Understanding projects](https://www.cloudskillsboost.google/course_templates/153/video/515736)

* [YouTube: Understanding projects](https://www.youtube.com/watch?v=VCOEb3e-XUc)

The console is used to access and use resources. Resources are organized in projects. To understand this organization, let’s explore where projects fit in the greater Google Cloud resource hierarchy. This hierarchy is made up of four levels, and starting from the bottom up they are: resources, projects, folders, and an organization node. At the first level are resources. These represent virtual machines, Cloud Storage buckets, tables in BigQuery, or anything else in Google Cloud. Resources are organized into projects, which sit on the second level. Projects can be organized into folders, or even subfolders. These sit at the third level. And then at the top level is an organization node, which encompasses all the projects, folders, and resources in your organization. Let’s spend a little more time on the second level of the resource hierarchy, projects. Projects are the basis for enabling and using Google Cloud services, like managing APIs, enabling billing, adding and removing collaborators, and enabling other Google services. Each project is a separate compartment, and each resource belongs to exactly one project. Projects can have different owners and users, because they’re billed and managed separately. Each Google Cloud project has three identifying attributes: a project ID, a project name, and a project number. * The project ID is a globally unique identifier assigned by Google that cannot be changed–it is immutable–after creation. Project IDs are used in different contexts to inform Google Cloud of the exact project to work with. * The project names, however, are user-created. They don’t have to be unique and they can be changed at any time, so they are not immutable. * Google Cloud also assigns each project a unique project number. It’s helpful to know that these Google-generated numbers exist, but we won’t explore them much in this course. They are mainly used internally, by Google Cloud, to keep track of resources. So, how are you expected to manage projects? Google Cloud has the Resource Manager tool, designed to programmatically help you do just that. It’s an API that can gather a list of all the projects associated with an account, create new projects, update existing projects, and delete projects. It can even recover projects that were previously deleted and can be accessed through the RPC API and the REST API. The third level of the Google Cloud resource hierarchy is folders. You can use folders to group projects under an organization in a hierarchy. For example, your organization might contain multiple departments, each with its own set of Google Cloud resources. Folders let you group these resources on a per-department basis. Folders give teams the ability to delegate administrative rights so that they can work independently. To use folders, you must have an organization node, which is the topmost resource in the Google Cloud hierarchy. Everything else attached to that account goes under this node, which includes projects, folders, and other resources.

### Video - [Google Cloud billing](https://www.cloudskillsboost.google/course_templates/153/video/515737)

* [YouTube: Google Cloud billing](https://www.youtube.com/watch?v=vVM595p24tU)

The next topic is Google Cloud billing. Billing is established at the project level. This means that when you define a Google Cloud project, you link a billing account to it. This billing account is where you will configure all your billing information, including your payment option. A billing account can be linked to zero or more projects, but projects that aren’t linked to a billing account can only use free Google Cloud services. Billing accounts are charged automatically and invoiced every month or at every threshold limit. Billing sub accounts can be used to separate billing by project. Some Google Cloud customers who resell Google Cloud services use sub accounts for each of their own clients. You’re probably thinking, “How can I make sure I don’t accidentally run up a big Google Cloud bill?” We provide a few tools to help. 1. You can define budgets at the billing account level or at the project level. A budget can be a fixed limit, or it can be tied to another metric - for example, a percentage of the previous month’s spend. 2. To be notified when costs approach your budget limit, you can create an alert. For example, with a budget limit of $20,000 and an alert set at 90%, you’ll receive a notification alert when your expenses reach $18,000. Alerts are generally set at 50%, 90% and 100%, but can also be customized. 3. Reports is a visual tool in the Google Cloud console that lets you monitor expenditure based on a project or services. 4. Finally, Google Cloud also implements quotas, which are designed to prevent the over-consumption of resources because of an error or a malicious attack, protecting both account owners and the Google Cloud community as a whole. There are two types of quotas: rate quotas and allocation quotas. Both are applied at the project level. 1. Rate quotas reset after a specific time. For example, by default, the GKE service implements a quota of 1,000 calls to its API from each Google Cloud project every 100 seconds. After that 100 seconds, the limit is reset. 2. Allocation quotas govern the number of resources you can have in your projects. For example, by default, each Google Cloud project has a quota allowing it no more than 5 Virtual Private Cloud networks. Although projects all start with the same quotas, you can change some of them by requesting an increase from Google Cloud Support. If you’re interested in estimating cloud computing costs on Google Cloud, you can try out the Google Cloud Pricing Calculator at cloud.google.com/products/calculator.

### Video - [Install and configure the Google Cloud SDK](https://www.cloudskillsboost.google/course_templates/153/video/515738)

* [YouTube: Install and configure the Google Cloud SDK](https://www.youtube.com/watch?v=v50R1TPUhmI)

Now let’s explore the Cloud Software Development Kit (SDK), which lets users run Google Cloud command-line tools from a local desktop. The Google Cloud SDK is a set of command-line tools that you can use to manage resources and applications hosted on Google Cloud. These include: the gcloud CLI, which provides the main command-line interface for Google Cloud products and services, gcloud storage, which lets you access Cloud Storage from the command line, and bq, a command-line tool for BigQuery. When installed, all of the tools within the Google Cloud SDK are located under the bin directory. To install the Google Cloud SDK to your desktop, go to cloud.google.com/sdk and select the operating system for your desktop; this will download the SDK. Then follow the instructions specific to your operating system. After the installation is complete, you’ll need to configure the Google Cloud SDK for your Google Cloud environment. Run the gcloud init command. You will be prompted for information including your login credentials, default project, and default region and zone.

### Video - [Cloud Shell](https://www.cloudskillsboost.google/course_templates/153/video/515739)

* [YouTube: Cloud Shell](https://www.youtube.com/watch?v=k7LO4_6J198)

The next way to access and interact with Google Cloud is Cloud Shell. Cloud Shell provides command-line access to cloud resources directly from a browser. It’s a Debian-based virtual machine with a persistent 5-GB home directory, which makes it easy to manage Google Cloud projects and resources. With Cloud Shell, the Google Cloud SDK gcloud command and other utilities are always installed, available, up to date, and fully authenticated. To start Cloud Shell, navigate to console.cloud.google.com and click the Activate Cloud Shell icon on the toolbar. This will activate the Cloud Shell terminal, which will open in the lower portion of the window. From the terminal window, you can launch the Cloud Shell code editor, which will open Cloud Shell in a new page. With the Cloud Shell code editor, you can edit files inside your Cloud Shell environment in real time within the web browser. This tool is convenient for working with code-first applications or container-based workloads, because you can easily edit files without needing to download and upload changes. You can also use text editors from the Cloud Shell command prompt.

### Video - [Lab Intro: A Tour of Google Cloud Hands-on Labs](https://www.cloudskillsboost.google/course_templates/153/video/515740)

* [YouTube: Lab Intro: A Tour of Google Cloud Hands-on Labs](https://www.youtube.com/watch?v=kv68VAMoeGc)

It’s time for the first hands-on lab of the course! In the lab titled “A Tour of Google Cloud Hands-on Labs,” you’ll get hands-on practice with the Google Cloud console. During this lab, you’ll: * Get an introduction to the Qwiklabs platform and be able to identify key features of a lab environment. * Access the Google Cloud console with specific credentials.

### Lab - [A Tour of Google Cloud Hands-on Labs](https://www.cloudskillsboost.google/course_templates/153/labs/515741)

In this first hands-on lab you will access the Google Cloud console and use these basic Google Cloud features: Projects, Resources, IAM Users, Roles, Permissions, and APIs.

* [ ] [A Tour of Google Cloud Hands-on Labs](../labs/A-Tour-of-Google-Cloud-Hands-on-Labs.md)

### Video - [Lab Intro: Getting Started with Cloud Shell and gcloud](https://www.cloudskillsboost.google/course_templates/153/video/515742)

* [YouTube: Lab Intro: Getting Started with Cloud Shell and gcloud](https://www.youtube.com/watch?v=2u2bljyngtc)

Now that you’ve had practice accessing the Google Cloud console, you’ll use it to run a series of gcloud commands with Cloud Shell. In the lab titled “Getting Started with Cloud Shell and gcloud,” you’ll learn how to connect to computing resources hosted on Google Cloud via Cloud Shell with the gcloud command-line. During this lab, you’ll: * Get practice using gcloud commands. * Connect to storage services hosted on Google Cloud.

### Lab - [Getting Started with Cloud Shell and gcloud](https://www.cloudskillsboost.google/course_templates/153/labs/515743)

In this hands-on lab you will learn how to connect to computing resources hosted on Google Cloud Platform, and how to use Cloud Shell and Cloud SDK gcloud commands. For a preview, watch the short video <A HREF="https://youtu.be/ZD1zvEyfpLI">Get Started with Cloud Shell, GCP Essentials</A>.

* [ ] [Getting Started with Cloud Shell and gcloud](../labs/Getting-Started-with-Cloud-Shell-and-gcloud.md)

### Video - [Google Cloud APIs](https://www.cloudskillsboost.google/course_templates/153/video/515744)

* [YouTube: Google Cloud APIs](https://www.youtube.com/watch?v=PDduO5i6buU)

The third way to access Google Cloud is through application programming interfaces, or APIs. A software service’s implementation can be complex and changeable. If each software service had to be coded for each implementation, the result would be brittle and error-prone. So instead, application developers structure the software they write in a clean, well-defined interface that abstracts away needless detail, and then they document that interface. That’s an Application Programming Interface. The underlying implementation can change as long as the interface doesn’t, and other pieces of software that use the API don’t have to know or care. The services that make up Google Cloud offer APIs so that code you write can control them. The Google Cloud console includes a tool called the Google APIs Explorer that shows what APIs are available, and in what versions. Suppose you’ve explored an API, and you’re ready to build an application that uses it. Do you have to start coding from scratch? No. Google provides Cloud Client and Google API Client Libraries in many popular languages to take much of the drudgery out of the task of calling Google Cloud from your code. Languages currently represented in these libraries are: Java, Python, PHP, C#, Go, Node.js, Ruby and C++.

### Video - [The Cloud Console Mobile App](https://www.cloudskillsboost.google/course_templates/153/video/515745)

* [YouTube: The Cloud Console Mobile App](https://www.youtube.com/watch?v=6et-tFaz1uE)

The fourth and final way to access Google Cloud is through the Cloud Mobile App. The Cloud Mobile App provides a way for you to manage services running on Google Cloud directly from your mobile device. It’s a convenient resource that comes at no extra cost. The Cloud Mobile App can be used to start, stop, and use ssh to connect to Compute Engine instances and to see logs from each instance. It also lets you stop and start Cloud SQL instances. Additionally, you can administer applications deployed on App Engine by viewing errors, rolling back deployments, and changing traffic splitting. The Cloud Mobile App provides up-to-date billing information for your projects and billing alerts for projects that are going over budget. You can set up customizable graphs showing key metrics such as CPU usage, network usage, requests per second, and server errors. The mobile app also offers alerts and incident management. Download the Cloud Mobile App at cloud.google.com/console-app.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/153/quizzes/515746)

### Video - [Summary](https://www.cloudskillsboost.google/course_templates/153/video/515747)

* [YouTube: Summary](https://www.youtube.com/watch?v=bUx56OTmVyw)

This brings us to the end of the second module of the Google Cloud Computing Foundations course. Let’s do a quick summary. You started by exploring the Google Cloud console. Next, you examined how projects are the basis for enabling and using Google Cloud services. After that, you saw the different billing options available in Google Cloud. From there, you learned how to install and configure the Google Cloud SDK. You explored the different use cases for using Cloud Shell and the Cloud Shell code editor. You learned how APIs work. And finally, you saw how to manage Google Cloud services from a mobile device.

## Use Google Cloud to build your apps

Compute: Discover the compute options in Google Cloud

### Video - [Introduction](https://www.cloudskillsboost.google/course_templates/153/video/515748)

* [YouTube: Introduction](https://www.youtube.com/watch?v=ghtOd-qFxUU)

Welcome to Module 3 of the Google Cloud Computing Foundations course: Use Google Cloud to build your apps. In this module, you’ll be introduced to how to build apps directly in Google Cloud. This means that you’ll: Explore the role of compute options in the cloud. Learn about building and managing virtual machines. Examine building elastic applications using autoscaling. Explore PaaS options by leveraging App Engine. Examine building event-driven services using Cloud Run functions. Identify containerizing and orchestrating applications with Google Kubernetes Engine. And identify developing and deploying scalable containerized applications with Cloud Run. The module agenda follows the objectives and includes five hands-on labs so you can put your learning into practice. The module concludes with a short quiz and a summary of the topics covered.

### Video - [Compute Options in the Cloud](https://www.cloudskillsboost.google/course_templates/153/video/515749)

* [YouTube: Compute Options in the Cloud](https://www.youtube.com/watch?v=LovOAj2Op10)

Let's start with the first topic, compute options in the cloud. Google cloud offers a variety of compute services spanning different usage options. For general workloads that require dedicated resources for your applications, Compute Engine is a good option. And if you're looking for a platform as a service, App Engine is a good option. Cloud Run functions offers a serverless option for triggering code to run based on some kind of event. To run containers on a managed Kubernetes platform, you can leverage Google Kubernetes Engine. And Cloud Run is a fully managed serverless platform that lets you develop and deploy highly scalable, containerized applications. You'll explore each of these compute services during this module.

### Video - [Exploring IaaS with Compute Engine](https://www.cloudskillsboost.google/course_templates/153/video/515750)

* [YouTube: Exploring IaaS with Compute Engine](https://www.youtube.com/watch?v=DnYDUM5DkcI)

Now you’ll explore how to build and deploy applications with Google Cloud’s IaaS solution: Compute Engine. With Compute Engine, users can create and run virtual machines in Google's innovative data centers and on its global fiber network. There are no upfront investments, and thousands of virtual CPUs can run on a system that is designed to be fast and offer consistent performance. Each virtual machine contains the power and functionality of a full-fledged operating system. This means a virtual machine can be configured much like a physical server: by specifying the amount of CPU power and memory needed, the amount and type of storage needed, and the operating system. You can run any computing workload on Compute Engine, such as web-server hosting, application hosting, or application backends. A virtual machine instance can be created by using the Google Cloud console, which is a web-based tool to manage Google Cloud projects and resources, or through the gcloud CLI. The instance can run Linux and Windows Server images provided by Google or any customized versions of these images. You can also build and run images of other operating systems and flexibly reconfigure virtual machines. You might also be curious about Compute Engine’s pricing and billing structure. For the use of virtual machines, Compute Engine bills by the second with a one-minute minimum, and sustained-use discounts start to apply automatically to virtual machines the longer they run. So, for each VM that runs for more than 25% of a month, Compute Engine automatically applies a discount for every additional minute. Compute Engine also offers committed-use discounts. This means that for stable and predictable workloads, a specific amount of vCPUs and memory can be purchased for up to a 57% discount off normal prices in return for committing to a usage term of one year or three years. And then there are Preemptible VMs. Let’s say you have a workload that doesn’t require a human to sit and wait for it to finish–like a batch job analyzing a large dataset, for example. You can save money, in some cases up to 90%, by choosing Preemptible VMs to run the job. A Preemptible VM is different from an ordinary VM in only one respect: Compute Engine has permission to terminate a job if its resources are needed elsewhere. While savings are possible with preemptible VMs, you'll need to ensure that your job can be stopped and restarted. Use Google Cloud’s online pricing calculator (that you learned about in the previous module) to see pricing estimates and discounts based on the different configuration options that are available.

### Video - [Lab Intro: Creating a Virtual Machine](https://www.cloudskillsboost.google/course_templates/153/video/515751)

* [YouTube: Lab Intro: Creating a Virtual Machine](https://www.youtube.com/watch?v=8iTv9_Xo-bg)

Now we’ll create a virtual machine in the lab exercise. In the lab titled “Creating a Virtual Machine,” you’ll create a virtual machine with the Google Cloud console, create a virtual machine using the gcloud command line, and deploy a web server and connect it to a virtual machine.

### Lab - [Create a Virtual Machine](https://www.cloudskillsboost.google/course_templates/153/labs/515752)

This hands-on lab focuses on how to create a Google Compute Engine virtual machine and explores zones, regions, and machine types.

* [ ] [Create a Virtual Machine](../labs/Create-a-Virtual-Machine.md)

### Video - [Configuring Elastic Apps with Autoscaling](https://www.cloudskillsboost.google/course_templates/153/video/515753)

* [YouTube: Configuring Elastic Apps with Autoscaling](https://www.youtube.com/watch?v=EQDFa9Hfwno)

Our next topic looks at building elastic applications with auto scaling. As you've just seen, with Compute Engine you can choose the most appropriate machine properties for your instances, like the number of virtual CPUs and the amount of memory. You can use a set of predefined machine types or create your own custom machine types. To do this, Compute Engine has a feature called autoscaling, where VMs can be added to or subtracted from an application based on load metrics. The other part of making that work is balancing the incoming traffic among the VMs. Google's Virtual Private Cloud, or VPC, supports several different kinds of load balancing, which we'll explore shortly. With Compute Engine, you can in fact configure very large VMs, which are great for workloads such as in-memory databases and CPU intensive analytics. But most Google customers start off with scaling out, not up. The maximum number of CPUs per VM is tied to its machine family, and is also constrained by the quota available to the user, which is zone-dependent. Specs for currently available VM machine types are available at cloud.google.com/compute/docs/machine-types.

### Video - [Exploring PaaS with App Engine](https://www.cloudskillsboost.google/course_templates/153/video/515754)

* [YouTube: Exploring PaaS with App Engine](https://www.youtube.com/watch?v=RYka7auTuk8)

In this next section, you’ll explore how App Engine can run your applications without requiring you to manage the infrastructure. App Engine lets you build highly scalable applications on a fully managed, serverless platform. App Engine is ideal if time-to-market is highly valuable to you and you want to focus on writing code without ever having to touch a server, cluster, or infrastructure. It’s also ideal if you don’t want to worry about a pager going off or receiving 5xx errors! App Engine allows you to have high availability apps without a complex architecture. So, how does it work? With App Engine, you can choose from popular coding languages, libraries, and frameworks to develop apps with tools you’re familiar with, and then automatically provision servers and scale app instances based on demand. Options include Eclipse, IntelliJ, Maven, Git, Jenkins, and PyCharm. That means that you can upload your code, and Google will manage your app's availability. App Engine also provides built-in services and APIs, like NoSQL datastores, Memcache, load balancing, health checks, application logging, and a user authentication API that is common to most applications. App Engine offers software development kits, or SDKs, to help you develop, deploy, and manage your apps on your local machine. Each SDK includes: * All of the APIs and libraries available to App Engine, * A simulated, secure sandbox environment that emulates all of the App Engine services on your local computer, * And deployment tools to upload your application to the cloud and manage different versions. The SDK manages your application locally, and the Google Cloud console manages your application in production. Use the Google Cloud console’s web-based interface to create new applications, configure domain names, change which version of your application is live, examine access and error logs, and more. There are two types of App Engine environments: standard and flexible. The first is the App Engine standard environment, which is based on container instances running on Google's infrastructure. Containers are preconfigured with a runtime from a standardized list of supported languages and versions, which include libraries that support App Engine standard APIs. For many applications, the standard environment runtimes and libraries may be all you need. The standard environment features include: * Persistent storage with queries, sorting, and transactions. * Automatic scaling and load balancing. * Asynchronous task queues for performing work outside the scope of a request. * Scheduled tasks for triggering events at specified times or regular intervals. * And integration with other Google Cloud services and APIs. There are a couple of requirements for using the standard environment: 1. You must use specified versions of Java, Python, PHP, Go, Node.js, and Ruby. 2. Your application must conform to sandbox constraints that are dependent on runtime. Applications run in a secure, sandboxed environment. This allows the App Engine standard environment to distribute requests across multiple servers and scale servers to meet traffic demands. This means that your application runs within its own secure, reliable environment that is independent of the hardware, operating system, or physical location of the server. A standard environment workflow typically follows these three steps: 1. First, a web application is developed and tested locally. 2. Second, the SDK is used to deploy the application to App Engine. 3. And third, App Engine scales and services the application. App Engine also offers a flexible environment. If the standard environment’s sandbox model is too restrictive for you, the flexible environment can let you specify the type of container your web application will run in. This option lets an application run inside Docker containers on Google Cloud’s Compute Engine virtual machines. In this case, App Engine manages Compute Engine machines for you. This means that: * Instances are health-checked, healed as necessary, and colocated with other module instances within the project. * Critical, backward-compatible updates are automatically applied to the underlying operating system. * VM instances are automatically located by geographical region according to the settings in your project. Google's management services ensure that all of a project's VM instances are colocated for optimal performance. * And VM instances are restarted on a weekly basis. During restarts, Google's management services will apply any necessary operating system and security updates. The flexible environment supports microservices, authorization, SQL and NoSQL databases, traffic splitting, logging, search, versioning, security scanning, Memcache, and content delivery networks. App Engine flexible environment allows users to also benefit from custom configurations and libraries while still keeping their main focus on what they do best – writing code. In addition, the App Engine flexible environment allows you to customize the runtime and the operating system of your virtual machine by using Dockerfiles. As in the App Engine standard environment, supported runtimes include Python, Java, Go, Node.js, PHP, and Ruby. However, in the App Engine flexible environment, developers can also use different versions of these runtimes or provide their own custom runtime by supplying a custom Docker image or using a Dockerfile from the open source community. So, how do these two environments compare to each other? Let’s start with the standard environment, which is fast. It starts up instances of your application in seconds, but you have less access to the infrastructure in which your application runs. With the standard environment, you can’t use ssh to connect to the virtual machines on which your application runs, and you can’t write to a local disk. The standard environment does support third-party binaries for certain languages, and you can use App Engine to make calls to the network. Finally, in terms of pricing, after a free tier usage, you pay per instance class with automatic shutdown. The flexible environment takes minutes to start up, instead of seconds. But it lets you use ssh to connect to the virtual machines on which your application runs, it lets you use local disk for scratch space, it lets you install third-party software, and it lets your application make calls to the network without going through App Engine. In terms of pricing, with the flexible environment, you pay for resource allocation per hour with no automatic shutdown. Because App Engine uses Docker containers, you may be wondering how App Engine compares to Google Kubernetes Engine. App Engine standard environment is for people who want the service to take maximum control of their web and mobile application’s deployment and scaling. Google Kubernetes Engine, however, gives the application owner the full flexibility of Kubernetes. App Engine flexible environment is somewhere between the two.

### Video - [Lab Intro: App Engine: Qwik Start - Python](https://www.cloudskillsboost.google/course_templates/153/video/515755)

* [YouTube: Lab Intro: App Engine: Qwik Start - Python](https://www.youtube.com/watch?v=84S4fYiOwCE)

Now it's time for some practice. In this hands-on lab, you'll deploy an application using App Engine. In the lab titled ‘App Engine: Qwik Start - Python’ you'll create a small App Engine application that displays a short message. During this lab, you'll download an application, test the application, and deploy the application.

### Lab - [App Engine: Qwik Start - Python](https://www.cloudskillsboost.google/course_templates/153/labs/515756)

This hands-on lab shows you how to create a small App Engine application that displays a short message. Watch the short video <A HREF="https://youtu.be/s0-pfuXj1aA">Build Apps at Scale with Google App Engine</A>.

* [ ] [App Engine: Qwik Start - Python](../labs/App-Engine-Qwik-Start-Python.md)

### Video - [Event-Driven Programs with Cloud Run Functions](https://www.cloudskillsboost.google/course_templates/153/video/515757)

* [YouTube: Event-Driven Programs with Cloud Run Functions](https://www.youtube.com/watch?v=tIPTvdU69HU)

Next on the agenda is event driven programs with Cloud Run functions. Cloud Run functions is serverless code that lets you run it based on certain events. In this section, we'll learn how it works. Many applications contain event driven parts. For example, maybe you have an application that lets users upload images. When that event takes place, the image might need to be processed in a few different ways, like converting the image to a standard format, converting a thumbnail into different sizes, and storing each new file in a repository. You can integrate this function into your application, but then you'd have to provide compute resources for it, whether it happens once a millisecond or once a day. With Cloud Run functions, you could write a single purpose function that completes the necessary image manipulations, and then arrange for it to automatically run whenever a new image is uploaded. Cloud Run functions is a lightweight, event based, asynchronous compute solution that allows you to create small, single purpose functions that respond to cloud events without needing to manage a server or a runtime environment. You can use these functions to construct applications from bite-sized business logic. You can also use Cloud Run functions to connect and extend cloud services. You are billed to the nearest 100 milliseconds, but only while your code is running. Individual Cloud Run functions are written in JavaScript, Node.js, Python, or Go and executed in a managed Node.js environment on Google Cloud. Events from Cloud Storage and Pub/Sub can trigger Cloud Run functions asynchronously, or you can use HTTP invocation for synchronous execution.

### Video - [Lab Intro: Cloud Run Functions: Qwik Start - Command Line](https://www.cloudskillsboost.google/course_templates/153/video/515758)

* [YouTube: Lab Intro: Cloud Run Functions: Qwik Start - Command Line](https://www.youtube.com/watch?v=BqCCDDlll3E)

Now we'll create a cloud function by completing another hands on lab. In the lab titled ‘Cloud Run Functions: Qwik Start - Command Line’ you'll use the Cloud Shell command line to create a simple cloud function, deploy and test the function, and view logs.

### Lab - [Cloud Run Functions: Qwik Start - Command Line](https://www.cloudskillsboost.google/course_templates/153/labs/515759)

This hands-on lab shows you how to create and deploy a Cloud Run function using Cloud Shell, the Google Cloud command line.

* [ ] [Cloud Run Functions: Qwik Start - Command Line](../labs/Cloud-Run-Functions-Qwik-Start-Command-Line.md)

### Video - [Containerizing and Orchestrating Apps with GKE](https://www.cloudskillsboost.google/course_templates/153/video/515760)

* [YouTube: Containerizing and Orchestrating Apps with GKE](https://www.youtube.com/watch?v=q-GFjawi8LM)

Let's move on to the next section. Containerizing and orchestrating apps with GKE. In this section of the course, you'll learn about containerization and how to leverage Google Kubernetes Engine. We've already discussed the spectrum between infrastructure as a service and platform as a service, and we've also discussed Compute Engine, which is the IaaS offering of Google Cloud with access to servers, file systems and networking. Now, you'll be introduced to containers in GKE, which is a hybrid that conceptually sits between the two, offering the managed infrastructure of IaaS with the developer orientation of a PaaS offering. IaaS lets you to share compute resources with other developers by using virtual machines to virtualize the hardware. This lets each developer deploy their own operating system, or OS, access the hardware, and build their applications in a self-contained environment with access to RAM, file systems, networking interfaces, etc. This is where containers come in. The idea of a container is to give the independent scalability of workloads in PaaS, and an abstraction layer of the OS and hardware in IaaS. A configurable system lets you install your favorite runtime, web server, database, or middleware, configure the underlying system resources such as disk space, disk I/O, or networking, and build as you like. But flexibility comes with a cost. The smallest unit of compute is an app with its VM. The guest OS might be large, even gigabytes in size, and take minutes to boot. As demand for your application increases, you have to copy an entire VM and boot the guest OS for each instance of your app, which can be slow and costly. Now, with App Engine, you have access to programing services, so you only need to write your code in self-contained workloads that use these services and include any dependent libraries. This means that as demand for your app increases, the platform scales your app seamlessly and independently by workload and infrastructure. This scales rapidly, but there's no option to fine tune the underlying architecture to save cost. A container is an invisible box around your code and its dependencies, with limited access to its own partition of the file system and hardware. It only requires a few system calls to create, and it starts as quickly as a process. All that's needed on each host is an OS kernel that supports containers and a container runtime. In essence, the OS is being virtualized. It scales like PaaS but gives you nearly the same flexibility as IaaS. This makes code ultra portable, and the OS and hardware can be treated as a black box, so you can go from development to staging, to production, or from your laptop to the cloud, without changing or rebuilding anything. As an example, let's say you want to scale a web server. With a container, you can do this in seconds and deploy dozens or hundreds of servers, depending on the size of your workload, on a single host. That's just a simple example of scaling one container running the whole application on a single host. However, you'll probably want to build your applications using lots of containers, each performing their own function. as is done when using a microservices architecture. If you build applications this way and connect them with network connections, you can make them modular, easily deployable and scaled independently across a group of hosts. The host can scale up and down and start and stop containers as demand for your app changes, or as hosts fail. Kubernetes is a container orchestration tool you can use to simplify the management of containerized environments. You can install Kubernetes on a group of your own managed servers, or run it as a hosted service in Google Cloud on a cluster of managed Compute Engine instances called Google Kubernetes Engine. More on that shortly. Kubernetes was built by Google to run applications at scale. It lets you install the system on local servers in the cloud, manage container networking and data storage, deploy rollouts and rollbacks, and monitor and manage container and host health. A software container makes it easy for teams to package, manage, and ship their code. They write software applications that run in a container. The container provides the operating system needed to run their application. The container will run on any container platform. This can save a lot of time and cost compared to running servers on virtual machines. Like a virtual machine imitates a computer, a container imitates an operating system. Everything at Google runs on containers. Gmail, Web search, Maps, MapReduce, batch, Google File System, Colossus, even Cloud Run functions, which are VMs in containers. Google launches over 2 billion containers per week. Docker is a tool that puts the application and everything it needs in the container. Once the application is in a container, it can be moved anywhere that will run Docker containers - any laptop, server, or cloud provider. This portability makes code easier to produce, manage, troubleshoot, and update. For service providers, containers make it easy to develop code that can be easily transferred and run both in the cloud and on a customer's on-premises servers. Kubernetes is an open source container orchestration tool for managing a cluster of Docker Linux containers on a single system. It can be run in the cloud and on-premises environments. It's inspired and informed by Google's experiences and internal systems. Google Kubernetes Engine, or GKE, is a managed environment for deploying containerized apps. It brings Google's latest innovations in developer productivity, resource efficiency, automated operations, and open source flexibility to accelerate time to market. GKE is a powerful cluster manager and orchestration system for running Docker containers in Google Cloud. GKE manages containers automatically based on specifications such as CPU and memory. It's built on the open source Kubernetes system, making it easy for users to orchestrate container clusters or groups of containers, and it also gives customers the flexibility to take advantage of on-premises, hybrid, or public cloud infrastructure.

### Video - [Lab Intro: Kubernetes Engine: Qwik Start](https://www.cloudskillsboost.google/course_templates/153/video/515761)

* [YouTube: Lab Intro: Kubernetes Engine: Qwik Start](https://www.youtube.com/watch?v=kQe4Dx0TGXI)

Now let's complete a lab using GKE. In the lab titled ‘Kubernetes Engine: Qwik Start’, you'll get hands-on practice with container creation and application deployment with GKE. During this lab you’ll: set a default compute zone, create a GKE cluster, get authentication credentials for the cluster, and deploy an application to the cluster.

### Lab - [Google Kubernetes Engine: Qwik Start](https://www.cloudskillsboost.google/course_templates/153/labs/515762)

Google Kubernetes Engine provides a managed environment for deploying, managing, and scaling your containerized applications using Google infrastructure.  This hands-on lab shows you how deploy a containerized application with Kubernetes Engine.

* [ ] [Google Kubernetes Engine: Qwik Start](../labs/Google-Kubernetes-Engine-Qwik-Start.md)

### Video - [Managed serverless computing with Cloud Run](https://www.cloudskillsboost.google/course_templates/153/video/515763)

* [YouTube: Managed serverless computing with Cloud Run](https://www.youtube.com/watch?v=d4ljE8dr2PE)

Now let's explore managed serverless computing. The final application platform that you'll explore in this section of the course is Cloud Run. Cloud Run is a managed compute platform that lets you run stateless containers by using web requests or Pub/Sub events. Cloud Run is serverless. That means that it removes all infrastructure management tasks so you can focus on developing applications. It's built on Knative, an open API and runtime environment built on Kubernetes that gives you freedom to move your workloads across different environments and platforms. It can be fully managed on Google Cloud, on Google Kubernetes Engine, or anywhere Knative runs. Cloud Run is fast. It can automatically scale up from zero and back down almost instantaneously, and it charges you only for the resources you use, calculated down to the nearest 100 milliseconds, so you'll never pay for your over-provisioned resources. The Cloud Run developer workflow is a straightforward three-step process. First, you write your application using your favorite programming language. This application should start a server that listens for web requests. Second, you build and package your application into a container image, and finally, you deploy the container image to Cloud Run. After you've deployed your container image, you'll receive a unique HTTPS URL back, which you will use to run your new containerized application. Cloud Run then starts your container on demand to handle requests, and ensures that all incoming requests are handled by dynamically adding and removing containers. Cloud Run is serverless, and that means that you as a developer, can focus on building your application and not on building and maintaining the infrastructure that powers your application. For some use cases, a container based workflow is great because it gives you a great amount of transparency and flexibility. If you build a container image, you have the power to decide exactly what file is added to your container image and how it gets there. However, building an application is hard enough already, let alone having to think about containerization and the responsibilities that come with that. Sometimes you're just looking for a way to turn source code into an HTTPS endpoint, and you want your vendor to make sure that your container image is secure, well configured, and built in a consistent way. With Cloud Run, you can do both. You can use a container-based workflow and a source-based workflow. If you use the source-based approach, you'll deploy your source code instead of a container image. Cloud Run then builds your source and packages the application into a container image for you. Cloud Run does this by using Buildpacks, an open source project. Cloud Run handles HTTPS serving for you. That means you only have to worry about handling web requests and you can let Cloud Run take care of adding the encryption. By default, your application is exposed on a unique subdomain of the global *run.app domain. You can also use your own custom domain. Cloud Run manages everything else: generating a valid SSL certificate, configuring SSL termination correctly with secure settings, and handling incoming requests, decrypting them, and forwarding them to your application. The pricing model on Cloud Run is unique. You only pay for the system resources you use while a container is handling web requests, with a granularity of 100 milliseconds, and when it's starting or shutting down. You do not pay for anything if your container does not handle requests. Additionally, there is a small fee for every 1 million requests you serve. The price of container time increases with CPU and memory. A container with more vCPU and memory is more expensive. Today, Cloud Run can allocate up to four vCPUs and eight gigabytes of memory. Most of the other compute products, such as Compute Engine, charge for servers as long as they are running, even if you're not using them. This means you're often paying for idle server capacity. You can use Cloud Run to run any binary as long as it's compiled for Linux 64-bit. Now, this means you can use Cloud Run to run web applications written using popular languages such as Java, Python, Node.js, PHP, Go, and C++. You can also run code written in less popular languages like COBOL, Haskell and Perl. As long as your app handles web requests, you should be able to run it and scale it automatically using Cloud Run.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/153/quizzes/515764)

### Video - [Summary](https://www.cloudskillsboost.google/course_templates/153/video/515765)

* [YouTube: Summary](https://www.youtube.com/watch?v=Mjj50iX7e68)

This concludes the ‘Use Google Cloud to build your apps’ module. Let me remind you of what you learned. You began by exploring the role of compute options in the cloud. Next, you learned about building and managing virtual machines. After that, you examined the process of building elastic applications using autoscaling. From there, you explored PaaS options by leveraging App Engine. You examined building event-driven services using Cloud Run functions. Then you identified containerizing and orchestrating applications with Google Kubernetes Engine. And finally, you identified developing and deploying scalable containerized applications with Cloud Run.

### Document - [Demonstrate your capabilities further!](https://www.cloudskillsboost.google/course_templates/153/documents/515766)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

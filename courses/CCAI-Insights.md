---
id: 1123
name: 'CCAI Insights'
datePublished: 2024-07-18
topics:
- API
- Data Ingestion
- Looker
type: Course
url: https://www.cloudskillsboost.google/course_templates/1123
---

# [CCAI Insights](https://www.cloudskillsboost.google/course_templates/1123)

**Description:**

In this course you will learn how to leverage Contact Center AI Insights to uncover hidden information from your contact center data to increase operational efficiency and drive data-driven business decisions.

**Objectives:**

- Become familiar with CCAI Insights along with its use cases and business values.
- Demonstrate an understanding of ingesting the audio or chat transcript files into Insights
- Become familiar with topic modeling and analyze different ways to create a topic model.
- Learn about LLM Summarization & ways to enable it via UI or AP
- Become familiar with  other insights offerings with LLM generative FAQ's as well as smart and custom highlighters.
- Learn how to analyze conversations via insights console or API
- Become familiar with exporting insights data to BigQuery
- Become familiar with pre-built looker dashboards for reviewing the conversation analytics
- Understand how to draft a Insights Proof of Concept
- Become familiar with the phases of discovery, design, implementation & testing, and production deployment as part of the Insights Delivery process
- Understand the four phases of the Optimization process with CCAI Insights.

## Introduction to CCAI Insights

This module introduce CCAI Insights and its features, use-cases, architecture and target customers.

### Video - [Introduction to Conversational Insights](https://www.cloudskillsboost.google/course_templates/1123/video/495127)

- [YouTube: Introduction to Conversational Insights](https://www.youtube.com/watch?v=koScPwObTLc)

Welcome to this course on Insights! Here you’ll learn how to uncover hidden information from your contact center data. Contact centers in all industries generate a lot of data, and extracting insights out of that data is a daunting task. While managing a contact center, you may have experienced: 1) Heavy reliance on time constrained agents to manually summarize and classify conversations to inform future business investments. 2) Heavy reliance on a subjective human approach for call review. 3) Suboptimal quality and compliance reviews. 4) Inability to capture user satisfaction. Using CCAI insights can help you address these pain points by extracting the required metrics to allow contact center management to make data driven business decision and increase operational efficiency. In this module, we’ll introduce you to CCAI Insights and its features, use-cases, architecture and target customers. In this section, we will walk through the following topics: 1) About CCAI Insights 2) High level architecture of CCAI Insights 3) Insights Value Addition 4) Insights Use cases 5) Business Value of CCAI Insights Contact Centers generate huge amounts of data on a daily basis in the form of call recordings, chat transcripts and conversation metadata. These data sets are a rich source of various crucial information but extracting insights out of this large corpus of data is a daunting task. This is where CCAI Insights can be a huge asset for Contact Center management. CCAI Insights uses Google’s Large Language Models (LLMs) to turn your contact center data from insights to action. The input data can be uploaded in the form of audio recordings or chat transcripts. The audio files are passed through Speech-to-Text (STT) and the Data Loss Prevention (DLP) pipeline to convert audio recordings to transcripts with redacted PII. Chat transcripts are also passed through the DLP pipeline to redact any PII. Insights can work on extracting various useful components from input text like topics, highlights, questions and summaries. Various metrics like call metadata, customer satisfaction, and agent quality management can also be extracted by Insights. Based on the outcomes of CCAI insights, contact center management can enact agent coaching, improved bots, and improved contact center workflows. So, to quickly recap the CCAI Insights architecture: The input data is uploaded as call recordings or chat transcripts with redacted PII (in case of input being chat transcripts) The insights module then extracts useful components and metrics. The outcomes of the insights module can be exported to BigQuery, which can be easily integrated with Looker dashboard for interactive visualizations of insights outcomes. The Looker dashboard representation of insights module outcomes can be a simple and effective way to understand the various operational nuances of the Contact Center. There are three steps for setting up CCAI Insights: The first is creating the data pipeline. This includes getting transcript data from Cloud Storage, redacting it and providing metadata that needs to be attached with the conversation. These metadata are visible in Insights as labels, which are covered later in the course Next is building and evaluating custom models. This includes topic modeling and building custom highlighters. We often require to involve Subject Matter Experts from the business (example Contact Center Managers or Infrastructure Consultants) to provide some additional data for building and evaluating custom models like taxonomy of topics, topic descriptions, labelled data with example topics, etc. . The final step is extracting value. Once data is analyzed, it’s about deriving meaning from it to best address the use case There are several possible personas who can utilize data extracted from Insights: 1) The first persona is the Customer Experience Leader: The goal for a Customer Experience Leader is to improve the customer experience with the contact center. Their pain points include Agent training and turnover, and understanding customer history. The desirable behavior would be to Analyze conversations, establish informed best practices, and discover new uses for GenAI. 2) There’s also the Contact Center Operations Manager: The goal for Contact Center Operations Manager is to predict workforce needs and ensure that staff and tools are in place to handle call center volume and objectives. Their pain points include forecasting and scheduling. The desirable behavior would be to use precise AI based planning to reduce burnout by correctly assigning courses to individuals. 3) And the third persona is the Agent Supervisor: The goal for Agent Supervisor is to ensure that agents are handling conversations effectively and meeting contact center goals. Their pain points are Real-time awareness of agent performance and personalized coaching, and agent burnout. The desirable behavior would be to use personalized data to help individual agents improve and boost job satisfaction. Insights can help the contact center management achieve use-cases like: Preparing data for analysis, Developing topic taxonomy, Summarizing agent-customer conversations, Monitoring customer issues, Conducting QA inspections, Exporting and visualizing data, and generating contact center FAQs.

### Quiz - [Graded Quiz: Insights- Introduction to CCAI Insights](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495128)

## Data Ingestion

This module explores how to validate data formats, protect PII, transcribe audio files, and ingest audio and chat transcription files into Insights.

### Video - [Create a Cloud Storage bucket](https://www.cloudskillsboost.google/course_templates/1123/video/495129)

- [YouTube: Create a Cloud Storage bucket](https://www.youtube.com/watch?v=G9CC2rAzTyQ)

In this first section, we’ll focus on ingesting the audio or chat transcription files into Insights. In this section, we will walk through the following topics: 1) Creating a Cloud Storage Bucket 2) Validating Data Format 3) Working with Vertex AI Workbench and Environment Setup 4) Transcribing Audio files to Text 5) Applying DLP on Personal Identifiable Information 6) Ingesting data into Insights 7) and an Ingestion Demo Data Ingestion Flow starts with transcripts or recordings available inside the Cloud Storage bucket for which we have the access. Later in the course, we’ll also learn how to directly integrate Insights with Dialogflow or CCAIP. The first step is validating the data, which involves ensuring that voice recordings and transcripts are in the expected format. This is mostly a manual process. Next, we transcribe the audio with Speech to Text API, which applies when we are ingesting voice recordings. In the case of chat transcripts, we can skip this step. The third step is de-identifying PII data using Sensitive Data Protection (previously known as Cloud Data Loss Prevention or Cloud DLP). This involves masking important PII information like names, emails and credit card numbers. The information types that we have to de-identify can be configured. Once everything is done, data is ingested into CCAI Insights using the API. This pipeline can be run on Vertex AI using a Jupyter notebook inside a workbench. Or it can be orchestrated in orchestration tools if required. In the first step, we’ll create a Cloud Storage bucket (assuming one doesn’t already exist in your environment.) This is where the raw and intermediate data will be stored for the ingestion process. First, we’ll create the Cloud Storage bucket required to host our data (if it doesn't already exist). [ Which project, do we need details about the GCP project ?] Navigate to the Cloud Storage console and click on the “Create” icon in the Buckets section. Provide a globally unique name for the bucket. Then select a region (ensuring that the same region or subregion is selected for rest of the steps in the pipeline.) Select standard storage class and then click on create.

### Video - [Validate data format](https://www.cloudskillsboost.google/course_templates/1123/video/495130)

- [YouTube: Validate data format](https://www.youtube.com/watch?v=A0bD5uAn4dA)

Data format validation is required before we begin the ingestion process and as mentioned earlier, this is a manual process. Audio files should have sufficient quality in the recording and should be a dual channel audio. For chat transcripts, we must ensure that it follows the proper JSON structure. As this example shows, conversation metadata can be added in the conversation_info field which can be used later to populate labels in Insights. We’ll explore this later in the course. Transcripts must be covered inside the entries field and contain four important fields: start timestamp usec, which indicates when the sentence was spoken text, which contains the actual chat, role of the user either CUSTOMER or AGENT and user id, either 1 or 2

### Video - [Vertex AI workbench and environment setup](https://www.cloudskillsboost.google/course_templates/1123/video/495131)

- [YouTube: Vertex AI workbench and environment setup](https://www.youtube.com/watch?v=5WEJmgYaPJg)

Vertex AI user managed notebooks are a powerful tool that can be used for a variety of tasks, such as data exploration, machine learning model development, and data visualization. We are going to execute this pipeline using Vertex AI user managed workbench. This section covers the creation of this workbench and environment setup. As a prerequisite, we need to enable required Application Programming Interfaces or APIs in our GCP project. This can be done by clicking on the burger menu, followed by API & Services, and then selecting library. We then need to enable APIs listed on this slide to proceed. Vertex AI user managed notebooks are a managed service that allows you to create and run Jupyter notebooks in the cloud. This is a convenient way to run code snippets and explore data. Navigate to Vertex AI, then Workbench. To access Vertex AI user managed notebooks, you can navigate to the Vertex AI section of the Google Cloud Platform or GCP console and click on the "Workbench" tab. Alternatively, you can use the search bar to search for "Vertex AI workbench". Click on “Create New” in the “User-Managed Notebooks” section in “Instances”: This action opens the "Create New Notebook Instance" dialog box. When the panel opens up, enter the instance name and region. The name of your notebook instance must be unique. Your selected region and zone will affect the latency of your notebook instance. It should be same as your selected region for CCAI insights and Cloud Storage bucket. Make sure to keep same region throughout this tutorial to avoid cross region data movement. We can also change the instance machine type or other settings if required. Your selected machine type will affect the performance of your notebook instance. Once done, click on “Create”. Wait several minutes for the instance to be created. Then click on “Open Jupyterlab” button to open the Jupyter workspace. Create a Text file called “requirements.txt” in the instance and paste this content in it. This creates a text file called “requirements.txt” in your notebook instance. The content of the file should be same as the content mentioned in this slide. Set up the Python environment by running the following commands in the terminal. These commands will install the Python packages that are required to follow this tutorial (pointing to first command in slide). Install Python packages using the “requirements” file you created. This command installs the Python packages that are listed in the requirements file. Pip3 (pip3) install -r (hyphen r) requirements.txt (requirements.txt) --force-reinstall (hyphen hyphen force reinstall) --no-deps (hyphen hyphen no dependencies) The requirements.txt file is a text file that lists the Python packages that are required for a project (Pointing to the text on right side of the screen that has packages listed.) The pip (pip) command is used to install Python packages. The --force-reinstall flag tells pip to reinstall the packages even if they are already installed. The --no-deps flag tells pip not to install the dependencies of the packages that are listed in the requirements.txt file.

### Video - [Transcribe audio file to text](https://www.cloudskillsboost.google/course_templates/1123/video/495132)

- [YouTube: Transcribe audio file to text](https://www.youtube.com/watch?v=VgkuGcHqLOQ)

The Cloud Speech-to-Text API is a Google Cloud service that can be used to transcribe audio files. Note: This step is only required when trying to ingest audio files to insights. If you’re not ingesting audio files to insights, you can skip this step. The transcript files must be the returned result of a Cloud Speech-to-Text API transcription. This means that the transcript files must be in the same format as the transcripts that are returned by the Cloud Speech-to-Text API. Specifically, it must match the response returned from audio recognition. This means that the transcript files must contain the same information as the transcripts that are returned by the Cloud Speech-to-Text API's audio_recognition method. This API can be called from Python code which can be run on a Jupyter notebook created in Vertex AI. This means that you can use Python code to call the Cloud Speech-to-Text API and generate the transcript files. At the start of the code, import the required packages and assign the required variables that will be used in the code. There are 4 main variables required for this step: Storage underscore uri: URI for audio file in Cloud Storage. encoding: The encoding to use for transcription. For example: enums dot Recognition Config dot Audio Encoding dot MP3, which is required for MP3 files. Similarly different audio encodings can be given depending on the file format like . WAV as well. Language underscore code: The language code to use for transcription. For example: en-US is one of the supported languages. Sample underscore rate underscore hertz: The sample rate of the audio. For example: 8000 Hertz. In this step, the config dictionary is a Python dictionary used to configure the Cloud Speech to Text API. The keys in the config dictionary are the names of the configuration parameters. The values are the values of the configuration parameters. After setting up everything, we can call the Speech To Text API and expect a response back in the format that will be supported for downstream activities in this tutorial. For more information and to review the entire code of this module, feel free to refer to the document linked in this slide.

### Video - [Apply DLP on PII](https://www.cloudskillsboost.google/course_templates/1123/video/495133)

- [YouTube: Apply DLP on PII](https://www.youtube.com/watch?v=EHdWebfRsPQ)

Sensitive Data Protection (previously known as Cloud Data Loss Prevention or Cloud DLP) is a Google Cloud service that can be used to detect and mask sensitive information in data. The Sensitive Data Protection API can be used to mask sensitive information in a variety of data formats, including text, images, and videos. Let’s see how we can use it to mask Personal Identifiable Information data present in our transcripts. The info_types variable is a list of the information types that to be masked. The information types that can be masked are defined in the Sensitive Data Protection documentation. Here we’re creating the DLP client and setting the info types variable. The inspect_config dictionary: This dictionary defines the inspection configuration. This PII data will be captured and de-identified with the help of the de-identify config dictionary. Inspect config dictionary contains all the info types from the previous step. This de-identify config should only be used for audio inputs. We’re using info type transformation. In this example, we’ll replace PII data with the masking character * and PII numbers with 0. This can be modified to best suit any use-case. For JSON transcript inputs, we can use record transformation. This is used to maintain the integrity of JSON structure while performing DLP. Since we don’t want to accidentally mask anything else, we’ll only perform de-identification on text field of the JSON transcript containing the actual chat messages. Masking characters can be specified here similar to the previous step. In the next step, we’ll set the project path variable and set an item variable which is the response we received from previous step of STT. Again, this is only required in case of audio files. For chat transcripts, the item should be set as the transcript itself, which can be downloaded directly from Cloud Storage. Run DLP process on the transcript: This code snippet will run the Sensitive Data Protection process on the transcript. The response variable will contain the results of the Sensitive Data Protection process. The results of the Sensitive Data Protection process will include the deidentified transcript, which will contain masked PII data. Once done, we can upload redacted transcript to Cloud Storage by using the code snippet on the right. Make sure to replace the project id, bucket name and desired blob name. For more information on specific sample code for DLP refer to the document linked in the slide.

### Video - [Ingest data into Conversational Insights](https://www.cloudskillsboost.google/course_templates/1123/video/495134)

- [YouTube: Ingest data into Conversational Insights](https://www.youtube.com/watch?v=oTnOdGzTltY)

Now that we have finished the required preprocessing, we can ingest data into insights. Call the Insights API by sending a request to the URL highlighted in the code snippet. Replace variables like project id. GCS transcript uri should be the same as the redacted transcript we stored in the previous step. Metadata dictionary can be optionally specified which will be added as labels in the conversation. The Conversation info field in the chat transcripts can also be loaded here. We are also using the auth token. So we must ensure that the service account or user executing this command has access to ingest conversations into insights. Once all the url, headers and data is setup, we can call the insights API. If the transcript is ingested, it will return the transcript uri, otherwise it will return the error. Once the conversation is ingested, we can open the CCAI console by clicking on the link mentioned in the slide. However, we must make sure to replace the project id first. When opening the insights console, a page similar to the following screenshot should appear. Project and location information is located in the top left corner. A conversation hub should be loaded automatically. Conversations can be viewed in the Conversation Hub, which provides a one stop shop to filter and deep dive into conversations. We can review how many conversations were historically ingested from the first chart. Conversation filters can also be applied on different fields and metadata of the conversation. Ingested conversations are visible as shown in the slides. Click on a conversation to open a more detailed view. In the more detailed view of the conversation we can access the following: Conversation labels, Analysis information (currently blank as we have yet to analyze the conversation), and the conversation transcript as shown in the snapshot. We can also search for a specific user or agent utterance by adding a search term at the top of transcript.

### Video - [Ingestion demo](https://www.cloudskillsboost.google/course_templates/1123/video/495135)

- [YouTube: Ingestion demo](https://www.youtube.com/watch?v=6wvLfkOTDwE)

The Cloud Speech-to-Text API is a Google Cloud service that can be used to transcribe audio files. Note that this step is only required when trying to ingest audio files to insights. This means that if you are not trying to ingest audio files to insights, you can skip this step. If you are looking to ingest audio files in Insights, please refer to this demo.

### Quiz - [Graded Quiz: Insights- Data Ingestion](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495136)

## Topic Modeling

This module explores how to identify training data to create a taxonomy and a topic model in CCAI Insights.

### Video - [Identify training data](https://www.cloudskillsboost.google/course_templates/1123/video/495137)

- [YouTube: Identify training data](https://www.youtube.com/watch?v=hpu25nLodU4)

Next, we are going to talk about Topic Modelling. We will walk out of this section being able to: Identify Training Data Define Initial Taxonomy and Model Size Creating a topic model And we will close with a small demo of all these capabilities in action Training a topic model begins with identifying training data that greatly defines the quality of trained topic model. In this section, we’ll talk about important aspects of training data for a topic model. Topic modeling is for discovering various topics or areas of conversations (also referred to as “call drivers”) betweens contact center agents and end users. Trained topic model will enable the deployed model to infer topics on new conversations, allowing you to continually classify incoming conversations. The process of training a topic model begins with the identification of appropriate training data. The first and the foremost requirement for a suitable training data is its similarity to the live conversations traffic expected. For instance, if a telecommunications contact center has around 30 topics, the training data should ideally have relevant conversations across these 30 topics. Topic model v3 is well equipped to work with smaller training datasets with a minimum requirement of one thousand conversations. This includes five back-and-forth turns between an agent and a customer. Although the recommendation is to use about ten-thousand conversations as part of the training dataset. Appropriate training data can also be identified by applying relevant filters like import time or any other metadata level filter from ingested conversations.

### Video - [Define initial taxonomy & model size (# of topics)](https://www.cloudskillsboost.google/course_templates/1123/video/495138)

- [YouTube: Define initial taxonomy & model size (# of topics)](https://www.youtube.com/watch?v=iJTzpvF4Y5E)

In this section, we’ll talk about the details of various configurable features of topic models during the training phase. The topic model v3 introduces exciting and unique features for the customers that facilitate customization as per specific needs. A customer can use their own topic taxonomy to provide a list of topics to be identified from conversations while training the model. The v3 model also allows users to select their industry (like retail, healthcare, telecommunication) to generate industry specific synthetic topics. Topic model training also offers the flexibility to select the topic model granularity. This a 5-point scale ranging across: more coarse, coarse, standard, fine and more fine. Once the topic model is trained, you’ll also get LLM powered-context aware topic names and descriptions for generated topics.

### Video - [Create a topic model](https://www.cloudskillsboost.google/course_templates/1123/video/495139)

- [YouTube: Create a topic model](https://www.youtube.com/watch?v=HHAUnQ7Na_Q)

In this section, we’ll review creating a topic model for your use-case based on learnings from the configurable parameters of topic models discussed in the previous section. Creating a topic model from the insights console requires walking through four broad areas. The first section is specifying model details like desired name, model granularity and model language. To configure the model details, just go to the topic model console and click on “Create New”. From the drop down menu, select topic model V2 (Insights Console and API still uses the name V2) . Set a desired display name for the model and model granularity. Then select an appropriate model language if you want to create a non-English model. Click continue. Next, you must provide a training dataset for topic model training. Import training conversations using all ingested conversations, or by using filtered conversations in the training conversations section. Some of the common filters that are often used include: Conversation Language, Conversation Channel, Turn Count, And Conversation Import Time. Once you’ve completed these actions, click continue. The third section lets you provide additional information like an industry name for your dataset so that your model is inclined towards producing specific industry topics. This way the model training process will be biased towards producing topics for the selected industry. The last section lets you include custom taxonomy. These custom topics can be entered manually one at a time, or by uploading a csv file containing a list of topics. All custom topics will be included in the final trained topic model. Click Start Training to begin training a new topic model. For better quality we recommend that you add short topics of 3 to 6 words, such as "troubleshooting my remote control" or "inquiring about billing policy". For a more detailed step-by-step guide to creating a topic model, refer to resources #15 and #16 hosted in the Additional resources document.

### Video - [Evaluating a topic model](https://www.cloudskillsboost.google/course_templates/1123/video/495140)

- [YouTube: Evaluating a topic model](https://www.youtube.com/watch?v=fmrWF7422LM)

In this section, we’ll briefly explore the mechanism of evaluating a trained topic model. The CCAI Insights console doesn’t provide any implicit metric or measure to quantify the performance of a trained topic model. In general, customers complete the topic model evaluations based on the criteria they find most suitable. There is no recommended approach to evaluating a trained topic model. It generally depends on the customer’s preference. Let’s take an example where one of the CCAI Insights customers evaluated the trained topic model by conducting human evaluation of conversations on the following parameters: Is_Top_Topic_Match which is a binary measure to assess if the top most predicted topic is a relevant topic. Is_Any_Topic_Match which is a binary measure to assess if any of the predicted topic is a relevant topic (including top 1). And comments to address any additional topics that should have been identified by the topic model. Aggregate numbers gave an insight into the percentage of accurately predicted top 1 topics and any matched topics.

### Video - [Topic model demo](https://www.cloudskillsboost.google/course_templates/1123/video/495141)

- [YouTube: Topic model demo](https://www.youtube.com/watch?v=ezjciHCiZWI)

Next, we are going to provide you with a demo of a topic model. In this demo, we are going to cover the following: Selecting training data for a topic model. Training a topic model. Exploring topics discovered. Analyzing a conversation to predict the top 3 topics of the conversation.

### Quiz - [Graded Quiz: Insights- Topic Modeling](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495142)

## LLM Summarization

This module explores the capabilities of LLM summarization within CCAI Insights and how to enable it within your model using via user interface or the API approach.

### Video - [All about LLM summarization](https://www.cloudskillsboost.google/course_templates/1123/video/495143)

- [YouTube: All about LLM summarization](https://www.youtube.com/watch?v=gvlL6VajloU)

Next, we will cover LLM summarization. In this section, we’ll walk through the following: 1) All About LLM Summarization, 2) Enabling LLM Summarization via user interface (or UI), 3) Enabling LLM Summarization via API, 4) and lastly, we are going to show an LLM Summarization Demo. This section briefly describes the basic details around the LLM summarization feature, how it works, and what you can expect from it. The Summarization feature intends to provide contact center agents with the conversation summaries. This can be enabled by setting the summarization annotator to ‘true’ while analyzing a conversation. Users can also specify which summarization model to use. It supports baseline v1.0, v2.0 and custom summarization model registered on Agent Assist. LLM Summarization, also known as the Baseline v2.0 Summarization is an Agent Assist feature that supports both voice and chat data without having to do any additional training. It can be used with CCAI Insights in conjunction with your pre-existing Agent Assist conversation profiles while analyzing the conversations. The LLM powered summarization model enables the customer to customize the summary content by selecting any or all of the following predefined sections: The situation section provides answers to what the customer needs help with or has questions about. The agent’s action to help the customer is captured in Action section. The Resolution section gives the result of customer service which can be: Yes, No, Partial or N-A (As in No Action). Customer Satisfaction is classified as Satisfied or unsatisfied according to the customer’s satisfaction at the end of the conversation. The “Reason for cancellation” section states the reason only if the customer’s request is to cancel the service. Otherwise it’s marked as N-A. Various entities in the conversation are extracted and shown in the entities section as key-value pairs.

### Video - [Enable LLM summarization via UI](https://www.cloudskillsboost.google/course_templates/1123/video/495144)

- [YouTube: Enable LLM summarization via UI](https://www.youtube.com/watch?v=Bad9Ic8z9R0)

This section covers the step-by-step process to enable LLM summarization via UI. LLM Summarization can be enabled via the UI of the Agent Assist Console. To set this up, access the Summarization section in the Agent Assist Console and enter the desired model display name with the correct language. Then click Start. The model can be further configured to include other sections relevant to your use-case like: Situation, Action, Resolution, Customer Satisfaction, Reason for Cancellation, And Entities. While creating the summarization model, you can create a new conversation profile or select an existing one.

### Video - [Enable LLM summarization via API](https://www.cloudskillsboost.google/course_templates/1123/video/495145)

- [YouTube: Enable LLM summarization via API](https://www.youtube.com/watch?v=q708lVPSvJA)

This section covers the step by step process to enable LLM summarization via API. Another way to enable LLM Summarization is via Insights API using a series of curl commands. If you’re using Curl commands in Insights API, Baseline Summarization 2.0 is considered as a Custom Model. You need to give a conversation profile ID to retrieve the summarization.

### Video - [LLM summarization demo](https://www.cloudskillsboost.google/course_templates/1123/video/495146)

- [YouTube: LLM summarization demo](https://www.youtube.com/watch?v=h6JEurJywEo)

Next, we are going to provide you with a demo of LLM Summarization In this demo we are going to cover how to enable, configure and perform LLM Summarization on already ingested conversations within CCAI Insights.

### Quiz - [Graded Quiz: Insights - LLM Summarization](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495147)

## Other Insights offerings

This module explores  LLM generative FAQs and smart and custom highlighters part of the CCAI Insights offering.

### Video - [Smart and custom highlighters](https://www.cloudskillsboost.google/course_templates/1123/video/495148)

- [YouTube: Smart and custom highlighters](https://www.youtube.com/watch?v=cm0tLDF7DLg)

In addition to what we have covered so far, there are additional Insights offerings that we are going to explore next. In this section, we‚Äôll walk through the following: 1) Smart and Custom Highlighters, 2) and LLM generative FAQ which is coming soon This section briefly discusses smart and custom highlighters. In this section, we‚Äôll outline types of highlighters available for smart highlighters, their examples and how we can configure the custom highlighters. A highlighter contains keywords or phrases that CCAI Insights recognizes as being important to determining the user's intent. Highlighters capture relevant segments of a conversation that apply to a particular area of interest. There are two types of highlighters: Smart and Custom Highlighters. A Smart highlighter is pre-configured with a set of phrases like: AUTHENTICATION INFO, CHECK ISSUE RESOLVED, and CONFIRM ISSUE RESOLVED. Some of the examples of highlighters are: 1) An agent verifies a customer's account information. 2) A customer says that they are planning to cancel their subscription Highlighters are applied when a conversation is analyzed. A highlighter contains keywords or phrases that CCAI Insights recognizes as being important to determining the user's intent. Highlighters capture relevant segments of a conversation that apply to a particular area of interest. There are two types of highlighters: Smart and Custom Highlighters. A Smart highlighter is pre-configured with a set of phrases like: AUTHENTICATION INFO, CHECK ISSUE RESOLVED, and CONFIRM ISSUE RESOLVED. Some of the examples of highlighters are: 1) An agent verifies a customer's account information. 2) A customer says that they are planning to cancel their subscription Highlighters are applied when a conversation is analyzed. These screenshots show the use of custom highlighters. The screenshot on the left shows a list of created highlights and the associated metadata. The screenshot on the right shows the starting steps to create a custom highlighter. A detailed step-by-step guide to creating custom highlighters can be found in resource #21 in the Additional resources document at the end of the course. A custom highlight is comprised of one or more phrase match rule groups. A phrase match rule group contains one or more rules. You can specify whether a highlight should be detected if only one of the rules resolves to true or if all of the rule groups resolve to true. Similarly, you can specify a rule group should resolve to true if only one of the rules is met or if conditions for all rules must be met. You can also use the semantic match feature. This feature lets you focus on concepts instead of specific strings, letting the system find the situations that match. A slider lets you control how narrow or wide the match should be. For fine-grained control, you can limit matches to specific words and configure whether the exact match specified by the rule is case-sensitive or not. This page showcases a few examples for Custom Highlighters. Custom Highlighters can be utilized to identify competitor mentions. This can be extended to any set of words or phrases, for example to identify a car model and make in car insurance call center conversations. It can also be used for customer entity detection that can help identify entities that could not be understood by NLP entity extraction, such as ESIM or MODB. This also helps ensure the highest possible security for this account by validating some phrases such as ‚ÄúI need to verify some information‚Äù or ‚ÄúBefore I can provide any information regarding this account, may I have the email address? ‚Äù It‚Äôs also important to identify key phrases that confirm the successful execution of the interaction, such as: ‚ÄúThanks, that‚Äôs all I needed. ‚Äù ‚ÄúPerfect. ‚Äù ‚ÄúYou‚Äôre very helpful. ‚Äù ‚ÄúThank you so much. ‚Äù Another important custom highlighter is helping identifying a specific system issue (e.g. an app issue, supply chain issue, network issue, etc.) Remember, using topic modeling with highlights provides more detailed analysis of your conversation.

### Video - [LLM generative FAQ](https://www.cloudskillsboost.google/course_templates/1123/video/495149)

- [YouTube: LLM generative FAQ](https://www.youtube.com/watch?v=qr0Dtao9l44)

This section briefly covers the Generative FAQ feature and how you can configure it for your use case. Generative FAQ in CCAI Insights displays the questions that customers are asking your contact center and how these questions are being answered. This information helps identify gaps in your FAQs, track trending questions, and improve customer service responses. For more information, refer to resource #22 hosted in the Additional resources document. Generating the top queries from the Insights conversations can be easily done using the Insights Console. You can follow the instruction referenced in resource #21 at the end of this course. to enable the GenerativeFAQ on your project after the allowlist.

### Quiz - [Graded Quiz:Insights - Other Insight Offerings](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495150)

## Analyze conversations

This module explores how to analyze a conversation using the CCAI Insight console or API's and walks you through the conversations analysis review process.

### Video - [Analyze conversations](https://www.cloudskillsboost.google/course_templates/1123/video/495151)

- [YouTube: Analyze conversations](https://www.youtube.com/watch?v=8HGD_Ron7OE)

In this module, we will develop an understanding of the meaning of “Analyze conversations” in the context of CCAI Insights. In this section, we’ll walk through the following: 1) Analyzing a conversation using Insights Console. 2) Analyzing a conversation using the API. 3) And reviewing Analyzed conversations. In this section, you‘ll learn how to analyze a conversation via Insights Console once all your required components are ready. Analyzing conversations ingested in Insights gives various components against each conversation like topics (given that the topic model is already trained and deployed), sentiment, highlighters, entities and so on. You can analyze conversations via the Insights Console. Before running analyze, make sure all the conversations are loaded in the Insights dashboard and the topic model is trained and deployed, if needed. Navigate to the Insights dashboard. Select the same project used for creating the conversations from the drop down menu. Verify the Total conversations count from the Conversation history section. If you need to analyze selected conversations only, then add the necessary filters. Next, click Analyze to analyze the selected conversations. This action brings up the pop-up display. Next, update the Analysis Percentage based on the percentage of conversations to analyze. Then click “Analyze number of conversations”. In this section, you’ll learn about analyzing conversations via API once all your required components are ready. You can also use Insights API to analyze conversations. This has to be followed in VertexAI workbench. Create a request dot json file stating how many percentage files there are to be analyzed. Using the links referenced in this slide, you can analyze conversations based on filters, or configure the request body with additional parameters. The command stated in this slide can be used to bulk analyze the conversations. Bulk analysis is a long-running operation. You can verify if the operation is completed using UI. Check the hourglass icon at the top right corner of the Insights dashboard. If the operation is completed, it will display “You currently have no operations.” This section covers guiding points for reviewing the analyzed conversations. To review the analyzed conversations, we can do some spot checks in the Conversation Hub UI to see if the topic generated against the conversations and rest of the fields is accurate.

### Quiz - [Graded Quiz: Insights - Analyze Conversation](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495152)

## Export data to BigQuery

This module explores the process of exporting data to BigQuery for in-depth analysis and visualization on Insights data.

### Video - [Filter conversations to export](https://www.cloudskillsboost.google/course_templates/1123/video/495153)

- [YouTube: Filter conversations to export](https://www.youtube.com/watch?v=zPb13RaRKXs)

This section discusses exporting the insights data to BigQuery. This enables custom in-depth analysis and visualization on Insights data. This section is broken into three parts: 1) How to filter exports, 2) Exporting conversations to BQ, 3) Reviewing the exported BQ Schema. 4) And lastly you’ll have the opportunity to see a demo of this export process. In this section, we’ll discuss filtering the set of conversations to export to BQ. CCAI Insights allows users to export conversation, analysis results, and topic modeling results directly to BigQuery for further analysis. We can use the filters provided in conversation hub view to filter only required conversations before exporting them into BigQuery. Here are the list of filters supported on UI inside conversation hub. For more information on these filters, refer to the CCAI Insights documentation.

### Video - [Export conversations to BQ](https://www.cloudskillsboost.google/course_templates/1123/video/495154)

- [YouTube: Export conversations to BQ](https://www.youtube.com/watch?v=DvTrf-qABOo)

Conversations can be exported directly into BigQuery for further analysis. This enables custom in depth analysis and visualization on Insights data. Once a subset of a conversation is selected after applying filters, we can configure the export job to BigQuery. Do note that filtering the conversation is an optional step. We can also export all the conversations if required. Before we trigger the export job, it is important that we have an empty table created in BigQuery first in which Insights data will be loaded. Go to BigQuery console and select a dataset (or create one if it doesn’t exist). Then click on create a new table. Input the required fields as shown in the slide and note that the schema is not required to be set as it will be done dynamically during the export job. After creating the BQ table, we can come back to the conversation hub in the CCAI Insights console and click on the Export button. This opens up a panel where we can review the applied filters and the conversation count. Enter the correct BigQuery dataset and table as shown in the snapshot. Once you’re satisfied with the list of conversations, click on the Export button at the bottom. This triggers a long running job (depending on the volume of conversations to be exported). Its progress can be checked by clicking on the notification icon at the top right corner of the Insights console. Do not utilize the Export button in the Insights interface as there are currently limits on the number of records that can be exported. It’s also not possible to append data in the target table. CCAI Insights export supports the following write disposition options from BigQuery via the API: WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result. This is the default option. WRITE_APPEND: If the table already exists, BigQuery appends the data to the table. Additionally, the export supports both filtering and writing data to customer-managed encryption key (CMEK) protected tables. Export to BigQuery is compatible with all combinations of filters that can be applied to conversation queries. For example, the you can craft a sample that exports all conversations with 10 or more turns handled by agent_id "007" between January 1st 2021 and January 2nd 2021 Pacific Standard Time:

### Video - [Review table data model and metrics](https://www.cloudskillsboost.google/course_templates/1123/video/495155)

- [YouTube: Review table data model and metrics](https://www.youtube.com/watch?v=EkUl_Ctp28I)

In this section, we’ll discuss Review BQ Schema. Once the Export job is completed, the table is visible in the BQ console. We can also click Preview to view the data or make use of the SQL query editor. Alternatively, we can view the data directly inside the SQL workspace by writing an SQL query. Many different metrics are captured at conversation level. Some of these metrics include: topic name, silence percentage of user or agents, and entities identified from the conversation. There are also multiple metrics captured at the sentences level, such as: the sentiment score of a sentence where a more positive score indicates positive sentiment, intent and highlights. And Word level metrics like speaker tag and language code are also exported. For a full list of exported metrics, refer to resource 27 referenced at the end of this course.

### Video - [Export to BQ demo](https://www.cloudskillsboost.google/course_templates/1123/video/495156)

- [YouTube: Export to BQ demo](https://www.youtube.com/watch?v=5zeRs9wmjP8)

next we are going to provide you with a demo of export to Big query in this demo we are going to cover how to create big query data set and table for insights data select and Export the conversations to Big query and finally explore important fields and exported data hi my name is Josh Radia and I'm A Cloud a engineer at Google today I'll be demoing how to export conversations from insights console to Big query this enables custom in-depth analysis and visualization on insights Data before we get started with this demo as a prerequisite it is important that we have a table created on big query we can click on the project and click on create data set I've provided a demo data set ID and selected the same region as the CCI insights region once the data set is created we can go to data set and then click on create table apart from giving the table name we don't really need to modify anything else here once the table is created we can click on go to table we can verify that this is an empty table that does not have any schema as of this moment once this is done we can head back to CCI insights console and then start by filtering the conversations that we want to export the first filter I'm going to apply is on agent ID we can apply multiple filters for example on agent ID conversation label duration summary status analysis status language and many more fields I'm going to apply another filter on turn count once we are happy with the set of conversations that we have we can click on export here we can select the data set and the table that we recently created we can also expand this to look at all the filters that are applied it also shows the number of conversations which will be exported we can click on export button here to start the export job this creates a long running job which can be viewed by clicking on view running operations once the data is loaded we can see that the schema of this table has changed it creates multiple Fields like name of the conversation which has the whole conversation URI agent ID and lots of conversation level information for example agent speaking percentage client speaking percentage uh client sentiment score also it contains the transcript turn count medium of the conversation it also has a nested field called issues this has all the topics like name of the topic score of the topic and more information it also has more information about entities for example speaker tag it also contains any additional labels in our conversation and it has Ned fields for words and sentences we can also see sentence level sentiment score and magnitude as well as Speaker tag and more information we can also see annotations and the latest summary can be found under the latest summary section this has different feeds like customer resolution action situation Etc that we observed in llm summarization section we can we can then do select star on the table to preview the data and start writing our sqls in the big query directly as you can see the summary section is populated correctly we can also export conversations from insides to Big query using the API and we can have different flags like whether we want to append the information into a table or do we want to overwrite it so to summarize we looked at how to create a empty big query table how to select conversations that we want to export how to start and Export big quer job and then we reviewed the final data model and data on big query

### Quiz - [Graded Quiz: Insights - Export to BQ](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495157)

## Looker dashboards

This module explores how to leverage Looker dashboards to enable conversation analytics within CCAI Insights.

### Video - [Looker dashboards](https://www.cloudskillsboost.google/course_templates/1123/video/495158)

- [YouTube: Looker dashboards](https://www.youtube.com/watch?v=h50RxyIlQHk)

This section discusses using the pre-built looker dashboards for reviewing the conversation analytics. In this section, we’ll walk through the following: 1) Understanding Utility: Looker dashboards & CCAI Insights, and 2) Explore Looker - CCAI Insights Blocks In this sub-module, we talk about the utility of looker dashboards with CCAI Insights outputs. CCAI Insights integrates with the Looker Block to aggregate data outside of Contact Center sources to provide a more holistic view of the business. With the Looker block, you can review the exported data from the CCAI Insights solution and analyze it in Looker. The flexibility of the data model gives you the ability to integrate Insights data with other first party data to unlock deep business insights. Before utilizing this block, you’ll need to follow the instructions for exporting the CCAI Insights data. Note that you’ll need to set the job to run on a schedule with appropriate filters or integrate with Cloud Data Fusion. This sub-module discusses the available looker Blocks for Google Contact Center Insights. Looker provides Looker Blocks for Google Contact Center for Virtual Agents, Agent Assist and Insights. It also provides embedded visualizations and pre-built data models for common analytical patterns and data sources.

### Quiz - [Graded Quiz: Looker Dashboards](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495159)

## Optimization process with CCAI Insights

This module explores the steps required to support the optimization process for CCAI Insights post production deployment.

### Video - [Optimization process introduction](https://www.cloudskillsboost.google/course_templates/1123/video/495160)

- [YouTube: Optimization process introduction](https://www.youtube.com/watch?v=PNYMpLaaaUA)

This section discusses using the pre-built looker dashboards for reviewing the conversation analytics. The main phases of the optimization process with CCAI Insights are: Monitor, Analyze, Identify, Enhance. We are going to delve in to each of this in this section. CCAI Insights and Looker offer a set of tools and dashboards that enables you to understand patterns in your conversational data so you can quickly identify issues at a glance. Any optimization process can be broken down into four steps as follows: First is Monitor: Use CCAI Insights built-in analytics and Looker dashboards to track an agent's performance and key indicators over time. This includes metrics such as topics and their distribution and highlights. Next is Analyze: Perform an analysis of conversational data to identify trends and anomalies. CCAI Insights stores all your conversation transcripts and performs analytics on these. You can analyze these data points to identify areas of improvement. Then Identify: Explore your opportunities to identify areas for improvement. Using CCAI Insights’ metrics, identify large impact and easy to implement enhancements to expedite improvements in management processes. The final step is Enhance: You can make enhancements with updates to quality management processes. Implement enhancements to your processes following your usual procedures

### Video - [Monitor](https://www.cloudskillsboost.google/course_templates/1123/video/495161)

- [YouTube: Monitor](https://www.youtube.com/watch?v=QAl7l84F5tE)

Let’s double click in the Monitor phase of the Optimization process. There are different signals you can monitor in the CCAI Insights console: First, in the Conversation hub you can check two dashboards: At the top, you’ll see conversations created. This shows the number of conversations per day so you can quickly see how much traffic is going through Insights. Below it, you’ll see the Conversation history dashboard. This shows high level metrics such as total number of conversations, their average duration, average turns per conversation, as well as the top three conversation topics in your data. Additionally, you can use filters to get a list of conversations that share the same primary topic and get a sense of how many turns they have or when they happened. Then, the topic models dashboard shows topic distribution over time. You can review this dashboard for spikes for some specific topics, or determine which topic receives the most or the least amount of traffic. Click on “View Legend” to open a sub-menu with a list of the identified topics. By selecting one or more topics, you can highlight in the graph the specific topic you require the distribution for. The Conversation highlights dashboard lets you monitor how popular keywords or key phrases are in your conversational data. Check under Smart Highlights or Custom Highlights to view a graph that displays each tracked phrase over time along with a list of all highlights and their count. Additionally, in the Custom highlights dashboard, you can click on “View Legend” for a breakdown of keywords and phrases that Insights is tracking. Click on any of them to highlight their graph. Lastly,let’s review the Generative FAQ dashboard, which is the last tab in the CCAI Insights console. This shows questions asked by customers and outlines how these questions are answered by the agent. This information can be used to monitor trending questions and give a general sense of how popular each question is and how many turns are typically required to answer each of them. There are different signals you can monitor in Looker. Under the Call Center Operations dashboard, there are four areas to monitor different metrics. At the top is the Overall KPIs for the last week dashboard. It shows overall metrics such as: The number of calls, containment, call duration, costs savings, and average sentiment for the entirety of your data. In our example here, the average call duration is 1.7 minutes and the general sentiment for the contact center during the last week is neutral. This example also shows a 73.5 percent call containment. However this will only apply if Looker is connected to a virtual agent. Next, is the Customer and Topic Overview dashboard. Here, you can review conversation topics by: customer segmentation, topic volume over time, overall conversation volume per day, or percentage of repeat callers. For example, the Calls by customer Segmentation view shows that opening a new account is more popular among retirees in rural areas. And the conversation Volume view shows that traffic volume is lower on Mondays. The Virtual Agent Performance dashboard is only applicable if Insights is integrated with a virtual agent. If you perform this integration, you can use this dashboard to monitor where your virtual agent performs well on its own, or in comparison to live agents. For example, we can see that opening a new account drives more satisfaction if performed with a live agent. Lastly, the Agent Performance dashboard refers to your live agents. In this last dashboard you can monitor waiting time to speak to a live agent by topic, identify which topics typically require a follow up, and review a break down of your live agents where you can see metrics like: their average CSAT, The number of conversations handled, And the average waiting time. For example, we can see here that online banking issues don’t require as many follow ups as submitting a fraud alert. Additionally, at any time, you can click on any piece of information in any dashboard or graph. This automatically applies a filter and the whole Call Center Operations page updates to show all metrics by the filter applied. This way, you can monitor all these metrics in a more granular way. Under the Agent Performance dashboard, you can select a specific agent, exclude an agent, or use other filters to get a view of their performance. You can monitor metrics like: The number of conversations that were handled in the last week, average call duration, speaker distribution, average sentiment, topics handled by the agent over time, conversation duration by topic over time, and customer ratings. For example, in this view we can see that Tonya Koop didn’t handle any conversations last week and that customers that speak with her have a neutral or positive satisfaction rating.

### Video - [Analyze](https://www.cloudskillsboost.google/course_templates/1123/video/495162)

- [YouTube: Analyze](https://www.youtube.com/watch?v=vc4VTGl0s3o)

Next, we are going to cover the Analyze phase. As you’ve discovered, both CCAI Insights and Looker offer different metrics that can be analyzed to find issues and areas of improvement. When analyzing these metrics, you can use the following questions to guide your analysis: How many conversations go through your analytic solution per day, week or month? Do you observe any unusual spike in volume? What topics are more popular in your conversations? Do you observe any unusual spike over time for any of the topics? Do you observe any gradual increase or decrease in one topic’s popularity? What phrases or keywords are more popular in your conversations? Do you observe any unusual spike over time for any of the phrases or keywords? Do you observe any gradual increase or decrease in the popularity of one phrase or keyword? What questions do end-users ask? Which ones are more common? Are their answers well covered in the company’s website or in other places? What questions seem to be more difficult to answer? What’s a sample of a good response? What’s the overall sentiment in conversations? Which conversation topic has the most positive sentiment? Which one has the most negative sentiment? Are there any trends or correlations between topic popularity and customer segmentation? What about between traffic volume and customer segmentation? If so, what factor could contribute to this trend? Which conversation topics typically require a follow-up? Which ones can be resolved quickly and do they require a follow-up? How long do customers need to wait to speak to an agent? Are there any topics that typically require more waiting time than others? If so, why do you think that is? Is there any correlation between CSAT and average conversation duration, average sentiment, number of messages, or average wait time? These are just some examples of questions to think about. But you are free to think about others. Keep in mind what you want to learn from the data, and see if you can find an answer.

### Video - [Identify](https://www.cloudskillsboost.google/course_templates/1123/video/495163)

- [YouTube: Identify](https://www.youtube.com/watch?v=wvEXtu1mmDg)

The third phase is Identify. When trying to identify areas of improvement, it’s important to prioritize those areas that will have the largest impact that can be quickly improved. Sometimes, a lot of small quick improvements can have a larger impact than an impactful improvement that requires months to be implemented. So, try to find a balance between these two perspectives. Ideally, you’ll want to prioritize easy to implement improvements with a big impact. In other words, quick wins. For example, implementing enhancements that affect popular topics will have a major impact, more so than focusing on niche topics. Similarly, fixing the answer to a question is easier than having to rework all your call center routing logic.

### Video - [Enhance](https://www.cloudskillsboost.google/course_templates/1123/video/495164)

- [YouTube: Enhance](https://www.youtube.com/watch?v=Q6LaPBZiYqY)

The last phase is to enhance the build. Once you’ve identified which areas you want to prioritize, it’s time to implement changes in your contact center. This can include delivering a fix or make a decision. Follow the same processes you would follow to implement any enhancement or make any decision. Remember also to make note of your metrics before and after implementing an enhancement or making a decision. So, keep monitoring all metrics and see if your enhancements improved the metrics you were interested in or not. After this, you can again analyze the data, and identify new opportunities.

### Quiz - [Graded Quiz: Optimization process with CCAI Insights](https://www.cloudskillsboost.google/course_templates/1123/quizzes/495165)

### Lab - [Conversational Insights](https://www.cloudskillsboost.google/course_templates/1123/labs/495166)

Conversational Insights provides contact center interaction data to answer business questions or support decisions to drive efficiency. It uses Google ML and Large Language Models to turn contact center data to insights to action. Based on the outcomes of the insights module various actions can be taken by contact center management like agent coaching, improved bots, improved contact center workflows.

- [ ] [Conversational Insights](../labs/Conversational-Insights.md)

## Additional Resources

This module includes the list of 37 additional resources that complement the course learning.

### Document - [Additional Resources](https://www.cloudskillsboost.google/course_templates/1123/documents/495167)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

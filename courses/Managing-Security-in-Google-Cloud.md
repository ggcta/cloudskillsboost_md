---
id: 21
name: 'Managing Security in Google Cloud'
datePublished: 2024-11-07
topics:
- Security
- Logging
- Virtual Private Cloud
type: Course
url: https://www.cloudskillsboost.google/course_templates/21
---

# [Managing Security in Google Cloud](https://www.cloudskillsboost.google/course_templates/21)

**Description:**

This self-paced training course gives participants broad study of security controls and techniques on Google Cloud. Through recorded lectures, demonstrations, and hands-on labs, participants explore and deploy the components of a secure Google Cloud solution, including Cloud Identity, Resource Manager, IAM, Virtual Private Cloud firewalls, Cloud Load Balancing, Cloud Peering, Cloud Interconnect, and VPC Service Controls.

This is the first course of the Security in Google Cloud series. After completing this course, enroll in the Security Best Practices in Google Cloud course.

**Objectives:**

- Identify the foundations of Google Cloud security.
- Manage administration identities with Google Cloud.
- Implement user administration with Identity and Access Management (IAM).
- Configure Virtual Private Clouds (VPCs) for isolation, security, and logging.

## Welcome to Managing Security in Google Cloud

Welcome to Managing Security in Google Cloud, the first course of Security in Google Cloud. This course gives you an overview of security controls and techniques on Google Cloud. Through lectures, demonstrations, and hands-on labs, you will explore and deploy the components of a secure Google Cloud solution.

### Video - [Welcome to Security in Google Cloud](https://www.cloudskillsboost.google/course_templates/21/video/513471)

- [YouTube: Welcome to Security in Google Cloud](https://www.youtube.com/watch?v=Yfj58gzRIOU)

From saving costs to leveraging new and innovative technology, businesses move to the cloud for many different reasons. Increasingly, security, and the ability to build a more secure infrastructure have become important factors in an organization’s cloud journey. Google Cloud prioritizes security in their own operations – operations that serve billions of users across the world. Google Cloud’s approach to security can be built into your own workflows to better secure your infrastructure. In the Security in Google Cloud course series, learn about implementing and managing security controls and techniques in Google Cloud. Hi, I’m Sean, a Technical Curriculum Developer at Google and today, I’m here to teach you about Security in Google Cloud. In this series of courses, you will learn how to manage security, implement best practices, and mitigate vulnerabilities in Google Cloud. This course series is designed for Cloud information security analysts and architects, engineers, cybersecurity specialists, and infrastructure architects. This series requires knowledge of foundational information security and cloud computing concepts. Basic proficiency with command-line tools and Linux operating system environments is also expected. You should also be able to understand code in Python or Javascript. Through a series of courses featuring lectures, quizzes, and hands-on labs, our expert trainers will describe Google’s approach to security and give you the in-depth training you need so you can manage and implement security controls into your own Google Cloud environment. You will Identify the foundations of Google Cloud security, Manage administration identities with Google Cloud, Implement user administration with Identity and Access Management, or IAM, Configure Virtual Private Clouds for isolation, security, and logging, Identify techniques and best practices for securely managing Google Compute Engine, Identify techniques and best practices for securely managing data on Google Cloud, Identify techniques and best practices for securing applications on Google Cloud, Identify techniques and best practices for securing Google Kubernetes Engine resources. Manage protection against distributed denial of service attacks, Manage content-related vulnerabilities, And implement Google Cloud monitoring, logging, auditing, and scanning solutions. Ready? Let’s get started.

### Document - [Welcome and Getting Started Guide!](https://www.cloudskillsboost.google/course_templates/21/documents/513472)

## Foundations of Google Cloud Security

Securing systems is a hot topic and should be a priority for everyone today - and, as you will see, it is definitely a priority here at Google. In this module we will introduce you to Google Cloud's approach to security. We will also discuss the shared security responsibility model, which is a collaborative effort between Google and its users. Next, we will outline several threats that are mitigated for you when your systems are run on Google's infrastructure in Google Cloud. And, finally, we will end with a section on access transparency.

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/21/video/513473)

- [YouTube: Module overview](https://www.youtube.com/watch?v=_vcUfUvNjIM)

Welcome to the Foundations of Google Cloud Security module. We are glad you are interested in learning more about Google Cloud security. Securing systems are a hot topic and should be a priority for everyone today - and, as you will see, it is definitely a priority here at Google. In this module, we will introduce you to Google Cloud’s approach to security. We will also discuss the shared security responsibility model, which is a collaborative effort between Google and its users. Next, we will outline several threats that are mitigated for you when your systems run on Google’s infrastructure in Google Cloud. And, finally, we will end with a section on access transparency.

### Video - [Google Cloud's approach to security](https://www.cloudskillsboost.google/course_templates/21/video/513474)

- [YouTube: Google Cloud's approach to security](https://www.youtube.com/watch?v=GEW3UyJ9fQ0)

OK, let’s get started with an outline of Google Cloud’s approach to security. At Google, we believe security empowers innovation. We’ve been operating securely in the cloud for over 20 years! Designing for security is pervasive throughout the infrastructure that Google Cloud and Google services run on. Security is always paramount! Countless companies and governments have lost data because of security incidents. Just one such breach could cost millions in fines and lost business— and more importantly, the loss of customer trust. As a result, security is increasingly becoming a high priority for CEOs and Boards of Directors. Unfortunately, many organizations do not have access to the resources needed to implement state-of-the-art security controls and techniques. Google has invested heavily in its technical infrastructure and has hundreds of dedicated engineers to provide a secure and robust platform. Deploying your systems on Google Cloud allows you to leverage that same infrastructure and can help you secure your services and data through the entire information processing lifecycle, including: Secure deployment of services, Secure storage of data, Secure communications between services, And safe operations by administrators. Internet services, including Google Cloud, is built on this infrastructure. Now you have a feeling for the high level of security implemented and “baked into” Google’s Infrastructure. Google Cloud benefits from running on top of all of this secure Google infrastructure, which highlights how Google Cloud is designed for security from the bottom up. It’s not enough to build something and try to make it secure after the fact. Security should be fundamental to all designs, not bolted on to an old paradigm. That’s why we build security through progressive layers that are integrated from the ground up. Google Cloud delivers true defense in depth, meaning our cloud infrastructure doesn’t rely on any one technology to make it secure. Let’s talk about a few of our security layers, starting at the bottom and working our way up. Google designs and builds its own data centers, which incorporate multiple layers of physical security protections. Access to these data centers is limited to only a very small fraction of Google employees. Both the server boards and the networking equipment in Google data centers are custom-designed by Google. Google also designs custom integrated circuits, including a hardware security chip called Titan, that’s currently being deployed on both servers and peripherals. Google server machines use cryptographic signatures to make sure they are only booting the correct software. Google’s infrastructure provides cryptographic privacy and integrity for remote procedure call (or “RPC”) type of data on the network, which is how Google’s services communicate with each other. The infrastructure automatically encrypts RPC traffic in transit between data centers. To help ensure that code is secure as possible, Google stores its source code centrally and requires two-party review of new code. Google also gives its developers libraries that keeps them from introducing certain classes of security bugs. Externally, Google also runs a bug bounty program where we pay anyone who is able to discover and inform us of bugs in our infrastructure or applications. In Google Cloud, all data is encrypted at rest by default - without any need for you to configure or enable anything. This default encryption leverages Google-managed encryption keys, but also supports: Customer Managed Encryption keys (CMEKs), where you can manage your own encryption keys with the Google Key Management  Service (KMS). As well as Customer Supplied Encryption keys (CSEKs), where you can provide and manage your own keys. We will cover encryption keys in more detail in a later module. Google meticulously tracks the location and status of all equipment within our data centers from acquisition, to installation, to retirement, to destruction. Metal detectors and video surveillance are implemented to help make sure no equipment leaves the data center floor without authorization. When a hard drive is retired, the disk is erased by writing zeros to the drive and performing a multi-step verification process to ensure the drive contains no data. If the drive cannot be erased for any reason, it is stored securely until it can be physically destroyed. Physical destruction of disks is a multi-stage process beginning with a crusher that deforms the drive, followed by a shredder that breaks the drive into small pieces, which are then recycled at a secure facility. Additionally, if customers delete their own data, we commit to deleting it from our systems within 180 days. Google services that want to make themselves available on the Internet register themselves with an infrastructure service called the Google Front End (GFE). GFE checks incoming network connections for correct certificates, best practices, strong encryption, and adds protection against Denial of Service attacks. The sheer scale of its infrastructure enables Google to simply absorb many Denial of Service attacks. Even behind the GFEs, Google also has multi-tier, multi-layer Denial of Service protections that further reduce the risk of any DoS impact. Cloud customers can take advantage of this extra protection by using the Google Cloud Load Balancer, which we’ll cover in more detail in a later module. Google Cloud also offers customers additional transport encryption options for connecting on-premises resources to the cloud. These options are Cloud VPN for establishing IPSec connections, and Cloud Interconnect for highly available, low latency connections. Google has created a thriving security culture for all employees. The influence of this culture is apparent during the hiring process, employee onboarding, and as part of ongoing training and in company-wide events to raise awareness. Google prioritizes keeping employees and their devices and credentials safe. Google is keen on reducing insider risk and intrusion detection as well.

### Video - [VPC network security and monitoring](https://www.cloudskillsboost.google/course_templates/21/video/513475)

- [YouTube: VPC network security and monitoring](https://www.youtube.com/watch?v=McvF8JscTJY)

In addition to the security provided by the Google infrastructure, there are a few Google Cloud specific items that help provide security at the cloud resource level. Google Virtual Private Cloud or VPC networking provides the ability to logically isolate networks when you define your resources. You can also control all network ingress and egress traffic to any resource on these networks via firewall rules. These concepts and many more will be discussed in detail in a later module. Logging and monitoring are the cornerstones of application and network security operations. Monitoring and logging enables application analysis, network forensics, access patterns, performance profiling, and more. Without monitoring it is very difficult to know exactly what is happening or when incidents occur. Monitoring and logging are also needed to help identify security or operational risks to your organization. Google Cloud’s Operations suite (formerly Stackdriver) enables monitoring and diagnostics for applications and provides a centralized place to manage and analyze operational resources. This helps you increase application reliability when running in the cloud. Cloud Logging (formerly Stackdriver Logging) allows you to store, search, analyze, monitor, and trigger alerts on log data and events from Google Cloud. Our API also allows ingestion of any custom log data from any other source. Cloud Logging is a fully managed service that performs at scale and can ingest application and system log data from thousands of VMs. Even better, you can analyze all that log data in real time. Combined with the powerful visualization tools, Cloud Logging helps identify trends and prevent issues before they happen. The error reporting and trace tools help to quickly locate and fix problems in production systems. Cloud Debugger has been deprecated, but you can still use open source tools like Snapshot Debugger to help you inspect the state of a running cloud system. For more information, see Snapshot Debugger. Other reporting systems include Security Command Center and Chronicle. We’ll cover the former in more detail in a later module. Another facet of security today is the need to ensure regulatory compliance, which involves much more than just making use of encryption and firewalls. You also need data protection and compliance with a variety of regulatory standards. Our products regularly undergo independent verification of security, privacy, and compliance controls, achieving certifications against global standards to earn your trust. We are constantly working to expand our coverage. As you have seen, Google Cloud provides many security controls automatically. When implementing systems correctly on Google Cloud, leveraging these aspects can reduce the IT Security resources required, and help drastically reduce the total cost of ownership. While compliance requirements are a facet of security, they are not one and the same thing. Compliance is very much specific to individual environments and industries. While this will not be covered at length in this course, check out some of the great links in the speaker notes of this module to learn more about Google Cloud’s compliance posture. Links have been provided in the course resources for this module to the Standards, Regulations and Certifications page that Google currently supports, and to downloadable reports from Google Cloud’s Compliance Reports Manager.

### Video - [The shared security responsibility model](https://www.cloudskillsboost.google/course_templates/21/video/513476)

- [YouTube: The shared security responsibility model](https://www.youtube.com/watch?v=XQ9uuccWbsQ)

Security on Google Cloud is a shared responsibility between Google and the customer. Depending on the service being used, division of responsibilities will vary. When you build an application with on-premise infrastructure, you are responsible for the physical security of the hardware and the premises in which it is housed, the encryption of the data on disk, the integrity of your network, and the security of the content stored in your applications. When you move an application to Google Cloud, Google handles many of the lower layers of the overall security stack. Because of its scale, Google can deliver a higher level of security at these layers than most of its customers could afford to do on their own. The shared-responsibility model provides you with many options and managed services for securing your workloads. This flexibility is a big reason why businesses are moving to Google Cloud. The upper layers of the security stack remain the customer’s responsibility. Google provides tools, such as Identity and Access Management (IAM) to help customers implement the policies they choose at these layers. One aspect of security which is almost always the responsibility of the customer is data access. This simply means you are the one who controls who has access to your data. However, in order to protect your data, these controls must be properly configured. We will discuss this in more depth later in the course. When calling a Google API to retrieve data, API requests are done via a REST service call. Authentication information must be included with requests. It is very common for legal or regulatory requirements to require a vulnerability assessment or penetration test against your cloud resources. For example, PCI-DSS security requirements will require this to be done. You will be exposed to many services and mechanisms for controlling data throughout the course, but a few examples are: Identity and Access Management (IAM), which allows you to grant granular access to specific Google Cloud resources and helps prevent access to other resources. API Gateways, which allow you to securely transport data between application clients and services. And Anthos Service Mesh or Istio, which gives you a control plane to control how microservices communicate and share data with one another. Another aspect of security responsibilities for customers relates to controlling access to computing resources. Google Cloud provides you with a variety of mechanisms to do this, which we’ll cover in more detail in Module 5. Some examples of this are: Service accounts and access scopes, which allow you to specify permissions and how your computing resources interact with services. As well as login options for VMs, which allow you to control who and how your computing resources are accessed. Depending on how a customer works in the cloud, this can involve more or less security responsibility and effort to ensure security compliance. Google helps you by providing best practices, templates, products, and solutions. Finally, another aspect of security responsibilities for customers relates to controlling access to networks. Now, we’ll cover the mechanisms Google Cloud provides in more detail in Module 6, but a few examples are: Firewall rules, which allow you to protect VM instances from unapproved connections. Shared VPCs, which allow ‘centralized network administration’ in which a VPC network is defined in a host project and is made available as a centrally shared network for eligible resources in service projects. VPC Service Controls, which enforce a security perimeter with VPC Service Controls to mitigate data exfiltration risks. VPC peering, which enables the resources in your VPCs to communicate across private RFC1918 space, which reduces exposure to attack. And Cloud VPN, which securely connects your on-premises network to your Cloud VPC network. The highest trust networks have no direct connectivity to the internet and satisfy strict requirements about when and how they can be used, what sort of traffic can flow into them, and how that traffic is scanned. Having different VPCs for different workloads can also facilitate location-based access regulatory requirements when combined with VPC service controls. Google Cloud does not require prior notification to perform penetration testing, but please note that you must abide by the Google Cloud Acceptable Use Policy and the Terms of Service when conducting your testing. Google Cloud also provides some security assessment services to help perform these assessments, which are Cloud Security Scanner and Security Command Center. We’ll learn more about these services in more depth later on in the course.

### Video - [Threats mitigated by Google and Google Cloud](https://www.cloudskillsboost.google/course_templates/21/video/513477)

- [YouTube: Threats mitigated by Google and Google Cloud](https://www.youtube.com/watch?v=f8NAIWsZVRU)

Deploying systems on Google Cloud offers many benefits derived from the security of Google’s underlying infrastructure. This means many of the threats your systems and applications face are automatically mitigated simply by using Google’s infrastructure. Some common security threats are DoS and DDoS. What is a DoS attack? Denial of Service attacks are a malicious attempt to make a computer or network resource unavailable to its intended users. DoS attacks typically involve flooding the target with so much traffic that it is unable to respond to legitimate requests. What is a DDos attack? In Distributed Denial of Service, just like a DoS attack, it involves flooding the target so that it is unable to respond to legitimate requests with a key difference being that the origin of attack is distributed across IP ranges, multiple geo locations, devices, and typically originates from a botnet controlled by a third party. We will handle this in a later module when we will talk about the Cloud Armor service. When there is a Denial of Service (or DoS) attack, there is time to isolate it and address it - but Google doesn't stop there. In Google Cloud, customers also benefit directly from our central DoS mitigation service that provides additional multi-tier, multi-layer protection. Our DoS mitigation service further reduces the risk to services running behind our Google front end by detecting when an attack is taking place and configuring load balancers to drop or throttle traffic associated with the attack. The best news is that there is minimal configuration required to activate this DoS defense, when you use Google Cloud Load Balancers to manage your resources. We’ll cover DoS attacks and mitigation strategies in more detail later on in this course. For additional features, such as IPv4 and IPv6 allowlisting or blocklisting, and defense against application-aware attacks such as cross-site scripting and SQL injection, Google Cloud offers Google Cloud Armor. Google Cloud Armor works in conjunction with global HTTP and HTTPS load balancing and enables you to deploy and customize defenses for your internet-facing applications. It has preconfigured WAF rules and helps mitigate the OWASP Top 10 risks. You can manually allowlist or denylist IP addresses or ranges. The named IP address list lets you reference IP addresses and IP ranges maintained by third party providers once you subscribe to the Google Cloud Armor Managed Protection Plus service. You can configure rate-based rules to protect the applications from a large volume of requests or volumetric attacks. We will cover Google Cloud Armor in more detail later on in this course. Google’s data centers leverage a layered security model and are protected with some of the most advanced physical security controls available today. Some of the controls implemented are: Custom designed electronic access cards, biometrics and metal detectors. Vehicle access barriers. Perimeter fencing and security patrols. Laser beam intrusion detection on data center floors. And interior and exterior cameras to detect and track intruders. For more information on Google’s security layers, check out the link in this module’s course resources. Additionally, all access is tracked and monitored and limited to only those with a direct need to have access. Less than 1% of Googlers will ever set foot in a data center. For more more information, check out the link in the speaker notes of this module. All data stored at rest in Google Cloud is chunked and encrypted automatically. All data stored at rest in Google Cloud is automatically split into chunks, and each chunk is encrypted with a unique data encryption key. These data encryption keys are then encrypted with (or sometimes called "wrapped" by) key encryption keys to provide another level of protection. There is nothing for the customer to configure for this to happen. Additional options are also available that allow for customer managed keys and customer supplied keys. These can sometimes be required by legal, regulatory, or organizational requirements. The details of these options will be discussed in further detail later on in this course. You can use solutions such as Cloud External Key Manager (EKM) when encrypting data-at-rest to store and manage keys outside of Google’s infrastructure, which the graphic on this slide gives you an example of. Check out the link in this module’s course resources for more information on ubiquitous data encryption with Cloud External Key Manager. Google applies different protections to data in transit, depending on whether that data is transmitted inside a physical boundary where we can ensure that rigorous security measures are in place, or whether it is transmitted outside a physical boundary controlled by or on behalf of Google. Data in transit within our physical boundaries is generally authenticated, but may not be encrypted by default. You can choose which additional security measures to apply based on your threat model. All data is automatically encrypted and authenticated when transmitted outside a physical boundary controlled by or on behalf of Google. When data is deleted by the customer, the data becomes inaccessible by the Google Cloud service and cannot be recovered by the customer. The data may still remain on physical storage devices for a period of time. All relevant data will then be deleted from all of Google’s systems and devices in accordance with applicable laws. This deletion will occur as soon as reasonably possible and within a maximum period of 180 days. What if you want to stop using Google Cloud? The ability to export data from the cloud can be a security concern. Data can be exported from Google Cloud without penalty, but you will need to pay the standard egress charges. This makes it easy for our customers to take their data with them if they choose to stop using Google Cloud. Google leverages all purpose-built servers and network equipment to help reduce its security footprint. All servers running in Google Cloud are homogeneous custom-built servers designed with security in mind. Google servers don’t include unnecessary components such as video cards, chipsets, or peripheral connectors, and leverage the Titan security chip mentioned earlier for trusted server boot process. All Linux stacks are stripped-down and hardened versions and are continually monitored for binary modifications.

### Video - [Access transparency](https://www.cloudskillsboost.google/course_templates/21/video/513478)

- [YouTube: Access transparency](https://www.youtube.com/watch?v=VECPbO8u48U)

When moving systems to the cloud, a common concern is access transparency and knowing exactly what is happening to your data. At Google, we try to expand your visibility into how your data is handled when in the cloud. So, what is access transparency? At a high level, it is Google's long-term commitment to transparency and user trust. Google Cloud customers own their data, not Google. The data that customers put into our systems is theirs, and we do not scan it for advertisements nor do we sell it to third parties. We offer our customers a detailed data processing amendment that describes our commitment to protecting customer data. It states that Google will not process data for any purpose other than to fulfill our contractual obligations. Google also provides customer trust through access transparency, which come in two flavors: The first are Standard access logs. Traditionally, cloud providers do not provide services or features to illustrate access. In Google Cloud, Cloud Audit Logs provide visibility into the actions of your own administrators. However, this audit trail typically stops once your cloud provider’s support or engineering team is engaged. For example, if you opened a ticket with Google Support that would require data access, that access would not have been reflected in an audit log. The second flavor is Google's Access Transparency product, which provides near-real-time oversight over data accesses by either Google support or engineering. But rest assured, at Google Cloud, we do not access customer data for any reason other than those necessary to fulfill our contractual obligations to you. Google also performs regular audits of access by administrators as a check on the effectiveness of our controls. The Access Approval API is an API for controlling access to data by Google personnel. Using Access Approval together with Access Transparency, means explicit consent is needed before Google support or Google engineers can access your project’s data.

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/21/video/513479)

- [YouTube: Module review](https://www.youtube.com/watch?v=09OQ2rNXmsk)

To summarize, in this module we learned more about the fundamentals of security in Google Cloud, including how security is built into the infrastructure at its core. Security starts at Google with secure user management, and includes data that is secured both at rest and in transit, as well as secure internet communication over Google’s own network, via the Google Front End. Google’s state of the art data centers complete this circle of trust and security, by making use of custom, Google-designed hardware to help reduce the risk of hardware exploits.

### Quiz - [Quiz: Foundations of Google Cloud Security](https://www.cloudskillsboost.google/course_templates/21/quizzes/513480)

## Securing Access to Google Cloud

In this module we will discuss Cloud Identity, a service which makes it easy to manage cloud users, devices, and apps from one console. We will also discuss a few related features to help reduce the operational overhead of managing Google Cloud users, such as the Google Cloud Directory Sync and Single Sign-On. We will end with some authentication best practices.

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/21/video/513481)

- [YouTube: Module overview](https://www.youtube.com/watch?v=jozXioIivNI)

Welcome to module 2 of Managing Security in Google Cloud: Securing Access to Google Cloud. In this module, we will discuss Cloud Identity, a service which makes it easy to manage cloud users, devices, and apps from one console. We will also discuss a few related features to help reduce the operational overhead of managing Google Cloud users, such as the Google Cloud Directory Sync, Managed Microsoft Active Directory, and Single Sign On. We will also talk briefly about Identity Platform. We will end with some authentication best practices.

### Video - [Cloud Identity](https://www.cloudskillsboost.google/course_templates/21/video/513482)

- [YouTube: Cloud Identity](https://www.youtube.com/watch?v=kaoMwocmzyA)

Let’s get started with an outline of Google Cloud’s approach to security. Before we dive into the specifics of Cloud Identity, let’s take a moment to level set and give you high level view of the services that we’ll cover in this module, as well as common uses cases. Cloud Identity helps you centrally manage identities and provides secure authentication and authorization to applications and devices. Cloud Identity is commonly used as a cloud-based directory, Authenitcaiton, Authorization, User Lifecycle Management, Multi-factor authentication, and Endpoint management service. Google Cloud Directory Sync (or GCDS) lets you synchronize the data in your Google Account with your Microsoft Active Directory or LDAP server. GCDS allows you to sync users, aliases, groups, and other data with your Google Account from LDAP or Microsoft Active Directory. Managed Microsoft Active Directory allows you to manage authentication and authorization for Active Directory-dependent apps and servers, as well as Automate Active Directory server maintenance and security configuration amongst other things. And finally, Identity Platform, which lets you add identity and access management functionality to your applications. Identity Platform is a Customer identity and access management (or CIAM) system commonly used for multi-tenant SaaS applications, mobile and web apps, games, APIs and more. Now that we have a good overview of the different services that will be discussed in this module, let’s dive into Cloud Identity. Cloud Identity is an Identity as a Service (IDaaS) solution for managing who has appropriate access to your organization's cloud resources and services. It is currently used by hundreds of thousands of business customers to manage millions of users and devices. Cloud Identity provides a single admin console so users, groups and domain-wide security settings can be managed for your entire organization from a central location. Cloud Identity can work with any domain name that is able to receive email, so you can use your existing web and email addresses. Your organization does not need to use Google Workspace services in order to use Cloud Identity. When you migrate to Cloud Identity, you must verify that you own the domain name, and create an account for each of your users. When you sign up for a Cloud Identity domain, the first domain name becomes the primary domain for your organization. Other domains can be added using the Admin Console. You must own each domain and verify your ownership when adding it. You can add up to 600 domains to your organization's Google account. You can then manage all users from the Google Admin Console. The Admin Console provides a central management location or a “single pane of glass” to manage user identities and access permissions across your entire domain. This allows you to easily enforce security policies and roles. Cloud Identity is available in both free and premium editions. The Cloud Identity Free edition includes core identity and endpoint management services. It provides free, managed Google Accounts to users who don’t need Google Workspace Services. The Cloud Identity Premium edition offers enterprise security, application management, and device management services. These services include automated user provisioning, application allowlisting, and rules for automating mobile device management. Visit the URL in this module’s course resources for a comparison of features offered by the free and premium editions of Cloud Identity. The Google Admin Console (which is found at admin.google.com) is the centralized console for managing users, groups, and security settings. From the Admin Console, Cloud Identity allows free accounts to be created for users who do not need Google Workspace services. For existing Google Workspace customers the Admin Console provides additional functionality to configure their user’s Google Workspace experiences. Cloud Identity can be used as a standalone service for any domain that you own. It can also be combined with your existing Google Workspace subscriptions. In either case, you can manage all users across your entire domain from the Google Admin Console. As mentioned earlier, the Google Admin Console allows admins to provision user accounts manually. The Google Admin Console allows you to upload individual accounts as well as batch enrollments from a spreadsheet. As you can see, Cloud Identity provides you with a variety of options that allow you to securely manage users in your organization. If you are a Google Workspace admin, sign up for Cloud Identity from the Billing section of the Google Admin Console. Google Workspace licenses are required only for users who need Google Workspace services, such as Gmail, Google Drive, etc. You can create free, non-licensed Cloud Identity accounts for managing users who do not need Google Workspace services.

### Video - [Google Cloud Directory Sync](https://www.cloudskillsboost.google/course_templates/21/video/513483)

- [YouTube: Google Cloud Directory Sync](https://www.youtube.com/watch?v=bxzjwrYzScQ)

As you have seen, Cloud Identity provides a central console to manage all users and groups across your entire domain. The Google Cloud Directory Sync tool can help simplify provisioning and deprovisioning user accounts. Most organizations already have a Microsoft Active Directory or LDAP service containing user and group information. The Google Cloud Directory Sync tool can synchronize Google Workspace accounts to match the data in an existing Active Directory or LDAP server. Your Google users, groups, and shared contacts are synchronized to match the information in your Active Directory/LDAP server. As mentioned previously, Google Cloud Directory Sync (or GCDS) allows you to synchronize the data in your Google Account with your Microsoft Active Directory or LDAP server. The synching process occurs in 4 steps. First, data is exported as a list from your LDAP server or Active Directory. You set up rules to specify how and when this list is generated. Then, GCDS connects to your Google domain and generates a list of existing Google users, groups, and shared contacts that you specify. GCDS then compares the list exported from your Active Directory or LDAP server with the generated Google users list and updates your Google domain to match the data. Finally, when the synchronization is complete, a report is emailed to the addresses that you specified when configuring GCDS. An important note is that GCDS only performs one-way synchronization. You simply administer users in your Active Directory or LDAP environment and then periodically update your Google domain. The data in your directory server is never modified or compromised. GCDS runs as a utility within your server environment, it does not need to run in the cloud. This means there is no access to your Active Directory or LDAP server needed outside your organization’s IT perimeter. The GCDS auto-provisioning and deprovisioning functions will remove a user’s account and deprovision that account from all cloud apps once that user has been removed from your directory. This means there is no need to rely on a manual process for this important task, reducing both operational overhead and security risks.

### Video - [Managed Microsoft AD](https://www.cloudskillsboost.google/course_templates/21/video/513484)

- [YouTube: Managed Microsoft AD](https://www.youtube.com/watch?v=QRrMoqkPvW8)

Now let’s discuss Managed Microsoft Active Directory. If you are already using Microsoft Active Directory on-premises and want that service and configuration to extend to your Google Cloud deployments, you now have the option to use Google’s Managed Service for Microsoft Active Directory. Managed Microsoft AD uses actual Microsoft Active Directory controllers, so your work will not be interrupted by the need to resolve application incompatibilities. Because it is a managed service, Google will take care of most routine maintenance needs. This management includes providing a highly available, secured deployment configuration, plus automated system patching and maintenance of appropriate firewall rules. Managed Microsoft AD allows you to choose how your on-premises and cloud domains and workloads interact. For example, you can run each as a standalone domain, or you can connect your cloud domain with your on-premises domain. This image highlights a sample architecture that uses Managed Microsoft AD. Check out the video link in this module’s course resources for a Managed Microsoft AD deep dive. Managed Microsoft Active Directory offers many useful and familiar features. As already mentioned, it uses actual Active Directory domains, which in addition to ensuring compatibility with your applications, can also be integrated with Cloud DNS to allow domain discovery for VMs. If you already use Group Policies and Remote Server Administration Tools (or RSAT) in your on-premises network, your IT department will be able to continue to use these familiar tools to manage your cloud-based Active Directory domains. Note that a key difference between GCDS and Managed Microsoft AD is that GCDS syncs to Google from on-premises AD, while Managed Microsoft AD is a hardened Google Cloud service running actual Microsoft AD. Managed Microsoft AD runs on hardened, highly available servers and includes the ability to take snapshots to aid in recovery. With its multi-regional Infrastructure, Managed Microsoft AD gives your apps and VMs access to your domain over a low-latency Virtual Private Cloud, and additional regions can be added as needed to increase your workload capacity.

### Video - [Google authentication versus SAML-based SSO](https://www.cloudskillsboost.google/course_templates/21/video/513485)

- [YouTube: Google authentication versus SAML-based SSO](https://www.youtube.com/watch?v=vsdd_pvROzc)

Next, let’s discuss the two types of authentication which are supported by Google Cloud. Up until now, we’ve focused on the various services available for managing users. We’ll now focus on two different ways that Google handles user account authentication: Google authentication and Single Sign-On (SSO) authentication. The two authentication mechanisms are mutually exclusive. They cannot be combined, except within super admin accounts. Google Authentication is the primary mechanism for signing in to Google Cloud. Using this method, a Google password is stored within Google’s infrastructure. You can specify the minimum and maximum number of characters (within guidelines) and monitor the length and relative strength of your users’ passwords. Google also supports SAML 2.0 and OpenID-compliant Single Sign On systems. Using this method Google operates as the service provider and your SSO system operates as the identity provider. This means you can use your own authentication mechanism, and manage your own credentials. This method will also work with hundreds of applications, straight out of the box. SSO configuration in Google Cloud is a relatively simple process. In the Google Admin Console (which can be found at admin.google.com), you will need to: Check the Setup SSO with third-party identity provider box As well as provide the required 3 URLs (sign-in, sign-out and password change) and upload your certificate file You can also configure your Cloud Identity account for SSO. When you enable SSO, users aren't prompted to enter a password when they try to access Google services. Instead, they are redirected to an external identity provider (or IdP) to authenticate. Using SSO can provide several advantages: You enable a better experience for users because they can use their existing credentials to authenticate and don't have to enter credentials as often. You ensure that your existing IdP remains the system of record for authenticating users. And you don't have to synchronize passwords to Cloud Identity or Google Workspace. For more information on single sign-on, refer to the documentation link in this module’s course resources.

### Video - [Identity Platform](https://www.cloudskillsboost.google/course_templates/21/video/513486)

- [YouTube: Identity Platform](https://www.youtube.com/watch?v=JEfdmPdJObU)

Now let’s talk about Identity Platform. Identity Platform is a customer identity and access management (or CIAM) system that can help you add identity and access management functionality to your applications, protect user accounts, and scale with confidence. So, what is a CIAM system? Your Apps may have many registered users. CIAM’s allow your users to authenticate themselves using federated identity providers, such as Google, Twitter, Github or Meta for example. You can use Identity Platform for multi-tenant SaaS applications, mobile and web apps, games, APIs, and more. Identity Platform is perfect if you're building a service on Google Cloud—or anywhere else for that matter—and want a Google-grade, easy to use authentication service. Identity Platform supports authentication using passwords, phone numbers, popular federated identity providers like Google, Facebook, or Twitter, and any provider that supports SAML or the OpenID Connect protocol. Identity Platform integrates tightly with Google Cloud services, and it leverages industry standards like OAuth and OpenID Connect, so it can be easily integrated with your custom backend. Identity Platform provides Google-grade authentication, advanced user security, and planet-scale infrastructure. For more information and hands-on practice with Identity Platform, search for the Securing and Integrating Components of your Application course on your preferred on-demand learning platform.

### Video - [Authentication best practices](https://www.cloudskillsboost.google/course_templates/21/video/513487)

- [YouTube: Authentication best practices](https://www.youtube.com/watch?v=lK9zFZ0FEtI)

Finally, let’s look at some authentication best practices. As with other identity systems, you should avoid managing permissions for individual users. Managing individual users will add a significant amount of operational overhead. It is much better to assign Google Cloud roles to groups and let the Google Workspace or Cloud Identity admins handle group membership. Group administration is completely handled in the Google Admin Console, and users can be added or removed from groups without making any changes in IAM. For high-risk areas, you may want to make an exception to this practice -- assigning roles to individuals directly and foregoing the convenience of group assignment. For convenience, you should have at least two Organization admins. This provides redundancy in case one of them is not available for any reason or if an account is lost. But, be careful about adding too many admins to your organization—a general guideline is to add no more than three. When the organization is first created, all users in your domain are automatically granted Project Creator and Billing Account Creator IAM roles at the organization level. This enables users in your domain to continue creating projects without disruption. However, Organization Admins should remove these Organization-level permissions and start locking down access at a finer granularity as soon as possible.

### Video - [Demo Intro: Defining Users with Cloud Identity Console](https://www.cloudskillsboost.google/course_templates/21/video/513488)

- [YouTube: Demo Intro: Defining Users with Cloud Identity Console](https://www.youtube.com/watch?v=tkxrSUz4M2A)

In this lab demo, you learn how to perform the following tasks: Register for a free Google Cloud trial account (only if you do not already have a Google Cloud account) Sign up for the free edition of Cloud Identity Create your Cloud Identity account and first admin user Verify your domain for use with Cloud Identity Create Cloud Identity user accounts Assign a Cloud Identity user access to a Google Cloud project And utilize groups to simplify user management and lower operational overhead

### Video - [Lab Demo: Defining Users with Cloud Identity Console](https://www.cloudskillsboost.google/course_templates/21/video/513489)

- [YouTube: Lab Demo: Defining Users with Cloud Identity Console](https://www.youtube.com/watch?v=l9mTuS9g4jc)

Person: In this lab demonstration, we learn how to perform the following tasks: Sign up for free edition of Cloud Identity, create your Cloud Identity account, and your first admin user, then verify your domain for use with Cloud Identity, create Cloud Identity user accounts, assign a Cloud Identity user access to a GCP project, and utilize groups to simplify user management and lower operational overhead. Let's get started. To start, we enter the business name. Then we need to select the number of employees. On the next screen you can see that we enter the country for the business and then enter the business phone number. Next we need to choose an e-mail address, which will be used for notification. Then we need to select a domain name. So in this example we're going to use a preexisting domain name just to demonstrate the process. Then we will be asked to create an admin account, so enter your first name and last name for the administration user. And then you'll need to create a username for the administrator and finally, enter a password for the administrator. Great. Your Cloud Identity account is now set up. So moving into GCP we can see that we have a project B established, and this project will be set up to use the domain we specified. So now we want to select some users, but unfortunately we don't have any users identified for our domain. So switching to cloud admin, we can enter some new users. So following the on-screen prompts we can add a new user to our domain. And for good measure, let's add the second user. In addition, we can also create groups for our domain. Now that our group has been created we're going to add our existing users to that group. So as you remember we have two users created. So let's add them both. Great. Now switching back to our GCP project, Project B, when we try to add users now we should find that they are picked up from Cloud Identity and we are able to add them to our project. And as you'd expect you're able to assign roles to both users. Congratulations. You've successfully completed this lap.

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/21/video/513490)

- [YouTube: Module review](https://www.youtube.com/watch?v=JFfuDi2_fYo)

To wrap up, here’s an overview of what we discussed: Cloud Identity is an Identity as a Service (or IDaaS) solution. It’s tied to a unique DNS domain that is enabled for receiving email and does not need to be using Google Workspace services like Gmail or Drive. Cloud Identity is used for managing users, groups, and domain-wide security settings from a central location. The Google Cloud Directory Sync tool can synchronize Google Workspace accounts to match the data in an existing Active Directory or LDAP environment. Identity Platform can help you add identity and access management functionality to your applications, protect user accounts, and scale with confidence. And finally, we covered authentication best practices. Avoid managing permissions for individual users. It is best to assign Google Cloud roles to groups. And, you should have at least two Organization admins, but not more than three.

### Quiz - [Quiz: Securing Access to Google Cloud](https://www.cloudskillsboost.google/course_templates/21/quizzes/513491)

## Identity and Access Management (IAM)

Identity and Access Management (IAM) lets administrators authorize who can take action on specific resources, giving you full control and visibility to manage your cloud resources centrally. More specifically, we will cover; the Resource Manager which enables you to centrally manage projects, folders, and organizations, IAM roles and policies, including custom roles, and IAM best practices, including separation of duties and the principle of least privilege.

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/21/video/513492)

- [YouTube: Module overview](https://www.youtube.com/watch?v=yGdeNHqS-cY)

Welcome to module 3 of Managing Security in Google Cloud—Identity and Access Management. Identity and Access Management (or IAM as it is known) lets administrators authorize who can take actions on specific resources, giving you full control and visibility to manage your cloud resources centrally. More specifically, we will cover the Resource Manager which enables you to centrally manage projects, folders, and organizations. We will then cover IAM roles, and service accounts. We will then cover Workload Identity Federation, which allows you to grant on-premises or multi-cloud workloads access to Google Cloud resources, without using a service account key. We will continue with IAM and organization policies. After this, we will cover Policy Intelligence, which helps you understand and manage your policies to proactively improve your security configuration. We will end the module with best practices and a lab, where you will configure IAM to grant roles and create custom roles. Let’s get started!

### Video - [Resource Manager](https://www.cloudskillsboost.google/course_templates/21/video/513493)

- [YouTube: Resource Manager](https://www.youtube.com/watch?v=QYvfaOTCNPM)

OK, let's dive into IAM and how to centrally manage your resources with the Resource Manager. IAM lets administrators authorize who, can do what, on which resources in Google Cloud. It provides full control and visibility to manage cloud resources centrally. Google Cloud provides resource containers such as Organizations, Folders, and Projects, which allow you to group and hierarchically organize cloud resources. This hierarchical organization lets you easily manage common aspects of your resources, like access control and configuration settings. The Resource Manager enables you to programmatically manage these resource containers. There are several objects that are important when discussing IAM in Google Cloud. These objects are: Organizations, Folders, Projects, Resources, Members, and Roles. These objects together form a resource hierarchy that can be managed using the Resource Manager. This Google Cloud resource hierarchy allows you to map your organization onto appropriate Google Cloud objects and presents logical attach points for access management policies. The organization node is the root node for Google Cloud resource hierarchy. It is the “super node” for all of your projects and resources and represents your organization. Folders can be used to implement organizational structure and/or group projects by department, team, application or environment. A folder can contain projects, other folders, or a combination of both. Organizations can use folders to group projects under the organization node in a hierarchy. For example, your organization might contain multiple departments, each with its own set of Google Cloud resources. Folders allow you to group these resources on a per-department basis. While a folder can contain multiple child folders or other resources, each folder or resource can only have exactly one parent. Folders are used to group resources that share common IAM policies. You can use folder-level IAM policies to control access to the resources the folder contains. For example, if a user is granted the Compute Instance Admin role on a folder, that user has the Compute Instance Admin role for all of the projects in the folder. You can also use deny policies in combination with roles, to restrict access to resources in a folder. It is important to note that the use of folders to organize resources is optional. Projects, however, are required in Google Cloud and any resource that is deployed must be associated with a project. Projects provide many management-related features, such as the ability to track resource and quota usage, assign projects to different billing accounts, assign manager permissions and credentials, and selectively enable specific services and APIs at the project level. The following slide demonstrates a sample organization—example.com— that has two folders: one for development and one for production. Each folder contains projects that contain Google Cloud resources.

### Video - [IAM roles](https://www.cloudskillsboost.google/course_templates/21/video/513494)

- [YouTube: IAM roles](https://www.youtube.com/watch?v=Z4BhIFDyMhU)

Now that you’ve learned a little bit about Resource Manager, let’s dive into Cloud IAM roles. In Google Cloud, you can grant permissions by granting roles. In this section, we will first review, and then take a more in-depth look at the different types of roles available. There are three kinds of roles in IAM: The first type are Basic roles: These are the roles that have been historically available in the Cloud Console. These roles existed prior to the introduction of IAM. The second type are Predefined roles: Also sometimes called “curated roles,” are the IAM roles that give finer-grained access control than the basic roles. Each Google Cloud service offers a set of predefined roles. And finally, we have Custom roles: Here, you can define roles consisting of permissions and resources of your choice. The IAM basic roles are applied at the project or service resource levels and control access to all resources in that project or resource. The level of access these provide is very coarse-grained and that is why they are called basic roles. They control what can be done on all resources in a project. There are three types of basic roles: Owner, Editor, and Viewer. These roles are concentric; that is, the Owner role includes the permissions in the Editor role, and the Editor role includes the permissions in the Viewer role. The Viewer role, as its name implies, provides view or read-only access to a project and all its resources. The Editor role provides the ability to modify or edit all resources in the project, as well as all the read-only access from the viewer role. The Owner role provides the ability to manage the project itself, such as deleting the project, and adding or removing other members to the project, as well as all the Editor role permissions plus the read-only access from the Viewer role. The Billing Administrator is an owner role for a billing account. Use it to manage payment instruments, configure billing exports, view cost information, link and unlink projects and manage other user roles on the billing account. As you have seen, basic roles are coarse-grained and are applied at the project level. Often items, these roles provide unnecessary access to Google Cloud services and resources, which can pose a Security risk to your cloud environment. Predefined roles on the other hand provide granular access for a specific service. They are designed to map to job functions, for example, Compute Network Admin, Security Reviewer, Storage Admin, and much more. Predefined roles are managed by Google Cloud. So if a new feature or service is added in the future, the appropriate permissions will be added to any predefined role that requires them. A predefined role is simply a collection of permissions for a particular service. For example, the InstanceAdmin predefined role provides the permissions needed to manage Compute Engine instances. An example of some of the permissions inherent in this role are shown here on the slide. As you can see, predefined roles give granular access to specific Google Cloud resources and prevent unwanted access to other resources. The predefined Browser role provides read-access to browse the hierarchy for a project, including the folder, organization, and IAM policy. The Browser role does not include permission to view resources in the project. So, what if you need something even finer-grained? This is when you might use a Custom role, which will allow you to map specific permissions to specific job roles. For example, maybe you need to define a “Privacy Reviewer” role, to allow some users the ability to audit data that is stored in Google Cloud Storage, Cloud Spanner, Cloud Bigtable, and other data repositories. You can create a Custom role which contains all of the specific permissions needed to do that particular job—and only those permissions. Be aware that once Custom roles are created, you must manage the permissions granted for them. If, for example, a new data storage service is created in the future that will need to be audited, permissions for that new service would need to be added to your Privacy Reviewer role.

### Video - [Service accounts](https://www.cloudskillsboost.google/course_templates/21/video/513495)

- [YouTube: Service accounts](https://www.youtube.com/watch?v=rUmJf8yAIy4)

Now, let’s talk about service accounts. In addition to the members already mentioned, you can also grant roles to service accounts. Service accounts control server-to-server interactions and are used to authenticate from one service to another and control what actions applications running on a service can perform. For example, if an application running on a Compute Engine instance needs to read a file from Cloud Storage, a service account with Cloud Storage Object Viewer role can be assigned to the Compute Engine instance. An application running on that instance would then be permitted to read a file from Cloud Storage. Service accounts are identified with a Google-managed email address in the gserviceaccount.com domain. There are two types of Google Service Accounts: Service accounts that Google manages, and service accounts that you manage. Some Google services need access to your resources so that they can act on your behalf. For example, when you use Cloud Run to run a container, the service needs access to any Pub/Sub topics that can trigger the container. To meet this need, Google creates and manages service accounts for many Google Cloud services. These service accounts are known as Google-managed service accounts. You might see Google-managed service accounts in your project's allow policy, in audit logs, or on the IAM page in the Google Cloud console. Google-managed service accounts aren't created in your projects, so you won't see them when viewing your projects' service accounts. And because accounts are not listed in your project, you won’t be able to access them directly. User-managed service accounts are service accounts that you create in your projects. You can update, disable, enable, and delete those service accounts at your discretion. You can also manage other principals' access to these service accounts. You can create user-managed service accounts in your project using the IAM API, the Google Cloud console, or the Google Cloud CLI. By default, you can create up to 100 user-managed service accounts in a project. Unlike normal users, service accounts do not have passwords. Instead, service accounts use RSA key pairs for authentication: If you know the private key of a service account's key pair, you can use the private key to create a JWT bearer token and use the bearer token to request an access token. The resulting access token reflects a service account's identity and you can use it to interact with Google Cloud APIs on the service account's behalf. Because the private key lets you authenticate as the service account, having access to the private key is similar to knowing a user's password. The private key is shown as a service account key. The key pairs used by service accounts fall into two categories, Google-managed and user-managed. Now, all service accounts have Google-managed key-pairs. With Google-managed service account keys, Google stores both the public and private portion of the key, and rotates them regularly. Each public key can be used for signing for a maximum of two weeks. Your private key is always held securely in escrow and is never directly accessible. You may optionally create one or more user-managed key pairs (also known as "external" keys) that can be used from outside of Google. Google only stores the public portion of a user-managed key. The user is responsible for security of the private key and performing other management operations such as key rotation, whether manually or programmatically. If you lose them, Google cannot help you recover them. Users can create up to 10 service account keys per service account to facilitate key rotation. And user-managed keys can be managed by using the IAM API, the gcloud command-line tool, or the Service Accounts page in the Google Cloud console. A final tip: the gcloud command line shown on this slide is a fast and easy way to list all of the keys associated with a particular service account.

### Video - [Workload Identity Federation](https://www.cloudskillsboost.google/course_templates/21/video/513496)

- [YouTube: Workload Identity Federation](https://www.youtube.com/watch?v=92sjbjoFh3M)

Let’s discuss Workload Identity Federation. Using Workload Identity Federation, you can grant on-premises or multi-cloud workloads access to data stored in Google Cloud services without service account keys. Traditionally, applications running outside Google Cloud have used service account keys to access Google Cloud resources. Service account keys are powerful credentials, and can represent a security risk if they are not managed correctly. Service account keys are akin to user passwords, allowing the holder to act as the service account and gain access to any resource that service account has access to. Unfortunately, there's no way to verify that the application holding the key has permission to use it. It's a key without an expiration date and with no guarantee around where it's stored or who has access to it. Because of this risk, managing the storage, distribution, and rotation of service account keys becomes a top priority, effectively turning an identity management problem into a secrets management problem. So, what's the solution? Ditch the keys. With workload identity federation, you can use Identity and Access Management to grant external identities IAM roles, including the ability to impersonate service accounts. This lets you access resources directly, using temporary credentials—or “tokens”—and eliminates the maintenance and security burden associated with service account keys. To set up workload identity federation, you'll first need to create a workload identity pool in your Google Cloud project. Fortunately, you don't need to be a super admin to do this. You only need permission to manage workload identity pools, service accounts, and IAM policies at the project level. A workload identity pool allows you to organize and manage external identities. A project can have multiple pools with each one allowing access from a different external identity provider. You'll need to create an IAM policy that allows identities in the workload identity pool to impersonate the service account. This allows you to create collections of identities and easily control the permissions granted to identities from each identity provider. To learn more about identity pools, view the documentation linked in this module’s course resources. After you have your identity pool set up, your application authenticates to your identity provider and receives account credentials. The application can then call a security token service to exchange the account credentials issued by your identity provider for a short-lived Google Cloud access token. Afterwards, a one-way trust between your identity provider and the workload identity pool is configured by providing relevant metadata about your provider. Now, when an application attempts to exchange their IDP credential, the security token service will be able to validate that the credential is from a trusted provider before issuing an access token to the application. We've mitigated a security risk while maintaining the ability to reliably make Google Cloud API requests. To learn more about how workload identity federation can help you better protect your Google Cloud access, check out the video link in the course resources.

### Video - [IAM & Organization policies](https://www.cloudskillsboost.google/course_templates/21/video/513497)

- [YouTube: IAM & Organization policies](https://www.youtube.com/watch?v=VdLvZ6Yj8A4)

Let’s now move on and discuss IAM policies. A policy is a collection of access statements attached to a resource. Each policy contains a set of roles and role members, with resources inheriting policies from their parent. You can think of it like this: resource policies are a union of parent and resource, where a less restrictive parent policy will always override a more restrictive resource policy. In addition to policies which grant access, there are also deny policies that can be used to restrict access. We will talk about deny policies in a moment. Another way to express the hierarchy of policies is: "allowed permissions are always inherited down the resource hierarchy unless overridden by a deny policy." You can grant access to Google Cloud resources by using allow policies, also known as IAM policies, which are attached to resources. The allow policy controls access to the resource itself, as well as any descendants of that resource that inherit the allow policy. An allow policy associates, or binds, one or more principals (also known as a member or identity) with a single IAM role and any context-specific conditions that change how and when the role is granted. In the example on this slide, Jie (seen here as jie@example.com) is granted the Organization Admin predefined role (which you can see here as roles/resourcemanager.organizationAdmin), and that is in the first role binding. This role contains permissions for organizations, folders, and limited project operations. In the second role binding, both Jie and Raha (seen here as raha@example.com) are granted the ability to create projects via the Project Creator role (which you can see here as roles/resourcemanager.projectCreator). Together, these role bindings grant fine-grained access to both Jie and Raha, and Jie is granted more access than Raha. Now let’s talk about IAM deny policies. IAM deny policies let you define deny rules that prevent certain principals from using certain permissions, regardless of the roles they're granted. Each deny rule specifies a set of principals that are denied permissions, the permissions that the principals are denied, or unable to use, and optionally, the condition that must be true for the permission to be denied. When a principal is denied a permission, they can't do anything that requires that permission, regardless of the IAM roles they've been granted. This is because IAM always checks relevant deny policies before checking relevant allow policies. IAM deny policies let you set guardrails on access to Google Cloud resources. With deny policies, you can define deny rules that prevent certain principals from using certain permissions, regardless of the role they're granted. Deny policies are made up of deny rules. IAM Conditions are specified in the role bindings of a resource's IAM policy. IAM Conditions allow you to define and enforce conditional, attribute-based access control for Google Cloud resources. With IAM Conditions, you can choose to grant resource access to identities (or members) only if configured conditions are met. Condition attributes are either based on the requested resource —for example, its type or name— or on details about the request— for example, its timestamp or destination IP address. There are two subtypes of condition attributes: Resource attributes, which allow you to write conditions that evaluate the resource in the access request. And request attributes, which allow you to write conditions that evaluate details about the request. As an example, think about if you wanted to only allow access to Cloud Storage buckets whose names start with a specified prefix. Since this is a resource your condition is focused on, your condition attribute would look like what’s on the slide. For more information on how to use IAM Conditions, refer to the documentation linked in this module’s course resources. An organization policy gives you centralized and programmatic control over your organization's cloud resources. Organization policies are set on organizations, folders, and projects in order to enforce the restrictions on that resource and its descendants. In order to define an organization policy, you choose a constraint, which is a particular type of restriction against either a Google Cloud service or a group of Google Cloud services. You configure that constraint with your desired restrictions. Descendants of the targeted resource hierarchy node inherit the organization policy. By applying an organization policy to the root organization node, you are able to effectively drive enforcement of that organization policy and configuration of restrictions across your organization. The example on the slide shows an organization policy that’s used to disable service account creation. You can think of a constraint as a blueprint that defines what behaviors are controlled. The enforcing service will evaluate the constraint type and value to determine the restriction. There are 2 main constraint types: list and boolean. The list constraint type allows or disallows values within a list. An example is the “compute.vmExternalIpAccess” list constraint. This constraint defines the set of Compute Engine VM instances that are allowed to use external IP addresses. Remember that by default, all Compute Engine instances are allowed to use external IP addresses. Boolean constraint types turn policies on or off. An example of this constraint type would be the “compute.disableSerialPortAccess” constraint. Of course, there are many different constraints for different Google Cloud services. This slide shows a few more constraints that are available for some other services. When you set an organization policy on a resource hierarchy node, all descendants of that resource hierarchy node inherit the organization policy by default. If you set an organization policy at the root organization node, then those restrictions are inherited by all child folders, projects, and resources. In the resource hierarchy diagram in this slide, each node sets a custom organization policy and defines whether it inherits its parent node's policy. You can learn more about organization policy inheritance from the documentation linked in this module’s course resources. Organization policies and their constraints are not the same thing as IAM policies and bindings. Organization policies and IAM policies compliment one another. Organization Policies focus on what, and lets the administrator set restrictions on specific resources, services, or groups of services to determine how they can be configured and used. IAM policies focus on who, and lets the administrator authorize who can take action on specific resources or services based on permissions.

### Video - [Policy Intelligence](https://www.cloudskillsboost.google/course_templates/21/video/513498)

- [YouTube: Policy Intelligence](https://www.youtube.com/watch?v=BNWHVP9qP_I)

Now, let’s discuss the Policy Intelligence suite. Policy Intelligence will assist you through the lifecycle of policy management to manage policies securely and with confidence. Policy Intelligence gives you a suite of tools for troubleshooting, analysis, and recommendations. These allow you to find out what went wrong quickly so you can take action right away with troubleshooting tools. Prevent mistakes from happening all together with analytical tools. Improve your security posture with actionable recommendations. And understand IAM policy changes before they are made. IAM Policy Troubleshooter helps you more closely examine policies that govern user access to a particular resource. This tool makes it easier to understand why a user has access to a resource or doesn't have permission to call an API. In order to generate a Policy Troubleshooter report, you will need the email of the user who needs access, the full name of the resource they need access to, and a permission that you want to check for. Troubleshooter will take this information and examine all the IAM policies that apply to that particular resource and then report on whether it found that permission for that user in the resource’s list of permissions. It will also report on the policies that bind that user to those roles. For security reasons, Policy Troubleshooter can only examine policies that the person using it has permissions to access. Because Troubleshooter cannot analyze permissions it does not have access to, it may not always be able to fully explain a resource’s access policies. If maximum effectiveness is the overriding concern, the member using the Policy Troubleshooter must be granted the Security Reviewer role. You can access Policy Troubleshooter using the console, the Google Cloud CLI, or the REST API. For simple queries, using the console is typically the fastest. For more complex scenarios, consider the gcloud CLI or the REST API. Policy Analyzer lets you find out which principals (for example, users, service accounts, groups, and domains) have what access to which Google Cloud resources based on your IAM allow policies. Policy Analyzer can help you answer questions like, Who can access this IAM service account? Who can read data in this BigQuery dataset that contains personally identifiable information (PII)? And what roles and permissions does the dev-testers group have on any resource in this project? Role recommendations help you identify and remove excess permissions from your principals, improving your resources' security configurations. Recommender identifies excess permissions using policy insights. Policy insights are ML-based findings about a principal's permission usage. Each role recommendation suggests that you remove or replace a role that gives your principals excess permissions. At scale, these recommendations help you enforce the principle of least privilege by ensuring that principals have only the permissions that they actually need. Recommender evaluates only role grants that were made at the project level and that have existed for at least 90 days. It does not evaluate any of the following items: conditional role grants, role grants for Google-managed service accounts, and access controls that are separate from IAM. Recommender will suggest that you revoke an existing role when it has been in effect for 90 days or more and when it has not been used within the past 90 days. The theory with this type of recommendation is that if the policy has not been used within the past 90 days, it may have been unnecessarily granted, or it may have outlived its usefulness. Removing such permissions keeps your roles pruned down to only those permissions that are actually required, which is a foundational security concept. Recommender may also suggest that you replace a particular role with another role or set of roles. For example, if a service account has an assigned role with permissions that are not used, it would be more secure if you revise it to use a combination of less-permissive roles that have only the necessary permissions. And, finally, Recommender may suggest that you add permissions to a role, even if those permissions are not currently being used. Recommender uses machine learning to predict which permissions may be needed by a particular role in the future. If those permissions are not currently enabled, Recommender will suggest adding them. Recommender creates daily IAM policy recommendations and serves them to you automatically. Your recommendations can be found on the IAM page in the list of current roles for your account. Next to each role, in the “over granted permissions” column, you will see one of two icons: a lightbulb that is either greyed out or one that is golden-orange and “lit,” indicating that there are recommendations available for that role. If a role has recommendations, clicking on the Recommendation available icon will show you more details about the recommendation, and you can then choose to accept and apply a recommendation or dismiss it. If you change your mind within 90 days about accepting or dismissing a recommendation, you can use the IAM Recommender logs to revert that decision. While using the Cloud console is the easiest way to manage your recommendations, you can also review and apply recommendations using the gcloud command-line tool and the Recommender API. Policy Simulator is a powerful tool that allows you to "try before you buy" when it comes to IAM policy changes. This reduces the risk of unexpected side effects. Before you make any adjustments to your permissions, Policy Simulator lets you test out the potential impact. It uses your actual historical access log data to predict whether a policy change will increase or reduce access levels for specific users and resources. This way, you can avoid breaking critical workflows, ensure essential access remains open, and gain greater confidence in implementing IAM policy changes. Now, Policy Simulator isn't just a theoretical "what if" tool; it works by grounding its analysis in your actual user activity patterns. This works by you providing the policy you want to test. The simulator will then go back in time and pull your recent access logs. Essentially, it replays those access attempts. Now the key difference here is that it replays them under both the rules of your existing policy and the rules of the proposed one. And the output, it isn’t guesswork. It's a data-driven analysis of how your proposed change will likely impact your users' ability to access Google Cloud resources based on their real-world usage patterns.

### Video - [IAM best practices](https://www.cloudskillsboost.google/course_templates/21/video/513499)

- [YouTube: IAM best practices](https://www.youtube.com/watch?v=DglzfDvuMw4)

Now, let’s discuss IAM best practices... The first is to always use the principle of least privilege - which just means always apply the minimal access level required to get the job done. If a particular role has too many permissions for that job, create a Custom role so you can whittle permissions down to only what is needed. Not only is this practice more secure, it can also help prevent incidents from occurring - such as the accidental editing or removal of a required resource. When creating policies, remember that a less restrictive parent policy will always override a more restrictive resource policy, so check when implementing parent policies to make sure you do not inadvertently grant more access to a child resource than you intended. For example, if someone in your organization is a project editor, you cannot restrict their access to a specific resource within that project. However, you can create deny policies that will prevent their access. Remember that deny policies are always applied before access policies. Disciplined and meticulous management of IAM is especially important in Google Cloud. Since access management is centralized, users can be given powerful permissions that allow them to control and manage Google Cloud resources. In on-premises environments, the target systems were physically discrete, which made it a challenge to have centralised control. In turn, the blast radius of misconfigurations were managed to an extent due to these physical boundaries between systems. It is best to use groups when configuring Google Cloud access, and… assign roles to the groups instead of individual users. Groups are defined and maintained in the Cloud Console for Google Workspace or Cloud Identity domains, they are not configured in Google Cloud, so using groups will drastically reduce the administration needed by Google Cloud admins. Only minimal changes will be needed within Google Cloud once groups and roles are defined. Then users can simply be added or removed from groups by your Google Workspace or Cloud Identity admin. Another best practice is to use predefined roles as basic roles can be overly permissive. For example, providing a user with a Compute Engine admin role is more fine-grained than giving a user an editor role, where they have access to any and all cloud resources. Try to utilize predefined roles if they meet your requirements as predefined roles offer less administration. Predefined roles are managed by Google and their permissions are automatically updated as necessary. For example: when new features or services are added to Google Cloud, all related predefined roles will be updated as needed. Custom roles on the other hand are not maintained by Google. When new permissions, features, or services are added to Google Cloud, your custom roles will not be updated automatically. And lastly, don’t forget to use the Policy Intelligence suite to manage policies securely and with confidence.

### Video - [Lab Intro: Configuring IAM](https://www.cloudskillsboost.google/course_templates/21/video/513500)

- [YouTube: Lab Intro: Configuring IAM](https://www.youtube.com/watch?v=NMBGcy-4SEA)

The objectives for this lab are for you to: Use IAM to implement access control, Restrict access to specific features or resources, Use predefined roles to provide Google Cloud access, Create custom IAM roles to provide permissions based on your own job roles, and Modify custom roles.

### Lab - [Configuring IAM](https://www.cloudskillsboost.google/course_templates/21/labs/513501)

Configuring IAM, including custom roles and organization policies

- [ ] [Configuring IAM](../labs/Configuring-IAM.md)

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/21/video/513502)

- [YouTube: Module review](https://www.youtube.com/watch?v=zQfG7IPhBpQ)

To wrap things up, here’s an overview of some topics we covered in this module: IAM lets administrators authorize who can take action on specific resources. Resources in Google Cloud are hierarchically managed by organization, folders, and projects. Permissions are given to members by granting roles. Google Cloud provides predefined roles, and the ability to create custom roles. Service Accounts control server-to-server interactions and are used to authenticate from one service to another. Workload identity federation allows you to grant on-premises or multi-cloud workloads access to Google Cloud resources without using a service account key. Recommender creates daily IAM policy recommendations and serves them to you automatically. And the IAM Policy Troubleshooter makes it easier to understand why a user has access to a resource or doesn't have permission to call an API.

### Quiz - [Quiz: Identity and Access Management](https://www.cloudskillsboost.google/course_templates/21/quizzes/513503)

#### Quiz 1.

> [!important]
> **Which TWO of the following statements about Cloud IAM Policies is TRUE?**
>
> - [ ] An organization policy can only be applied to the organization node.
> - [ ] A less restrictive parent policy will not override a more restrictive child resource policy.
> - [ ] A Policy binding binds a list of members to a role.
> - [ ] A policy is a collection of access statements attached to a resource.

#### Quiz 2.

> [!important]
> **Which THREE of the following are IAM Objects that can be used to organize resources in Google Cloud?**
>
> - [ ] Organization
> - [ ] Folder
> - [ ] Role
> - [ ] Instance
> - [ ] Bucket
> - [ ] Container
> - [ ] Project
> - [ ] Member

#### Quiz 3.

> [!important]
> **Projects in Google Cloud provide many management-related features, including the ability to (choose TWO)**
>
> - [ ] Selectively enable specific services and APIs.
> - [ ] Track and manage quota usage.
> - [ ] Balance server load between different Projects.
> - [ ] Keep on-prem AD/LDAP accounts synced up with user's Google Cloud resources.

## Configuring Virtual Private Cloud for Isolation and Security

Managed networking on Google Cloud utilizes a Virtual Private Cloud (or VPC). In this module we will discuss VPC related security concepts including: VPC firewalls, load balancing SSL policies, network Interconnect & peering options, VPC network best practices and VPC flow logs. You will also have the opportunity to practice what you've learned, by completing the labs exercises "Configuring VPC Firewalls" and "Configuring and Using VPC Flow Logs in Cloud Logging." 

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/21/video/513504)

- [YouTube: Module overview](https://www.youtube.com/watch?v=iKDQd5QncIA)

Welcome to module 4 of Managing Security in Google Cloud: Configuring Virtual Private Cloud for Isolation and Security. In this module, we will discuss many VPC related security concepts including VPC firewalls, load balancing and SSL policies, network interconnect and peering options, VPC service controls Access context manager, VPC flow logs, and Cloud IDS. You will also have the opportunity to practice what you’ve learned, by completing the Configuring VPC Firewalls, Configuring and Using and Viewing VPC Flow Logs in Cloud Logging, and Getting Started with Cloud IDS hands-on labs.

### Video - [VPC firewall rules](https://www.cloudskillsboost.google/course_templates/21/video/513505)

- [YouTube: VPC firewall rules](https://www.youtube.com/watch?v=cCl6MVsO7GE)

Let’s get started by learning more about VPCs and VPC firewalls. A Virtual Private Cloud (or VPC) is a global, private, isolated virtual network partition that provides managed networking functionality for your Google Cloud resources. A VPC network on Google Cloud lets you create and control your own private, logically isolated network, where you can deploy your Google compute resources (for example, Compute Engine instances, Google Kubernetes Engine instances, and so on). Each VPC network in your project provides private communication among your Google Cloud compute resources. You can control individual ingress and egress traffic for compute resources using firewall rules. You can also connect your on-premise network with your VPC network using VPN IPsec Tunnels or Dedicated Interconnect. Google Cloud firewall rules let you allow or deny traffic to and from your VM instances based on a configuration you specify and can be applied to both inbound (or ingress) and outbound (or egress) traffic. Google Cloud firewall rules provide effective protection and traffic control regardless of the operating system your instances use. Google Cloud firewall rules are defined for the VPC network as a whole, and since VPC networks can be global in Google Cloud, firewall rules are also global. Every VPC network functions as a distributed firewall. While firewall rules are defined at the network level, connections are allowed or denied on a per-instance basis. You can think of the Google Cloud firewall rules as existing not only between your instances and other networks, but between individual instances within the same network. Firewall rules can be applied to your network and resources in several ways. Applying rules to all instances in the network means the rule will apply to every instance running in that VPC network without having to tag or mark the instances in any other way. Applying rules to instances tagged with a specified target tag requires any instance needing the firewall rule to be “tagged” with the firewall rule target tag. Lastly, applying firewall rules to specific service accounts will apply those rules to both new instances created and associated with the service account and existing instances, if you change their service accounts. Note that changing the service account associated with an instance requires that you stop and restart it for the change to take effect. Google Cloud firewalls are stateful, which means for each initiated connection tracked by allow rules in one direction, the return traffic is automatically allowed, regardless of any other rules in place. In other words, firewall rules allow bidirectional communication once a session is established. The connection is considered active if at least one packet is sent every 10 minutes. A firewall rule is composed of many settings that are specified by the following five parameters: Direction rules can be applied depending on the connection direction. Values can be ingress or egress. The source parameter is only applicable to ingress rules and the destination parameter is only applicable to egress rules. Firewall targets can be applied to all instances in a network, source tags, and service accounts, and can be further filtered by IP addresses or ranges. Another parameter is the Protocol (such as TCP, UDP, or ICMP) and the port number. You can specify a protocol, a protocol and one or more ports, a combination of protocols and ports, or nothing. If the protocol is not set, the firewall rule applies to all protocols. The action parameter can be set to either allow or deny, and will determine if the rule permits or blocks traffic. Finally, the Priority parameter is a numerical value from zero to 65,535, which is used to determine the order the rules are evaluated. Rules are evaluated starting from zero, so a lower number indicates a higher priority. If you do not specify a priority when creating a rule, it is assigned a priority of 1000. When evaluating rules, the first rule that matches is the one that will be applied. If two rules have the same priority the rule with a deny action overrides a rule with an allow action.

### Video - [VPC firewall defaults](https://www.cloudskillsboost.google/course_templates/21/video/513506)

- [YouTube: VPC firewall defaults](https://www.youtube.com/watch?v=xkKx9Nyphco)

It’s important to note that all VPCs have implied firewall rules. Implied IPv4 firewall rules are present in all VPC networks, regardless of how the networks are created, and whether they are auto mode or custom mode VPC networks. The default network has the same implied rules. The first implied firewall rule is an egress rule whose action is allow, destination is 0.0.0.0/0, and priority is the lowest possible (65535), which lets any instance send traffic to any destination, except for traffic blocked by Google Cloud. The second implied firewall rule is an ingress rule whose action is deny, source is 0.0.0.0/0, and priority is the lowest possible (65535), which protects all instances by blocking incoming connections to them. A higher priority rule might allow incoming access. If IPv6 is enabled, the VPC network also has these two implied rules: An egress rule whose action is allow, destination is ::/0, and priority is the lowest possible (65535), which lets any instance send traffic to any destination, except for traffic blocked by Google Cloud. A higher priority firewall rule may restrict outbound access. Internet access is allowed if no other firewall rules deny outbound traffic and if the instance has an external IP address. The second implied rule is an ingress rule whose action is deny, source is ::/0, and priority is the lowest possible (65535), which protects all instances by blocking incoming connections to them. A higher priority rule might allow incoming access. The implied rules cannot be removed, but they have the lowest possible priorities. For more information on implied rules, refer to the documentation link in this module’s course resources. You will also find links to more information on subnet ranges and blocked traffic. In Google Cloud, all projects get a default VPC created automatically. In addition to the implied rules, the default VPC network is pre-populated with firewall rules that allow incoming, or ingress, traffic to the instances. The first rule is default-allow-internal, which allows ingress connections for all protocols and ports among instances within the VPC network. It effectively permits incoming connections to VM instances from others in the same network. The other three rules in the default network are default-allow-ssh, default-allow-rdp, and default-allow-icmp. These rules allow port 22 - also known as secure shell (or ssh), port 3389 - also known as remote desktop protocol (or RDP), and ICMP traffic respectively, from any source IP address to any instance in the VPC network. All of these rules have the second-to-lowest priority of 65534. As you may have noticed, some of these rules can be a little dangerous. These rules can (and should) be deleted or modified as necessary. Some network traffic is always allowed. For VM instances, VPC firewall rules and hierarchical firewall policies do not apply to packets sent to and received from the Google Cloud metadata server, and packets sent to an IP address assigned to one of the instance's own network interfaces (or NICs) where packets stay within the VM itself. IP addresses assigned to an instance's NIC include: The primary internal IPv4 address of the NIC. Any internal IPv4 address from an alias IP range of the NIC. If IPv6 is configured on the subnet, any of the IPv6 addresses assigned to the NIC. An internal or external IPv4 address associated with a forwarding rule, for load balancing or protocol forwarding, if the instance is a backend for the load balancer or is a target instance for protocol forwarding. Loopback addresses, and, addresses configured as part of networking overlay software you run within the instance itself. For more information on always allowed traffic, refer to the documentation link in this module’s course resources. You will also find links to more information on hierarchical firewall policies, the Google Cloud metadata server, and alias IP ranges. There is some network traffic that is always blocked on VPC networks. Google Cloud accounts for bandwidth per VM instance, for each network interface (NIC) or IP address. A VM's machine type defines its maximum possible egress rate; however, you can only achieve that maximum possible egress rate in specific situations. Google Cloud protects each VM by limiting ingress traffic delivered to an external IP address associated with the VM. Google Cloud blocks incoming DHCP offers and acknowledgments from all sources except for DHCP packets coming from the metadata server. External IPv4 and IPv6 addresses only accept TCP, UDP, ICMP, ICMPv6, IPIP, AH, ESP, SCTP, and GRE packets. By default, Google Cloud blocks egress packets sent to TCP destination port 25 of an external IP address (including an external IP address of another Google Cloud resource). However, this traffic is not blocked in projects owned by select Google Cloud customers. For more information on blocked traffic, refer to the documentation link in this module’s course resources. You will also find a link to more information on machine types.

### Video - [VPC firewall best practices](https://www.cloudskillsboost.google/course_templates/21/video/513507)

- [YouTube: VPC firewall best practices](https://www.youtube.com/watch?v=NlG6SCPRHNY)

There are a few firewall rule best practices to help secure instances running in Compute Engine. Keep your firewall rules in line with the model of least privilege. Create rules to explicitly allow only traffic necessary for your applications to communicate. It’s always best to minimize direct exposure to the internet. To do this, avoid having “allow” firewall rules defined with the source or destination range set to 0.0.0.0/0. To prevent ports and protocols from being exposed accidentally, create a firewall rule with the lowest priority that blocks all outbound traffic for all protocols and ports. This rule will override the implied egress rule that allows all outbound traffic and instead lock down your Compute Engine instances from making connections. You should then create higher-priority firewall rules for specific Compute Engine instances to open required ports and protocols. This helps prevent ports and protocols from being exposed unnecessarily. Another best practice is to adopt a standard naming convention for firewall rules. The exact format is not critically important, just create a standard and be consistent. An example of a naming convention would be to include the following information in your firewall rules: The direction, which is ingress (allow) or egress (deny) indicating the rule’s action. The service or protocol name. And the word “from” or “to” and then a short description of the source or destination. Examples using this formation would be ingress-allow-ssh-from-onprem and egress-allow-all-to-gcevms. When applying firewall rules, you should consider using service account firewall rules instead of tag-based rules. The reason for this is that tag-based firewall rules can be applied by any user who has the Compute Engine Instance Admin role, but users require explicit IAM rights to use a service account. Hierarchical firewall policies let you create and enforce a consistent firewall policy across your organization. You can assign hierarchical firewall policies to the organization as a whole or to individual folders. These policies contain rules that explicitly deny or allow connections, as do Virtual Private Cloud (VPC) firewall rules. Global and regional network firewall policies improve upon the previous VPC firewall rules structure. Similar to hierarchical firewall policies, these network firewall policy structures act as a container for firewall rules. Rules defined in a network firewall policy are enforced once the policy is associated with a VPC network, enabling simultaneous batch updates to multiple rules in the same policy. The same network firewall policy can be associated with more than one VPC network, and each VPC network can only have one global network firewall policy, and one regional firewall policy, per region, associated with it. Both global network firewall policies and regional network firewall policies support IAM-governed tags, and all Cloud firewall enhancements moving forward will be delivered on the new network firewall policy constructs. A global network firewall policy provides a global firewall configuration structure to match the global nature of Google Cloud VPC networks. It applies to workloads deployed in all Google Cloud regions in the VPC network. A regional network firewall policy provides a regional firewall configuration structure for Google Cloud firewalls that can only be used in a single target region. When using regional network firewall policies, users can designate a target region for a firewall policy. The firewall configuration data will be applied to workloads only in that specific region and will not be propagated to any other Google Cloud regions. Firewall Insights, a component product of Network Intelligence Center, produces metrics and insights that let you make better decisions about your firewall rules. It provides data about how your firewall rules are being used, exposes misconfigurations, and identifies rules that could be made more strict. Firewall Insights uses Cloud Monitoring metrics and Recommender insights. Cloud Monitoring collects measurements to help you understand how your applications and system services are performing. A collection of these measurements is generically called a metric. The applications and system services being monitored are called monitored resources. Measurements might include the latency of requests to a service, the amount of disk space available on a machine, the number of tables in your SQL database, the number of widgets sold, and so forth. Resources might include virtual machines, database instances, disks, and so forth. Recommender is a service that provides recommendations and insights for using resources on Google Cloud. These recommendations and insights are per-product or per-service, and are generated based on heuristic methods, machine learning, and current resource usage. You can use insights independently from recommendations. Each insight has a specific insight type. Insight types are specific to a single Google Cloud product and resource type. A single product can have multiple insight types, where each provides a different type of insight for a different resource. To learn more about how to use Cloud Monitoring for metrics, as well as Recommender for insights, refer to the links in this module’s course resources.

### Video - [Lab Intro: Configuring VPC Firewalls](https://www.cloudskillsboost.google/course_templates/21/video/513508)

- [YouTube: Lab Intro: Configuring VPC Firewalls](https://www.youtube.com/watch?v=VzD54mLrRhI)

In this lab, you learn how to perform the following tasks: Create an auto-mode network, a custom-mode network, and associated subnetworks Investigate firewall rules in the default network and then delete the default network And learn how to use features of Firewall rules for more precise and flexible control of connections

### Lab - [Configuring VPC Firewalls](https://www.cloudskillsboost.google/course_templates/21/labs/513509)

Configuring VPC Firewalls

- [ ] [Configuring VPC Firewalls](../labs/Configuring-VPC-Firewalls.md)

### Video - [Load balancing and SSL policies](https://www.cloudskillsboost.google/course_templates/21/video/513510)

- [YouTube: Load balancing and SSL policies](https://www.youtube.com/watch?v=Nbdxk23LklE)

Google Cloud load balancers support SSL for encryption in transit. In this course, the term “SSL” refers to both the SSL and TLS protocols. In this section, we will review the SSL capabilities in the Google Cloud load balancer. Google Cloud load balancers support HTTPS or SSL Proxy for encryption in transit. These load balancers require at least one signed SSL certificate installed on the target HTTPS proxy for the load balancer. You can use Google-managed or self-managed SSL certificates. The client SSL session terminates at the load balancer. Google Cloud Load Balancing terminates user SSL connections at the load balancing layer, then balances the connections across your instances using the SSL or TCP protocols. Cloud SSL proxy is intended for non-HTTPS traffic. For HTTPS traffic, HTTPS load balancing is recommended instead. Placing a load balancer in front of all web servers provides many benefits, including a global anycast IP address and built in DDoS protection and mitigation. An SSL policy gives you the ability to control the features of SSL that your SSL proxy or HTTPS load balancer negotiates with clients. An SSL policy specifies a minimum TLS version and a profile. The TLS versions currently supported are TLS 1.0, 1.1, 1.2, and 1.3. Using SSL policies allows you to control the SSL encryption being used for the encryption in transit. There are 3 pre-configured Google-managed profiles that allow you to specify the level of compatibility appropriate for your application. A fourth custom profile allows you to select SSL features individually. The specific settings in any of the pre-configured profiles are managed by Google and will be adjusted over time as required. COMPATIBLE allows the broadest set of clients, including those which support out-of-date SSL features. MODERN supports a wide set of SSL features, allowing modern clients to negotiate SSL. And RESTRICTED supports a reduced set of SSL features, intended to meet stricter compliance requirements. Custom SSL policy profiles can also be created. They let you select the exact set of SSL features you would like to support. However, the features will need to be managed as requirements or as available features change. If no SSL policy at all is set, a default SSL profile is applied that is equivalent to an SSL policy that is using the COMPATIBLE profile.

### Video - [VPC peering](https://www.cloudskillsboost.google/course_templates/21/video/513511)

- [YouTube: VPC peering](https://www.youtube.com/watch?v=gNACbNk9ZvE)

Next, we’ll address Interconnect and VPC peering options. VPC peering allows you to create connectivity across two nonoverlapping VPC networks. VPC peering enables the resources in these VPCs to communicate across private RFC1918 space, reducing exposure to attack. Peered networks do not need to be in the same project, or even in the same organization. The network firewall rules and routes are independently managed by the project that each respective VPC belongs to. These firewall rules are not imported across the peered networks, you need to configure rules in each of the peered VPCs to control traffic across the peered VPCs. Currently, a network can have up to 25 directly-peered networks. These networks can be connected in a series or a hub-spoke-style, as long as subnets do not overlap. VPC Network Peering does not provide granular route controls to filter out which subnet CIDRs are reachable across peered networks. You must use firewall rules to filter traffic if such filtering is needed. VPC Network Peering gives you several advantages over using external IP addresses or VPNs to connect networks, including: Decreased network latency. Public IP networking suffers higher latency than private networking. Increased network security is another advantage. Service owners do not need to have their services exposed to the public Internet and deal with its associated risks. And finally, lower network costs are also a benefit. Google Cloud charges egress bandwidth pricing for networks using external IPs to communicate even if the traffic is within the same zone. If the networks are peered, however, they can use internal IPs to communicate and save on those egress costs. Regular network pricing still applies to all traffic. Shared VPCs, on the other hand, allow an organization to connect resources from multiple projects to a common VPC network, so they can communicate with each other securely and efficiently using internal IPs. When you use Shared VPC, you designate a project as a host project and attach one or more other service projects to it. The VPC networks in the host project are called Shared VPC networks. Shared VPCs allow you to implement a security best practice of least privilege for network administration, auditing, and access control. Shared VPC Admins can delegate network administration tasks to Network and Security Admins in the Shared VPC network without allowing Service Project Admins to make network-impacting changes. The diagram shows a host project sharing its VPC network with two service projects. It is sharing Subnet_1 with one project and Subnet_2 with another project. Shared VPC connects projects within the same organization. Participating host and service projects cannot belong to different organizations.

### Video - [Connecting to Google Cloud](https://www.cloudskillsboost.google/course_templates/21/video/513512)

- [YouTube: Connecting to Google Cloud](https://www.youtube.com/watch?v=3b3FlEB8b_M)

So, what about connecting from your local on-prem network to your cloud VPC network? Secure connections to public cloud providers are a concern for all organizations, and some organizations may want to securely extend their data center network into Google Cloud projects. This can be accomplished through Cloud VPN or Cloud Interconnect. Cloud VPN securely connects your peer network to your Virtual Private Cloud network through an IPsec VPN connection. Cloud Interconnect extends your on-premises network to Google's network through a highly available, low latency connection. We’ll talk about these in more detail now. Google offers IPSec-based, managed VPNs to connect your on-premise corporate network, data center network, or other cloud service providers. Cloud VPN uses the IPSec protocol connection to provide end-to-end encryption between the two networks, and supports IKEv1 and IKEv2 using a shared secret (also known as an IKE pre-shared key). Cloud VPN traffic will either traverse the public Internet or can use a direct peering link to Google’s network. Each Cloud VPN tunnel can support up to 3 gigabits per second when the traffic is traversing a direct peering link, or 1.5 gigabits per second when it’s traversing the public internet. When using VPNs with static routes, each update to the network requires a manual addition of the static routes and the network to be rebooted. This would be required whenever a new subnet is added to either the VPC network or the on-prem corporate network. A Cloud Router enables you to dynamically exchange routes between your VPC network and on-premises networks by using Border Gateway Protocol (or BGP). Changes to the network topology no longer have to be managed with static routes. New subnets added in Google Cloud or added in the on-prem network are discovered and shared, enabling connectivity between the two peers for both entire networks. The Cloud Router automatically learns new subnets in your VPC network and announces them to your on-premises network. Before diving more into Cloud VPN, let’s take a moment to discuss Google Cloud routes and the difference between dynamic and static routes. Google Cloud routes define the paths that network traffic takes from a virtual machine instance to other destinations. These destinations can be inside your Google Cloud VPC network (for example, in another VM) or outside it. A route is created when a network or subnet is created, enabling traffic delivery from anywhere. This is what enables VMs on the same network to communicate. In a VPC network, a route consists of a single destination prefix in CIDR format and a single next hop. When an instance in a VPC network sends a packet, Google Cloud delivers the packet to the route's next hop if the packet's destination address is within the route's destination range. Static routes are defined using static route parameters and support static route next hops. You can create static routes manually using the Google Cloud Console, using the CLI (with the gcloud compute routes create command), or with the routes.insert API call. Dynamic routes are managed by Cloud Routers in the VPC network. Their destinations always represent IP address ranges outside your VPC network, received from a BGP peer. Dynamic routes are used by: Dedicated Interconnect Partner Interconnect High availability VPN tunnels, and Classic VPN tunnels that use dynamic routing One key benefit of using dynamic routes is that it allows you to discover topology changes and route traffic accordingly so users don’t sense disruptions. For more information on routes and the difference between static and dynamic routes, check out the documentation link in this module’s course resources.

### Video - [Cloud Interconnect](https://www.cloudskillsboost.google/course_templates/21/video/513513)

- [YouTube: Cloud Interconnect](https://www.youtube.com/watch?v=gJx_zGUomwc)

In addition to IPSec VPN connections, there are two other options for connecting on-premises network to Google Cloud: Dedicated Interconnect and Partner Interconnect. These provide low latency, highly available, dedicated connections to enable you to reliably transfer data between your on-premises and VPC networks. Also, Cloud Interconnect connections provide RFC 1918 communication, which means internal (private) IP addresses are directly accessible from both networks. Dedicated interconnect provides a direct physical connection between your on-premises network and Google Cloud VPC networks. Partner Interconnect provides connectivity between your on-premises network and Google Cloud VPC networks through a supported service provider. When choosing an interconnect type, there are several features that need to be evaluated. Dedicated interconnect has a minimum bandwidth of 10 gigabits per second. If you don't require 10 gigabit per second connections, Partner Interconnect starts at only 50 megabits per second and provides a variety of capacity options. If more than 10 gigabits per second bandwidth is needed, multiple interconnects can be provisioned. Dedicated Interconnect requires routing equipment in a colocation facility that supports the Google Cloud regions that you want to connect to. In this case, all traffic flows directly between your on-premises network and your VPC network. Nothing travels on the public Internet. For users that can't physically meet Google's network in a colocation facility, you can use Partner Interconnect to connect to a variety of service providers to reach your VPC networks. All traffic flows through the service provider’s network, and nothing travels on the public Internet. The service level agreement is slightly different depending on the interconnect type. For Dedicated Interconnect, Google provides an end-to-end SLA for the connection. For Partner Interconnect, Google provides an SLA for the connection between Google and service provider. An end-to-end SLA for the connection depends on the service provider.

### Video - [VPC Service Controls](https://www.cloudskillsboost.google/course_templates/21/video/513514)

- [YouTube: VPC Service Controls](https://www.youtube.com/watch?v=AYdTav0cuOQ)

Now, let’s talk about VPC service controls. VPC Service Controls improve your ability to reduce the risk of data exfiltration from your Google-managed services like Cloud Storage and BigQuery. VPC Service Controls create security perimeters around your Google-managed resources and allow you to control the movement of data across that perimeter. VPC Service Controls protect resources within a perimeter so they can only be privately accessed from clients within authorized VPC networks using Private Google Access with either Google Cloud or on-premises. They also ensure clients within a perimeter that have private access to resources do not have access to unauthorized (or potentially public) resources outside the perimeter. VPC Service Controls prevent data from being copied to unauthorized resources outside the perimeter using service operations. They also restrict Internet access to resources within a perimeter using allowlisted IPv4 and IPv6 ranges. VPC Service Controls provide an additional layer of security defense for Google Cloud services that is independent of IAM. While IAM enables granular identity-based access control, VPC Service Controls enables broader context-based perimeter security, including controlling data egress across the perimeter. It is recommended that both VPC Service Controls and IAM be used for defense in depth. Private Google Access on-premises extensions allow private communication between VPC networks that span hybrid cloud environments. VPC networks must be part of a service perimeter for VMs on that network to privately access managed Google Cloud resources within that service perimeter. VMs with private IPs on a VPC network that are part of a service perimeter cannot access managed resources outside the service perimeter. For example, a VM within a VPC network that is part of a service perimeter can privately access a Cloud Storage bucket in the same service perimeter, but the VM will be denied access to Cloud Storage buckets that are outside of it. Access from the internet to managed resources within a service perimeter is denied by default. You can enable access based on the context of the request by creating access levels that control access based on a number of attributes, such as the source IP address. Requests made from the internet are denied if they do not meet the criteria defined in the access level. The Cloud console can be used to access resources within a perimeter, but you must configure an access level that allows access from one or more IPv4 or IPv6 ranges (or to specific user accounts). The first two tools in this list, the Google Cloud console and the gcloud command-line tool, are likely to already be familiar to you. The Access Context Manager allows Google Cloud organization administrators to define fine-grained, attribute based access control for projects and resources in Google Cloud. We will dive into this service in depth in a future lesson. Can VPC Service Controls be used in a hybrid cloud environment? Yes, they can! Perimeter bridges can be used to enable communication between projects in different service perimeters. Keep in mind that a project can belong to more than one perimeter bridge but can only be included in one service perimeter. Note that instead of using a perimeter bridge, we recommend using ingress and egress rules that provide more granular controls. Let’s discuss these next. VPC Service Controls use ingress and egress rules to allow access to and from the resources and clients protected by service perimeters. Ingress rules allow an API client that is outside the perimeter to access resources within a perimeter. Egress rules allow an API client or resource that is inside the perimeter to access Google Cloud resources outside the perimeter. The perimeter does not block access to any third-party API or services in the internet. The diagram shows two organizations, Org1 and Org2, which use VPC Service Controls and share data by using a Pub/Sub topic. To enable data exchange, Org1 must define an egress rule that allows the subscription and save the file as org1egress.yaml. Org2 must define a corresponding ingress rule allowing the subscription and save the file as org2ingress.yaml. Let’s go over the steps required to actually configure and enable VPC service controls. The six stages of a typical VPC service perimeter configuration are: Create an access policy. Secure Google-managed resources with service perimeters. Set up VPC accessible services to add additional restrictions to how services can be used inside your perimeters (which is optional). Set up private connectivity from a VPC network (again, also optional). Allow context-aware access from outside a service perimeter using ingress rules (also optional). And configure secure data exchange using ingress and egress rules (which is also optional). Let’s take a look at each of these stages in more detail. An access policy collects the service perimeters and access levels you create for your organization. An organization can have one access policy for the entire organization and multiple scoped access policies for the folders and projects. Service perimeters are used to protect services used by projects in your organization. After identifying the projects and services you want to protect, create one or more service perimeters. When you enable VPC accessible services for a perimeter, access from network endpoints inside your perimeter is limited to a set of services that you specify. To provide additional security for VPC networks and on-premises hosts that are protected by a service perimeter, we recommend using Private Google Access. For more information, see private connectivity from on-premises networks. You can allow context-aware access to resources restricted by a perimeter based on client attributes. You can specify client attributes, such as identity type (for example, service account or user), identity, device data, and network origin (for example, IP address or VPC network). You can include your project only in one service perimeter. If you want to allow communication across the perimeter boundary, set up ingress and egress rules.

### Video - [Demo - VPC Service Controls](https://www.cloudskillsboost.google/course_templates/21/video/513515)

- [YouTube: Demo - VPC Service Controls](https://www.youtube.com/watch?v=SalUy0_OZSI)

Max: Hey, Steve. My new app, Moneymaker, is doing great. Turns out, a lot of people wanna trade stocks from their phones. But now I've collected all these account numbers and credit numbers, I'm pretty worried about protecting all that sensitive information so I can maintain the trust of everyone using my app. Steve: Sounds like you need some additional security. What if one of your employees decides to go rogue and start their own competition? Max: Oh, no. I definitely need to minimize any data exfiltration, either from a disgruntled employee or any attacker. Steve: Great. How do you control data access today? Max: Well, I've got some sensitive data, but it's stored so that many projects have access to it. I'm really worried about unauthorized copying going on. Can you help? Steve: Absolutely. I'll show you how a VPC Service Controls perimeter can make you more secure. Max: Great. [upbeat electronic music] Steve: All right. We've got two projects, one that has sensitive data and one that is attempting to exfiltrate data. Each project has its own storage bucket. The sensitive storage bucket is locked down and is only accessible to a select few service accounts. For this example, we will use this service account. Oh, no! An attacker gained access to our service account and to the sensitive data. They've added the compromised service account to an unauthorized project and created a bucket to exfiltrate data using the Cloud Storage API. Let's take a look. Here, I'm acting as the malicious actor. I copy sensitive data--account numbers-- from the customer_account_data bucket to the exfiltrated_customer_data bucket using the compromised service account. The malicious actor copies the data to their own bucket and can now allow access from outside the company. Max: That's bad, right? How do we protect against that? Steve: We'll create a perimeter with VPC Service Controls. This lets you lock down GCP services, similar to how firewalls protect your servers. From the console, we'll go to VPC Service Controls and select our organization. This perimeter controls which projects can call on the GCP APIs, specifically allowing only the ones you choose. I give it a name--in this case, SuperExfiltrationProtection-- then choose the project I want to protect. Finally, I'm going to choose to restrict the Storage API. Any Storage API call coming from outside that perimeter will fail. Now, only Storage API calls from inside this project will be allowed. Success! Our data is safe, or at least safer. As you can see, you can use VPC Service Controls to lock down your projects and protect sensitive data. [explosion] Max: That's great. I'll go set that up today. And it keeps me safe from attackers inside or outside my company. Steve: This is just one of the many tools that Google Cloud provides to make sure your public cloud workloads stay as private as you need. [upbeat electronic music]

### Video - [Private Google API access](https://www.cloudskillsboost.google/course_templates/21/video/513516)

- [YouTube: Private Google API access](https://www.youtube.com/watch?v=3gNIQhinhCU)

In this lesson, we will dive into Private Google API access. Private Google API Access enables Compute Engine instances on a VPC subnet to reach Google APIs and services using an internal IP address rather than an external IP address. Previously, you had to provide a public path for your internal Compute Engine instances (for example, an external IP address or a NAT gateway) to allow the instances to access Google APIs. With Private Google Access, an API call is resolved to a public IP address, but the traffic is all internal and private. Network address translation is in Google's infrastructure and is transparent to the user. If Private Google Access is not enabled, an organization requires an external IP address to communicate with Google APIs. Although the communication is encrypted, this IP address can increase an organization’s risk by unnecessarily exposing its network to the internet. The Cloud and Developer APIs and services that can be reached include, but are not limited to: BigQuery, Cloud Bigtable, Container Registry, Dataproc, Datastore, Pub/Sub, Cloud Spanner, and finally, Cloud Storage. The following diagram illustrates an implementation of Private Google Access. The VPC network has been configured to meet the DNS, routing, and firewall network requirements for Google APIs and services. Private Google Access has been enabled on subnet-a, but not on subnet-b. VM A1 can access Google APIs and services, including Cloud Storage, because its network interface is located in subnet-a, which has Private Google Access enabled. Private Google Access applies to the instance because it only has an internal IP address. Private Google Access does not apply to instances with external IP addresses. VM B1 cannot access Google APIs and services because it only has an internal IP address and Private Google Access is disabled for subnet-b. VM A2 and VM B2 can both access Google APIs and services, including Cloud Storage, because they each have external IP addresses. Private Google Access has no effect on whether or not these instances can access Google APIs and services because both have external IP addresses.

### Video - [Access Context Manager](https://www.cloudskillsboost.google/course_templates/21/video/513517)

- [YouTube: Access Context Manager](https://www.youtube.com/watch?v=OcQ_xwzgi_A)

Now let’s talk about Access Context Manager. So, what is Access Context Manager? Access Context Manager is a tool with an API that allows Google Cloud organization administrators to define fine-grained, attribute based access control for projects and resources in Google Cloud. Administrators first define an access policy, which is an organization-wide container for organizing access levels and service perimeters, that includes the necessary requirements for requests to be allowed. Requirements may include device type and operating system, IP address, and User identity. Access Context Manager isn't responsible for policy enforcement. Its purpose is to describe the desired rules. Access policy is configured and enforced across various points, including through VPC Service Controls. What is an Access Policy? An access policy acts as a container for access levels, and as such, a single access policy can contain multiple access levels. When using Access Context Manager to manage your Access Policies, you can create policies that are attached to a project - say, for quota purposes - but such policies are not restricted to just that project and can also be used elsewhere in your organization. An access level is a set of attributes (such as IP address, device type and User identity) that are assigned to requests based on their origin. Using this information, when requests come in, you can decide what level of access to grant. Access levels are customizable; "High_Trust," "Medium_Trust," and “Low_Trust” are examples. You can specify multiple access levels as part of an access policy. Now, let’s look a bit more closely at these assignable attributes. The first attribute is IP address, which means you can grant a certain access level based upon the IP address of the originating request. The range of IPs to allow is specified in the form of a Classless Inter-Domain Routing block (most commonly know as CIDR), which allows for an easily recognizable, simple, and fine-grained control over the IPs allowed. A single access level can contain one or multiple IP ranges. Access Context Manager uses Endpoint Verification to gather information regarding user devices, including operating system and version. You can then grant an access level based on this data; for example, you might decide to grant a more permissive access level to devices running the latest version of the primary operating system deployed at your company. In some instances, you may wish to grant an access level to specific entities - in this case, the identity of the requester determines whether the condition is met. This scenario is often used in conjunction with Service Accounts and VPC Service Controls; for example, to enable a Cloud Function to access data protected by VPC Service Controls. Identity-only access levels can only be created and managed with the gcloud command line tool, not via the Google Cloud Console.

### Video - [VPC Flow Logs](https://www.cloudskillsboost.google/course_templates/21/video/513518)

- [YouTube: VPC Flow Logs](https://www.youtube.com/watch?v=xIQlKselEA8)

Now let’s have a look at VPC Flow Logs. VPC Flow Logs record network flows sent from or received by VM instances. Examples include geographic details, source and destination IPs, etc. VPC flow logs will only include traffic seen by a VM. For example, if outbound traffic was blocked by an egress rule, it will be seen and logged, but inbound traffic blocked by an ingress rule, not reaching a VM, will not be seen and will not be logged. These logs can be used to monitor network traffic to and from your VMs, and can also be used for forensics, real-time security analysis, and expense optimization. You can view flow logs in Cloud Logging - formerly known as Stackdriver Logging - and you can export logs to any destination that Cloud Logging export supports—for example Pub/Sub or BigQuery. Flow logs are aggregated by connection, at 5-second intervals, from Compute Engine VMs and exported in real time. By subscribing to Pub/Sub, you can analyze flow logs using real-time streaming APIs. You can enable or disable VPC Flow Logs per VPC network subnet. When you enable VPC Flow Logs, you enable them for all VMs in a subnet. VPC Flow Logs are natively built into the networking stack of the VPC network infrastructure. There is no extra delay and no performance penalty in routing the logged IP packets to their destination, but some systems generate a large number of logs, which can increase costs in Cloud Logging.

### Video - [Lab Intro: Configuring and Using VPC Flow Logs in Cloud Logging](https://www.cloudskillsboost.google/course_templates/21/video/513519)

- [YouTube: Lab Intro: Configuring and Using VPC Flow Logs in Cloud Logging](https://www.youtube.com/watch?v=zO5U8wUi_PQ)

In this lab, you learn how to work with VPC flow logs. You will enable VPC flow logging and then use Cloud Logging to access the logs. You will filter logs for specific subnets, VMs, ports, and protocols. You will also perform network monitoring, forensics, and real-time security analysis. When finished, you will disable VPC flow logging.

### Lab - [Configuring and Using VPC Flow Logs in Cloud Logging](https://www.cloudskillsboost.google/course_templates/21/labs/513520)

Viewing and using VPC flow logs in Cloud Logging

- [ ] [Configuring and Using VPC Flow Logs in Cloud Logging](../labs/Configuring-and-Using-VPC-Flow-Logs-in-Cloud-Logging.md)

### Video - [Cloud IDS](https://www.cloudskillsboost.google/course_templates/21/video/513521)

- [YouTube: Cloud IDS](https://www.youtube.com/watch?v=RvLKO2yu0Ks)

Now, let’s talk a little bit about Cloud IDS. Cloud IDS is an intrusion detection service that provides threat detection for intrusions, malware, spyware, and command-and-control attacks on your network. Cloud IDS works by creating a Google-managed peered network with mirrored VMs. Traffic in the peered network is mirrored, and then inspected by Palo Alto Networks threat protection technologies to provide advanced threat detection. Cloud IDS provides full visibility into network traffic, including both north-to-south and east-to-west traffic, letting you monitor VM-to-VM communication to detect lateral movement. Not only does Cloud IDS give you immediate indications when attackers are attempting to breach your network, the service can also be used for compliance validation, like PCI 11. Cloud IDS also automatically updates all signatures without any user intervention, enabling users to focus on analyzing and resolving threats, without managing or updating signatures. To better understand Cloud IDS, it’s important to understand how the service uses endpoints and packet mirroring. Cloud IDS uses a resource known as an IDS endpoint, a zonal resource that can inspect traffic from any zone in its region. Each IDS endpoint receives mirrored traffic and performs threat detection analysis. Cloud IDS uses Google Cloud packet mirroring, which creates a copy of your network traffic. After creating an IDS endpoint, you must attach one or more packet mirroring policies to it. These policies send mirrored traffic to a single IDS endpoint for inspection.

### Video - [Lab Intro: Getting Started with Cloud IDS](https://www.cloudskillsboost.google/course_templates/21/video/513522)

- [YouTube: Lab Intro: Getting Started with Cloud IDS](https://www.youtube.com/watch?v=54fldaiv7Tg)

In this lab, you deploy Cloud IDS, a next-generation advanced intrusion detection service that provides threat detection for intrusions, malware, spyware and command-and-control attacks. You will simulate multiple attacks and view the threat details in the Cloud Console.

### Lab - [Getting Started with Cloud IDS](https://www.cloudskillsboost.google/course_templates/21/labs/513523)

Deploy Cloud IDS (Intrusion Detection System), a next-generation advanced intrusion detection service that provides threat detection for intrusions, malware, spyware and command-and-control attacks, to simulate multiple attacks and view the threat details. 

- [ ] [Getting Started with Cloud IDS](../labs/Getting-Started-with-Cloud-IDS.md)

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/21/video/513524)

- [YouTube: Module review](https://www.youtube.com/watch?v=UCn2f1WTTmk)

Let’s recap what you learned in this module. We covered firewall rules and how they can be used to enforce the principal of least privilege. This is achieved by minimizing direct exposure to and from the internet and preventing ports and protocols from being exposed unnecessarily. SSL policies specify the minimum TLS version clients can connect with and provide a profile of SSL policy features. VPC peering allows you to create connectivity across two nonoverlapping VPC networks. Shared VPC allows an organization to connect resources from multiple projects to a common VPC network. Cloud Interconnect offers options for connecting on-premises networks to Google Cloud. VPC Flow Logs are used for network monitoring, forensics, real-time security analysis, and expense optimization. And finally, you learned that Cloud IDS is an intrusion detection service that provides threat detection for intrusions, malware, spyware, and command-and-control attacks on your network.

### Quiz - [Quiz: Configuring Virtual Private Cloud for Isolation and Security](https://www.cloudskillsboost.google/course_templates/21/quizzes/513525)

## Course Resources

PDF links to all modules

### Document - [Managing Security in Google Cloud - Course Resources](https://www.cloudskillsboost.google/course_templates/21/documents/513526)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

---
id: 327
name: 'Developing Data Models with LookML'
type: Course
url: https://www.cloudskillsboost.google/course_templates/327
date_published: 2024-12-03
topics:
  - Dashboard
  - Data Engineering
  - Caching
---

# [Developing Data Models with LookML](https://www.cloudskillsboost.google/course_templates/327)

**Description:**

This course empowers you to develop scalable, performant LookML (Looker Modeling Language) models that provide your business users with the standardized, ready-to-use data that they need to answer their questions. Upon completing this course, you will be able to start building and maintaining LookML models to curate and manage data in your organization's Looker instance.

**Objectives:**

* Define LookML basic terms and building blocks
* Model new dimensions and measures using LookML
* Use dashboards to combine key queries and visualizations into a one page executive view
* Model files of LookML projects to design and build custom Explores for business users
* Use derived tables in Looker to create new custom tables that do not yet exist in the underlying database.
* Articulate how caching works in Looker and how developers can use datagroups to manage caching policies.

## Introducing Looker and LookML

This module provides an overview of Looker and the Looker integrated development environment (IDE) for LookML developers.

### Video - [Looker and LookML](https://www.cloudskillsboost.google/course_templates/327/video/515582)

* [YouTube: Looker and LookML](https://www.youtube.com/watch?v=kxgcj9T0G1Q)

Let us discuss how Looker is a Business Intelligence (BI) software and big data analytics platform that helps business users to explore, analyze and share real-time data analytics easily. As a browser-based, Software as a Service (SaaS) platform, Looker connects directly to SQL databases. For example, you can connect Looker to: Other SaaS applications such as Salesforce, Mailchimp, and Zendesk. Heavy read-write operations in transactional databases such as Oracle, IBM Db2, and Microsoft SQL Server. Business planning tools such as SAP, NetSuite, and Oracle. And web analytics products such as Google Analytics or Adobe Analytics. These are just a few examples. Looker is multi-cloud and supports over 65 database dialects. One major benefit of Looker is its agile modeling layer, which can save data teams and business analysts time that would otherwise be spent manually writing and editing SQL queries. Looker’s agile modeling layer allows developers to define, through Looker Modeling Language or LookML, how the database is structured and how the tables and columns relate to each other. A useful way to think about LookML is that it is an abstraction layer for SQL that developers use to tell Looker what data to use from the connected database and how it should interpret that data. As users explore and analyze the data, Looker uses the defined LookML models to automatically generate SQL SELECT queries to send to the database and return the appropriate results. Another benefit of Looker is data governance, which means that you can define a single source of truth for data that everyone in the organization can understand and trust. In Looker, you can enforce various types of data security and governance through the Looker user interface (UI), such as assigning specific user roles, as well as through LookML, such as providing access to specific fields or rows of data. To help organizations disseminate data, Looker can surface and expose query results in several ways. The first is through the web interface. This can be in the form of Explores (which are report-builder interfaces), Looks (which are standalone reports or visualizations), and dashboards (which contain multiple visualizations). Another way is through scheduled data deliveries, such as sending Looks and dashboards to specific email addresses or Cloud Storage buckets on a one-time or recurring basis. Explores, dashboards, and Looks can also be embedded within other websites or applications. Last, Looker provides a REST API that allows you to retrieve, analyze, and transform data and metadata directly from the Looker platform. Looker's unique architecture provides a rich development framework that is built to support enterprise-grade workflows and help your users and tools access the most accurate and up-to-date version of your organization’s data. With this unified view into your organization’s data, you, as a LookML developer, can curate data experiences to ensure that both people and systems get the data they need, how and when they need it.

### Video - [The Looker user interface](https://www.cloudskillsboost.google/course_templates/327/video/515583)

* [YouTube: The Looker user interface](https://www.youtube.com/watch?v=zHXoGKQJVBU)

To understand how you as a LookML developer can support business users, it’s important to become familiar with the business user experience and how they use the Looker platform on a daily basis to answer data-driven questions. Furthermore, the ability to navigate the Looker platform as a business user will help you to to fully test your changes to LookML code by reviewing how results appear when accessed by business users. Let’s explore the business user experience by walking through an example Looker instance. When you first log in to the Looker platform, your home page may vary depending on what your company’s Looker administrator has configured. In this example instance, we will begin on the Shared folders page. Folders in Looker are where content lives, just as files in your computer or Google Drive are stored in folders. As you may know, Looker has two primary categories of users: business users and developers. As a LookML developer, you use the Develop environment to curate report-builder interfaces called Explores that are used by business users and to configure other aspects in your Looker instance such as rules for caching and data security. Business users can click on Explore to see a list of the custom Explores that LookML developers have modeled for them. Within the Explores, they can analyze and visualize data to answer business questions and save their results as visualizations and reports. This example Looker instance has many Explores including one for Order Items under the E-Commerce Training header and another for Flights under the FAA header. As a business user working at a hypothetical ecommerce company, you can also navigate through the various folders of the Looker instance to find content that has already been built using the available Explores, such as one of the Business Pulse dashboards. For business users, this example Business Pulse dashboard provides some high-level key performance indicators (KPIs) that a typical ecommerce company might care about, such as the number of new users acquired and the average order amount. In Looker, these are called single value visualizations. Scrolling down, you can see other visualizations such as the number of orders by category over time in an area chart. Let’s say you want to learn more about new users your company has acquired. You can click on the number provided in the New Users Acquired tile to drill down to the underlying data. After drilling down on the New Users Acquired tile, you can view the granular rows of data that constitute the overall number of new users acquired. For example, for this tile, you can see each user’s ID, first name, and last name. In Looker, these data attributes are called dimensions. After drilling down on the New Users Acquired tile, you can view the granular rows of data that constitute the overall number of new users acquired. For example, for this tile, you can see each user’s ID, first name, and last name. In Looker, these data attributes are called dimensions. This takes you out of the dashboard and into the Explore, which is the report-builder interface that has been curated by a LookML developer. In this example, the overall Explore is called Order Items, but there are several expandable groups of fields in the field picker found in the left-side panel. These are called views. An Explore is composed of one or more views. For example, when you want to analyze order information, you also might want to include fields from other related views such as Users. In SQL terms, each view represents a database table, and the tables are pre-joined in the LookML model file to define the overall Explore, like this Order Items Explore. Using this Explore, you can ask questions about the newly acquired users. For example, maybe you are curious about the age of each of these users. To see age information about these users, you can expand the Users view, and click on the Age dimension to add it to your results set. Then, you can click Run to view the results. If you want to know how much each of these new users has already spent, you can expand the Order Items view, and click on the Total Revenue measure, which aggregates all of the purchases for each user. Once again, you need to click Run to view the new results. Behind the scenes, Looker has automatically generated a SQL query for the drill-down results and is updating it with the new selections. As a LookML developer, you can click on the SQL tab—typically hidden from business users—to see that Looker is SELECTing users.id, users.first_name, users.last_name, and users.age, which are the dimensions selected in the Explore. Looker is also executing a SUM of order_items.sale_price for total_revenue, which is the measure selected to aggregate the purchase data for each user. You can also see that the data comes FROM a table called looker_ecomm.order_items, with a LEFT JOIN to looker_ecomm.users. Finally, there’s a big WHERE condition that is identifying only the new users from the past 180 days. Rather than writing this SQL query manually, it was so easy for the business user to click on some fields and get this output automatically. This is all because of the agile modeling layer in LookML. A LookML developer or team of developers had already created this Order Items Explore, specified which views should be in the Explore, specified which dimensions and measures should be in each view, and defined the SQL logic for each dimension and measure. Now, you can save these results as a standalone report, or Look, for ongoing reference by clicking on the gear icon in the top right, select Save, and then choose As a Look from the fanout menu. That was a quick demonstration of the significance and value of LookML for empowering business users to explore and analyze data. If you’re completely new to Looker, there’s a fundamental prerequisite to be aware of regarding the underlying data that is used by business users. A Looker administrator needs to create a connection to a specific data source such as your company’s primary database, in order for LookML developers to access and model that data to curate Explores for business users. Admins can find setup and configuration details in the Database configuration details section of Looker’s dialects documentation page. As a LookML developer, you can see available database connections in your organization’s Looker instance by clicking on the Develop menu in left-side navigation panel of the Looker UI… ... then, selecting SQL Runner. SQL Runner is a console or portal to the databases that have been connected to your organization’s Looker instance. You can see all of the database connection options under Connection. Now, after this brief overview of the Looker business user experience, we hope that you are excited to explore Looker further as a LookML developer.

### Video - [The Looker IDE](https://www.cloudskillsboost.google/course_templates/327/video/515584)

* [YouTube: The Looker IDE](https://www.youtube.com/watch?v=24kHL8-zIHQ)

Looker provides an integrated development environment (IDE) that developers can use to modify existing and to model new dimensions, measures and Explores for business users to employ in their data analysis approaches. In this section, we will explore the overall Looker development environment and review the key components for your workflow as a LookML developer. In Looker, business users interact with and experience the Looker instance in Production Mode while developers make changes and test new features through Development Mode. Production Mode uses the latest production version of Looker. Everyone using a Looker instance in Production Mode accesses its projects, Explores, and content in the same state. LookML project files are read-only in this mode. As a LookML developer, you can use Development  Mode to make changes to projects without affecting anyone else. ​Development Mode accesses a completely separate version of your project files that only you can see and edit. If you’re familiar with Git, Production Mode uses the main branch of the Git repository of the LookML project with the default Looker Git integration, while Development Mode uses a separate branch created from the main branch. After testing, changes made by LookML developers in the separate branch can be merged into production, so that all users of the Looker instance can access the updates. By default, LookML projects open in Production Mode. This means that they show the latest version of the project that has been merged to production. To make changes in your LookML projects, you need to enable Development Mode, which is frequently referred to as “dev mode.” When you are in working in Development Mode, Looker will display a blue banner at top of the Looker User Interface (or UI) with a message that you are in Development Mode. As a LookML developer, you have several options to enter Development Mode. One option is to use the toggle button at the bottom left-side of the Looker UI to enter Development Mode. You can also use the same toggle button to exit Development Mode and return to Production Mode. There is also a keyboard shortcut: Control+Shift+D. Alternatively, at the top left-side of the Looker User Interface, you can click on Develop menu to see the options, and then select Projects. Then, once you are on the Projects page, you can turn on Development Mode by clicking on the Develop option from the top menu bar and using the toggle button for Development Mode. From the Projects page, you can also click on a specific project name, such as training_ecommerce, to open it within the Looker Integrated development environment (IDE). An IDE is an industry term for an application in which software engineers or developers can write and test their code. Looker has its own built-in IDE in which developers can write LookML. The Looker IDE displays six navigation options on the left-side panel. We’ll walk through each option to understand the functionality that it provides for LookML developers. The first option, represented by the folder icon, is the file browser. This displays all the LookML project files in the folder hierarchy. Depending on the complexity of the project, you could see dozens or even hundreds of files, within many folders and levels of subfolders. At your company, with your own development team, you can decide on any kind of folder structure that would be the most intuitive for your workflows. The second option, represented by the compass icon, is the object browser. The object browser organizes project files by LookML object type in the project. Each model can be expanded to show the Explores within. Furthermore, each Explore can be expanded to reveal the views that are joined together, and each view can be expanded to display the dimensions and measures. This is really useful when you need to find a specific field or view being used within an Explore, especially if you have many similarly named objects in the model. You may also need to “visualize,” in a sense, in how many Explores the same view is being used, or which models have the same or similar Explores. Next is the find-and-replace option. You can search for a specific word like “count” and see where and how many times this term appears throughout all the files in your entire project. You can also batch-replace all instances of a text string with something else. The fourth option in the IDE shows the available Git actions. These options allow you to switch between Git branches, view past commits by yourself and fellow developers, view the project on GitHub, or whichever Git provider you use at your company, and more. Inside of Git Actions is the Commit History pop-up. This page lets you see the recent changes that have been deployed to the production environment. Additional details about the changes, such as the user and date associated with the change, are also available on this page. The last option displays the project settings. As a LookML developer, you can see the configurations, but only a Looker admin can change them. For example, admins can specify what is or isn’t required to commit code, enable pull requests if your team prefers to do code reviews before deploying to production, change the Git connection, and more. In summary, as a LookML developer, you can make and test changes in your organization’s Looker instance in Development Mode, without impacting the production environment. When working in your organization’s Looker instance, be mindful of whether you are currently in Production Mode or Development Mode. The Looker IDE and Explore menus will offer a few different features and options in Production versus Development Mode. Depending on your permissions and local code differences, you may even see different lists of projects, project files, and Explores. With this understanding of the differences between Production and Development Mode, we hope that you have fun exploring the LookML projects in your organization’s Looker instance!

### Video - [LookML project version control](https://www.cloudskillsboost.google/course_templates/327/video/515585)

* [YouTube: LookML project version control](https://www.youtube.com/watch?v=x5c04Yklw_s)

An important component of the overall LookML workflow is project version control. In this section, we will discuss how Looker integrates with Git for version control of LookML projects. Git is a widely used version-control system for multiple programmers to collaborate on the same library of code. Through Looker’s integration with Git, you can make and test changes locally first in Looker’s integrated development environment (or IDE), and then send your changes to the primary production environment after the changes have been tested locally. This version control process allows you to collaborate on one project with other developers who can receive your updates as well as share their updates with you. To understand how version control with Git works, it is helpful to think of the Git repository for a LookML project as a tree. New LookML code is always written in a branch of the tree. The main production code that is live would be the trunk of the tree, while each developer creates a branch from the trunk to create and test new objects such as dimensions, measures, Explores and more. After changes have been tested locally in a branch, the LookML developer can send the changes to the trunk, or the production environment for the LookML project. After that point, other developers can pull changes from the trunk to their branches of the project. You can use Git with Cloud Source Repositories, or through a third-party provider, such as GitHub, Bitbucket, or GitLab. To configure Git, you need a URL or connection string for the repository that you would like to use. The Git configuration is typically completed by a Looker team lead or administrator and only has to be completed once per LookML project. The lead or administrator will set up the GitHub repository to allow write access from the LookML developers, so that all of them can sync changes to and from the primary production repository on GitHub. One key point that you need to know as a LookML developer is that when you enter Development Mode, Looker automatically creates a local branch for you to make and test changes. This branch can be only be modified by you, though developers with access to the same project can view others’ branches if they like. The Looker IDE will alway display which branch you are working in, at the top of the page next to the project name. In this example, the project is training_ecommerce and the personal branch is called dev. On the Git Actions page, you can also view others’ branches in read-only mode, or even create new branches or even shared branches, also known as feature branches. You may want to create a new branch if you have only partially completed a large workflow on your own branch, and you need to develop and deploy an unrelated change without sending all of your other code changes to the production environment. Shared branches are useful for allowing multiple developers to collaborate on the same version of code to implement a new feature or bug fix. The shared branch can easily be deleted once the collaboration is complete. Another key concept for developers to remember is that all changes made in Development Mode remain in the active development branch until they are pushed to production. So you can continue to make and test changes to LookML code in Development Mode without having to push these changes to production until you are ready. Depending on the settings configured by the administrator of you organization’s Looker instance, you may have access to send your changes directly to production. While by default LookML developers can merge and deploy their changes to production, Looker administrators can choose to restrict the deployment of changes to production by configuring projects to use pull requests using the Configuration options on the Project Settings page. When pull requests are enabled, developers submit pull requests to notify others that they want to submit changes to the production code. Another team member (usually a lead or designated reviewer) reviews the pull request in the Git provider (such as github.com), and if they approve the changes, they can choose to merge the changes to production. While you are working in your branch, you may decide that you no longer want to save the changes that you have been making. Luckily, in the Looker IDE, you can revert any changes made in Development Mode that have not been pushed to production by using the Revert to options on the Git Actions page. This action will undo all uncommitted changes, so that you can start over with a clean branch that matches the latest production environment. Looker also includes a built-in Project Health feature, so you can easily surface any data- or connection-related issues affecting your LookML projects. Available from the checkbox icon in the top right corner of the user interface, the Project Health section contains the following automated tests: A test designed to determine if your persistent derived tables are currently properly built, or somehow unbuilt, which would likely indicate a problem. A test designed to review all LookML code project wide, to surface as human input errors that could be creating downstream issues. A test designed to test connectivity for data in your database being pulled into and used by Looker. This won’t screen for every possible problem, but for a very quick health assessment, it’s incredibly useful. In summary, when you enter Development Mode, Looker will automatically create a local branch for you to make and test changes. The branch that you are currently working in will always be displayed at the top of the Looker IDE. You can see additional information about your branch and access different options under the Git Actions page of the IDE. All changes made in Development Mode will remain in Development Mode until they are merged to production. Depending on the settings configured by your Looker admin, you may have permission to directly merge your changes to production, or you may have to submit a pull request for someone else to review and approve your changes. With this introduction to Looker’s integration with Git, you are now ready to start using version control to manage your changes and collaborate with others in your organization’s Looker instance.

### Video - [Example: Git workflow in Looker](https://www.cloudskillsboost.google/course_templates/327/video/515586)

* [YouTube: Example: Git workflow in Looker](https://www.youtube.com/watch?v=Wt1UmZmJcpU)

To fully understand how you can leverage Looker’s integration with Git to make changes and collaborate with others on code, let’s walk through the typical Git workflow in the Looker IDE. Begin by enabling Development Mode using the toggle button for Development Mode in the bottom left corner of the Looker home page. Then, click Develop on the left side navigation menu. Within the Develop options, click on the training_ecommerce project. A best practice when working in a new branch is to first pull changes from production to your local branch, to ensure that you have the most recent version of all project files. You can pull changes from production by clicking the Pull from… option on the Git Actions page. In the window that opens, select Pull from Production. After you have pulled the updates from production, you are ready to start writing new LookML code in your current development branch. As you make changes in your branch, the button in the top right corner of the IDE will display the next step that is needed in the Git workflow. A greyed out status of Up to Date indicates that the branch matches the production environment. This means that your current branch contains all changes previously sent to the production environment and that new no changes have been made yet in your branch. When you do make a new change in your branch, a button labeled Save Changes will appear in the top right of the code window. Be sure to save your changes often. If you have made changes in a file without saving them, you will prompted to save your changes before you navigate to other files in your project. As you save changes to a file (such as adding, editing, or removing code), a blue dot will a blue dot will appear next to the name of the modified LookML file in the File Browser. This makes it easy for you to see where you have been making changes in your branch. After you save your changes, you will be prompted to validate the changes by selecting Validate LookML. This ensures that your changes include valid LookML code. If the initial validation identifies errors, you can resolve the errors, save your changes, and validate the changes again. After validating your LookML code, the next step in the Git workflow is to Commit Changes & Push changes to your branch. This step completes two actions: first, it commits your changes to the local . git folder, where local versioning takes place. Then, it pushes your local branch to sync with your remote branch on the external Git repository, which would be in a Git provider. While this step makes the validated LookML code from your branch available on the remote Git repository such as GitHub, the changes are not available yet to the business users—there’s one more step we’ll see next to deploy the changes to production. After you click on Commit Changes & Push, a new window will open in the IDE with a list of the files that were modified. In this Commit window, it is a best practice to include a short comment explaining the changes that were made in the commit. The last step in the Git workflow is to Deploy to Production. This action will deploy your changes to production, where business users will see your changes immediately. Before this happens, though, you may be presented with a prompt to run the Project Health tests. Do so, and then continue on deploying. Also, depending on the settings configured by your Looker admin, you may not see this option if you do not have permission to directly merge your changes to production. In that case, you would submit a pull request for someone else to review and approve your changes. If you do have the sufficient permissions but still do not see the option to merge and deploy, then you likely have encountered a merge conflict that needs to be resolved. A merge conflict means that another developer recently committed some code that conflicts with yours. Perhaps you both tried to edit line 10 of the same view file, as shown in this example of a model file called e_flights. You will need to review the conflicting files (highlighted in the file browser), choose which changes to keep, and then commit again to receive the option to merge and deploy. For more information, review the section about resolving merge conflicts on Looker’s using version control and deploying documentation page. After you successfully merge and deploy your changes to production, the Looker IDE will once again display an Up to Date status. Congratulations! You have now successfully walked through the entire Git workflow to make, validate, and merge changes to a LookML project.

### Video - [How Looker writes SQL](https://www.cloudskillsboost.google/course_templates/327/video/515587)

* [YouTube: How Looker writes SQL](https://www.youtube.com/watch?v=bob9A8vWVUQ)

As a LookML developer, you can define as many dimensions and measures as you like in your view files to curate data. Remember though, for business users to leverage these dimensions and measures, you need to make them available through Explores. To create Explores, it is helpful to first understand how Looker generates SQL before learning how to work with the model file within your project. In this section, we will examine in more detail how SQL query generation works in Looker. All SQL queries in Looker begin with the data and options that business users select from the Explore. When users click the run button, Looker automatically generates and sends the necessary SQL to the underlying database, and then returns the results to the user. In this example, the business user has requested to see user count by state by selecting the State dimension and the Count measure from the Users view. As a LookML developer, you can see the SQL query generated by Looker and then sent to the underlying database in the SQL window. Let’s deconstruct this query to understand how Looker generates the SQL. In the SQL query, the dimensions and measures selected by a user are the “columns” or fields that follow the word SELECT at the start of the query. Remember that dimensions are the individual data attributes such as users’ states of residence, while measures are aggregate functions applied to dimensions such as count. Thus, measures will appear as aggregating functions in the SELECT statement. In this example, the count measure appears as an aggregating function that counts distinct user IDs. The word FROM in the SQL query identifies the base view of the Explore, as defined in the model file. The base view of the Explore is always part of the generated SQL query, even if no dimensions or measures are selected from that view. Looker then joins to any other view that is needed based on the dimensions and measures selected. In this example, the base view of the Order Items Explore is order_items. Though the query is looking for the count of users by users.state, Looker still selects from order_items first and then joins to users. However, unnecessary views are not joined in the query, as long as no dimensions or measures are selected from those views. When a business user filters their data by a dimension, this adds or modifies the WHERE clause in the SQL query. In this example, the user has added a filter for users.country to equal to USA, which is then included in the generated SQL query. However, when a user filters their data by a measure, this adds or modifies the HAVING clause in the SQL query. In this example, the user has selected a filter of Order Items Count greater than 5, which has been included in the generated SQL query in the HAVING clause. Business users can also set row limits on how much data is returned. In the generated SQL query, these limits are reflected in the LIMIT clause. For example, if the user sets the row limit to 10 to only see the top 10 results, the LIMIT clause of SQL query will update to match the row limit set by the user. To summarize, the dimensions selected by business users are listed in the SELECT statement of the generated SQL query, while the selected measures appear in the SELECT statement as aggregating functions, such as count, applied to dimensions. In the SQL query, the base view of an Explore is always selected first, and other needed views are joined based on users’ selections; unnecessary views in the Explore are not joined in the SQL query. As the users select filters and update limits in the Explore, those are also reflected in the generated SQL query using the WHERE, HAVING, and LIMIT clauses. Now after this deep dive into the SQL queries generated by Looker, you are ready to leverage Looker-generated SQL to design Explores for your business users.

### Quiz - [Module 1 Quiz](https://www.cloudskillsboost.google/course_templates/327/quizzes/515588)

#### Quiz 1.

> [!important]
> **What role most often manages the creation, configuration and ongoing maintenance of the Looker platform LookML project version control? Please choose the best answer.**
>
> * [ ] Database administrator.
> * [ ] None of these roles apply.
> * [ ] LookML developer.
> * [ ] Looker administrator.

#### Quiz 2.

> [!important]
> **LookML developers cannot write, commit, or implement LookML code unless in Development Mode in the Looker platform.**
>
> * [ ] False
> * [ ] True

#### Quiz 3.

> [!important]
> **Where would a data explorer end user notice new LookML code you wrote, committed and implemented as a LookML developer? Please choose the best answer.**
>
> * [ ] Looks.
> * [ ] Dashboards.
> * [ ] Boards.
> * [ ] Explores.

#### Quiz 4.

> [!important]
> **All users can access, read, and write to LookML files in Production Mode.**
>
> * [ ] False
> * [ ] True

#### Quiz 5.

> [!important]
> **What are the fundamental components Looker uses to generate a complete SQL query? Please choose the best answer.**
>
> * [ ] Model, Explore, sort order.
> * [ ] Model, Explore, fields, filter.
> * [ ] Model, fields, sort order.
> * [ ] Model, Explore, fields, filter, sort order.

#### Quiz 6.

> [!important]
> **The Looker platform can connect to other SaaS platforms, but specifically NOT business planning or web analytics solutions.**
>
> * [ ] False
> * [ ] True

#### Quiz 7.

> [!important]
> **Which of these features central to the value proposition of the Looker platform empowers the self-service of data viewers and data explorers by allowing them to work with and visualize data without writing SQL? Please choose the best answer.**
>
> * [ ] Looker data democratization.
> * [ ] Looker agile modeling layer.
> * [ ] Looker data governance.
> * [ ] None of these features empower the self-service of data viewers and data explorers.

#### Quiz 8.

> [!important]
> **LookML developers can use Looker's SQL Runner feature to investigate and modify any query.**
>
> * [ ] False
> * [ ] True

#### Quiz 9.

> [!important]
> **What is the keyboard shortcut LookML developers can use to place themselves into Development Mode? Please choose the best answer.**
>
> * [ ] Control + Alt + D.
> * [ ] Control + Shift + D.
> * [ ] Shift + Alt + D.
> * [ ] None of these shortcuts apply.

## Data Modeling using LookML

This module reviews how to model new dimensions and measures using LookML. The module also explores the use of dashboards to combine key queries and visualizations into a one page executive view

### Video - [Anatomy of a LookML project](https://www.cloudskillsboost.google/course_templates/327/video/515589)

* [YouTube: Anatomy of a LookML project](https://www.youtube.com/watch?v=HBV8HVDfK6k)

To prepare yourself for writing LookML code, there are some key terms and overall project structure that you need to know. Let’s begin with an easy one - what does the “ML” in LookML stand for? LookML stands for Looker Modeling Language. It is Looker’s proprietary language that establishes an abstraction layer for SQL. Developers use LookML to tell Looker what data to use from the connected database and how it should interpret that data. Specifically, LookML acts as the modeling layer between the connected SQL database and your business users. Looker uses the LookML code written by developers to define how business users interact with a connected database and to construct SQL queries against that particular database. Developers use LookML to define many items from the connected SQL database including data attributes called dimensions, aggregates of dimensions called measures, data relationships such as how to join tables, and custom tables and fields. A key concept of LookML to remember is: If it’s possible in your SQL dialect, it should be possible in Looker. If you can go to your database console and hand-write a SELECT statement that does something in the database, you can also code LookML that Looker can use to accomplish the same task. For full comprehension of the key LookML terms, developers need to understand where each object fits into the overall hierarchy of a LookML project. The highest level is the LookML project itself, which is a library of self-contained LookML code. Because Looker uses Git for version control, a best practice is for each project to map one-to-one with a dedicated Git repository. A project is essentially a library of code for a specific data source or database connection and contains one or more data models. You can think of each project as an semi-independent or mini-instance of Looker, and each project should map one-to-one to a Git repository for version control. Data that cannot be joined together should be separated into different projects because there is no relation to be made across the data. The next level in the hierarchy are models. As previously mentioned, a LookML project is composed of one or more models. A model specifies a database connection and the data views that utilize that connection. Specifically, a model file is used to define: the database connection, the view files that are accessible to this model, and the Explores (which are pre-joined views) and their join logic. Models can also be used to separate and organize Explores by business area. Next on the hierarchy are Explores, which are sets of pre-joined views organized by business area defined within the model files. For example, you might create a model file containing multiple Explores pertaining to customer purchases. Explores are the central component of Looker that allow business and data analysts to conduct self-serve data exploration, analysis, and visualization. Within a model file, developers define Explores that join one or more views together to target specific questions that business users may have. Business users then use the predefined Explores to run queries and create reports and visualizations to answer their questions. So you can think of an Explore as a predefined set of tables that would frequently be joined for business inquiries and use cases. Next, the views that are joined in the Explores represent the underlying database tables. Views are the building blocks of Explores used by business users. Within view files, developers can define the dimensions (or data attributes) and measures (or aggregations of attributes) to provide to business users in the Explore interface. The view names that are joined to create an Explore are also the headers that business users see in the Explore. For example, in an Explore called Order Items, business users may see the Users view, which contains dimensions on users, such as their age and city of residence, and measures, such as their total purchases. Last, but not least on the hierarchy, are the dimensions and measures defined in the view files. Dimensions are data attributes and represent the fields or column of a database table. When the view files are generated from a table by Looker, dimensions are automatically created for any columns that already exist within your database tables. You can also create additional dimensions that would serve as logical representations of table columns. All dimensions appear in the SELECT and GROUP BY clause of a SQL statement that is generated by Looker based on the business user’s selections in the Explore. Measures are aggregates of dimensions and do not live explicitly in your database tables. They must be created using LookML. They aggregate dimensions into values like sums or counts. Note that they do not appear in the GROUP BY statement of the SQL generated by Looker. Instead, they depend on dimensions to determine that grouping, so they appear as aggregate functions in the SELECT statement of the SQL query. To recap, a LookML project is a library of code that models a data source and should map 1:1 to a Git repository for version control. Projects contain model files, which define the Explores that should be packaged together, how those Explores work, and which views are joined in which Explores. View files describe database tables or logical representations of them and are joined together to define Explores in the model files. Views are then accessed by business users through the Explore to query data and create reports and visualizations. Dimensions and measures are defined within view files. Dimensions are attributes of data and represent fields or columns in the database tables, while measures are aggregates of dimensions such as a COUNT or SUM. After this introduction to the LookML key terms and hierarchy, you are now ready to start exploring your organization’s Looker instance as a LookML developer.

### Video - [Modeling dimensions](https://www.cloudskillsboost.google/course_templates/327/video/515590)

* [YouTube: Modeling dimensions](https://www.youtube.com/watch?v=ZK6GnPAEdxc)

In Looker, dimensions are qualities or attributes of your data. Typically, each dimension represents a column in your underlying database. If you use Looker to generate your model files from a data source, your model’s view files will already contain a dimension for each column in the database tables. In the view files, you can also define custom dimensions using LookML. Let’s dive into modeling dimensions within view files, so that you can create new ones or modify existing ones using LookML. When Looker generates a new view file from a table, it automatically creates dimensions for every column (or field) in the database table. Auto-generated dimensions have a sql parameter containing the word TABLE highlighted in blue, with a dollar sign and curly braces, such as: sql: ${TABLE}. first_name ${ } is LookML substitution syntax. The substituted value is added, then the expression is processed. ${TABLE} references the table specified in the sql_table_name parameter at the top of your view file. This lets Looker know which database table to use as the default table when pulling the dimensions and measures. Another version of the substitution syntax is using an existing dimension or measure name within curly braces, preceded by a dollar sign, such as: sql: ${field_name} When defining new dimensions that build on existing ones, it is a best practice to use the ${field_name} substitution operator instead of the ${TABLE} reference, so that you can reduce the instances of hard-coding columns names in your code. In this example, the syntax references existing LookML objects called first_name and last_name to build a new dimension called full_name. Note that concat( ) is only an example. You can use any database-specific SQL statement in the LookML sql parameter to define a new dimension. Referencing the Looker object is better than the hard-coded database column, so that the new field inherits any transformations or additional logic from the overall dimension. It also reduces the number of times or places you’ll need to make updates if something like the database column name changes. In Looker, there are four common dimension types. The first one is string. String is the LookML term for what in your database dialect could be varchar, char, text… or simply string! It is used for text values, such as a name, and is the default dimension type in Looker. This example shows how a new string dimension called full_name can be created from concatenating two existing string dimensions, first_name and last_name. The next common dimension type is number. Number type fields are used for columns of numeric data types such as int, decimal, or float. You should also use the number type to define new dimensions whenever you will use it to store mathematical computations like addition or subtraction. For example, a common use case for number is date difference logic, such as the one seen in this example which calculates the number of days since a user signed up on a platform. The third common dimension type is the yesno field type, which is a Boolean. It produces a “Yes” value if the condition entered in the sql parameter is met. If the condition is not met, then it produces a “No” value. An example use case for yesno field types would be to label “new” users who have only been users on a platform for a specific length of time, such as 90 days or fewer. The last common dimension type are Tier dimensions, which are useful for bucketing values. When defining a new tier dimension, you need to use the tiers parameter to indicate which buckets you want to assign. Each comma-separated number will be the start of a range. For example, a 0 followed by 30 means that there is a first bin containing the values from 0 to 29, followed by a second bin beginning at 30, and so on. There is also a style parameter where you can specify how you want the results to be formatted for business users, such as integer to display the bin range as whole numbers or relational to display text expressions that include symbols such as less than or greater than. To learn more about the various style options, refer to the Looker docs on styles for tier dimensions. Less commonly used, but still very useful, is the dimension group of type time. For these dimension groups, you use the timeframes parameter to specify the date and time parts required for the data. There are many options for the timeframe, such as hour, day_of_week, month, quarter, or year. The number of dimension fields created within a dimension group is dependent on the number of timeframes listed in the timeframes parameter. For example, including only date, hour, month, and year will result in only these four dimension fields created as part of the dimension group called “created”. The timeframe is appended to the dimension group name in the field picker when you explore the data, like "Created Date" and "Created Month". Thus, do not use words like "date" or "time" in the dimension group name, otherwise you will see the field name like "created date date". When generating new view files from tables, Looker will automatically create dimension groups for most date and time columns; though, it is possible for some formats to not be automatically recognized by Looker. When using an existing dimension group timeframe to define another dimension, for example, in a dimension performing a DATE_DIFF( ) or difference between two dates, you can specify the desired date or time unit to identify the date field from the dimension group called “created”. To do this, simply append the date or time unit to the name of the dimension group using an underscore, such as ${created_date} to specify that you want the date field from the dimension group called “created.” In this example, a new dimension named shipping_days is created based on the difference between the ${shipped_date} and the ${created_date} in number of days. Another dimension group type that is not as commonly used and can be quite helpful is the dimension group of type duration. Using the intervals parameter, you can allow business users to choose from a range of time intervals. When possible, a best practice is to create dimension groups of type duration instead of defining dimensions that perform DATE_DIFF() functions in the sql parameter. This allows you to avoid hard-coding the date part, so your business users can choose what works best for them. Additionally, this prompts Looker to write the function for you, which is easier if you’re not as comfortable with SQL, and it will create less work for you in the future, in case your company ever decides to change the underlying data source. Similar to timeframes, the number of dimension fields created for a dimension group of type duration depends on the number of intervals provided in the intervals parameter. To use a dimension group interval to define another dimension, you need to write the desired interval before the dimension group name itself, like ${hours_enrolled} or ${days_enrolled}. In conclusion, there are many dimension types in Looker including string, number, yesno, tier, and dimension groups for time and duration. When referencing a column from a database table for the first time in a LookML model, use ${TABLE}. When defining new dimensions that build on existing ones, you can reduce the instances of hard-coding column names by using the ${field_name} substitution operator to reference the existing LookML object. After this introduction to modeling dimensions, you are now ready to start curating dimensions in your organization’s Looker instance!

### Video - [Example: Creating dimensions using LookML](https://www.cloudskillsboost.google/course_templates/327/video/515591)

* [YouTube: Example: Creating dimensions using LookML](https://www.youtube.com/watch?v=Ukvxva56D28)

As a LookML developer, you can modify existing dimensions and define new new ones as needed for your business users. For example, imagine you are working with marketing business users. They appreciate that they can see the first name and last name of each user in the Order Items Explore, but they have asked if you can create a single dimension that contains the users’ full names. Let’s walk through an example to see how you can create a new dimension for full name by combining existing dimensions for first name and last name in the Users view file. To begin, enable Development Mode by toggling the button for Development Mode on the bottom left corner of the Looker home page. Then, click Develop on the left side navigation menu to see the develop options. Within the Develop options, click on Projects. Click on the training_ecommerce project under Project. In the file browser, navigate to the users.view file in the training_ecommerce project. To make a new dimension to represent a user’s full name, scroll down to find the last_name dimension. Then, add a new blank line to make space for the new dimension. The location of the new dimension could be anywhere in the view file, even before the last_name dimension, and Looker would work perfectly. Placing it after the last_name dimension is simply a convention to help keep the code organized. Now, using the same indentation as the existing dimensions, start typing the word dimension. Notice that as you write code, the Looker IDE will check your syntax and make suggestions in real time. Enter a colon (:) after the word dimension. You will see two curly braces appear. Be sure to leave these curly braces. You will add code within these curly braces to tell Looker how this dimension should be defined. After the colon following the word dimension, but before the curly braces, you need to provide a name for the new dimension. Use all lowercase letters because LookML is case-sensitive. For names containing multiple words, we recommend using underscores to represent spaces between words. For example, full_name would work well as the name for the new dimension that combines first_name and last_name. Looker will display the field to the end user with the underscore replaced with a space and the first letter of each word capitalized. Next, between the curly braces on the following line, define the type of dimension you want with the keyword type, followed by a colon. Now, because you are combining two other string dimensions (first_name and last_name) to create this new dimension, you would choose the dimension type string. On another new line between the curly braces, add the sql parameter by typing sql, followed by a colon. Just like before, Looker will suggest options and add syntax, such as the two auto-generated semicolons at the end of the sql parameter. Be sure to leave these semicolons, as this syntax is how Looker knows where the SQL expression ends for a given field. For the SQL, there are two options to select existing dimensions, such as first_name. The first way that we can specify first_name is to type ${TABLE}. first_name. This substitution syntax hard-codes the first_name column in the database and will plug in the view’s sql_table_name at runtime. However, because there is an existing dimension in our view file, it is a best practice to use ${first_name} for the sql parameter, so we can reference the existing LookML dimension. So you can replace ${TABLE}. first_name with ${first_name}. To finish the SQL statement, you need to combine first_name and last_name. To do this, you can use the SQL function CONCAT. It’s important to note that anything you write in the sql parameter needs to be valid for your database dialect. So for this example that uses data in BigQuery, start the SQL expression with concat, followed by an open set of parentheses. Within the parentheses, include the first_name dimension, followed by a comma. Then, include an empty space within double quotes (“ ”), followed by another comma, and then the last_name dimension. Notice again that you are referencing the existing dimension names, so the final code for the sql parameter is: concat(${first_name}, “ ”, ${last_name}) Now, click Save Changes. Then, click Validate LookML to check that you have written valid LookML to define your new dimension. If you have the permissions to make changes to production, you will see a button to commit changes and push to production. For now, know that while you can choose to commit and push the changes after validating the LookML, it is always a good idea to review your changes in the Explore first. Within the Explore tab, click on Order Items to pull up the Explore. When developing in LookML, we recommend keeping one tab open on the Explore in Development Mode, so you can switch to it, refresh, and quickly validate what you’ve just built. Notice that Full Name is now a new dimension under Users. You can select Full Name along with First Name and Last Name, and click Run to see the results. Congratulations - you have successfully defined and tested a new dimension in Looker!

### Video - [Modeling measures](https://www.cloudskillsboost.google/course_templates/327/video/515592)

* [YouTube: Modeling measures](https://www.youtube.com/watch?v=rYz_vOc4I9A)

In Looker, dimensions represent the data attributes in a database table, whereas measures are ways to perform aggregate functions, such as a count, on the dimensions. In this section, we will focus on how you can define measures within view files to curate various types of aggregations using LookML. Whenever you define new dimensions and measures that build on existing ones, it is a best practice in Looker to use ${field_name} to reference existing LookML objects. Since measures aggregate dimensions, it makes sense that definitions of new measures use this syntax to reference existing dimensions, rather than hard-coding the underlying column name. Specifically, the LookML code for a measure points to one or more existing dimensions in the sql parameter and then defines a way to aggregate them in the type parameter. There are three common types of measures in Looker. The first type is sum. As it sounds, sum aggregates the values in a specified dimension by adding all values together to calculate a total value. In this example, a new sum measure called total_revenue is defined, based on the existing dimension called sale_price. The final result is a measure that provides the total of the values in the sale_price dimension. The second type of measure is average. This measure delivers its namesake, in other words, the mean value of the specified dimension. In this example, a new average measure called average_sale_price is defined and uses the same existing dimension (sale_price) as the previously created sum measure. In this case, Looker knows that the new measure called average_sale_price is an average and not a sum because the measure type is set to average. This results in a measure that provides the average of the values in the sale_price dimension. The last type of measure is count. Unlike the sum and average measures, count measures do not require the sql parameter by default. For instance, if you use Looker to generate your model files from a data source, your model’s view files will already contain a default measure for the count of rows. This count does not use the sql parameter; instead, it will simply use the view’s primary key as the dimension to aggregate. In this example, the default count measure would provide a count of the order_item_id, which is the primary key of the view. If you want to count something other than the view’s primary key, you need to use the measure type called count_distinct. It requests you to input a sql parameter for the dimension you want to count. In the second example, the count_distinct uses the ${user_id} dimension to calculate the count of unique users. In summary, there are three primary measure types in Looker including sum, average, and count. To define a new measure, use the sql parameter to specify which dimensions you want to aggregate, and then define a way to aggregate them using the type parameter. And that’s it! Hope you are excited to start creating new measures in your organization’s Looker instance!

### Video - [Example: Modeling measures using LookML](https://www.cloudskillsboost.google/course_templates/327/video/515593)

* [YouTube: Example: Modeling measures using LookML](https://www.youtube.com/watch?v=amsMR6j6v1E)

In Looker, you can define measures to aggregate dimensions in your data such as getting a count or average. For this example, imagine that your view already contains a dimension for sale price for ordered items, and you want to use it to calculate the total dollar amount of all ordered items. What kind of measure do you need to create? The keyword total tells you that you need to create a measure of type sum. Let’s see how easy it is to create a new measure to calculate a total of all sale prices for ordered items. To begin, enable Development Mode by toggling the button for Development Mode on the bottom left corner of the Looker home page. Then, click Develop on the left side navigation menu to see the develop options. Within the Develop options, click on Projects. Click on the training_ecommerce project under Project. In the file browser, navigate to the order_items.view file in the training_ecommerce project. To make a new measure for total sales, scroll down to the last dimension in the order_items.view, and add a new blank line under the last dimension. While the measure can go anywhere in the view file and Looker will work perfectly, this supports readability of the view file, as all measures will be defined after the dimensions in the view. Now, using the same indentation as the existing dimensions, start typing the word measure. Notice that as you write code, the Looker IDE will check your syntax and make suggestions in real time. Now, enter a colon after the word “measure”. You will see two curly braces appear. In the next steps, you will add code within these curly braces to tell Looker how this measure should be defined. Add a name for the new measure after the colon, following the word measure but before the curly braces. Similar to naming other LookML objects, we recommend using all lowercase letters and using underscores to represent spaces between words. In this case, “total_sales” would work well as the name of the new measure that you are creating for the total dollar amount of all ordered items. Next, between the curly braces on the following line, define the type of measure you want with the keyword type, followed by a colon. Now because you are calculating a total, you would choose the measure type sum. On another new line between the curly braces, add the sql parameter by typing sql, followed by a colon. Notice that Looker adds two auto-generated semicolons at the end of the sql parameter. Similar to defining dimensions, you need to add the desired SQL before these two auto-generated semicolons, so that Looker knows where the sql parameter ends. In this case, you can use the syntax to identify an existing dimension called sale_price by typing: ${sale_price}. The sql parameter combined with the type sum will result in a new measure that is the sum of all values in the sale_price dimension. Last, specify a format for the measure using the value_format_name parameter and the parameter value usd_0, which represents the currency format ($) used in the United States, rounding to the nearest dollar. Now, click Save Changes. Then, click Validate LookML to check that you have written valid LookML to define your new measure. At this point, you could commit your changes, but you should test your new measure locally to ensure it works as intended for your end users. Within the Explore click on Order Items under E-Commerce Training to pull up the Explore. Notice that Total Sales is now a new measure under Order Items. You can select Total Sales, and click Run to see the results. And with that, you have now defined and tested a new measure in Looker! Pretty easy, right?

### Video - [Dimension + measure modeling logic](https://www.cloudskillsboost.google/course_templates/327/video/515594)

* [YouTube: Dimension + measure modeling logic](https://www.youtube.com/watch?v=sEKGsmzP2r4)

LookML provides advanced logic options that you can use when you define dimensions and measures. Let’s review some of these options, so that you can further customize dimensions and measures to curate data experiences for your business users. As you may know, in LookML, you can use the syntax ${field_name} to reference existing dimensions and measures within the current view file. Additionally, you can also reference dimensions and measures from other view files by fully identifying them, just as you would in SQL. To do this, you simply write the view name and a period before the field name, all within the curly braces following a dollar sign, such as: ${inventory_items.cost}. Keep in mind, though, that in order for this syntax to work correctly, the two views involved need to be joined together in an Explore. In this example, the current view containing the sale_price dimension would need to be joined with the inventory_items view in an Explore where the dimension “profit” is used. Now, just as you can reference existing dimensions when creating new measures, you can also reference previously-modeled measures when defining a new measure. For example, your new measure could include multiple measures interacting with each other, such as calculating the percentage of users located in a specific country, out of the total number of users. Please remember though that whenever you want to include other measures in the sql parameter of a new measure, you need to use the measure type called number. Last, a useful parameter for defining measures is the filters parameter, which you can use to create measures based on specific dimension values. In this example, the filter is based on the value “USA” in the country dimension. The count is completed using the primary key of the view, which in this case is user_id for the users view. The resulting measure is a count of user ids with a country value equal to “USA”. Take note though that although the filters parameter does not use the familiar substitution syntax of ${field_name}, the field names still actually refer to existing LookML dimensions, not the literal database column names. However, in this second example, the filter is based on an existing yesno dimension named is_new_user. Only rows that return a value of “Yes” for this dimension are summed across the sales_price dimension for a sum of sales to only new users. Both of these examples would generate a CASE statement (in other words, if/then/else) within the aggregate function of the SQL query. In summary, LookML provides several options for advanced logic when defining custom dimensions and measures. As demonstrated through these examples, you can reference fields in other views, use measures to define other measures, and use dimensions to filter measures. You should find these advanced logic options useful, as you gain more experience with curating dimensions and measures for your business users.

### Lab - [Creating Dimensions and Measures with LookML](https://www.cloudskillsboost.google/course_templates/327/labs/515595)

In this lab, you write LookML code to create new dimensions and measures for business users using a mock e-commerce dataset containing information on orders and users.

* [ ] [Creating Dimensions and Measures with LookML](../labs/Creating-Dimensions-and-Measures-with-LookML.md)

### Video - [LookML dashboards](https://www.cloudskillsboost.google/course_templates/327/video/515596)

* [YouTube: LookML dashboards](https://www.youtube.com/watch?v=7HxFLimtlT8)

This final lesson picks up near the conclusion of a relatively realistic scenario involving a number of employees of a company who are working together to answer a data-related question. A Looker dashboard is a collection of queries displayed as visualizations on a page. Dashboards let you combine key queries and visualizations into a one page executive view. You can add filters to make the dashboard interactive and rearrange its tiles. You can create as many dashboards as you want, so you can tailor each dashboard to the specific needs of the people who use it. Depending on the type of user, Looker provides the capability of creating two different types of dashboards: user-defined, or LookML dashboards. User-defined dashboards are the ones data viewer and data explorer end users create, modify and otherwise generally work with, stored locally in the Looker instance. LookML dashboards, however, are modeled by LookML developers using LookML and live in a code storage with version control system, like GitHub. One of the powerful features of Looker offers for user-defined dashboards to be dynamically converted to user-defined dashboards, and LookML dashboards to be dynamically converted to user-defined dashboards, allowing for ultimate dashboard flexibility in who can use what. To create a LookML dashboard, we first need to be in Development Mode. Begin by enabling Development Mode by toggling the button for Development Mode on the bottom left corner of the Looker home page. Then, click Develop on the left side navigation menu to see the develop options. Within the Develop options, click on Projects. Click on the training_ecommerce project under Project. In the training_ecommerce project, click vertical three-dot menu at the top of the file browser panel in the Looker IDE and click Create Dashboard. Give your dashboard a new name, but take note of the file extension . dashboard.lookml. This naming convention is Looker best practices when working with LookML dashboards. Once your new dashboard file has a name, click on the Create button. You will then be presented with the LookML dashboard version of a Hello World coding example. This is the scaffolding of a blank LookML dashboard. As a LookML developer, you could begin coding your own LookML into this framework to create your new LookML dashboard. However, you could also reuse LookML from an existing user-defined dashboard. It’s very easy. Let’s do that. If your Looker administrator has enabled the see_lookml permission for your account, you can navigate to a user-defined dashboard’s underlying LookML by selecting Go to Dashboard LookML from the dashboard’s vertical three-dot menu and select “Get LookML”. When you select Get LookML, Looker generates that user-defined dashboard into its comparable LookML code. You can click the “Copy to Clipboard” link to grab all of this user-defined dashboard’s LookML, or you can highlight only what you want and right-click and select “Copy”. Once you paste in the LookML from the user-defined dashboard, you will edit the LookML dashboard’s file header with the name, title, and any configuration or layout preferences. When the dashboard configuration is completed, you would validate, test, commit and ultimately push it to a repository like GitHub just like you would for any other LookML file. But how can we accomplish the reverse: creating a user-defined dashboard from a LookML dashboard? From the navigation pane on the left, click on the Folders drop-down menu and select the LookML dashboards folder. On the LookML Dashboards page, tick the checkboxes on for any LookML dashboards that you want to convert to user-defined dashboards. When you’ve completed your LookML dashboard selection, click on the Import button to begin the process of deciding what parts of the LookML dashboard to pull into your new user-defined dashboard. In the Import Dashboards pop-up, choose a folder for your new user-defined dashboard. Select OK to import the dashboard into the selected folder. You have have a brand new user-defined dashboard, mirroring its LookML dashboard sibling! Note that it’s very easy to distinguish which is which, because the new user-defined dashboard has (imported) in its name. If you’re already viewing a LookML dashboard, though, you can click on the vertical three-dot menu and select the “Copy LookML dashboard” menu option to accomplish the same thing. In the Copy  pop-up, assign your new user-defined dashboard a name, its folder destination, and whether you want the new dashboard to preserve the existing LookML dashboard locale keys. Only select this option if you believe it will get converted back into a LookML dashboard in the future. When you’re ready, click on the Copy button to create the new user-defined dashboard. And that’s it. You have a brand new user-defined dashboard once again!

### Quiz - [Module 2 Quiz](https://www.cloudskillsboost.google/course_templates/327/quizzes/515597)

#### Quiz 1.

> [!important]
> **count computes a distinct count of the field in the SQL parameter.**
>
> * [ ] False
> * [ ] True

#### Quiz 2.

> [!important]
> **Developers utilize the Looker modeling language (LookML) to define all but one of the following items. Which item would a LookML developer NOT define using LookML? Please choose the best answer.**
>
> * [ ] Data relationships.
> * [ ] Extends.
> * [ ] Dimensions.
> * [ ] Measures.

#### Quiz 3.

> [!important]
> **What is the definition of a measure in Looker? Please choose the best answer.**
>
> * [ ] It represents multiple rows of data in a table.
> * [ ] It leverages aggregate functions similar to those found in SQL to represent rows of data.
> * [ ] It leverages ONLY SUM, AVG, and COUNT functions to represent multiple rows of data.
> * [ ] It represents multiple rows AND columns of data in a table.

#### Quiz 4.

> [!important]
> **When you create a new LookML dashboard, what's the filename convention used? Please choose the best answer.**
>
> * [ ] dashboard.lookml.new_dashboard.
> * [ ] new_dashboard.dashboard.lookml.
> * [ ] new_dashboard.lookml.dashboard.
> * [ ] lookml.dashboard.new_dashboard.

#### Quiz 5.

> [!important]
> **The number dimension type is the default dimension type assigned by Looker to a newly created dimension.**
>
> * [ ] True
> * [ ] False

#### Quiz 6.

> [!important]
> **Views correspond to Explores in the Looker platform.**
>
> * [ ] False
> * [ ] True

#### Quiz 7.

> [!important]
> **Using LookML, developers can reference fields in other view files.**
>
> * [ ] True
> * [ ] False

#### Quiz 8.

> [!important]
> **Which option does NOT represent an example of a dimension? Please choose the best answer.**
>
> * [ ] A column in an underlying table.
> * [ ] A derived value, based on the values of other fields.
> * [ ] A fact, or numerical value.
> * [ ] The entirety of a data table.

#### Quiz 9.

> [!important]
> **Which of these scenarios is possible using LookML? Please choose the best answer.**
>
> * [ ] None of these scenarios are possible using LookML.
> * [ ] Measuring the percentage of a LookML-defined filter.
> * [ ] Measuring the percentage of a Look-defined dimension.
> * [ ] Measuring the percentage of a COUNT function result.

#### Quiz 10.

> [!important]
> **User-defined dashboards are stored in version-controlled files associated with a project in a Git repository.**
>
> * [ ] False
> * [ ] True

## Modeling Explores for your Users

This module provides a deeper dive into the model files of LookML projects for developers to start designing and building custom Explores for business users.

### Video - [Modeling new Explores](https://www.cloudskillsboost.google/course_templates/327/video/515598)

* [YouTube: Modeling new Explores](https://www.youtube.com/watch?v=Go-fUUPUM50)

In Looker, Explores can be thought of a set of tables with predefined join logic. As a LookML developer, you define and curate Explores for users at your organization to analyze data and answer their business questions. Within the model file of a project, you can define Explores similarly to how you define dimensions and measures: by typing the word “explore” followed by a colon (:), and giving it a name such as order_items. Unlike dimensions and measures, which can be named however you like, the name of the Explore must be the name of an actual view file. For example, in the training_ecommerce.model file, you can define an Explore called order_items that references the order_items.view file. To understand how to define explores, let’s review the key parameters within the explore definitions in a model file. First, the explore name establishes the base view, meaning that it is the central view for analysis in the Explore. Other views joined to this Explore provide additional or supplemental analysis capabilities. For example, the base view for an e-commerce company could be named order_items, which would provide details on individual orders. Since all ordered items are associated with a user, your business users may also want to pull details for the users to track their engagement and order history. Now, to support this, you need to define a join in the explore definition using the join parameter. In this example, you can join the users view to the order_items view by typing the word “join” followed by a colon (:), and giving it a name such as users to indicate that the join is to the users view. Then, you need to provide a value for the type parameter to identify the join type between order_items and users. The four types of joins available in Looker are: left_outer, inner, full_outer, and cross. If no type is provided, the default type applied is left_outer. left_outer join means that all records in the left-side view of the join will be retained, even if there is not a match with any records in the right-side view of the join. inner join means only matched records between the two views will be retained, while full_outer means all records in both views will be retained whether or not there is a match in the other view. Cross join generates a paired combination of all rows across both views, independent of whether records match or not. In this example, left_outer results in all records in the order_items view to be retained even if there is not a match in the users view. After defining the join table and type, you need to provide the data fields for the join using the sql_on parameter. The fields provided in the sql_on parameter identify how to actually join, or connect, the two tables based on a shared value. Typically, you join two tables using a dimension from one view that is the same as a dimension in the other view. For example, the order_items view contains a user_id field that is the same as the id field in the users view, you can join the tables on these two fields. However, depending on your use case, you could join on multiple dimensions, perform an inequality join, and more, using any regular SQL query syntax that you need. Last, the relationship parameter describes the cardinality between the two views, meaning how many records could potentially be matched between the views based on the fields identified in the sql_on parameter. In Looker, the options for relationships are one-to-one, one-to-many, many-to-one, or many-to-many. If no relationship parameter is provided, the default relationship applied is many_to_one. One-to-one indicates that each record in both views has only one matching record in the other table. Many-to-one indicates that there may be many records from the first view that are connected to only one record in the second view table, and vice versa for one-to-many. Many-to-many means that there could be multiple records in the left view that match multiple records in the right view. For example, in the Order Items Explore, there may be many ordered items connected to the same user, so the relationship is many_to_one. As the name of the Explore is also the base view, it is always in the FROM clause of any SQL query generated in the Explore. Joins defined directly to the base view of an Explore are referred to as standard joins. Here we have a different dataset that contains flight information. In this example, the join for inventory_items is considered a standard join because it joins directly to the base view of flights in the sql_on parameter. Let’s take a look at a different model file. Sometimes you may need to join the same table twice in an Explore. In the world of manually writing SQL queries, you would give the two tables different aliases. In LookML, you can do this by providing a unique name for the join, and then referencing the actual view name to be joined in the from parameter. In this example, the joins named aircraft_origin and aircraft_destination are both joining the same views named flights and airports to provide different information: one join for the origin location and another join for the destination location. The names of the joins use alias names, while the from parameter both specify airports. Notice that the sql_on parameter uses the alias names as well. Of course, you can also write indirect joins that do not join to the base view; instead, they join to another view in the Explore that is already joined to the base view. Indirect joins can be useful when there is no shared join key with the base view but can potentially impact performance. In this example, the join aircraft_flight_facts does not join to the base view called flights; instead, it joins to aircraft, which is referenced in the second join in this Explore. Any time a business user has an inquiry involving aircraft_flight_facts, the generated SQL query will first select FROM flights and then join to aircraft—even if no fields or filters are needed from aircraft itself—so that it can then join to aircraft_flight_facts. So due to the extra join, we recommend that you aim to use a join key from the base view when possible, rather than using indirect joins. At this point, it is useful to review how Looker generates SQL to better understand the role of the joins defined in the explore. You should recall that a typical SELECT statement grabs one or more columns FROM a table, possibly with a JOIN or two, ON some columns, WHERE some filter condition is met. In Looker, as users run queries in an Explore, their chosen dimensions and measures are added as the columns to SELECT statement of the generated SQL query. The FROM clause uses the base view, and any required JOINs are added from the provided sql_on logic in the join definition. Then, if the user adds a filter on a dimension, such as date greater than or equal to (>=) ‘2020-01-01’ or country equal to (=) ‘USA’, this becomes the WHERE clause. Here is an example SQL query you might have needed to write by hand before using Looker. Imagine that you want to get the number of canceled flights whose aircraft originated in the state of California as well as some additional details about these canceled flights such as flight destination, aircraft name, and aircraft origin. In the SQL query, you are: SELECTing three columns FROM flights with LEFT JOINs to aircraft and airports, using COUNT to get the number of flights, applying WHERE clauses to identify aircraft originating in the state of California and flights that have been canceled, and then GROUPing by flight destination, aircraft name, and aircraft origin. By defining the Flights Explore, you can allow Looker to write that SQL query for your business users. They can simply select the three dimensions for flight destination, aircraft name, and aircraft origin, the measure for count, and two filters for canceled and aircraft_origin—all selected from the three views for flights, aircraft, and airports. The type and sql_on parameters in the aircraft and aircraft_origin joins would identify how those joins should work in the Explore to provide the requested results. No interaction with SQL needed! By leveraging your pre-defined Explore logic, Looker empowers self-serve analysis and exploration by your business users, which saves you time and resources as a LookML developer. In summary, as a LookML developer, you define the Explores for business users within the model file of a project. The name of the Explore must be the name of an actual view file, and you can define joins to other views in your model to provide additional details in the Explore. To define a new join, use the join parameter to name the join, typically the same name as the actual view file. Then, use the type parameter to identify how the two views should be joined, such as left_outer. The sql_on parameter identifies the shared column that is being used to join the tables, while the relationship parameter is used to identify the cardinality, or how the records in the views are matched, such as many_to_one. After this overview of Explores and join logic, you can now create new or modify existing Explores for your business users to analyze and visualize data in your organization’s Looker instance.

### Video - [Using LookML to filter Explores](https://www.cloudskillsboost.google/course_templates/327/video/515599)

* [YouTube: Using LookML to filter Explores](https://www.youtube.com/watch?v=ZOV-CdQ8aBE)

In Looker, a great way to take your Explores to the next level is with custom filters to guide your business users as they explore the data. To filter an Explore, you need to apply a default WHERE or HAVING clause to every SQL query that gets generated in that Explore. There are three principal ways to add default filters to an Explore: sql_always_where and sql_always_having, which behave similarly and have the same use case; always_filter; and conditionally_filter. As we review these options, we will discuss common use cases for each. Both sql_always_where and sql_always_having allow you to add filters to an Explore that cannot be modified by business users. This is useful when you have certain rows of data you always want to exclude from the Explore results such as sensitive data or personally identifiable information (PII). The filtering does not display in the user interface, so business users are not informed that the data are being filtered, unless they have permission to look at the generated SQL. Remember though, if your Explore filter uses a field from a different view other than the base view, that view will always be joined in to every Explore query as well, even if the business user doesn’t explicitly select or filter on any dimensions or measures from it. The join to that Explore needs to be there for the filter condition to work. sql_always_where is specifically used to add a WHERE clause that applies to dimensions in the SQL query. sql_always_where will also affect field filter suggestions, as well as Looks and dashboards. For example, if you set up a filter to remove test data from the Full Name dimension, the filter dropdown menu for Full Name would not suggest any names containing the word “test”. If desired, this can be overridden with the full_suggestions parameter for dimensions. Similarly, sql_always_having is used to add a HAVING clause that applies to measures in the SQL query. Again, when applied, this filter cannot be modified by business users and is not visible to them, unless they have access to see the generated SQL query. always_filter adds a filter to the Explore frontend that is accessible to business users. Users can change the filter operator and specific values, but they cannot remove the filter itself. always_filter has a subparameter to define the dimensions that users must provide values for, such as a value for order status or user country. For example, while the default order status is “Complete”, business users can change this value to say orders with a different status like “Returned”. This filter is helpful for optimizing query performance and cost savings because you ensure that users always filter by specific dimensions, such as filtering by order status or user country, so that they do not request all of the possible data at one time. Similar to always_filter, conditionally_filter adds a filter to the Explore frontend that is accessible to business users. In this case, users can remove the filter itself if they put a filter on a specific alternative field. conditionally_filter has a subparameter to define the specific filters as well as a subparameter to define the alternative dimensions that can be used to filter the data. For example, conditionally_filter can be used to create a filter that only returns data for the past 1 month, unless a filter is applied to a user ID or state dimension. This filter is helpful when you want to limit the amount of data that a business user requests, but you also want to give them a list of alternative dimensions that they can use to filter the data. In summary, there are three principal ways to add default filters to an Explore. sql_always_where and sql_always_having are both used to add filters that cannot be modified or seen by business users. Specifically, sql_always_where is used to apply default filters for dimensions, while sql_always_having is used to apply default filters for measures. Both always_filter and conditionally_filter are helpful for ensuring that users always filter the data using specific dimensions, so that they do not request all of the possible data at one time. While the filter for always_filter cannot be removed by business users, conditionally_filter allows users to remove the default filter if they choose an alternative dimension from a provided list of options. Be sure to take advantage of these useful filter options in Looker to further customize Explores for your organization’s business needs!

### Video - [Understanding symmetric aggregation](https://www.cloudskillsboost.google/course_templates/327/video/515600)

* [YouTube: Understanding symmetric aggregation](https://www.youtube.com/watch?v=81IDvCbYYRI)

A key concept to understand when working with Explores and join logic is symmetric aggregation. This is a great feature of Looker that ensures accurate aggregation of data for counts, sums, and averages. Let’s explore in detail how symmetric aggregation works in Looker. Symmetric aggregation addresses a common problem in data and analytics called the fanout problem. Imagine you have two tables, customers and orders. The customers table stores customer data such as customer ID, first name, last name, and the number of visits they have made to your ecommerce platform. The orders table stores order data such as order ID, the amount of the order, and the ID of the customer who placed it. The relationship between the tables is one-to-many because a customer can make multiple orders, but each order can only be made by a single customer. Consider these two tables individually: count(*) produces counts of 3 customers and 4 orders. sum(visits) and sum(amount) produce 8 visits and $250 in total revenue. When considering these tables individually, the count and sum operations produce accurate results. There are 3 total customers, 4 orders, 8 total visits, and $250 in total order spending. To join these two tables in an Explore, it is pretty clear that customer_id should be the join key. However, given the one-to-many relationship, you actually produce what is called a fanout when you join them on customer_id. This join fans out the customer table: count(*) and sum(amount) still work on the orders table fields, but… count(*) and sum(visits) produce bad results on customers table fields. Looker handles this with symmetric aggregates! This new table illustrates the result of the one-to-many join, which fans out the customers table. It introduces a duplicate row for customer_id 1 because Amelia Earhart made more than one order. When performing aggregations on the customers side of the table, you would now get incorrect results. For example, SUM(visits) amounts to 10. Looking at this table, you are capable of realizing that one of those total visits is a duplicate, and that the true answer is 8. Likewise, a COUNT(*) of customers yields 4 rows, which you can identify should actually be 3. On the orders side of the table, the aggregations return accurate, as no fanout occurs in the “many” side of the join. The fanout problem is a longtime database problem that is not specific to Looker. Looker has simply implemented symmetric aggregation to resolve this problem, and luckily, it is not a feature that you as a LookML developer need to be conscious of activating in your Looker instance. As long as symmetric aggregation is supported by your underlying database, Looker will automatically implement symmetric aggregations when the following two conditions are met. First, every view file in your model must have a primary_key defined to join it to an Explore. As a best practice, you should strive to define a primary_key in every view regardless of whether it will be joined to an Explore. Second, the relationship parameter needs to be specified accurately for every Explore join. An easy way to test if a primary key is functioning as a unique key is to compare a count of the field you believe to be a primary key against a COUNT(*) on the table. If the two counts return the same number, you have your primary key. If not, or you already know that there is no primary key in your database, you can create a new dimension that concatenates all the columns necessary to make each row unique. Remember you cannot assign the primary_key: yes parameter to more than one dimension in a view. To better understand how joins work in Looker, let’s examine the concepts of left and right tables in more detail. The left side of the relationship value refers to the view that appears first in the Explore, meaning in an earlier line of code. The right side is the view being joined in later, meaning farther down the code file, and is the name next to the join parameter. In this example, the left side of the relationship identified as “one” refers to customers, while the right side, or “many”, refers to orders. Please note, though, that the order in which fields appear in the sql_on parameter does not impact the join. To figure out which relationship is occurs in your data, you can construct a sentence for each possibility and think about whether it makes sense, such as “one customer can relate to many orders”. Another option is to think about the join keys. Is customer_id the primary key? Are the values unique in the first view? What about the other view—is it possible that the same value could appear multiple times there? So what would happen if you specified the wrong relationship between customers and orders, say, one-to-one instead of one-to-many? Well, in this case, the data on the customer's side would fan out. Remember, you only had 3 customers: Amelia Earhart, Charles Lindbergh, and Wilbur Wright. Their combined visits totaled 8. However, by using a one-to-one relationship instead of one-to-many, the Explore returns 4 customers with a total of 10 visits because Amelia Earhart is counted twice, along with her two visits. If you specify the correct relationship between customers and orders, which is one-to-many, then Looker will automatically apply symmetric aggregation, resulting in the correct outputs of 3 customers and 8 total visits. So how does COUNT actually work in symmetric aggregation? You might have already been wondering about COUNT(DISTINCT). Since this query executes a one-to-many join, Looker indeed realizes it needs to count the distinct customer_id values rather than a blanket COUNT(*), which would include duplicate customer_id values from the orders side. Sums and averages are a bit more complex, but function similarly in that distinct records are identified for the calculations using the MD5 hash function. While it can be alarming to click on the SQL button in the Explore and behold a query like the one seen in this example, you can look for instances of MD5 to know that Looker is doing symmetric aggregation for the sum or average. As symmetric aggregation is already implemented by Looker, you do not need to fully learn when and why to use MD5 to be a successful LookML developer. What Looker is basically doing is generating a unique numeric amount for each primary key value using the MD5 hash function. So the two rows for Amelia Earhart would both get assigned a big_unique_number. Then, to calculate the total true visits, Looker uses basic arithmetic problem to determine whether or not it should count a given number of visits again, something like: SUM(DISTINCT visits + big_unique_number) - SUM(DISTINCT big_unique_number) You might wonder, “Why not do a regular SUM(DISTINCT …) without all the hashes?” Well, the SUM(DISTINCT) function only looks at distinct values to sum them up. In this case, it would take only one of the instances of 2 visits and add it to the 4, to give you a total of 6 visits. However, you know you still need two instances of the 2 visits, both Amelia’s and Charles’ number of visits, to give you 8 as the accurate total of visits. In summary, symmetric aggregation is a great feature of Looker that addresses potential fanout problems resulting from data joins. As long as symmetric aggregation is supported by your underlying database, Looker will automatically implement symmetric aggregations when the following two conditions are met. First, every view has a primary_key to join it to an Explore, and second, the relationship parameter for every Explore join is accurate. With symmetric aggregation, Looker ensures that your counts, sums, and averages are always accurate for your business users!

### Quiz - [Module 3 Quiz](https://www.cloudskillsboost.google/course_templates/327/quizzes/515601)

#### Quiz 1.

> [!important]
> **A one-to-many type join can result in fanout if symmetric aggregates are not properly applied.**
>
> * [ ] True
> * [ ] False

#### Quiz 2.

> [!important]
> **Which of the following is required for symmetric aggregation to work in Looker? Please choose the best answer.**
>
> * [ ] Unique primary keys defined in all view files being joined ONLY.
> * [ ] None of these options are required for symmetric aggregation to work in Looker.
> * [ ] Unique primary keys defined in all joined views, and defined join relationships among views.
> * [ ] Correctly defined join relationships between views ONLY.

#### Quiz 3.

> [!important]
> **An Explore can be created from either a single view or table, or a combination of two views.**
>
> * [ ] True
> * [ ] False

#### Quiz 4.

> [!important]
> **The usage and implementations of type: location is NOT dependent on a database's dialect.**
>
> * [ ] True
> * [ ] False

#### Quiz 5.

> [!important]
> **How many different relationship parameters exist for how tables relate to one another? Please choose the best answer.**
>
> * [ ] Three (3).
> * [ ] Four (4).
> * [ ] One (1).
> * [ ] Two (2).

#### Quiz 6.

> [!important]
> **What is the default type given to a filter if one is not defined by a LookML developer? Please choose the best answer.**
>
> * [ ] yesno.
> * [ ] unquoted.
> * [ ] number.
> * [ ] string.

## Working with Derived Tables

This module explains how to use derived tables in Looker to create new custom tables that do not yet exist in the underlying database. This module also provides an overview of how caching works in Looker and how developers can use datagroups to manage caching policies.

### Video - [Introducing derived tables](https://www.cloudskillsboost.google/course_templates/327/video/515602)

* [YouTube: Introducing derived tables](https://www.youtube.com/watch?v=j572nvPAlP8)

Derived tables are a great feature of Looker that allows you create new tables that do not yet exist in a database. In this section, we’ll explore how to use derived tables to define new custom tables to address complex business questions. Recall that when you work with existing tables in your connected database, you reference the necessary table names in the sql_table_name parameter of the view files. You can also see the table names used by a view by reviewing the generated SQL for Explores queries. However, it is not unusual for existing database tables to be insufficient to assist us in answering more complex questions of our data. Sometimes we need to structure our data in other ways through SQL objects like temporary tables, materialized views, common table expressions (CTEs), and subqueries. In LookML terms, if you need to produce a CTE or temp table, you need to define a derived table. The most common use case for derived tables is to overcome structural limitations for patterns that would require a subquery in raw SQL. A nested or multi-step aggregation is a common pattern where we need to do an aggregate of an aggregate. Consider the example of trying to find which department has the highest total sales. You may think to try something like: SELECT MAX(SUM(sales)) FROM orders GROUP BY department However, this query won’t work for two reasons: We cannot take the max of a sum—any database dialect would complain about these nested aggregates. The GROUP BY logic needs to be applied separately. To resolve the issue in SQL, you can isolate the first aggregation and grouping in a subquery, then find the max from those results using: SELECT MAX(subquery.total_sales) FROM (SELECT SUM(sales) as total_sales FROM orders GROUP BY department) AS subquery Now, maybe you want to do some shopping cart analysis, like: are there any patterns to, or drivers behind, orders that contain multiple items as opposed to just one? Or, what is the average number of items people tend to combine in a single order? For the question, you would need to separate orders with one item each versus orders with multiple items, while the second question would be like an average of a count. Or maybe you want classify “high-” vs. “low-value” orders, or determine the average total order cost using a table that is granular to the item level. For the first question, this would be like doing a CASE WHEN with each order_id’s sum of sale_price, while the second question is another inquiry about the average of a sum, specifically average customer lifetime spending. To understand how derived tables can help answer these questions, let’s take a look at an example dataset. Imagine that to the left is the actual structure of the data in the table. To the right is the table structure that you need to answer those various questions related to number of items per order and total order cost. Specifically, you need to calculate each order ID’s count of item IDs and sum of cost. Using derived tables, you can create a new table of these two aggregations, and then use this new derived table to answer questions about orders based on the total number of items or total revenue. So far, we have explored a few use cases where we would need to pre-aggregate, or “dimensionalize,” metrics using derived tables. Of course, there are many more situations in which derived tables would be useful, such as: … analyzing behavioral patterns using raw event data that needs to be partitioned and organized into user sessions based on specific activity timeframes. With a derived table, you can ask questions such as: How often does someone who starts on page A end up converting (doing a specific, desired action)? Or, how much more likely is a consumer to purchase Product B given that they purchased Product A? Another example might be order information that needs to be rolled up by customer and month, so you can determine things like the average amount of time that passes between one order and the next. Or, maybe you are working with multiple tables for various marketing channels. You may want to combine these tables into one large table using a union, so that you can calculate and compare results across all the channels. So, now that we know why derived tables are useful, how do we actually define derived tables to create new aggregations or tables that we need? Derived tables are either manually written SELECT statements or Looker-generated SELECT statements that produce results that can be queried just like a “real” database table. Derived tables are integrated in LookML projects as views. You can explore or join those views in the same way as the other views that point to actual database tables. Derived tables have two types of existence: Ephemeral tables, which compile at runtime and are generated as CTEs or temp tables. Persistent tables, or PDTs, which are stored in the underlying database. The benefit in persisting derived tables is that they are ready to go when business users need them, and therefore reduce query runtimes. The downsides are that they take up storage space in your database (which may correlate to cost), and they are more rigid (they can’t accept dynamic logic). So you may choose to persistent only some of your derived tables, such as the most frequently used ones. In summary, derived tables are a useful feature for defining new custom tables that do not yet exist in your database. Derived tables are used just like other views in your LookML project and produce results that can be queried just like a real database table. Depending on your use case, derived tables can be ephemeral or written back to the database as a persistent derived table. With derived tables, you can create custom tables to aggregate your data in a variety of ways to help you answer business questions. Hope you have fun experimenting with derived tables in your organization’s Looker instance!

### Video - [Types of derived tables](https://www.cloudskillsboost.google/course_templates/327/video/515603)

* [YouTube: Types of derived tables](https://www.youtube.com/watch?v=lGHDeWSQ1iE)

In Looker, you can use derived tables to define new custom tables that do not exist in your underlying database. Derived tables are created in LookML projects as views that you can join in an Explore, just like other views that point to actual database tables. Derived tables also produce results that can be queried just like real database table, and they can be either ephemeral or written back to the database as a persistent derived table. Independent from the two degrees of permanence (ephemeral or persistent), we can use two methods of defining derived tables. First, derived tables can be written in SQL, which is an easy option if you’re already comfortable with SELECT statements in SQL. In addition to being easier to learn and understand for SQL users, SQL derived tables have the advantage of being able to leverage complex and custom joins and calculations, as well as the UNION function. Second, derived tables can also be written entirely in LookML, which we call native derived tables, or NDTs. NDTs embody the essential LookML principle of reusability by allowing you to leverage existing objects in your model, such as dimensions and measures, to define new tables. Because NDTs minimize the number of “hard-coded” database references in your code, they are easier to maintain and allow your model to scale efficiently as your organization’s usage of Looker increases. Let’s explore a simple example to further highlight the key differences between SQL derived and native derived tables. Imagine that you want to create a derived table that contains the numbered of ordered items and the total price for each order in your database. However, what if your LookML model already contains measures for order_item_count and total_revenue? Rather than creating a SQL derived table, you can reuse these existing measures to easily define a new NDT. This would allow you to avoid hard-coding another reference to the underlying database table, thereby saving you work in the future if and when you need to update those measures. In summary, there are two ways to define derived tables in Looker. First, SQL derived tables are easy for SQL users to learn and understand, and can include complex joins and calculations, as well as the UNION function. In contrast to SQL derived tables, native derived tables are expressed entirely in LookML and reuse existing objects in your model such as dimensions and measures to create new tables. They are often easier to maintain and scale because they minimize the number of “hard-coded” database references in your code. Though which option you use will depend on your particular details of your LookML project, both SQL derived and native derived tables are great features in Looker that you can use to create new, custom tables for your business needs.

### Video - [Using SQL derived tables](https://www.cloudskillsboost.google/course_templates/327/video/515604)

* [YouTube: Using SQL derived tables](https://www.youtube.com/watch?v=IenVL3VJM5E)

In Looker, you can use SQL derived tables to create new custom tables using manually written SQL queries. For example, imagine that you want to create a table that contains the following details for each order in your database: order ID, user ID, the number of items ordered, and total price of the order. To create a SQL derived table with this information, you need to manually write a SQL query that selects the data attributes and aggregations that you want to include in the table. Let’s walk through an example of creating a SQL derived table that summarizes the desired information for each order. Let’s dive right in! Begin by ensuring that you are in Development Mode. You can enable Development Mode by toggling the button for Development Mode on the bottom left corner of the Looker home page. Then, click Develop on the left side navigation menu to see the develop options. In Looker, the easiest way to create a SQL derived table is through SQL Runner, which provides an interface for you to write and test SQL queries to your available database connections. To open this interface, click SQL Runner under the Develop options. In SQL Runner, you can type out the desired query, and click Run to get the results. For this example, the desired query selects the order_id and user_id from the order_items table, counts the number of items associated with each order, and then sums the price of those items. Specifically, the COUNT clause is counting the number of individual order item IDs (the primary key of the order_items table), and the SUM clause is totaling the sale_price of the order item IDs. The GROUP BY clause is used to group the results by order_id and user_id, and the LIMIT clause is used to limit the results returned, as you only need to review a subset of records to ensure that the query is working successfully. Next, take a moment to review the results of the query to ensure that your syntax is valid and returns the desired results. In this example, the query is indeed returning the order ID, user ID, and number of items associated with each order as well as the total revenue from each order. After confirming that the query returned the desired results, click on the gear icon in the top right corner and choose Add to Project. Select the project name training_ecommerce from the dropdown, and give your derived table a descriptive name such as order_facts. Then, click Add. You will be redirected to the Looker IDE to review the newly created view file for your derived table. Notice that Looker auto-generates a dimension for each column in the SELECT clause of the SQL query as well as a default count measure. Also notice that the new view file for the order_facts view has been created outside of the views folder. It is a best practice in Looker to keep the view files organized in the views folder of a LookML project. To move the order_facts.view file, simply click on the order_facts.view file in the file browser, and drag the file under the folder named views. Another best practice is to remove the LIMIT clause that you used for testing, since you do not actually want to limit the rows accessible by business users. To remove the limit, you can simply delete the line for LIMIT 10 from the sql parameter of the derived table. As highlighted previously, Looker auto-generates a count measure along with the dimensions used in the derived table. Sometimes this auto-generated count measure is not valuable, if you already have a count in another view that provides the same number. In this example, the auto-generated count measure is counting the order IDs, and there is already a count of orders in the order_items view. So you can either delete the measure, or hide it using the hidden: yes parameter. Hiding the measure is a good idea if you would like to retain it for validation, but do not want to expose it to users. A final best practice is to ensure that the new view has a primary key. In this example, you can add the primary_key: yes parameter to the order_id dimension, which is the core organizing ID of this view that provides details about each individual order. And with that, the new SQL derived table called order_facts is now ready for you to create new dimensions and measures, join it to the explore in the model file, and/or finish out the Git workflow to send your changes to production. Pretty easy, right? In summary, let’s review the best practices used to create the new SQL derived table. After generating the new view file from the query in SQL Runner, you moved the new view file for order_facts to the folder named views, where all of the other view files are stored. Next, you removed the LIMIT clause that was only needed for testing, and then hid the auto-generated count measure for orders because it already exists in the order_items view. Last, you established order_id as the primary key for the order_facts view. With these best practices, you are now ready to create new SQL derived tables in your organization’s Looker instance.

### Video - [Using native derived tables](https://www.cloudskillsboost.google/course_templates/327/video/515605)

* [YouTube: Using native derived tables](https://www.youtube.com/watch?v=3R8KifmNNes)

In Looker, you can create custom tables using either SQL derived tables, which depend on manually written SQL queries, or native derived tables, which are written entirely in LookML. Because native derived tables reuse existing LookML objects to define new custom tables, they promote code reusability and reduce hard-coded references to your underlying database tables. The easiest way to create a native derived table in Looker is through an Explore. Let’s walk through an example of using the Order Items Explore to create a native derived table that summarizes the following details for each order: order ID, user ID, the number of items, and the total cost of items ordered. Let’s dive right in! Begin by ensuring that you are in Development Mode. You can enable Development Mode by toggling the button for Development Mode on the bottom left corner of the Looker home page. Then, click Explore on the left side navigation menu to see the develop options. Under the Explore options, click on Order Items under the E-Commerce Training heading. In the Order Items Explore, select the dimensions and measures you need for your native derived table. Remember that the Explore will automatically generate a valid, performant SQL query for you. For this example, you want to first select the Order ID and User ID dimensions from the Order Items view. Then, also within the Order Items view, select the Order Item Count and Total Revenue measures. Click the Run button to review the results. Now, take a moment to review the results of the query to ensure that it is returning the desired results. For this example, the request correctly returns the Order ID, User ID, number of items for each order in Order Item Count, and the total price of each order in Total Revenue. After you have confirmed the request returns the desired results, click on the gear icon in the top right corner and select Get LookML… Within the popover window for Get LookML, click on the Derived Table tab, and copy the LookML code to your computer clipboard. In the next steps, you will paste this LookML code into a new view file for this native derived table. Now, you need to create a new view file to contain the LookML code that you just copied. To get to the Looker IDE where you can create new view files, return to the Looker home page by clicking Looker on the top left-side of the user interface. Then, click Develop to see the options. Now, click on the training_ecommerce project to open the Looker IDE in this project. In Looker, it is a best practice to always create a new view for a new native derived table. To create a new view file in the file browser, click on the plus (+) icon, and choose Create View. Name this new view file order_details. Then, click Create. Notice that the order_details.view file is automatically created outside of the views folder in the file browser. To follow the best practice of storing all views together in a views directory, click on the order_details.view file in the file browser and drag it under views. Now, replace the auto-generated LookML in the view file with your previously copied LookML code. Following another best practice, be sure to change the auto-generated view name to order_details to match the view file name. Notice that Looker makes a suggestion to include the model file but the lines are commented out. It is a best practice to leave the line for the model file commented out. Otherwise, you risk creating circular dependencies in your model and causing validation errors because model files typically include many other files. The new native derived table called order_details is now ready for you to create new dimensions and measures, join it to the explore in the model file, and/or finish out the Git workflow to send your changes to production. For this example, you will join it to the order_items explore definition in the model file, and then use the Order Items Explore to review what business users would see if you pushed the changes to production. First, click Save Changes to save the updates to the order_details view file. Then, click on the training_ecommerce.model file to add a new join to the Order Items Explore. Locate the explore definition for order_items. Notice that there are several joins already defined such as the one for the users view. Above the existing join for users, add a new join for order_details by specifying: The join name as order_details. The join type as left_outer. sql_on as ${order_items.order_id} = ${order_details.order_id}. And the relationship as many_to_one (because order_details is organized as one summary row for each order). Then, click Save Changes. Next, click Validate LookML to check your new LookML. Now you can review the revised Explore to view and query the native derived table. Within the Explore tab, click on Order Items under E-Commerce Training. In the Order Items Explore, select the dimensions for Order Details: Order ID, Order Item Count, Total Revenue, and User ID. Then, click Run to see the results. Finally, click the SQL tab to view the generated SQL query. Notice the common table expression (CTE) identified by the WITH clause. Though there are options in Looker to persist derived tables, this new derived table is considered ephemeral because it is generated at run-time. In summary, let’s review the best practices used to create the new native derived table. First, you created a new view file for the native derived table, and then moved the new view file to the folder named views. Next, you pasted the copied LookML code into the new view file and replaced the auto-generated view name with the name of the view file. And last, you left the model file commented out in the view file. Following these best practices, you can use native derived tables to create new custom tables in your organization’s Looker instance.

### Video - [Native derived table parameters](https://www.cloudskillsboost.google/course_templates/327/video/515606)

* [YouTube: Native derived table parameters](https://www.youtube.com/watch?v=ks0fQZDrZ2A)

In Looker, native derived tables allow you to create new custom tables that reuse existing objects in your project, such as dimensions and measures, and are expressed entirely using LookML. To fully understand how native derived tables function, let’s review the parameters in detail. A key parameter for native derived tables is explore_source, which points to the Explore in your model that serves as the foundation for the derived table. In other words, it’s the FROM part of your SQL query and specifies any required joins. Another key parameter is column, which specifies an output column for the native derived table. In other words, it is a field that is being SELECTed. Sometimes, you will see a field parameter inside the curly braces {} for a column. If you have more than one field with the same name throughout the Explore, you can use the field parameter to tell Looker exactly which dimension or measure to use. If your field name is unique throughout the Explore, you can leave the curly braces {} empty. This also means that you can use the field parameter to name new column differently from the underlying field name. In addition to the key parameters for explore_source and columns, there are many other helpful parameters for native derived tables. First, filters can be used to apply filters to the derived table, similar to a filtered measure. In essence, it adds a WHERE or HAVING clause to the query. If you need to add a dynamic or templated WHERE or HAVING clause to your derived table logic, you could use bind_filters. This parameter will allow the native derived table to take on the filters that a user applies on a dimension or measure in the Explore query, and makes the filters “trickle down” to the derived table query itself. Now, imagine that you would like to use a field that does not currently exists in the Explore or model. In a native derived table you can use the derived_column parameter to define a new column that does not yet exist in the Explore specified by the explore_source parameter. Traditional filters in Looker only let you specify what are basically key-value pairs and then it forces an AND conjunction between multiple inputs. expression_custom_filter, on the other hand, lets you define nuanced logic with your own choice of AND/OR conjunctions and order of operations. Very powerful! In summary, the key parameters for native derived tables are explore_source and column. explore_source points to the Explore in your model that serves as the foundation for the derived table and is the basis of the FROM statement in your SQL query. column specifies an output column for the native derived table and represents a field that is being SELECTed in your SQL query. In addition, there are other useful parameters for native derived tables, such as filters and derived_columns, which you can use to apply filters and define new columns that do not yet exist in your Explore. Have fun customizing native derived tables in your organization’s Looker instance!

### Video - [Using persistent derived tables](https://www.cloudskillsboost.google/course_templates/327/video/515607)

* [YouTube: Using persistent derived tables](https://www.youtube.com/watch?v=C-ionVddpss)

In Looker, derived tables can be ephemeral, meaning that Looker builds them at run-time, or they can be persistent, meaning that they are written back to the connected database. The benefit of persistent derived tables, or PDTs, is that they are ready to go when business users need them; while the main downside is that they take up storage space in your database, which may correlate to cost. In this lesson, we will explore how PDTs are written back to and stored in the connected database in Looker. In Looker, ephemeral derived tables build at runtime as temporary tables or common table expressions (CTEs) that are defined in the generated SQL with the following syntax: WITH derived_table_name AS (SELECT column_1 ... and so on. Note the subsequent SQL represents the Explore itself. By contrast, a PDT will run a SQL CREATE statement in the underlying database to create a physical table. Both SQL derived and native derived tables can be saved as PDTs. When a business user selects a field or filter from a PDT, the generated SQL will join to the PDT, just as it would to a regular table in the database. Another key point about PDTs is that Looker will build a version of the PDT specifically for your Git branch in Development Mode. After you have deployed your code to production, or if the PDT already existed in production and you were modifying it, business users querying the PDT in production mode will be pointed to a separate version for production. Let’s review the generated SQL for a persistent derived table. First, notice the schema of the PDT, which is teach_scratch in this example. We recommend naming the schema for PDTs something like “X_scratch”, but you could call it anything you want. The important thing is to configure a schema dedicated to Looker PDTs in your database. Typically, a database admin would create the schema, and then a Looker admin would specify the schema name in the connection settings of the Looker instance. Second, although the derived table is named user_order_facts, Looker will auto-generate the name for the PDT, so it can keep track of different versions of the PDT in development or production modes. In the table name, a text string of a long jumble of letters and numbers will be prepended to the derived table name. PDT names always start with this hash, which encodes information such as the database connection and SQL that it uses. To persist a derived table, you must use at least one of the following parameters in the definition. First, datagroup_trigger uses a datagroup, or caching policy configured in the model. As a best practice, we recommend using datagroup_trigger if datagroups are already defined in your model. Second, sql_trigger_value uses a pre-written SELECT statement that returns one value such as the maximum value of a user ID column. Looker sends that SELECT statement to the database repeatedly, and when it discovers the result has changed, it takes this as a cue to rebuild the PDT. Last, persist_for instructs the PDT to be available for a set duration, such as “1 hour” or “4 hours”. There are a few things to consider before choosing this option to persist your derived tables. First, because persist_for does not contain any rebuild logic, the PDT does not get updated at any time within the specified duration. In addition, once time is up, the PDT is dropped and is not recreated until the next business user needs it for a query. As the primary benefit of PDTs is having data readily available to minimize query runtimes, we recommend that you use persist_for in conjunction with sql_trigger_value to ensure that data updates within the duration, or simply use datagroup_trigger or sql_trigger_value on their own. If you have a use case for it, you can also make SQL derived tables select FROM one or more other derived tables. This would create cascading derived tables due to dependencies between the tables. Given that PDT names always start with a long hash, you can use . SQL_TABLE_NAME (in capital letters) as a substitution operator to refer to the view name. This enables Looker to plug in the physical table name at runtime. If you persist the cascading derived tables, then it is important to ensure they rebuild in the correct sequence, so the dependent PDTs rebuild with the most recent data. You cannot explicitly control the sequence that Looker users to rebuild PDTs. Now, one way you could try to make all your PDTs build in the right order is to stagger the sql_trigger_value, based on the typical build time of the preceding derived table. As you might imagine, this isn’t foolproof. This is another reason why datagroup_trigger is better than sql_trigger_value for applying persistence. If all your cascading PDTs use the same datagroup_trigger, then Looker will actually be able to detect the dependencies and rebuild the PDTs in the guaranteed correct sequence. Last, we also recommend that you add indexing to your PDTs. Indexing is like a card catalog in a library, where you could look up the location of a book to quickly find it among the shelves. Similarly, indexes help databases process queries more quickly. Looker accepts the indexing parameters for most database dialects. We suggest discussing indexing of PDTs with a data engineer or database administrator at your company to determine the best option for your use case. More information on these parameters can be found in the Derived Table Parameters section of Looker’s View parameters documentation page. In summary, after PDTs are written back to your databases, they are stored as physical tables that be queried and joined just like any other table in your database. Looker builds a separate version of the PDT in development and production modes to ensure that you can create and test PDTs without impacting the production environment until you are ready to merge your updates. Be sure to create a schema specifically for Looker PDTs. Within this schema, Looker auto-generates the name for the PDT, so it can keep track of different versions and encode information such as the database connection and SQL that it uses. With all of these features, Looker makes it very easy to create PDTs and leverage their great benefits. We hope that you give them a try in your Looker instance!

### Lab - [Creating Derived Tables with LookML](https://www.cloudskillsboost.google/course_templates/327/labs/515608)

In this lab, you create SQL derived and native derived tables in LookML to define new tables that do not already exist in the underlying database. You also persist the derived tables, so they can be written back to the underlying database.

* [ ] [Creating Derived Tables with LookML](../labs/Creating-Derived-Tables-with-LookML.md)

### Video - [Caching and datagroups](https://www.cloudskillsboost.google/course_templates/327/video/515609)

* [YouTube: Caching and datagroups](https://www.youtube.com/watch?v=Npt-m9okNbM)

In Looker, caching is a useful feature that LookML developers can use to reduce database load and optimize query performance. Caching leverages the saved results from previously executed queries, so that the same query does not need to be run on the database each time. The overall caching process in Looker is straightforward and begins with a query. As users are exploring and analyzing data, Looker generates SQL queries and checks whether there are valid cached results for each query. If there are valid cached results for a query, Looker will avoid requesting the same data again from the database, and instead, simply send those cached results back to the user. If there are no valid cached results for that query, Looker sends the query to the connected database. These new SQL results are then cached and stored in an encrypted file on the Looker instance. This file can then be used by Looker, if and when the same query is run again. Now, to help ensure that cached results remain valid and up-to-date, LookML developers can set up datagroups, or caching policies, to manage the frequency and conditions for caching on a Looker instance. For example, a datagroup can be created to ensure that all cached results are updated at least once an hour, or when a new ID is added for a key field such as user ID or order ID. The datagroups are then used by Looker to check whether cached results are still valid. If the cached results are no longer valid per the datagroups, Looker will send the query to the database to obtain new results. In Looker, datagroups can be defined both to establish caching policies and rules for entire models, individual Explores, or specific PDTs in your LookML projects, and to ensure a refreshed cache. The number and types of datagroups you would need to create depends on how often your data is updated and should take into account your organization’s data extraction, transformation, and loading (or ETL) processes and business requirements. Now, let’s discuss how to define a datagroup. To define a new datagroup using LookML, you must provide a unique name and two parameters: max_cache_age and sql_trigger. The first parameter, max_cache_age, specifies the maximum number of hours to keep a cached result, such as 24 hours. The other parameter, sql_trigger, is used to write a SELECT statement that can tell Looker whether the results have changed. The sql_trigger should be written to return only one value, such as the maximum ID value in a table. Looker will send this statement to the connected database on a regular frequency. Once it finds that the value has changed, Looker takes that as a cue to refresh the cache. Of course, while only one of these parameters is required, we do recommend as a Looker best practice using both to achieve the desired caching results. For example, if no change is detected by the sql_trigger check, that could mean something went wrong with the database ETL process or the sql_trigger itself. By including a max_cache_age, the cache would still get refreshed regardless after a set duration. The frequency of the sql_trigger’s pinging of the database is defined in the connection settings by your Looker administrator. The frequency is determined by a cron string in the connection’s PDT And Datagroup Maintenance Schedule field. By default, it is every 5 minutes. The frequency of the sql_trigger check should match the approximate frequency of the data updates. For example, every 5 minutes is too frequent if your data warehouse is only updating every few hours or once per day. In addition, companies using certain database dialects may want to let the database “hibernate” outside of work hours to save money, so they would not want Looker waking up the database with sql_trigger checks. Be aware though that in Looker, defining a datagroup by itself doesn’t do anything. It is a two-step process. After defining the datagroup, you need to apply the datagroup to a LookML object. For example, you can use the persist_with parameter to apply a datagroup at the model level. When you do this, Looker will apply the same caching rules to all Explores within this model. In fact, whenever you create a new LookML project by having Looker generate the model from the database schema, Looker will automatically create a default datagroup in the model file that you can customize as needed. You can also choose to apply a caching policy on an individual Explore, which would override whatever is set at the model level. For example, to apply a datagroup to specific Explore, use the persist_with parameter within that Explore’s definition, rather than at the model level. To apply a datagroup to a specific set of Explores but not all Explores in a model, use the persist_with parameter in each Explore’s definition and specify the same datagroup name. Since Explores are the foundation for all content in Looker, the same caching logic would carry over to Looks and dashboards created from the Explore. You can also use datagroups to tell Looker when to rebuild a persistent derived table (or PDT). To do this, simply specify the datagroup name in the datagroup_trigger parameter of the PDT. While there are a few different options for persisting derived tables in Looker, using the datagroup_trigger parameter is the recommended best practice to ensure that the data remain current. So if you have ever created a persistent derived table (or PDT) in Looker, then you have may already used datagroups! Additionally, schedules for Looks and dashboards can also be run on datagroups. You can instruct Looker to run a Look or dashboard automatically upon expiration of a caching policy, so new data is retrieved and “pre-cached” for any business users who need it.

### Video - [Implementing datagroups in Looker](https://www.cloudskillsboost.google/course_templates/327/video/515610)

* [YouTube: Implementing datagroups in Looker](https://www.youtube.com/watch?v=tyHCmIkJwlo)

In this example, we will review how to define and apply datagroups to individual Explores in a LookML model. Specifically, imagine that you want caching for all views in the Order Items Explore to refresh whenever a new order_item_id is added because the order_item_id is the primary key for order items. You can accomplish this by simply applying a datagroup to the Explore definition in the LookML model. Let’s see how easy it is in Looker! Begin by enabling Development Mode using the Development Mode toggle button in the bottom left corner of the Looker home page. Then, click Develop on the left side navigation menu. Within the Develop options, click on the training_ecommerce project. In the file browser, navigate to the training_ecommerce.model file in the training_ecommerce project. Notice that this model file has a default datagroup with a max_cache_age of 1 hour. Since this default datagroup is applied at the model level using the persists_with parameter, it is applied to all explores defined in the model. This means that the caching automatically updates every hour for all explores defined in the model file. Recall that you want to implement a specific datagroup for just the Order Items Explore. To do this, you need to remove the default datagroup and the existing persists_with parameter. Then, you can create and apply a new datagroup to the order_items explore definition. Begin by removing all of the code lines for training_ecommerce_default_datagroup and the persists_with parameter. Then, add the code for the new datagroup, beginning with: datagroup: order_items_datagroup followed by a set of curly brackets ({}). To complete the definition of the new datagroup, you need to provide values for two parameters: sql_trigger and max_cache_age. For the sql_trigger, you can select the maximum ID for order_item_id using: SELECT MAX(order_item_id) from order_items ;; You can also set the max_cache_age to be “1 hour”, so that caching will continue to refresh every hour, even if there is an issue with data updates. Last, you need to apply the datagroup to the definition for the Order Items Explore. Add a new line under the first line of the explore definition, including the following code: persist_with: order_items_datagroup Click Save Changes. Then, click Validate LookML to check that you have written valid LookML to define and apply the datagroup to the Order Items Explore. Last, after validating the new LookML code, you can commit and push the changes to your repository. And with that, you have now defined a new datagroup that checks for new order item IDs and applied it to the Order Items Explore. How easy was that?! Please remember though if your database connection is configured in Looker to use dynamic usernames such as OAuth for BigQuery, then you cannot use datagroups for models using that connection. Instead, use a persist_for parameter to cache Explore queries for a fixed amount of time. In addition, remember that when using OAuth for BigQuery, persistent derived tables are not supported. More information on dynamic usernames can be found in the Looker documentation on OAuth for BigQuery connections. In summary, every time that a user runs a query, Looker checks to see if that query has been run before. If it has not been run before, Looker runs the query on the database, and then caches the results for future use. If the query has been run before, Looker then checks the caching policies to evaluate whether the results should still be considered valid. If the cached results are still valid, Looker returns the cached results to the business user. If the same query has been run before, but the results are no longer valid per the caching policies, then Looker sends the query to the database to get new results. It then caches the new results for future use. With its efficient caching process and varied options, Looker puts the power into your hands as a LookML developer to optimize queries and reduce database load for your organization’s Looker instance.

### Quiz - [Module 4 Quiz](https://www.cloudskillsboost.google/course_templates/327/quizzes/515611)

#### Quiz 1.

> [!important]
> **Persistent derived tables remain stored within the Looker platform, just like other derived tables.**
>
> * [ ] False
> * [ ] True

#### Quiz 2.

> [!important]
> **Developers create SQL derived tables by manually constructing SQL queries.**
>
> * [ ] True
> * [ ] False

#### Quiz 3.

> [!important]
> **The LookML parameter explore_source corresponds to what part of a SQL query? Please choose the best answer.**
>
> * [ ] FROM.
> * [ ] COUNT.
> * [ ] SELECT.
> * [ ] explore_source doesn't correspond to any of these SQL query parts.

#### Quiz 4.

> [!important]
> **Developers can implement caching in Looker to improve speed of query results.**
>
> * [ ] True
> * [ ] False

#### Quiz 5.

> [!important]
> **An Explore MUST be utilized for its LookML code to construct a native derived table.**
>
> * [ ] False
> * [ ] True

#### Quiz 6.

> [!important]
> **In what type of file contained within a LookML project would a LookML developer write code for a native derived table? Please choose the best answer.**
>
> * [ ] None of these file options allow a LookML developer to write code for a native derived table.
> * [ ] Model file.
> * [ ] View file.
> * [ ] LookML dashboard file.

#### Quiz 7.

> [!important]
> **End users and LookML developers alike can create their own derived tables for their respective use cases.**
>
> * [ ] False
> * [ ] True

#### Quiz 8.

> [!important]
> **Filter parameters can be used to apply filters to a  native derived table using the same syntax as a filtered measure.**
>
> * [ ] True
> * [ ] False

#### Quiz 9.

> [!important]
> **In what language are native derived tables written? Please choose the best answer.**
>
> * [ ] Native derived tables aren't written in any of these languages.
> * [ ] SQL.
> * [ ] LookML.
> * [ ] Python.

#### Quiz 10.

> [!important]
> **Developers can successfully utilize derived tables to roll up user data to the month time level in order to track periods of (in)activity and analyze retention.**
>
> * [ ] True
> * [ ] False

#### Quiz 11.

> [!important]
> **Which of these terms is NOT used to identify new tables or sub-selects in SQL? Please choose the best answer.**
>
> * [ ] Queries.
> * [ ] Materialized views.
> * [ ] Temporary tables.
> * [ ] Common table expressions (CTEs).

#### Quiz 12.

> [!important]
> **Where in the Looker user interface can someone best and most easily write SQL queries for a SQL derived table? Please choose the best answer.**
>
> * [ ] Looker's SQL Runner.
> * [ ] In the database.
> * [ ] The Looker IDE.
> * [ ] None of these options allow SQL queries to be written for a SQL derived table.

#### Quiz 13.

> [!important]
> **What is the recommended naming convention for persistent derived tables? Please choose the best answer.**
>
> * [ ] None of these naming conventions are recommended for persistent derived tables.
> * [ ] _____.persistent.
> * [ ] _____.scratch.
> * [ ] _____.pdt.

#### Quiz 14.

> [!important]
> **To what does a LookML developer add and apply a datagroup? Please choose the best answer.**
>
> * [ ] Explore.
> * [ ] View.
> * [ ] SQL.
> * [ ] None of these options are added and applied to a datagroup.

## Course Resources

PDF links to all modules

### Document - [Course Resources](https://www.cloudskillsboost.google/course_templates/327/documents/515612)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

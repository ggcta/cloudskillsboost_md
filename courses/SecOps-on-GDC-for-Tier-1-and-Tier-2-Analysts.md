---
id: 1195
name: 'SecOps on GDC for Tier 1 and Tier 2 Analysts'
type: Course
url: https://www.cloudskillsboost.google/course_templates/1195
date_published: 2025-01-24
topics:

---

# [SecOps on GDC for Tier 1 and Tier 2 Analysts](https://www.cloudskillsboost.google/course_templates/1195)

**Description:**

This course gives you a deep dive into the workflows of Tier 1 and Tier 2 security analysts. 

**Objectives:**

* Describe Tier 1 and Tier 2 security analysts workflows, including monitoring, intake, and incident response.

## Course overview

This module introduces the audience, prerequisites, and agenda for the learning pathway.

### Video - [Course overview](https://www.cloudskillsboost.google/course_templates/1195/video/522229)

* [YouTube: Course overview](https://www.youtube.com/watch?v=XFbUM7MoVCE)

SPEAKER: Welcome to the Google Distributed Cloud, or GDC air-gapped Security Operations Fundamentals series of courses. Security itself is an all-encompassing endeavor. Within each of the three courses that make up this series, you'll focus on a specific aspect of GDC for security operations. The first course provides a high-level overview of security fundamentals on the GDC platform. You'll be introduced to the GDC offering and architecture, the SecOps roles in the GDC Security Operations Center, or SOC, and the definitions of the security principles. You'll also learn about the day-to-day processes and tools that you can use to keep the GDC deployment secure, both proactively and reactively. Finally, you will review the default logs, dashboards, and alerts which are at the core of GDC security monitoring. The second course provides you with a deep dive into the workflows of Tier 1 and Tier 2 security analysts. These workflows are monitoring, intake, and incident response. You will go through a variety of video demonstrations that mimic how you would tackle these workflows in GDC. The third course provides you with a deep dive into the workflows of Tier 3 analysts. This workflow will focus on vulnerability management, threat modeling, and security engineering. Once again, you will watch video demonstrations on how you would tackle these activities. To benefit fully from taking this course, you should have these prerequisite skills and knowledge prior understanding of SecOps, basic proficiency with Windows and Linux logs, basic understanding of Kubernetes terminology for logging, prior completion of the Google Cloud Fundamentals-- Core Infrastructure course, or equivalent experience with Google Cloud Services hosted by GDC. Throughout this series of courses, you'll learn about GDC in context by exploring how Cymbal Federal, a fictional organization, accomplishes its SecOps goals using the GDC air-gapped platform. Imagine that you have just joined the GDC Security Operations Center team for Cymbal Federal as a security analyst. Congratulations on your new role. Cymbal Federal is a government entity aligned to support the broad mission objectives of the executive branch of government. During a recent review, the operation and application capabilities of Cymbal Federal were designated mission critical. An organization-wide, multi-year digital transformation program is underway. Cymbal Federal aims to ensure compliance while modernizing its suite of applications with GDC. GDC offers a solution for use in an on-premises environment. Up to this point, the Cymbal Federal internal teams have mastered Google Cloud Fundamentals and Kubernetes and have defined the major applications to develop on GDC. The team is now focused on the creation of the first end-user applications and workloads on GDC. In preparation for the go-live, Cymbal Federal has awarded their existing third-party data center management partner the task of creating and running the mission operations center. This partner has started to establish the operate portion of the GDC program. This involves end-to-end integrated infrastructure management. As a new staff member, you are being onboarded in order to handle security as part of the GDC Security Operations Center for Cymbal Federal. Based on your previous work experience, you have some familiarity with SecOps. You also have a high-level understanding of the GDC platform. You now want to learn more about the security operations on GDC so that you are able to keep the platform secure. The Cymbal Federal case study attempts to mirror an enterprise-level scenario, and aims to help you understand how the different components of the platform fit together and what their capabilities are. You will revisit this case study throughout all three courses. Each course will include a variety of video presentations, quizzes, and video demonstrations. By completing this course, you'll learn everything you need to begin your role-specific operations in the security operations center of GDC. Let's get started.

## Monitoring and intake for Tier 1 analysts

 In this module, you will explore two critical phases of the incident management lifecycle: incident monitoring and intake. Then, you will investigate how cyber events are detected. You will learn about automated and manual detection methods, the difference between internal and external alerts, and how to distinguish between false positives and true positives. You will also learn to assess the impact of an incident, use an incident response plan, and appropriately categorize an incident in order to determine your response strategy. You will then leverage real-world examples for Cymbal Federal to illustrate common containment strategies and their application in remediation scenarios. Finally, you will learn about the SecOps support activities that are essential during the monitoring and intake phases. The focus here will be on the implementation of standard operating procedures. 

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/1195/video/522230)

* [YouTube: Module overview](https://www.youtube.com/watch?v=jK5ah-kMEjk)

SPEAKER: Welcome to monitoring and intake for tier 1 analysts. In this module, you will explore two critical phases of the incident management life cycle-- incident monitoring and intake. First, you will review what occurs during incident monitoring and intake, why these phases are significant, and their role within the broader spectrum of incident response. Then you will investigate how cyber events are detected. You will learn about automated and manual detection methods, the difference between internal and external alerts, and how to distinguish between false positives and true positives. You will also learn to assess the impact of an incident, use an incident response plan, and appropriately categorize an incident in order to determine your response strategy. You will then leverage real-world examples for Cymbal Federal to illustrate common containment strategies and their application in remediation scenarios. Finally, you will learn about the SecOps support activities that are essential during the monitoring and intake phases. The focus here will be on the implementation of standard operating procedures. Upon completing this module, you will be fully prepared to perform monitoring and intake activities in the security operations center, or SOC, with proficiency. This knowledge is a key component in your role as a tier 1 analyst in SOC Google Distributed Cloud, GDC air-gapped.

### Video - [Monitoring security events](https://www.cloudskillsboost.google/course_templates/1195/video/522231)

* [YouTube: Monitoring security events](https://www.youtube.com/watch?v=luC4sFW2VQA)

SPEAKER: Monitoring and intake represent the initial stages where potential security events are identified, detected, triaged, and classified for further investigation and remediation. Efficient incident response involves continuous monitoring of security systems and logs combined with effective intake procedures for handling potential incidents reported by various sources. Let's start by exploring the purpose of continuous monitoring. During the monitoring phase, tier 1 analysts monitor security systems and logs for suspicious activity. The goal of this phase is twofold, early detection of security events, the accurate identification of genuine incidents. To achieve these goals, tier 1 analysts use various tools and techniques, Endpoint Detection and Response, EDR, solutions, and Security Information and Event Management, SIEM, systems. By combining EDR and SIEM, the analysts can detect anomalies about user behavior and take action accordingly. For example, if you notice a sign-in to the company outside of business hours, a policy can be created that blocks the copying of data outside of business hours. Tier 1 analysts also work to accurately identify genuine incidents. This involves learning to differentiate between real security events and false alarms, false positives. This ability requires robust detection mechanisms and skilled analysts to analyze alerts and identify true threats. By learning to accurately identify genuine incidents, you help to avoid unnecessary resource allocation and wasted time. A detection modality is a general term that refers to the various detection methods employed by tier 1 analysts during the monitoring phase. These modalities aim to detect potential security events and can be automated, internal, or external. Each method offers distinct advantages and limitations. In the following videos, you will explore each one.

### Video - [Automated detection methods](https://www.cloudskillsboost.google/course_templates/1195/video/522232)

* [YouTube: Automated detection methods](https://www.youtube.com/watch?v=TFwH__vsRLY)

SPEAKER: First, there are automated detection systems. Automated detection refers to the use of technology to identify potential security threats or anomalies within a system or network. Automated detection does not rely on human oversight. Examples of automated detection systems include the following. Security information and event management SIEM systems, such as Splunk. These collect and analyze logs from various sources, triggering alerts based on preconfigured rules or threat intelligence. Endpoint detection and response, EDR solutions. These monitor endpoint activity for suspicious behavior, such as unauthorized file access or application execution. Network intrusion detection prevention systems, NIDS, NIPS. These analyze network traffic for malicious patterns and signatures, detecting potential intrusions and attacks. Automated detection is a necessity in modern security. Automated detection helps you keep one step ahead of potential threats. Automated detection methods offer continuous monitoring. You don't need to rely on manual oversight and are thus able to monitor systems 24/7. Automated detection offers increased scalability. You can efficiently handle your ever-growing volume of data and ensure consistent security as the data expands. Automated detection also enables you to swiftly identify potential threats in real time. This allows for preemptive action before issues escalate, which helps to minimize the need for manual intervention. But are there limitations associated with automated detection? While automated detection offers significant benefits, it's not without drawbacks. The nature of automated detection means you may experience triggering alerts for normal, albeit unusual, user activities. These are known as false positives. False positives require manual analysis in order to filter out legitimate actions. This can create unnecessary work and possibly overwhelm security teams. Reliance on predefined rules can make automated detection systems blind to novel or sophisticated attacks that don't match existing patterns. This leaves automated detection methods vulnerable to new threats. While you can tune the complexity of automated systems by adjusting the sensitivity and rules, this itself requires careful configuration to avoid missing real threats or generating excessive, unhelpful alerts. Finding the right balance can be challenging.

### Video - [Internal detection methods](https://www.cloudskillsboost.google/course_templates/1195/video/522233)

* [YouTube: Internal detection methods](https://www.youtube.com/watch?v=gWHIxTrJ-t4)

SPEAKER: Internal detection methods are also used during threat monitoring. Internal detection involves actively searching for security vulnerabilities and Indicators of Compromise, IOCs, within the organization. Examples of internal detection methods include the following. Targeted investigation of suspicious network traffic-- noticing an unusual spike in outbound network traffic from its internal accounting server which is not typical for its normal operations. This spike was initially flagged by an automated-alert system but requires a more focused analysis to determine the nature of the traffic. Analysis of an unauthorized access attempt. An automated system at Cymbal Federal flags an unauthorized access attempt to a sensitive-records database. Multi-stage Advanced Persistent Threat, APT, detection, a multinational corporation security system detects unusual network traffic patterns originating from a seemingly benign application update server. Internal detection is employed, along with automated-detection methods to enhance an organization's security posture. While automated systems provide broad and continuous monitoring, internal detection addresses some of the drawbacks associated with automated detection, such as the potential for false positives, and the inability to recognize complex, multi-stage attack patterns. Internal detection offers focused analysis so tier 1 analysts can tailor their detection to a specific environment or a potential threat. This helps you detect specific threat indicators that were not signaled out by automated tools. Internal detection methods analyze activity within the context of the organization's network and IT infrastructure. This helps you identify vulnerabilities and weaknesses within the organization's system. Internal detection uses hunting queries created by analyst experts. This means internal detection methods can identify novel or zero-day attacks that bypass automated detection mechanisms. But again, there are limitations associated with internal detection methods. Internal detection methods are resource-intensive. They require skilled personnel and dedicated resources to conduct manual analysis. Internal detection methods are limited in scope. They may not cover all aspects of the IT environment because they are resource-intensive, focused, and depend on existing knowledge and tools. An internal detection model also typically takes a considerable amount of time to build at an effective and efficient level. Internal detection also takes a reactive approach, as it relies on identifying existing vulnerabilities, or IOCs, after an attack might have occurred. With reactive security operations, organizations primarily focus on incident response, with their SOC teams waiting for alerts, or breaches to occur before taking action. This reactive approach is characterized by a firefighting mentality, where the focus is on containing and mitigating the damage caused by an attack.

### Video - [External detection methods](https://www.cloudskillsboost.google/course_templates/1195/video/522234)

* [YouTube: External detection methods](https://www.youtube.com/watch?v=Q-lPnBmLL5s)

SPEAKER: Finally, there are external detection methods. External detection refers to the identification of security threats or anomalies that originate from outside an organization's network or systems. This method of detection focuses on detecting threats that attempt to penetrate the organization's perimeter from external sources. External detection methods include the following-- proactive detection of a coordinated phishing campaign. For example, Cymbal Federal employs an advanced threat intelligence system to anticipate potential cyber threats. Implementing a holistic cybersecurity approach in a retail company-- for example, at Cymbal Federal, you can use advanced network monitoring tools to analyze incoming and outgoing traffic. This helps in identifying suspicious patterns or anomalies that could indicate a cyber attack or breach attempt. Cross-industry cybersecurity forums-- these are used when organizations seek to share and gain insights on emerging threats and collaborate on best practices. This enables organizations to develop collective strategies that enhance their cybersecurity posture across different sectors. External detection offers numerous advantages. External detection offers advanced notice of potential threats targeting the organization. External detection methods offer a broader perspective on emerging threats and attack trends beyond the organization's specific environment. External detection allows you to learn from the experience of other organizations, enabling you to leverage collective expertise. Similar to the other detection modalities, there are limitations associated with external detection. Filtering and analyzing information from various sources can be time consuming and resource intensive for tier 1 analysts. This may cause data overload. External sources may contain inaccurate or misleading information that requires careful verification to avoid relying on false information. External sources may not be tailored to your organization's specific environment and security posture. Effective detection is crucial to monitoring and cybersecurity, as it enables timely identification of potential threats, which ensures proactive defense and response. The choice of detection modality depends on specific needs. Internal detection focuses on tailored security within the organization's unique environment. External detection brings in broader threat intelligence and industry best practices, and automatic detection offers continuous and scalable threat monitoring. Often, a combination of all three modalities is employed, creating a comprehensive and layered security strategy that addresses the diverse and evolving needs of cyber threat monitoring. After you get data from the detection modalities, you need to start the intake phase. Let's explore that topic in the next video.

### Video - [Incident intake](https://www.cloudskillsboost.google/course_templates/1195/video/522235)

* [YouTube: Incident intake](https://www.youtube.com/watch?v=EwAskFH6oNc)

SPEAKER: Following monitoring, tier 1 analysts are involved in the intake of incidents. The intake phase is crucial for gathering initial information, understanding client needs, and defining scope and objectives, thereby laying a solid foundation for effective project planning and execution. During intake, incidents are triaged, categorized, and shared with the appropriate teams for timely incident response. Intake involves continuously gathering and analyzing data. This process allows organizations to swiftly detect and respond to security events, minimizing potential damage and enhancing response efficiency. During intake, the tier 1 security analysts undertake the following actions. You start by performing an initial assessment. This means gathering all relevant data about the event, including logs, network traffic, system configurations, and user reports. You filter out noise and redundant data, verify the legitimacy of the event, and enrich it with context from threat intelligence feeds and internal sources. You classify the event based on its severity, potential impact, and attack type. This crucial step determines resource allocation and response time. You use initial containment to implement basic measures to prevent further damage, such as isolating affected systems or disabling compromised accounts. You efficiently assign ownership to route the event to the appropriate team or analyst based on its category and required expertise. During intake, tier 1 analysts will engage with numerous tools and techniques in order to complete these actions. Security Information and Event Management, SIEM systems, are central platforms that aggregate security data from various sources. This allows for automated event correlation and initial analysis, for example, in Splunk. Security Orchestration, Automation, and Response, SOAR platforms, automate routine tasks like data collection, enrichment, and basic containment actions. This frees analysts to focus on complex investigations. SOAR is not currently used in GDC, but its capabilities are achieved through Trellix, EDR, NDR, and anti-malware solutions. Ticketing systems streamline communication and collaboration between intake teams and investigation teams. These systems provide a clear record of events and actions taken, for example, ServiceNow. Threat intelligence feeds are real time updates on emerging threats and attack patterns. These systems help security analysts accurately categorize and prioritize events. It is worth noting that, despite these systems, tier 1 analysts are likely to face numerous challenges during the intake of potential security incidents. For example, you may experience the following challenges-- overwhelming amounts of false positives and noise to filter out from the ever increasing volume of security data, difficulties balancing fast intake and thorough analysis with limited personnel and resources, challenges ensuring clear communications within and between teams, difficulties staying up to date in regards to new attack techniques and vulnerabilities. Overcoming these challenges is important to ensure accurate event categorization and an effective response. Let's discover how to do so in the following videos.

### Video - [Alert triage](https://www.cloudskillsboost.google/course_templates/1195/video/522236)

* [YouTube: Alert triage](https://www.youtube.com/watch?v=5dvrzXNiXus)

SPEAKER: As a tier 1 analyst, it is important to note that incident detection is not limited to automated, internal, or external modalities. You will also need to monitor the modalities dashboard in a real-time manner. When you receive an alert, you will need to proceed with alert triage. Alert triage is a process that helps you identify and best respond to threats. Alert triage is the first step when you intake an alert. During alert triage, you start a process of critically filtering and prioritizing security alerts in order to identify and respond to the most pressing threats first. Alert triage plays an important role in the broader spectrum of incident response. Alert triage helps organizations proactively identify and address potential threats before they cause significant damage. By effectively triaging alerts, you minimize alert fatigue by focusing resources on the most critical threats. You facilitate efficient investigation by providing incident responders with relevant context and information about prioritized alerts. Alert triage also enables improved decision making as you provide clear insights into the nature and severity of identified threats. You also optimize the incident response workflow and enhance the efficiency and effectiveness of the overall incident response process. This helps facilitate a faster response to genuine threats, minimizes potential damage, and more quickly restores business operations. Let's deep dive into what occurs as you triage an alert.

### Video - [The alert triage process](https://www.cloudskillsboost.google/course_templates/1195/video/522237)

* [YouTube: The alert triage process](https://www.youtube.com/watch?v=VgiXVRKcWaY)

SPEAKER: The alert triage process is comprised of five steps. You start with collecting and aggregating alerts from various monitoring systems and security tools. These logs are placed in a central location in Splunk for review and analysis. Next, you enrich and correlate the data by supplementing alerts with additional information from various sources. These include security logs and threat intelligence feeds. The goal here is to provide richer context for analysis. Then you analyze alerts based on severity, potential impact, and other relevant criteria to determine their priority for investigation. Next, you assign the alerts to appropriate incident response teams or individuals for further investigation and remediation. Finally, you track and monitor progress to ensure timely updates and communication regarding incident resolution. In some cases, you will move from this step directly into the impact assessment. You will learn more about this later. In other cases, you may need to collect more information to supplement what you have uncovered during alert triage. During the alert triage process, you will use various tools to proactively identify, assess, and mitigate cybersecurity threats. This ensures the continuous monitoring, protection, and resilience of IT infrastructure against a wide array of cyberattacks. These include the following tools. SOAR platforms can automate repetitive tasks taken during the triage process, improve efficiency, accelerate response times, and assist you in better mitigating threats. Splunk can leverage machine-learning algorithms to analyze historical data and identify patterns. This can help enhance alert filtering and prioritization. Threat intelligence feeds can feed into triage tools and provide insights into emerging threats. This can help you prioritize alerts tied to known attack patterns. Incident scoring and risk assessment models assess the potential impact and risk associated with each alert. This can help you with decision-making. For example, EDR can provide you with a score that indicates your weaknesses and vulnerabilities against well-known threats.

### Video - [Alert triage at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522238)

* [YouTube: Alert triage at Cymbal Federal](https://www.youtube.com/watch?v=ujd_I6vu0W8)

SPEAKER: Let's return to our use case at Cymbal Federal to illustrate how a tier 1 analyst might engage in the alert triage process. In this example, it is assumed that Cymbal Federal already has a triage process in place. Imagine you, as a tier 1 analyst, receiving a high priority SIEM alert indicating multiple failed login attempts within a short time frame on a critical server. What would you do? Given that it's a high priority alert and involves multiple failed login attempts on a critical server, the alert demands immediate attention. You start by collecting alerts from all the systems. This could include any of the following types of information-- details about the alert, including timestamp, effective server, number of failed login attempts, and any additional contact from Splunk; SIEM; relevant logs; server network logs; other relevant data from the Splunk console and the affected server or system. This will enable you to undertake an assessment of the alert in order to determine its severity and urgency. Then you enrich the data you collected. You analyze this data in order to achieve the following. Identify patterns in failed login attempts, for example, specific usernames and different time windows, such as an employee coming to work outside business hours when this is not their habit. IP addresses, in other words, a specific user connecting from a different IP address, such as a different country. Find correlations with other alerts or security events. For example, 10 servers are disconnected at the same time-- hh:mm:ss. This could indicate that there is a connectivity problem, and not a server problem. Determine if any successful logins occurred amidst the failed attempts. That is, you will identify if the credentials of a user were compromised. Following this, you correlate with threat intelligence. This means you compare the collected data with known threat intelligence. The goal is to identify potential attack vectors or known bad actors. Based on the contextual information gathered, You are then able to categorize and prioritize the alert based on its nature and potential impact. This means you evaluate whether it indicates a potential security breach, an intrusion attempt, or a brute force attack on user accounts. As a tier 1 analyst at Cymbal Federal, you need to consider utilizing available resources like a Threat Intelligence Platform, TIP, to delve deeper into the source IP address. Here is an example of a Threat Intelligence Platform, TIP, that you can use. A TIP is a cybersecurity tool that helps organizations proactively manage and combat cyber threats. TIPs are a central hub for all your threat intelligence needs. You can use a TIP to collect, analyze, and share information about potential dangers to your network and data. In this case, Cymbal Federal is using TIP. Within an increasingly aggressive threat landscape, you, as a tier 1 analyst, need to explore and implement threat intelligence programs to understand cyber attacks and remain ahead of the curve. Using threat intelligence data to your advantage is an essential component of any organization's risk remediation and security program. Some key features of TIPs include-- threat intelligence scoring uses Machine Learning, ML, algorithms to rate confidence in the score to reflect the severity of the threat; automated data collection that incorporates threat data from hundreds of multiple sources and in multiple formats, notably anomali labs, Open Source Intelligence, OSINT, feeds; and Information Sharing and Analysis Centers, ISACs. After you organize and prioritize the alert, you would then decide if you would assign the alert to a Cymbal Federal tier 2 analyst or proceed with immediate remediation actions. If your analysis confirms a security breach or significant risk, you would create a ticket in ServiceNow. Then you would escalate the incident to Cymbal Federal tier 2 analysts, the appropriate stakeholders, and incident response teams. If your analysis confirms a low risk security threat, you would then initiate immediate remediation measures. This would also depend on whether remediation is feasible within your authorized response capabilities. In this Cymbal example, it is feasible within your authorized response capabilities, so you would intake instant remediation actions. This would be isolating the endpoint on either the server, laptop, desktop, or mobile device from your network in order to eliminate the risk of malware propagation. Finally, you reach the end of the triage process. At this point, you track and monitor the progress of the ticket you created. You start by updating the ticket in ServiceNow, noting every single action performed in order to solve the incident. Then you regularly review the ticket in order to determine progress and make updates. In the Cymbal case, you would note the remediation actions you took, such as the fact that you isolated the machine from the network in order to minimize the impact of the malware being spread. That's it. You've now completed the alert triage process. In the following videos, you'll learn some best practices to ensure your triage process is as effective and efficient as possible.

### Video - [Alert triage best practices](https://www.cloudskillsboost.google/course_templates/1195/video/522239)

* [YouTube: Alert triage best practices](https://www.youtube.com/watch?v=OR3hta0Wjwc)

SPEAKER: Every organization may have its own process for triaging alerts. However, here are some general best practices that all organizations can follow to ensure efficiency and accuracy during alert triage. Have a well-defined triage process with clearly established procedures and guidelines for reviewing, analyzing, and prioritizing alerts. Use appropriate tools and technologies in order to leverage automation and AI-powered solutions. Offer training and ensure tier 1 analysts stay up to date on effective triage techniques and threat-analysis methodologies. Update and refine processes to reflect evolving threats and organizational needs. For example, the incident score that needs to be communicated to incident responders is changed from an exhaust threshold of 75% to 90%. This change should be reflected in procedures. Share knowledge and collaborate with incident-response teams in order to enhance threat recognition and response effectiveness. After triage comes the data collection. You'll learn about that in the following video.

### Video - [Data collection](https://www.cloudskillsboost.google/course_templates/1195/video/522240)

* [YouTube: Data collection](https://www.youtube.com/watch?v=lUhyGpTC6mc)

SPEAKER: Let's return to the high-level overview of the intake phase. As you've seen, alert triage helps organizations proactively identify and address potential threats before they cause significant damage. If the data you obtained during alert triage is sufficient for you to either escalate or remediate, then you would immediately advance to an impact assessment. You will learn about impact assessments shortly. However, it is very possible that the data that emerged from alert triage is still insufficient for you to make a decision. Or perhaps the alert itself is part of a larger risk event that is happening. That is why you may need to collect even more data about the alert or correlate the alert with other alerts in order to make the correct assessment of the incident. To prevent attackers spreading across the network, this would need to be achieved within a limited time frame, no more than 30 minutes. This data will enable you to further categorize the incident and continue to assess its impact. You can then decide if you can contain the problem yourself or escalate it to tier 2. You can collect this additional data from many sources-- system, application, network, and security event logs. These provide valuable insights into the activities leading up to and during an incident. Network traffic-- this can also be captured and analyzed to identify malicious activity, communication patterns, and potential points of entry. Endpoint logs, configuration files, and other data from affected systems-- these can reveal evidence of attacker activity and compromised files. Memory dumps from affected systems-- these allow you to collect data for a deeper analysis of running processes. This can help you potentially identify hidden malicious code. External sources like threat intelligence feeds, vulnerability databases, and industry reports-- these give you valuable context and information about the attack campaign or threat actors involved.

### Video - [Data categorization](https://www.cloudskillsboost.google/course_templates/1195/video/522241)

* [YouTube: Data categorization](https://www.youtube.com/watch?v=0-BGxZsVFaE)

SPEAKER: Using this additional data, you are now ready to categorize the incident. This involves classifying the identified security incident based on specific criteria. Criteria should be predefined in the Splunk system-- such as hardware, software, maintenance, or application-- in order to facilitate efficient investigation, prioritization, and remediation. This also allows you, as a tier 1 analyst, to group similar incidents together and obtain a clearer view of the criticality of the event so you can assess the impact. Numerous standards exist to assist in case categorization. You can use existing frameworks such as the Miter ATT&CK framework. This comprehensive framework classifies adversary tactics, techniques, and procedures, TTPs, allowing for a categorization based on specific attack behaviors. You also can use a catalog of common software vulnerabilities like Common Weakness Enumeration, CWE. This enables categorization based on the exploited vulnerabilities in the incident. You can develop customized models tailored to your specific needs and security posture. Here is a sample cyber incident table used by the Department of Defense to help tier 1 analysts categorize incidents based on their nature. Keep in mind that categories are always subject to change and can be modified based on the needs of your organization or specific use case.

### Video - [Impact Assessment](https://www.cloudskillsboost.google/course_templates/1195/video/522242)

* [YouTube: Impact Assessment](https://www.youtube.com/watch?v=cOpuZaY4KPQ)

SPEAKER: The last step during intake is the impact assessment. You use the impact assessment to evaluate consequences and severity of the security incident that you have identified. If you determine that the security incident is not malicious, you document the triage steps you have taken and the additional information you have collected in Splunk. The incident response is then closed. If you determine the security incident is malicious, you would again take initial remediation actions and/or escalate the incident to tier two analysts for further analysis. Here is a sample cyber incident table. Consider the following steps. User credentials fall under the confidentiality security objective and are therefore categorized as moderate. Administrative credentials to DOD information networks and IS's also fall under confidentiality but are considered high impact. Malicious logic defeated by defense mechanisms falls under the integrity security objective and has a low impact. Malicious logic capabilities that are unknown or not fully understood are considered high impact. If a single user workstation is inaccessible, this falls under the availability security objective and has a low impact, since it's only one user. If you are facing degradation or unavailability of DNS, routing, or PKI infrastructure, this is also availability, but this has a high impact, since it is affecting a lot of users.

### Video - [Tier 1 remediation actions](https://www.cloudskillsboost.google/course_templates/1195/video/522243)

* [YouTube: Tier 1 remediation actions](https://www.youtube.com/watch?v=xClx9uYnPY0)

SPEAKER: Tier 1 analysts in SecOps commonly undertake a range of remediation actions that are critical in responding to and managing security incidents. These actions include resetting passwords in cases of suspected account compromise. Applying available security patches to prevent exploitation when vulnerabilities are identified. Disabling a user account when it is suspected of being compromised or involved in malicious activities. Maintaining and updating antivirus and antimalware tools. Mitigating phishing attacks when they are detected, such as blocking the sender's email address or setting up filters to catch similar phishing attempts. Informing relevant stakeholders and users about incidents and the required precautions or actions to take. Containing an incident by temporarily revoking network access for affected systems or areas. Adjusting firewall settings to block or restrict malicious traffic based on the characteristics of the incident. Isolating infected or suspected systems from the network in order to prevent the spread of malware or further compromise. Reviewing logs to understand the scope of an incident or to confirm that a remediation action was successful.

### Video - [A phishing attack at Cymbal Federal is fully resolved in Tier 1](https://www.cloudskillsboost.google/course_templates/1195/video/522244)

* [YouTube: A phishing attack at Cymbal Federal is fully resolved in Tier 1](https://www.youtube.com/watch?v=uZuq2BIboaI)

SPEAKER: Let's explore an example to illustrate how you, as a tier 1 analyst, would contain a phishing attack. Note that, in this scenario, the phishing attack is fully resolved in tier 1. As a tier 1 analyst at Cymbal Federal, you receive an alert from the email security system indicating a potential phishing email. Employees receive a phishing email that appears to be from the IT department, asking them to update their passwords by clicking a link. The SOC receives alerts from their email security gateway and reports from a few employees about the suspicious email. The tier 1 analyst quickly identifies the email as a phishing attempt based on its content and the reported suspicious nature. The tier 1 analyst uses email security tools to remove the phishing email from all affected inboxes in order to prevent further exposure. Then the tier 1 analyst sends a communication to all employees, warning them about the phishing attempt and reminding them not to click on links in unsolicited emails. This incident is resolved at tier 1 because it was a clear-cut case of phishing without indications of a successful breach or a more sophisticated attack. vectors.

### Video - [A phishing attack at Cymbal Federal is escalated to Tier 2](https://www.cloudskillsboost.google/course_templates/1195/video/522245)

* [YouTube: A phishing attack at Cymbal Federal is escalated to Tier 2](https://www.youtube.com/watch?v=xPojmQa7sMg)

SPEAKER: In this video, you will explore a more complex phishing attack that might require escalation beyond Tier 1. Employees receive a phishing email impersonating a senior executive, urging them to download and attach document for an urgent meeting. Several employees download the attachment, which turns out to be malware. And the SOC receives alerts about suspicious activity on the network. The Tier 1 analyst identifies the email as a phishing attack and starts the standard response protocol. However, they notice that the malware from the attachment has started to communicate with an external server, indicating a potential data breach. They deem the complexity of the attack has increased, and that the malware needs to be analyzed in detail to understand its capabilities and the extent of the breach. As a result, the Tier 1 analyst determines that additional resources and expertise are required. They escalate the incident. You start by triaging the alert. As previously discussed, this involves the following. Collecting and aggregating alerts from various monitoring systems and security tools, such as EDR logs, event logs, and Splunk. Enriching and correlating data to determine patterns and correlations and connect with threat intelligence. Prioritizing alerts to determine severity, potential impact, and priority for investigation. Assigning alerts by assigning a ticket in Splunk or engaging in remediation actions. Tracking and monitoring the progress of the ticket and making updates as they become available. In some cases, your alert triage may not provide you with enough information for you to feel comfortable proceeding. In our example, you are still unsure of the true nature of the email. So before escalating or engaging in remediation, you decide to collect more data about the event in order to assist you in your decision making. Your additional data collection involves the following. You gather additional alerts or reports related to the incident. You check if similar emails have been flagged by the system or reported by other employees. You examine the emails metadata, like the sender, IP address, and links within the email. You correlate this information with known phishing indicators and threat intelligence databases. You are now ready to use this enriched data to make a decision regarding the nature of the email. The data you collected enables you to categorize the email as a phishing attack. You assess the impact of the phishing email. In this case, you would evaluate the number of affected users. Since no other user is affected by this mail, it is not critical and can be contained and treated by you, the Tier 1 analyst. You would also update the priority of the ticket to reflect your findings. So in this case, you would ensure that the ticket listed the email as a priority 3 threat. You contain the incident by quarantining the suspicious email to prevent it from reaching additional inboxes. You notify employees by email that they might receive a phishing email. You advise employees not to click on any links in the email and ask employees to report if they have interacted with it. Now let's move back to the impact assessment step and imagine an alternate scenario in which you assess the impact and determine that the phishing attack is reaching a large number of users. In this case, you assess the attack as critical. If the previous ticket priority is different, then you would need to update it. This means you will need to escalate the incident to Tier 2 analyst for further investigation. Once escalated to Tier 2 analyst, you as a Tier 1 analyst need to communicate internally with the incident response team to ensure work has begun on the incident. Finally, as a Tier 1 analyst, you report to the client by updating the ticket status in the ticketing system to escalate it to Tier 2 analyst. You add a note to the ticket informing the client about what has been done up until this point.

### Video - [Support processes](https://www.cloudskillsboost.google/course_templates/1195/video/522246)

* [YouTube: Support processes](https://www.youtube.com/watch?v=FB7VoPkTtQo)

SPEAKER: Tier 1 analysts engage in incident reporting in order to document incident details, aid in analysis, and fulfill SecOps compliance requirements. Escalation is critical to ensuring complex or severe security incidents are addressed by the appropriate levels of expertise and authority. Communication is needed in order to coordinate an effective incident response and to keep stakeholders informed throughout the process. Collaboration ensures that all parties share intelligence, resources, and best practices, thereby strengthening the overall cybersecurity strategy. All of these support processes enable you to do your job more effectively. But when do you use each one? These support processes are used at specific points during your incident response as a tier 1 analyst. Let's start with incident reporting. You use reporting during the monitoring phase, immediately after you detect a security event. Your goal in reporting is to document and inform relevant teams or authorities about the nature, scope, and initial assessment of the incident. For example, you identify a potential data breach. You immediately report it to the SOC manager and detail the nature of the breach, the affected systems, and your preliminary findings. You also engage in continuous reporting during the intake phase in order to log incoming alerts or to generate initial triage reports for analysis and prioritization. You may escalate the incident, both during the monitoring and intake phase. You will choose to escalate based on the scope and complexity of the event, as well as the resource capabilities of the current handling team. If the incident requires high-level expertise or decision-making authority, the appropriate step would be to escalate. For example, you, as a tier 1 analyst, discover the data breach involves sophisticated malware beyond your expertise. You would then escalate the issue to a tier 2 analyst who has more specialized skill in malware analysis and incident handling. What about collaboration and communication? You collaborate proactively by sharing insights and strategies across different teams and organizations. You collaborate reactively during incident response to leverage collective expertise and resources for effective resolution. For example, you may detect a surge in traffic indicative of a DDoS attack on web servers. You respond by simultaneously collaborating with multiple teams. You collaborate with the network team in order to adjust firewall settings and activate preconfigured rate limits to mitigate the traffic surge. You collaborate with tier 2 analysts to undertake a deeper analysis of the attack patterns and devise more sophisticated defense strategies. You collaborate with the communications team to prepare external communications for customers and stakeholders. This is to ensure the parties are informed about the service disruptions and ongoing resolution efforts. You collaborate with the ISP for assistance in mitigating the attack. This may involve rerouting traffic or additional filtering at the ISP level. Communication occurs throughout the entire incident life cycle, from initial detection to post-incident review. This is to ensure effective coordination and transparency among all parties involved. During the monitoring phase, you also communicate immediately with your response team. During the intake phase, you continuously acknowledge the reported incident. For example, you detect a surge in traffic indicative of a DDoS attack on the web servers. You, as a tier 1 analyst, immediately alert the SOC team and network administrators.

### Video - [ServiceNow tickets](https://www.cloudskillsboost.google/course_templates/1195/video/522247)

* [YouTube: ServiceNow tickets](https://www.youtube.com/watch?v=787OCWgGVGU)

SPEAKER: During the monitoring phase, you receive a ticket created in Splunk, which includes details of the alert such as the time of detection, nature of the anomaly, and any immediate observations. At this point, you need to start updating the ticket in ServiceNow by assigning the ticket to yourself. In your role as a tier 1 analyst, you would then perform an initial analysis of the alert and update the ticket with your findings, which may include the following-- information about the suspected cause of the anomaly, potential impact, any immediate steps taken in response. You also investigate if the anomaly or issue was reported by users or other systems. You update the ticket in ServiceNow with this additional information as well. The goal is to provide a more comprehensive view of the incident. Then you have reached the end of the monitoring phase. However, the ticket still needs to be regularly updated to reflect the current status of the issue. This includes ongoing monitoring results and any further developments or insights. During the intake phase, you go beyond the initial analysis conducted during monitoring. You conduct a preliminary assessment of the incident and examine the suspected severity, scope, impacted systems, and any immediate actions recommended or taken. You, again, update the ticket with these findings. You then add any additional relevant information you've obtained from the users or external sources. You update this additional data in ServiceNow in order to ensure a comprehensive record of all known details about the incident. Once complete, you determine if the incident requires escalation to a higher tier team due to its complexity or severity. If yes, you update the ticket and reflect this decision along with the reasons for escalation. You continually update the ticket with any new developments, actions taken, and changes in the status of the incident as it moves through the intake phase.

### Video - [Collaborating with other Tier 1 analysts](https://www.cloudskillsboost.google/course_templates/1195/video/522248)

* [YouTube: Collaborating with other Tier 1 analysts](https://www.youtube.com/watch?v=AHaRRP1B2A4)

SPEAKER: You may often collaborate with other tier 1 analysts during the monitoring phase. Collaboration at this level is essential for effective incident detection, analysis, and initial response. You may collaborate to share monitoring responsibilities. For example, many tier 1 analysts may be simultaneously assigned to monitor different segments of the network or different types of security tools, like IDS, firewalls, et cetera. In this case, you would collaborate to share findings and insights. This is to ensure comprehensive monitoring coverage and to identify patterns that might not be visible when working in isolation. You may collaborate on incident verification. For example, you notice unusual outbound traffic from a server. You may work with another tier 1 analyst to determine if this is a false positive or a genuine threat. You may collaborate for knowledge and experience sharing. For example, a newly onboarded security analyst is less familiar with a certain type of malware. He or she may consult with you as you have previously handled similar incidents. You may collaborate during shift handovers. For example, your shift ends, but before departing, you need to provide updates and insights on ongoing monitoring activities to another tier 1 analyst. This is in order to ensure that incoming analysts are fully aware of any ongoing issues or notable events observed during the previous shift. This ensures continuity and incident resolution and helps ensure swift time to resolution. You may collaborate before you escalate an issue or create an incident ticket. You might collaborate to cross-check and validate the findings. For example, you might observe a spike in login attempts and believe this might indicate a brute-force attack. You might ask a colleague to review and validate the observations. Remember, by collaborating with other tier 1 analysts, you enable a more accurate and effective monitoring process. This enhances the overall capability of the SecOps team to promptly detect and respond to security incidents. Collaboration between tier 1 analysts also occurs during the intake phase. This is to ensure a thorough analysis and an accurate assessment of incidents. You may collaborate when you assess and classify the incident. For example, when you receive an alert about a possible security breach, you might collaborate with another analyst to assess the severity and type of the incident. This may include determining whether it's malware infection or an attempted data breach. You may collaborate when you gather additional information to assess and classify the incident. For example, if a user reports a suspicious email, you could start tracing the email's origin while another tier 1 analyst investigates if similar reports have been filed. You may collaborate during the initial response coordination. For example, when a potential ransomware infection is detected, you collaborate to coordinate an initial response, such as isolating affected systems. In such situations, you might focus on communicating with the affected department to understand the extent of the infection while another tier 1 analyst works on the technical isolation of systems. You may collaborate on documentation and reporting by splitting responsibilities. For example, you focus on detailing the technical aspects of the incident while another tier 1 analyst compiles user reports and communications into the incident log. You may collaborate when determining the need for escalation. For example, you might collaborate with another tier 1 analyst to review the available data and decide whether to escalate the incident to a higher-tier team for more advanced handling. You may collaborate to do a cross-verification of findings. For example, before finalizing the assessment of an incident, you may work with other tier 1 analysts to cross verify your findings. This ensures that all aspects of the incident have been accurately identified and assessed. Overall, collaboration ensures that incidents are comprehensively assessed from multiple perspectives. This leads to more effective and informed decision making during the critical intake phase.

### Video - [Support processes at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522249)

* [YouTube: Support processes at Cymbal Federal](https://www.youtube.com/watch?v=KchZ7FXo0fE)

SPEAKER: Let's return to our use case to see these support processes in action. As discussed earlier, employees at Cymbal Federal receive emails that impersonate a company executive, asking them to click on a link for an important update. During detection, reporting is achieved either automatically through the Incident Management System or after receiving the information from any media. You, as a tier 1 analyst at Cymbal Federal, will report the incident in ServiceNow by either updating the ticket created in Splunk or manually creating a ticket. This ticket should include all the necessary details about the incident. Then you start assessing the incident. You determine the incident to be a suspected phishing attack. You collaborate with a fellow analyst to confirm the nature of the email. And you communicate the findings by updating the ticket in ServiceNow. You then move on to the intake phase. You engage in alert triage. You report the ticket internally to other tier 1 analysts in order to verify if this is a false positive or if it should be classified as a critical incident. Then, during the data collection, you collect additional information to gain a more global understanding of the alert. This may include whether the same alert has come from a different user. You log your findings in ServiceNow. This is to keep a record of the attack's extent. Then you communicate with external stakeholders and provide guidance through email to Cymbal Federal employees. Finally, you move to categorization and impact analysis. During categorization, you collaborate with other tier 1 analysts to determine the most accurate incident category. You report the category in ServiceNow. You collaborate with network administrators, IT staff, or other SecOps team members to assess the potential impact of the phishing attack. You communicate with department heads or the IT help desk to gather information about reported cases or system anomalies that might be related. Finally, you report these updates in ServiceNow. You are now done with the impact assessment. You either escalate the ticket to tier 2 analysts or you close the ticket and Mark it as solved. Whichever option you choose, you need to communicate and update the ticket in ServiceNow. The processes followed in this example and that you will need to perform in real life when securing the SOC are well defined and comprehensively documented. This is to ensure that you, as a security analyst, can always refer to the right sequence of steps to perform.

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/1195/video/522250)

* [YouTube: Module review](https://www.youtube.com/watch?v=CJ9ShnKzvSo)

SPEAKER: In this module, you were introduced to incident monitoring and intake for tier 1 analysts. You learned why these phases are important and how they fit within the spectrum of incident response. You explored the role of automated and manual detection methods, as well as key differences between internal/external alerts, and how to distinguish between false positives and true positives. You were introduced to the alert triage process and learned about data collection, incident categorization, and the impact assessment. This module also leveraged an example to illustrate how tier 1 analysts would be involved in remediating an incident, either by fully resolving the incident at tier 1 or by escalating it to tier 2. Finally, this module concluded with common support processes which tier 1s use at specific points during the incident process. These include incident reporting, escalation, communication, and collaboration. Now that you have a solid understanding of these topics, you're ready to advance to the next module.

### Quiz - [Knowledge check](https://www.cloudskillsboost.google/course_templates/1195/quizzes/522251)

## Incident response for Tier 2 analysts

 In this module, you will learn how to investigate an incident, including data correlation and data analysis. You will also learn advanced techniques that Tier 2 analysts can use for containing and remediating incidents. This may involve more complex solutions, such as re-configuring network devices, applying sophisticated patches, or executing custom scripts to neutralize threats and secure systems. Then, you will learn how to oversee the recovery process so that all systems return to normal function securely and efficiently. You will explore how to compile comprehensive reports that detail the incident timeline, actions taken, and recommendations for preventing future incidents. Finally, you will learn about the importance of collaborating with other teams, such as incident response teams or external experts. This includes understanding when and how to escalate further and how to coordinate effectively for a swift and thorough resolution of the incident. 


### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/1195/video/522252)

* [YouTube: Module overview](https://www.youtube.com/watch?v=OnxEyiVrya4)

SPEAKER: Welcome to Incident Response for Tier 2 Analysts. In the previous module, you learned about the Incident Response Process for Tier 1 Analysts, including when an incident needs to be escalated to Tier 2 Analysts. In this module, you'll learn how to handle incident tickets escalated from Tier 1. This involves understanding the preliminary analysis done by Tier 1, reassessing the severity and priority of the incident, and determining next steps for a more in-depth investigation. You will learn how to investigate an incident, including data correlation and the data analysis. You will explore strategies for deeper analysis. These include conducting an in-depth analysis of system logs, network traffic, and any other relevant data in order to uncover the root cause and full extent of the incident. You will also learn advanced techniques that Tier 2 analysts can use for containing and remediating incidents. This may involve more complex solutions such as reconfiguring network devices, applying sophisticated patches, or executing custom scripts to neutralize threats and secure systems. Then, you will learn how to oversee the recovery process so that all systems return to normal function securely and efficiently. You will explore how to compile comprehensive reports that detail the incident timeline, actions taken, and recommendations for preventing future incidents. Finally, you will learn about the importance of collaborating with other teams, such as incident response teams or external experts. This includes understanding when and how to escalate further, and how to coordinate effectively for a swift and thorough resolution of the incident.

### Video - [Incident response for Tier 2](https://www.cloudskillsboost.google/course_templates/1195/video/522253)

* [YouTube: Incident response for Tier 2](https://www.youtube.com/watch?v=n8BfZ5yWsvE)

SPEAKER: Let's start with a quick review. During incident response, the Tier 1 Analyst may hand over the incident ticket to Tier 2 Analysts. This is done according to procedures defined in the incident response plan. The act of routing the ticket to the Tier 2 Analyst is called escalation. Once escalated, the incident response becomes the responsibility of the Tier 2 Analyst. Let's continue with the incident response process by exploring what occurs once the ticket reaches the Tier 2 Analyst. Incident response is essential for organizations. It provides a structured approach to detect, contain, eradicate, and recover from security breaches, thus minimizing damage and preserving evidence. For Tier 2 Analysts, incident response is composed of three phases which can be continuously iterated upon-- investigation, containment/remediation, recovery/report. Let's briefly explore what the Tier 2 Analyst does during each phase. During the investigation, the Tier 2 Analyst receives the escalated incident ticket and undertakes deeper analysis. This analysis includes a more in-depth look at system logs, network traffic, and affected assets. The goal here is to understand the full scope and impact of the incident. The Tier 2 Analyst may also undertake advanced forensics using forensic tools and techniques. The goal here is to trace the origin of the attack, understand how security controls were bypassed, and identify the extent of the compromise. During the investigation, the Tier 2 Analyst may collaborate with specialists for a more in-depth analysis. For example, network security or application developers. Based on the outcome of the investigation, Tier 2 Analysts may also engage in containment and remediation. Tier 2 Analysts will determine whether the incident can be contained and remediated by them, or needs to be further escalated. In this case, the incident will move to Tier 3 Analysts. To achieve this, Tier 2 Analysts will first develop a strategic plan to contain the incident. This plan may involve isolating affected systems, blocking malicious traffic, or disabling compromised user accounts. After the containment, Tier 2 Analysts will focus on thoroughly removing any threats from the environment. For example, the Tier 2 Analyst may clean infected systems, close security gaps, and update compromised credentials. The Tier 2 Analyst then implements remediation measures to repair any damage and strengthen the organization's defenses. This could involve patch management, system hardening, and updating security policies. Finally, the Tier 2 Analyst oversees the restoration of affected services and systems to full functionality. This is known as recovery and reporting. The Tier 2 Analyst ensures the restored systems are free from threats and vulnerabilities. The Tier 2 Analyst also engages in heightened, ongoing monitoring to detect any signs of reinfection or residual impact from the incident. The Tier 2 Analysts also generate a comprehensive report that details the nature of the incident, the response actions taken, the findings from the investigation, and the recovery process. Finally, the Tier 2 Analyst conducts a post-incident review to evaluate response effectiveness, identify lessons learned, and recommend improvements to prevent future incidents.

### Video - [Reception of an escalated incident ticket](https://www.cloudskillsboost.google/course_templates/1195/video/522254)

* [YouTube: Reception of an escalated incident ticket](https://www.youtube.com/watch?v=bKJnrqlcCuQ)

SPEAKER: Now that you have a fuller picture of how tier 2 analysts support the incident response, let's take a closer look at how incident tickets are used by tier 2 analysts during the incident response. As a tier 2 analyst, you receive an escalated incident ticket from a tier 1 analyst. Tier 1 analysts will only escalate a security incident in specific cases. The incident's response requires specialized knowledge or specialized tools only available to tier 2 analysts for example, complex malware analysis, advanced network forensics, or decryption techniques. The incident response requires threat intelligence gathering, detailed analysis of logs and network traffic, or potentially identifying sophisticated malware. The incident poses a significant risk to critical systems, sensitive data, or core business operations, for example, widespread malware infections, data breaches, or ransomware attacks. The incident meets predefined thresholds that act as triggers for escalation, for example, the number of affected users or criticality of roles; affected systems, like central infrastructure or sensitive data repositories; or specific security breach indicators, like unusual network activity or unauthorized access attempts. But what channels exist for case escalation? First, there are ServiceNow tickets. These are created in Splunk Endpoint Detection and Response, EDR, or through Security Orchestration Automation and Response, SOAR. By using these tickets, the Security Operations Center, SOC, creates a documented trail of the incident and ensures clear information handover. Tickets can be assigned based on predefined rules. This enables urgent incidents to be prioritized and directed to the appropriate tier 2 analysts. Tier 2 analysts may also use internal communication platforms during incident response. Slack channels, chat rooms, or dedicated incident response forums facilitate communication between tier 1 and tier 2 analysts and enable timely updates and coordinated action. Phone calls or face-to-face meetings may be used in case of urgent or complex cases where tier 1 analysts need to provide detailed information, discuss critical decisions, and ensure a seamless transition to tier 2 investigations. The tier 1 analyst will always need to ensure that the incident is fully analyzed and data carefully documented before handing it over to the tier 2 analyst. Now, let's look at the escalation process in more detail.

### Video - [Review of an escalated ticket](https://www.cloudskillsboost.google/course_templates/1195/video/522255)

* [YouTube: Review of an escalated ticket](https://www.youtube.com/watch?v=o9QwCoo58EM)

SPEAKER: As a tier 2 analyst, you will receive an escalated ticket from ServiceNow. You must then engage in a thorough review before taking further action. This is to ensure you have a clear understanding of the incident before taking any next steps. First, you review the case categorization by identifying the categorized incident-type field in ServiceNow. This provides you with context on the nature of the issue-- for example, a server outage, a malware infection, a data breach, et cetera. Then you look for additional related categories under the Subcategory field or any custom fields that offer further granularity. For example, a specific server is affected by a type of malware. Next, you reassess the impact of the incident. You review the Priority field to understand the perceived severity of the incident. You analyze the Urgency field to evaluate the expected speed of resolution. You can explore additional details under the Impact sections, for example, affected users, services, or business functions. Then you check the steps taken thus far. You review the activity log or timeline of the ticket in order to obtain historical actions undertaken by tier 1 analysts. You also check troubleshooting steps, logs, reviewed communication logs, and any temporary fixes that were implemented. Finally, you check for any additional data that may contain additional diagnostic information, relevant procedures, or escalation criteria-- for example, attached documents or references to knowledge-base articles within the ticket. Throughout the entire process, ticket management is assured using ServiceNow as a ticketing system. You'll learn more about that in the following video.

### Video - [Ticket management with ServiceNow](https://www.cloudskillsboost.google/course_templates/1195/video/522256)

* [YouTube: Ticket management with ServiceNow](https://www.youtube.com/watch?v=XGObF3nWC3o)

SPEAKER: Throughout the entire escalation process, ticket management is assured using ServiceNow as a ticketing system. Once the ticket is escalated, ServiceNow assigns it to a tier 2 analyst. The ServiceNow platform assures that once a ticket is assigned to the tier 2 analyst, you receive real-time notifications and readily accessible information from ServiceNow dashboards. This includes the initial incident description, attached screenshots, logs, and collected data. ServiceNow also ensures that each ticket has a designated owner. This provides accountability and transparency as the ticket progresses through the resolution process. Finally, ServiceNow ensures any updates, comments, and action items are documented within the ticket. This helps tier 2 analysts facilitate collaborative investigation and knowledge sharing. This collective intelligence ensures no detail is overlooked and that others may learn from the incident. But do tier 2 analysts ever need to, once again, communicate with tier 1 analysts? In some situations, the tier 2 analyst may need to reach back out to the tier 1 analyst. This may be for the following reasons-- clarification of details, verification of actions, collaboration on analysis. For example, if the initial information is unclear, incomplete, or ambiguous, a tier 2 analyst will contact tier 1 for clarification. This may include details about specific error messages or logs, user-reported symptoms/timelines, context surrounding the incident, such as recent changes or known vulnerabilities. The tier 2 analyst may also want to verify the actions that were taken by tier 1 or obtain additional contextual information, such as the following-- troubleshooting steps already attempted, temporary fixes or workarounds implemented, type of communication with affected users or stakeholders. Finally, the tier 2 analyst may need to collaborate with tier 1 during analysis. This is especially true for complex incidents. For example, collaboration can yield the following outcomes during analysis-- additional findings and insights, potential solutions or mitigation strategies, additional data points for a comprehensive assessment. Throughout the investigation, there are specific cases where you will need to communicate with the SOC manager. You will need to contact the SOC manager if you encounter critical incidents or SOC incidents involving potential regulatory or legal implications. In such cases, tier 2 analysts need to immediately notify the SOC manager to explain the incident and highlight the potential impact. You will also need to inform the SOC manager about urgent decisions or resource allocations. You are also required to notify the SOC manager at specific stages during your investigation and during escalation. You may also need to involve the SOC manager in decisions regarding containment, remediation, or communication strategies. Finally, you need to provide the SOC manager with regular status updates regarding the process of investigations, significant findings, challenges, and anticipated-resolution timelines, and resource needs.

### Video - [An escalated ticket at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522257)

* [YouTube: An escalated ticket at Cymbal Federal](https://www.youtube.com/watch?v=nhCgO_7it3c)

SPEAKER: Let's consider an example in which a Tier 2 analyst will accept an escalated ticket and undertake an investigation. You are a Tier 2 analyst at Cymbal Federal and have just received an escalated incident ticket. Let's consider your first steps as you decide what to do with the ticket. The ticket is regarding an unusual outbound traffic spike from an internal server outside of business hours. You start by reading the ticket notes that the Tier 1 analyst has left in ServiceNow. You learn that the Tier 1 analyst has already isolated the server and started a basic scan, but couldn't find anything suspicious. You start by reviewing the detailed information provided in the escalated ticket. You focus on what was observed by Tier 1, including the server involved and the nature of the traffic spike. Then you check and consider the role of the potential compromised server, int-srv-001, within the network. You look at typical traffic patterns, any recent changes or maintenance activities. You evaluate the Tier 1 response with particular attention to the decision to isolate the server, as well as the effectiveness of the basic scan performed by Tier 1. Given the unusual nature of the traffic, you assign the incident to a high priority due to its potential impact on network security. Then you decide what additional tools may be needed. For example, in this case, you choose advanced analysis software. You can access these resources. You then engage in additional information gathering by contacting the Tier 1 analyst for any insights or observations that were not included in the initial report. Based on your analysis, you hypothesize potential incident causes. These include a misconfigured backup process, unauthorized access, or malware activity. You establish a communication plan. You update the security team lead and IT management throughout the investigation and you escalate it if this is a Tier 3 case. Your initial findings lead you to decide that further investigation is needed. You undertake additional tasks, such as in-depth log analysis and network monitoring. In the following video, you will learn more about investigations for Tier 2 analysts on the following topic.

### Video - [Incident investigation](https://www.cloudskillsboost.google/course_templates/1195/video/522258)

* [YouTube: Incident investigation](https://www.youtube.com/watch?v=v5L1L2WrCFA)

SPEAKER: Investigation is a critical stage where the tier two analyst gathers information, analyzes data, and explores various aspects of an incident in order to understand it thoroughly. During an investigation, a tier two analyst will engage in a number of steps to fully investigate and understand an incident. To gain insight into the bigger picture, a tier two analyst will engage in event correlation. This means the tier two analyst investigates beyond isolated events and looks for connections between seemingly unrelated incidents. Event correlation can help reveal the full attack timeline, scope, and potential impact. The tier two analyst also aims to identify the root cause of the incident. This involves employing various analysis techniques, such as system analysis, malware analysis, and network traffic analysis. For now, it's important to note that these analysis techniques enable you to pinpoint the source of the breach with greater precision. This can lead to more targeted and effective remediation efforts. By understanding the root cause of the incident, you are also able to more effectively prevent future attacks. This is because you're able to identify and patch exploited vulnerabilities. Tier two analysts will also analyze attack patterns and historical data in order to better anticipate the attacker's next moves. This proactive approach allows tier two analysts to apply preventative measures. This enables faster response times and can minimize potential damage. These three steps enable tier two analysts to gain a better understanding of the attack's scope, criticality, and correlation with other events. This enables you to better prioritize your response efforts by addressing the most impactful threats. This also ensures that resources are allocated most effectively. During an investigation, tier two analysts will face challenges associated with data correlation and analysis. For example, you will be faced with a large amount of data of different varieties. You will also need to consider timeliness in your response, responding to evolving threats, and the accuracy of the data you are handling. Ultimately, you will need to make contextual interpretations, and this will be highly dependent on your experience and skills during the incident investigation. The investigation phase consists of two phases, correlation and analysis. During correlation, you integrate and analyze data from various sources to identify potential security incidents. This helps you make sense of the large volume of diverse data generated by network devices, security systems, and applications. During incident analysis, you aim to undertake an in-depth investigation in order to determine the nature, scope, and impact of an incident. In the following video, you will take a deeper look at data correlation.

### Video - [Data correlation during investigation](https://www.cloudskillsboost.google/course_templates/1195/video/522259)

* [YouTube: Data correlation during investigation](https://www.youtube.com/watch?v=vCGWYCgt49k)

SPEAKER: During data correlation, you piece together disparate pieces of information to form a coherent picture of an incident. Data correlation is foundational during incident response, as this process is essential for constructing an accurate and legally defensible narrative of a security incident. To do this effectively, you need to do the following. Undertake data identification and collection. Maintain data integrity and preservation. Follow a clearly defined chain of custody. During data identification and collection, you determine which data sources are relevant to the incident. You systematically gather data from these sources. Sources may include system logs, network traffic data, security device logs, endpoint data, and more. As you work through these sources, it is critical that you maintain the integrity of the data you collect. This means ensuring that the data is not altered, tampered with, or damaged during the collection, transfer, and analysis processes. Techniques such as hashing are commonly used to verify the integrity of data at various stages. During data correlation, it is also essential that you maintain a strict chain of custody. This involves documenting every interaction with the data, including who accessed it, when, and for what purpose. The chain of custody is crucial for legal and compliance reasons, especially if the findings are to be used in a legal context. Let's take a moment to discuss why data integrity and chain of custody are so important during correlation. First, data integrity-- data integrity is essential to maintaining the forensic validity of your evidence. You need to ensure any digital evidence you provide can withstand scrutiny in legal proceedings. Furthermore, the analysis and conclusions you draw from the data are dependent on the integrity of the data you use. Compromised data can lead to incorrect conclusions, which can impact decision-making and incident response. Finally, data integrity is also required for compliance reasons. Noncompliance can result in legal ramifications and a loss of reputation. Maintaining a strict chain of custody matters for legal reasons, particularly in criminal cases. The chain of custody serves to prove that the evidence presented in court is the same as what was originally collected. If the chain of custody is broken or unclear, the evidence could be considered inadmissible. Chain of custody is also used to maintain trust, as a well-documented chain of custody ensures that the data and evidence are trusted by all parties involved. This agreement is crucial for the credibility of the investigation's findings. Finally, maintaining a strict chain of custody helps prevent and identify any unauthorized or accidental alterations to the data. A breakglass procedure is a supportive procedure that tier 2 analysts can use in case you require emergency access to a system or data. Tier 2 analysts can rely on breakglass when normal access methods are either too slow or unavailable. For example, you need to access a locked-down system during a critical system failure, or a health care provider needs to access restricted patient data during a life-threatening situation. Breakglass procedures can bypass regular security protocols, however, the access granted is usually limited to the duration of the emergency and restricted to the necessary data or systems. The use of a breakglass procedure is heavily monitored and audited. Breakglass procedures should be reserved for scenarios where security must be balanced with the need for urgent access. Ensure a breakglass is only used when genuinely required. In the previous module, you learned about the data correlation that occurs during intake by tier 1 analysts. This differs from the data correlation that occurs during investigation by tier 2 analysts. At intake, the tier 1 analyst is undertaking an initial assessment of the data. This assessment is focused on filtering and prioritization. During the investigation, the tier 2 analyst is involved in a detailed analysis. This assessment aims to uncover all the facts behind an incident. The intake phase also relies more heavily on automated tools for rapid data processing. Investigation usually involves advanced and sometimes manual techniques for deeper analysis.

### Video - [Key sources for data correlation](https://www.cloudskillsboost.google/course_templates/1195/video/522260)

* [YouTube: Key sources for data correlation](https://www.youtube.com/watch?v=-np_IOOyDc8)

SPEAKER: Correlating various types of data is a key aspect of cybersecurity, network management, and data analysis. Tier 2 analysts will work with different types that can often be correlated in these contexts. Network traffic data-- these are logs and records of all data passing through a network, such as source and destination IP addresses, protocol types, and packet sizes. System logs-- these are records generated by operating systems detailing events that occur within the system, including system errors, configuration changes, and system access records. Application logs-- these are logs generated by applications that provide insights into application performance, user activities, errors, and transactions. Security device logs-- this is data from devices like firewalls, Intrusion Detection Systems, IDS, and Intrusion Prevention Systems, IPS, including traffic blocks, alerts, and security events. Authentication and access logs-- these are records of user authentication attempts and access to systems, applications, or data, including successful and failed login attempts. Endpoint protection logs-- this is data from antivirus programs and other endpoint protection tools detailing detected threats, quarantine actions, and system changes. Threat intelligence feeds-- this is information from external sources about known threats, vulnerabilities, malicious IP addresses, URLs, and file signatures. File metadata-- this is information about files, such as creation date, modification date, file size, and file type, which can be crucial in digital forensics. Database transaction logs-- these are records of transactions made in a database. This is useful for understanding data access patterns and changes over time. Audit trails-- these are comprehensive records of sequences of activities or changes in a system or application. These are often used for compliance and investigative purposes. Email logs-- these are records of email transactions within an organization, including sender, receiver, date, time, and subject, which can be crucial in investigating phishing attacks or data leaks. User Behavior Analytics, UBA data-- this is data that reflects user activities and behavior patterns. This is useful in detecting anomalies or malicious insider activities. Cloud service logs-- these are logs from cloud platforms and services detailing usage, activities, configurations, and security events in cloud environments. DNS, Domain Name System, query logs-- these are records of DNS lookups. These can be analyzed to identify potentially malicious domain interactions or network compromise indicators. VPN logs-- this is data regarding VPN connections, including user access records, connection times, and amounts of data transferred. By using these types of sources, you are able to create a comprehensive understanding of the network, system, or application behavior. This is essential in identifying and responding to cybersecurity threats, system malfunctions, or unauthorized activities. You'll see this in action in the following video. For now, it's important to note that there are numerous challenges you may face during data correlation. Security incidents generate vast amounts of data from diverse sources, including logs, network traffic, system configurations, and endpoint telemetry. This may cause you to feel overwhelmed. False positives and negatives can lead you to waste your time and delay your response. False negatives can leave the organization exposed to ongoing attacks. The need for a swift response can put pressure on you to rush through the correlation process. This can lead to incomplete analysis, missed connections, and ineffective response strategies. If you are not equipped with the right tools, you may not be able to accurately identify and respond to sophisticated security threats. Sophisticated tools exist to help you address these challenges. These tools enable you to handle complex attack techniques or analyze the diverse data formats involved in incident correlation.

### Video - [Data correlation at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522261)

* [YouTube: Data correlation at Cymbal Federal](https://www.youtube.com/watch?v=sc283T9IPhY)

SPEAKER: Now that you have a fuller understanding of what occurs during data correlation, let's return to the Cymbal Federal use case. You are a tier 2 analyst working at Cymbal Federal. An alert is raised about suspicious activity in a sensitive internal database. This alert, initially flagged by automated systems, has been escalated to you for further investigation. You begin your investigation by conducting an initial assessment. You start examining the alert details. You notice multiple login attempts to the database from an unusual IP address followed by a successful login. Then you correlate database-access logs with network-traffic logs and find a significant data query and a transfer to the same IP address around the time of the login. Further correlation with user account logs reveals that the login credentials belong to a recently terminated Cymbal Federal employee. This suggests a possible case of unauthorized access using old credentials. Throughout correlation, you ensure the integrity of logs by verifying their cryptographic hashes. This confirms that the logs haven't been altered since they were generated. You also document every step of your investigation, including the time you accessed each log and the specific actions you took. This meticulous documentation maintains a clear chain of custody, which is essential if the incident leads Cymbal Federal to legal action. That's it for your initial data correlation. You now move forward with the next step following data correlation-- analysis.

### Video - [Incident analysis during investigation](https://www.cloudskillsboost.google/course_templates/1195/video/522262)

* [YouTube: Incident analysis during investigation](https://www.youtube.com/watch?v=EDSGwp0UVw0)

SPEAKER: Incident analysis aims to identify the root cause of the compromise and predict attacker actions. There are three analysis techniques that you are often going to use. You may rely on a single one or a combination of all of them. System analysis. Malware analysis. Network traffic analysis. Let's quickly review the aim of each type of analysis before exploring each one in depth. Malware analysis involves dissecting and studying malicious software to understand its functionality, origin, and potential impact on the system. This analysis is typically divided into two approaches. Static analysis. This examines the malware without executing it. Dynamic analysis. This observes the malware's behavior during execution, often within a controlled and isolated environment, sandbox. Network traffic analysis monitors and analyzes network communication to detect suspicious activities, security threats, or unauthorized access. This analysis technique involves the examination of data packets moving across the network. During network traffic analysis, you use tools and methods to identify anomalies, patterns, or signs of malicious activity. Examples include packet sniffers and flow data analysis. At this point, you have started to connect the initial data to additional sources such as logs, network activity, and unusual readings. However, you still don't know the main cause of the incident. This cause is hidden somewhere in the technical details. Using analysis tools, you will now carefully search through log entries, follow network paths, and check odd sensor readings. You will gradually advance through all this data until you uncover the source of the problem. You now have a high level understanding of these three in-depth investigation strategies. In the following videos, you'll learn more about each one.

### Video - [System analysis strategies](https://www.cloudskillsboost.google/course_templates/1195/video/522263)

* [YouTube: System analysis strategies](https://www.youtube.com/watch?v=Mcm8UDlCJww)

SPEAKER: You start with system analysis, in which you look for the attackers' footprints on the various components of the computer system. During system analysis, you engage in numerous forensic investigation strategies, where you gather scattered clues to put pieces together like a puzzle. This includes the following strategies-- a forensic examination of system logs and event histories, investigating user activity and privilege escalation attempts, uncovering hidden malware, reconstructing the timeline of events. Let's now explore each of these investigative strategies in more detail and apply them to examples.

### Video - [System analysis at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522264)

* [YouTube: System analysis at Cymbal Federal](https://www.youtube.com/watch?v=_m5A9ildcu0)

SPEAKER 1: Diving into system logs and event histories provides you with a chronological record of system activity. This reveals unusual events, suspicious access attempts, and potential indicators of compromise. System logs help you track system activities, errors, and warnings. These logs can reveal unauthorized changes, system failures, or security alerts. Application logs provide insights into application-level activities, such as user actions, transaction histories, and errors. Security logs enable you to check the firewall, intrusion detection systems, and antivirus software. These logs can identify security-related events, like blocked attacks, detected malware, or failed login attempts. Imagine you are reviewing the Windows Event Viewer on a server after a suspected security incident at Cymbal Federal. You come across multiple entries for event ID 4625, indicating failed login attempts to the administrator account from a foreign IP address. This immediately stands out, as these attempts occurred during off hours, when administrative access is typically not required. Further forensic system analysis of the logs shows the installation of a new, unrecognized service shortly after one of the failed login attempts finally succeeded. The network logs indicate that this service is continuously restarting and attempting to communicate with an external server. This pattern is a strong indicator of a compromised account being used to install malicious software, likely a backdoor or a remote access trojan. In this scenario, the chronological record of system activity provided by the logs was crucial in piecing together the timeline of the attack, identifying the initial breach, unauthorized login, and understanding the subsequent actions of the attacker, installation of malicious software. This information is vital for incident response, as it guides your steps in containing and remediating the incident. It also helps you reinforce defenses against similar future attacks. During system analysis, you will also analyze logins, privilege changes, and access patterns. This can help you identify compromised accounts and lateral movement within the network. For example, you may monitor and analyze login activities, especially from unusual locations, odd times, or repeated failed attempts. This data can help you identify unauthorized access attempts or compromised credentials. You will also want to track changes in user privileges, such as unexpected elevations of access rights. This may indicate an attacker trying to gain broader access within the system. Let's consider a scenario where you're analyzing the network security logs at Cymbal Federal. You notice that an account belonging to a regular user with standard user privileges has been used to access the network during the weekend. This is unusual for this user. Further investigation reveals that this account has had its privileges escalated without proper authorization. The account has access to multiple sensitive servers and downloaded large volumes of data. These observations are cause for concern and further investigation. Off-hours access, unauthorized privilege escalation, and atypical data access patterns, they all suggest that the user's account might have been compromised. You believe this could be a case of an external attacker gaining access to the account and then moving laterally within the network to reach high-value targets. This is a common tactic for Advanced Persistent Threats, also known as APTs. In this scenario, your swift identification of these irregularities enables you, the tier 2 analyst, to take immediate action. This includes revoking the escalated privileges, changing the user's credentials, conducting a thorough investigation to determine the extent of the breach, and taking steps to prevent further unauthorized access. You will also use forensic tools to analyze memory dumps, registry modifications, and unusual system behaviors. This helps you detect rootkits and other stealthy malware that traditional antivirus may miss. Memory dump analysis involves examining the contents of a system's memory, RAM, captured at a specific point in time. This could provide you with valuable data about what processes were running, network connections, and even potential malicious code that was executing, but not written to disk. Windows Registry is a database storing configuration settings and options. Analyzing changes in registry keys can reveal actions taken by malware, such as establishing persistence, disabling security features, or modifying software behavior. Unusual system behavior includes observing deviations from normal operational baselines, such as unexpected system reboots, slow performance, or unusual network traffic. These all may indicate the presence of malware. For example, imagine you are using a tool, like Volatility, to analyze a memory dump from a suspicious Windows machine at Cymbal Federal. In the memory dump, you uncover a hidden process that doesn't appear in the Task Manager or other conventional process listing tools. This process involves maintaining a persistent network connection to an external, unrecognized IP address. You use a registry analysis tool, like Reg Shot, and uncover that several registry keys have been modified to include this hidden process in the system startup sequence. This suggests an attempt to maintain persistence. The registry also shows alterations in the group policy settings that have disabled the Windows Defender antivirus. Finally, you observe that the machine has been experiencing unexplained reboots and significant slowdowns. This behavior is atypical under normal operating conditions. This comprehensive approach to using forensic tools has enabled you to uncover a hidden process in memory, registry modifications for persistence and security feature circumvention, and unusual system behavior. These all indicate the presence of a sophisticated rootkit. Your findings allow you to analyze malware that might otherwise remain undetected. This provides crucial insights for effectively countering advanced persistent threats. Finally, you may also analyze time stamps and log entries in order to establish the sequence of events leading up to the incident. You can check the timestamp correlation by aligning the time records from various logs-- system, network, application, security-- to create a continuous timeline. Timestamps are key in determining the order of events. You can analyze log entries by examining entries in different logs. This allows you to identify the initial point of compromise, subsequent actions taken by the attacker, and any changes made to the system. Correlating the sequence of events enables you to create a narrative that explains how the incident unfolded step by step. This includes identifying the entry point, movement within the network, and any data or system manipulation. Let's imagine you are investigating a data breach at Cymbal Federal. You start by examining the web server logs. You notice an unusual spike in traffic to a specific URL that corresponds with the execution of a SQL injection attack. This is indicated by the payload in URL requests. You cross-reference these entries with database logs and find subsequent unauthorized database queries retrieving user data. These are all timestamped immediately following the web server attack. Security logs from a file server reveal unauthorized access to sensitive files shortly after the database queries. This suggests lateral movement by the attacker within the network. Firewall logs show an outbound transfer of a large amount of data to an external IP address. This coincides with the timing of the file server access. By correlating these logs and timestamps, you build a clear sequence of events, a web server compromise leading to a database breach, followed by a lateral movement to a file server and culminating in data exfiltration. Through this meticulous process of aligning timestamps and analyzing log entries, you build a comprehensive understanding of the incident timeline, offering invaluable insights into the attacker's methods and goals. This understanding is crucial for effective incident response and for implementing measures to prevent similar breaches in the future. These measures will be discussed later in this course.

### Video - [Malware analysis strategies](https://www.cloudskillsboost.google/course_templates/1195/video/522265)

* [YouTube: Malware analysis strategies](https://www.youtube.com/watch?v=iX2ou0WrGmA)

SPEAKER: Let's return to the analysis techniques you have at your disposal. You may need to engage in malware analysis. With malware analysis, you go beyond simply detecting malicious code and begin to decipher the enemy's code. You begin with an examination of the malware. This may involve several levels of analysis. You start with initial quick checks on a malware sample to understand its basic characteristics. This is known as a surface analysis. During surface analysis, you will be able to make a basic determination of the malware's nature and intent, identifying strings and binary files, understanding cryptographic hashes, check the antivirus software detection status, note file sizes and types, and obtain file attribute information. You will also identify packers and check for signature-based detection status. If this information is still not sufficient, you execute a runtime analysis where you execute the malware in a controlled, isolated environment to observe and record its behavior. During a runtime analysis, you uncover network touchpoints, like addresses, protocols, and ports, file system and registry activity, vulnerabilities in specific runtime environments, system service interactions, and the dynamic unpacking of packed executable files. You also assess the success of remediation techniques in these environments and get suggestions of adversarial intent. If additional information is required, you move to a successive level of analysis. This requires personnel who possess more sophisticated skills and have access to additional tools or ISs. Large organizations often have dedicated tier 2 or tier 3 security teams with malware analysis capabilities. Small organizations may not have the resources for in-house expertise and rely on tier 1 analysts working with external threat intelligence firms or vendor support for a deeper analysis. The next level of analysis is called static analysis. During static analysis, you focus on the malware's contents and structure and examine the malware without executing it. You achieve a definitive understanding of the program's source code, static unpacking of packed executables, determination of adversarial intent with a high degree of confidence, and deobfuscation with obfuscated data. Once this is complete and, if you have sufficient data, you record the results, communicate the analysis, and finish your malware analysis. If your data is still incomplete, the malware moves on to even more specialized analysis. If you still lack information, you would then engage in reverse engineering. This is the most in-depth form of analysis in which you disassemble the malware sample executable files and interpret the assembly language. Through reverse engineering, you can manually unpack packed executable files, understand obfuscation or encryption techniques, gain a definitive understanding of malware capabilities, characterize the sophistication of the malware, and compare capabilities across different malware samples. Once this is complete, you record the results and communicate the analysis. You are finished with your malware analysis. During malware analysis, you use specialized tools to dissect the malware. Your goal is to understand the purpose of the malware, its capabilities, and potential connections to known threats. During malware analysis, you perform these steps-- extract and analyze malicious code, extract indicators of compromise, determine the purpose and capabilities of the malware, inform other specialists in order to contain and eradicate the malware. In the following video, you'll explore these in-depth investigative strategies in more detail and apply them to examples.

### Video - [Malware analysis at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522266)

* [YouTube: Malware analysis at Cymbal Federal](https://www.youtube.com/watch?v=5wQ51Ko_JVw)

SPEAKER: During malware analysis, you aim to understand the malware's functionality and identify its vulnerabilities. You extract and analyze the malicious code using specialized sandboxes, emulators, and disassembly tools. You use a sandbox environment to safely execute the malware and observe its behavior without risking the security of your actual network. Sandboxes provide you with a controlled setting where you can analyze how the malware interacts with files, the system, and network resources. You can also use emulators that allow you to run the malware in a simulated environment that mimics different operating systems or hardware configurations. This helps in understanding how the malware operates under various conditions. You can use disassembly tools like IDA Pro or Ghidra to assemble the malware and inspect its code. This code-level analysis helps you identify the programming logic, functionalities embedded in the malware, and potential weaknesses. For example, imagine you've come across a new piece of malware while troubleshooting a suspicious file attachment at Cymbal Federal. You first extract the attachment and run it in a sandbox, like Cuckoo Sandbox. This allows you to observe the malware's actions in a safe environment. In the sandbox, you notice the malware attempts to connect to several suspicious external IP addresses and tries to download additional payloads. You use an emulator to mimic different operating systems in order to see if the malware behaves differently on each. You discover the malware has a component that only activates when running on a Windows server environment. This suggests the malware is only targeting enterprise networks. You use a disassembly tool, like Ghidra, to delve into the malware's code. You uncover that the malware uses known vulnerabilities in a popular application to escalate its privileges. However, you also identify a flaw in the malware encryption routine. This offers a potential point for developing a decryption tool or a countermeasure. Through this comprehensive analysis, you not only understand the malware's behavior and targets but have also identified a weak point that can be exploited to neutralize its threat. This level of understanding is vital for developing effective defenses and remediation strategies against sophisticated malware threats. During malware analysis, you also identify unique signatures, file hashes, and network communication patterns. This provides valuable information for threat hunting and the detection of similar attacks. Unique signatures allow you to identify specific patterns or characteristics in the malware's code that are unique to the malware itself. These signatures can be used in intrusion detection systems, IDS, or antivirus software to detect and block malware. You check the file hash, which is the unique digital fingerprint of a file. This is determined by calculating the hashes, like MD5, SHA-1, or SHA-256, of malware files. Using these can quickly identify and flag these files in the future, even if they are renamed or relocated. You can also analyze the malware's network behavior, such as the IP addresses it communicates with, DNS requests it makes, or specific network protocols it uses. This information enables you to identify the malware communication channels and block them. Let's imagine you're analyzing a ransomware sample at Cymbal Federal. You start with analysis in a controlled environment and identify a unique code sequence that the ransomware uses to encrypt files. You create a signature based on the sequence and integrate the code into your IDS, enabling the code to detect and block the ransomware in the future. Next, you calculate the file hash of the ransomware executable. This hash is then added to a database used by Cymbal Federal's antivirus systems. This ensures that if the file appears again on any system, it is immediately flagged and quarantined. Finally, you observe the network traffic generated by the ransomware and notice it consistently attempts to contact a specific set of IP addresses and uses a unique DNS query pattern to locate its command and control server. You configure your firewall and network monitoring tools to alert and block any traffic matching these patterns. By extracting indicators of compromise and utilizing these unique identifiers, signatures, hashes, and network patterns, you significantly enhance your organization's ability to detect, block, and mitigate similar malware attacks in the future, thereby bolstering your cybersecurity posture. You also need to determine the malware's purpose and capabilities. This helps you identify the attacker's motives and predict future actions. You analyze the malware's payload. This is the active component of the malware that causes the actual damage or performs the intended malicious activity. This form of analysis helps you determine what the malware is designed to achieve, stealing data, encrypting files for ransom, or creating a backdoor for future access. You analyze what data the malware attempts to access, modify, or exfiltrate. From this, you can infer the value of the targeted information to the attacker and potentially their identity or motive. For instance, malware targeting financial data may indicate financial fraud motives. You compare the characteristics of the malware with known malware families, attacker group signatures, or ongoing campaigns. From this, you identify connections that could provide insight into the larger strategy, techniques, and goals of the attackers. For example, imagine you're analyzing a piece of malware that has infiltrated Cymbal Federal's network. Upon examination, you find that its payload is designed to search for and exfiltrate documents with specific keywords related to proprietary technology. By researching these characteristics, you find similarities with a known malware variant used by a cyber espionage group that targets technological intellectual property. This group has been involved in several long-term campaigns against organizations in your industry. Further analysis reveals that the malware is designed to establish long-term access to the network. This suggests that the attackers are interested in ongoing surveillance and data theft, rather than immediate financial gain. This understanding helps you not only address the current threat but also anticipate and prepare for potential future actions by this group, such as similar malware attacks or other espionage tactics. Through a comprehensive analysis of the malware's purpose and capabilities, you gain a clearer understanding of the threat actor's motives, the nature of the threat, and how it aligns with broader attacker behaviors. This knowledge is crucial for developing targeted defense strategies and for sharing information with the broader cybersecurity community to aid in collective defense efforts. Finally, malware analysis provides insight that helps inform containment and eradication efforts. Based on your analysis, you can identify which systems are compromised and need to be isolated from the network in order to prevent the spread of the malware. This includes disconnecting systems from the network and possibly shutting them down, if necessary. Understanding the malware's network behavior allows you to identify and block the communication channels it uses. This may involve blocking specific IP addresses, domain names, or network ports that the malware uses for data exfiltration or command and control, CNC, communications. You also take steps to remove the malware from infected systems and to restore them to a secure state. This could include deleting malicious files, reversing changes made by the malware, applying security patches, and strengthening security configurations to prevent reinfection. For example, imagine that the malware analysis at Cymbal Federal revealed that the malware communicates with a command and control server using encrypted traffic over TCP port 443. Based on this insight, you block outgoing traffic on this port to the identified malicious IP addresses at the firewall level. This disrupts the malware's ability to receive further instructions or exfiltrate data. Malware analysis also showed that the malware propagates through the network by exploiting a specific vulnerability. In your response, you isolate all systems showing signs of infection. You begin patching the vulnerability across the network to prevent further spread. You then use antivirus and malware removal tools to eradicate the malware from infected systems. Following the removal, you conduct a thorough review to ensure no remnants of the malware remain and monitor the systems closely for signs of reinfection. All of these actions were informed by the detailed malware analysis. Using these insights, you effectively contain the spread of the malware, disrupt its communication channels, and eradicate the malware from the infected systems. You mitigate the threat and restore the integrity of your network.

### Video - [Network traffic analysis strategies](https://www.cloudskillsboost.google/course_templates/1195/video/522267)

* [YouTube: Network traffic analysis strategies](https://www.youtube.com/watch?v=2LJPA7PrXV8)

SPEAKER: Tier 2 analysts may engage in network traffic analysis. Examining network traffic provides you with a unique perspective on the attack, revealing how the attacker moved within the network and communicated with external resources. This information helps you uncover attempts to steal sensitive information. Network analysis also provides insights into the attacker's methods and activities. Let's explore network traffic analysis in detail. Network traffic analysis has three main objectives-- timeline reconstruction, exploit analysis, and retrospective analysis. Timeline reconstruction focuses on creating a chronological sequence of the attacker's actions by identifying relevant hosts, network connections, and application events. You analyze network logs and traffic data to pinpoint when the intrusion started, the progression of the attack, and the sequence of events. This timeline is then correlated with system logs, file timestamps, and other data sources. Exploit analysis is where you determine what vulnerabilities were exploited and how the attack was carried out. This involves a deep analysis of traffic data to understand the protocols involved and the network manifestation of the exploit. You look for anomalies in the traffic that coincide with the timing of the attack. Retrospective analysis is where you discover additional actions taken by the attacker that might have been initially missed. You reconstruct past network events related to the intrusion by using traffic summaries or packet capture data. This includes by identifying new patterns or anomalies that were not detected by IDs systems. With each of these approaches, the focus is on dissecting network traffic to uncover the details of the attack. This includes identifying data transfers to suspicious IPs, recognizing connections to anonymizing networks, and observing any deviations from normal traffic patterns. Let's examine network analysis in more detail.

### Video - [Network traffic analysis at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522268)

* [YouTube: Network traffic analysis at Cymbal Federal](https://www.youtube.com/watch?v=nPJo_ANtcuc)

SPEAKER: Examining network traffic involves identifying unusual traffic spikes and unauthorized connections through the analysis of network flow patterns. This helps identify anomalous activity, such as sudden increases in data transfers or suspicious connections to external servers. You monitor the network traffic spikes and check the volume of data passing through the network. You search for a significant and unexpected increase in traffic that can be a sign of data exfiltration, distributed denial of service, or DDoS attacks, or other malicious activities. You check unauthorized connections by identifying connections to or from unknown/external IP addresses or to unusual ports. This can indicate a breach that includes inbound connections that could represent unauthorized access attempts, or outbound connections that might be data exfiltration or communication with a command and control server. You analyze the network flow by reviewing the overall network traffic patterns. These include the source, destination, volume, and type of traffic. Deviations from typical network flow patterns can be indicative of security incidents. For example, imagine you're using a network monitoring tool like Wireshark or SolarWinds Network Performance Monitor. You notice an unusually high amount of traffic being directed from a server within the Cymbal Federal network to an unknown external IP address. This spike is occurring during off-peak hours. This is unusual for Cymbal Federal's normal traffic pattern. You examine this further and find that this traffic is mainly comprised of large file transfers. This is atypical for the server in question. This raises suspicions of potential data exfiltration. Additionally, you notice several inbound connection attempts to this server on ports that are not typically used by Cymbal Federal. To confirm your suspicions, you cross-reference this data with Cymbal Federal's intrusion detection system, IDs logs and find alerts correlating to the time of the traffic spike. This indicates possible malware communication attempts. In this scenario, your examination of network traffic flows and communication patterns enabled you to note the unusual spike in data transfer, the nature of the traffic, and the unauthorized connections. This led you to uncover what appears to be a data breach. This insight enables you to take immediate action to investigate further, contain the threat, and prevent potential data loss. During network traffic analysis, you may also analyze network logs and captured packets. This will help you identify the communication protocols used by the malware and enable you to trace the attacker's movements across the network. You analyze network logs by scrutinizing logs from routers, switches, firewalls, and other network devices. These logs provide information about the traffic that has traversed the network, including source and destination IP addresses, port numbers, and timestamps. Also, you analyze packets captured using tools like Wireshark or tcpdump. This allows you to see the actual data being transmitted over the network. This information may reveal the contents of the communication, including any malware, command and control instructions, or data being exfiltrated. You identify communication protocols by analyzing the captured packets. This helps you determine which protocols the malware uses for communication-- for example, HTTP, HTTPS, or FTP. Some malware may use standard protocols to blend in with normal traffic, while others may use less common protocols or custom encryption to avoid detection. A brief list of what to examine includes the following-- wire speed network capture and/or examination; traffic summarization; pattern matching; protocol analysis at all layers of the protocol stack; behavioral analysis; statistical anomaly detection. During network traffic analysis, you may also analyze network logs and captured packets. This will help you identify the communication protocols used by the malware and enable you to trace the attacker's movements across the network. You analyze network logs by scrutinizing logs from routers, switches, firewalls, and other network devices. These logs provide information about the traffic that has traversed the network, including source and destination IP addresses, port numbers, and timestamps. Also, you analyze packets captured using tools like Wireshark or tcpdump. This allows you to see the actual data being transmitted over the network. This information may reveal the contents of the communication, including any malware, command and control instructions or data being exfiltrated. You identify communication protocols by analyzing the captured packets. This helps you determine which protocols the malware uses for communication-- for example, HTTP, HTTPS, or FTP. Some malware may use standard protocols to blend in with normal traffic, while others may use less common protocols or custom encryption to avoid detection. A brief list of what to examine includes the following-- wire speed network capture and/or examination; traffic summarization; pattern matching; protocol analysis at all layers of the protocol stack; behavioral analysis; statistical anomaly detection. Imagine you're analyzing an incident where a network intrusion is suspected at Cymbal Federal. You start by reviewing firewall logs and notice several outbound connections to an unfamiliar IP address on an unusual port, which isn't standard for web traffic. Using a packet sniffer, you capture the traffic going to this IP address. Upon examining the captured packets, you find that they contain encrypted data being sent over HTTPS. This is unusual for the applications typically running on your network. By analyzing the sequence and timing of these packets, along with correlating this information with the firewall logs, you identify a pattern that suggests these connections are part of a command and control channel set up by the intruder. The use of HTTPS on an unconventional port was a tactic to bypass standard network monitoring. Through this in-depth analysis of network logs and packet data, you're able to identify the communication method of the attacker, understand how they are moving data, and gain insights into their tactics. This information is vital for mitigating the current threat and fortifying the network against similar attacks in the future. You may also need to combine network insights with information gleaned from system and malware analysis. This is to provide a holistic view of the attack and to identify the most affected systems. You may combine your analysis with network insights. This means looking at data obtained from monitoring network traffic, analyzing packet captures, and reviewing logs from network devices. This type of analysis reveals the pathways used by the attackers, the nature of network-based attacks, and the flow of data in and out of the network. You may also integrate your analysis with information from system analysis. This approach provides insights into changes or anomalies within individual systems, such as unauthorized file modifications, suspicious processes, or unusual system behavior. This approach helps identify which systems have been compromised or affected by the attack. Finally, you may rely on the findings from your malware analysis. This includes the behavior of the malware, its communication methods, and its payloads. This approach offers a deep understanding of the tools and techniques used by the attackers. For example, imagine you're dealing with a sophisticated cyber attack on Cymbal Federal's network. From a network analysis, you've identified unusual traffic patterns and traced data exfiltration to specific external IPs. Meanwhile, system analysis on affected workstations has revealed the presence of a Trojan that's been downloading and executing additional malicious payloads. By combining these insights, you realize that the Trojan is not just stealing data, but also spreading laterally across the network. The network analysis helps you trace the spread of this Trojan from one system to another. The system analysis reveals the changes each system undergoes after being compromised. Malware analysis uncovers that this Trojan is part of a known family of malware that is commonly used in corporate espionage. This suggests that the attack is targeted and sophisticated. This information guides you to focus on securing critical intellectual property and to search for additional indicators of compromise associated with this malware family. Through this holistic approach, you combine network, system, and malware analysis in order to pinpoint the most affected defected systems, understand the attackers' tactics and objectives and develop a targeted response to mitigate the attack and prevent future occurrences. This comprehensive understanding and high-level view is crucial for effectively managing and resolving complex cybersecurity incidents. Finally, you may analyze network traffic for unusual data transfers and connections to anonymous networks. You hunt for exfiltration attempts to steal sensitive information. You check for unusual data transfers by spotting significant, unexpected movements of data within or out of your network. You look for large data transfers, especially to unfamiliar external locations. You search for connections to anonymous networks. This involves detecting traffic to or from privacy-focused services like Tor or VPNs, which can be used by attackers to anonymize their activities. Imagine that the Cymbal Federal network monitoring tool alerts you to a large file transfer from a confidential data server to an external IP address late at night, a time when network activity is typically low. Upon hunting for a data breach during the investigation, the destination IP is found to be registered in a country where your company has no business. This scenario strongly suggests a data breach and the unauthorized exfiltration of sensitive information. You then take these analyses and integrate the findings together. In this case, large data transfers at odd hours and traffic to anonymizing services. This helps you build a clearer picture of a potential security incident. You then combine these findings with system logs or alerts from intrusion detection systems. This can provide additional context, such as the possible method of initial compromise or the types of data being targeted. In this case, you hunted for exfiltration attempts by tracking data through network trails, system footprints, and malware fingerprints. You have provided a surgical response and future proofed your data against silent thieves.

### Video - [Key points about incident investigation](https://www.cloudskillsboost.google/course_templates/1195/video/522269)

* [YouTube: Key points about incident investigation](https://www.youtube.com/watch?v=BJObpKD8h70)

SPEAKER: Before you move on from the incident investigation, it's important to remember two important summarizing points. First, technical analysis is iterative and can be conducted many times throughout the incident-handling process. Secondly, sometimes you, as a tier 2 analyst, cannot identify the root cause of an incident, for example, when an intruder has deleted or tampered with logs and files, or when multiple unpatched vulnerabilities exist and make it challenging to determine the exact point of compromise. In these cases, you have a couple of options. You proceed with remediation. This involves taking actions to mitigate the potential damage and strengthen the system's security, even without pinpointing the exact cause. Here, you can implement general best practices for security, such as updating and patching all systems, changing passwords, and reviewing network access controls. You also implement monitoring to catch similar incidents in the future. Alternatively, you can choose to escalate to tier 3. This escalation involves passing the incident to a more specialized, higher-tier team for deeper analysis. For now, let's look at cases where an investigation has identified the root cause, and you want to proceed with containment and remediation.

### Video - [Remediation of an incident](https://www.cloudskillsboost.google/course_templates/1195/video/522270)

* [YouTube: Remediation of an incident](https://www.youtube.com/watch?v=NSNMxNfRXrE)

SPEAKER: Containment involves isolating the affected systems and resources to prevent the attack from spreading further. You can visualize containment as if you are building a firewall around the incident. Containment prevents an intruder from further accessing data or other information, destroying evidence, tampering with the system, or using the system to attack other systems. Containment involves four steps-- one, disconnecting infected machines from the network; two, blocking specific IP addresses or ports; three, disabling compromised user accounts; four, stopping malicious processes or services. Let's walk through each step in more detail. You start by isolating the infected devices and preventing them from communicating with other systems and spreading threat. Network isolation involves the use of network access controls to logically segment the network and restrict access to the affected hosts. Isolation strategies that you may use include the following. You disconnect the information system from any local area network. This helps you prevent further contamination of the affected information network and information system. You disconnect the information system from the internet or any other public networks. This is to prevent inbound access, outbound traffic, or data exfiltration. You isolate the affected network host and/or segment from the rest of the network. This helps you prevent further contamination and helps contain malicious activity in an information system or logical network segment. This also allows attached information systems to still function but not spread malicious activity to the rest of the infrastructure. Then you block specific IP addresses or ports to hinder malicious actors from accessing vulnerable systems and exploiting the network further. Blocking is the use of network access controls at the perimeter, or enclave boundary, to prevent the attacker from connecting to information networks, data, and services. Your decision to block is based on the incident category and the threat to the network. You Then disable compromised user accounts to prevent unauthorized users from accessing sensitive information or performing actions that could escalate the incident. Other containment strategies presented by NIST 800-61 reference CC include the following. You eliminate the attacker's route into the environment. This prevents the attacker from accessing nearby resources that might be targets. You block the transmission mechanisms for the malicious code between infected information systems. You disable user accounts that may have been used in the attack. Lastly, you stop malicious processes or services. This allows you to terminate any malicious activity running on the infected systems, thus halting the attack. You might need to shut down an information system, server, or service, as this helps you to limit damage and prevent further access to the information system by the adversary. However, these actions would also affect your ability to acquire valuable data for the incident analysis. The decision to pursue this containment strategy should be weighed carefully. In the next video, you'll explore an example of containment for Cymbal Federal.

### Video - [Containing a malware outbreak at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522271)

* [YouTube: Containing a malware outbreak at Cymbal Federal](https://www.youtube.com/watch?v=fXDK5xmGQoo)

SPEAKER: You are a Tier 2 analyst at Cymbal Federal and have determined that malicious code, potentially, a worm or Trojan, has compromised the corporate network. You observe lateral spread through elevated network traffic and resource utilization. You suspect data exfiltration based on anomalous outbound communication patterns. You determine whether immediate containment and eradication measures are required. You start by isolating the affected part of the network in order to prevent the spread of the threat to other areas, then you shut down the infected network. At Cymbal Federal, you identified that the infection is on a computer in the accounting department. You can either shut down the physical switch that serves the accounting department or access the switch configuration and shut down the ports that are assigned to the accounting VLAN. Then, you reroute the traffic, if needed. You disable network access for the compromised devices you identified. This is to prevent further spread or communication with the attacker. You update the firewall rules by implementing new rules to block traffic to and from known malicious IP addresses or domains associated with the incident. Then, you quarantine the infected systems. You move infected or suspicious systems to a quarantined network to prevent interaction with clean systems. Finally, you temporarily limit user access or privileges, especially in areas of the network where the incident is active. This is to reduce the risk of further spread or damage.

### Video - [Containing a malware outbreak at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522272)

* [YouTube: Containing a malware outbreak at Cymbal Federal](https://www.youtube.com/watch?v=AU77vJ3I-JE)

SPEAKER: In the previous video, you examined how to contain the compromise. Now you can look at remediating the vulnerability that led to the incident. With remediation, you focus on addressing the root cause of the incident and eliminating the vulnerabilities exploited by the attacker. Remediation also involves four steps-- one, removing malware from infected systems; two, patching software vulnerabilities; three, updating security policies and procedures; four, restoring compromised data. Let's walk through each step in more detail. You start by removing malware from infected systems. This involves using specialized tools and techniques to eliminate the malicious software from affected devices. For example, you use Palo Alto Next Generation Antivirus as a tool to remove the malware. You may also need to quarantine, delete, replace, or restore the integrity of infected files. In most cases, this will require rebuilding the system using trusted media. It may also involve updating antivirus signatures. Then you patch software vulnerabilities. This is a crucial step needed to close the security loopholes that were exploited during the attack and to prevent future breaches. If the system cannot be patched for technical or operational reasons, you mitigate the vulnerability by directly moving to the next step in the process, updating configurations, policies, and procedures to protect or segment the affected host. Updating security policies and procedures ensures that your security posture is strengthened and similar incidents are less likely to occur. You can modify access controls by removing compromised user or administrator accounts. You can also modify network access controls, for example, IDS, IPS, firewall, or content filtering, update baseline configurations, and remove any other access mechanisms used by the adversary. Finally, you restore the compromised data. If the data was encrypted or stolen during the attack, you apply data restoration procedures. These procedures will be explained in the next module. For now, that's it. You have completed the remediation process. In the next video, you'll walk through an example of remediation in action at Cymbal Federal.

### Video - [Remediation of a DDoS attack at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522273)

* [YouTube: Remediation of a DDoS attack at Cymbal Federal](https://www.youtube.com/watch?v=f6H0hm0uMwY)

SPEAKER: You are a tier 2 analyst and encounter a malicious attempt to access the Cymbal Federal website by overwhelming it with traffic. You believe this to be a DDoS attack. This type of attack leaves the server unable to handle legitimate requests. It also slows down the service, delaying access for users trying to access the website. If the attack is severe enough, the server can crash, completely shutting down the website for all users. You start by removing the malware by using antivirus and anti-malware tools, such as Palo Alto and Bitdefender. These tools thoroughly scan and remove any traces of the malware from infected systems. Then you apply all necessary security patches and updates to the operating systems and applications. This is to close the vulnerabilities that were exploited by the malware. After that, you change all user and administrator passwords. You restore affected data and systems from clean, verified backups. This ensures that backups have not been compromised. You implement additional security measures, such as improving endpoint protection, hardening network defenses, and enhancing intrusion detection systems. You conduct a thorough security audit to identify and rectify any remaining vulnerabilities or security gaps. Finally, you increase the surveillance of network activity to quickly identify any signs of reinfection or other malicious activities.

### Video - [Key points on containment and remediation](https://www.cloudskillsboost.google/course_templates/1195/video/522274)

* [YouTube: Key points on containment and remediation](https://www.youtube.com/watch?v=y0N-RrjMEO8)

SPEAKER: You've now completed the section on containment and remediation. Let's take a moment to highlight three points you should keep in mind about this phase of the incident respons. Analysis, containment, and remediation are iterative. You execute remediation steps after the first round of containment actions occur and then interact with any further analysis and containment activities. Sometimes, full remediation can only happen after long-term policy and configuration-management changes are put into place. In that case, the threat should be mitigated to the fullest extent possible before rebuilding and reconnecting any affected ISs. Some systems, due to the nature of the incident, may not need any containment and/or remediation steps, or they may occur as part of the recovery activities when the infected system is wiped or erased and rebuilt.

### Video - [The recovery process](https://www.cloudskillsboost.google/course_templates/1195/video/522275)

* [YouTube: The recovery process](https://www.youtube.com/watch?v=2ETRSGmx0Bc)

SPEAKER: After the initial shock and flurry of activity that occurs during response and containment, you now move towards recovery and report. This phase marks a significant turning point in incident response. You focus on rebuilding and emerging from the incident stronger and more resilient. This phase is akin to cleaning up the debris, assessing the damage, and laying the foundation for a stronger and more fire-resistant structure. During the recovery phase, you will be restoring normalcy and minimizing the lasting impact of the incident. This includes the following-- restoring the integrity of affected systems; returning the affected data, systems, and information networks to their operational state; ensuring the complete resolution and closure of the incident; implementing follow-up strategies to prevent the incident from happening again. During recovery, you will engage in numerous activities, including the following-- one, rebuilding or restoring affected systems; two, cleaning and verifying data integrity; three, communicating recovery progress; four, reviewing and updating user access and permissions. Let's walk through each activity in more detail. Recovery strategies vary depending on the incident type, affected component, and local policy and procedure. A common recovery strategy is to rebuild or restore affected systems, either by reinstalling operating systems, reconfiguring settings, or patching vulnerabilities. You will also need to clean and verify the integrity of the data by recovering lost or compromised data from backups and carefully reviewing systems for any remaining malicious code or corruption. You also need to communicate recovery progress with stakeholders and impacted users to minimize anxiety and ensure everyone is informed about the progress of the recovery and any potential delays. Finally, you need to review and update user access and permissions. This is crucial to prevent unauthorized access and to ensure only authorized users have access to sensitive information. As part of the recovery process, you will also need to remember that you may need to remove certain containment activities. This can include removing any blocks that are no longer necessary, re-enabling services, and reconnecting IS's and networks to the LAN or internet if they were disconnected.

### Video - [Recovery from a DDoS attack at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522276)

* [YouTube: Recovery from a DDoS attack at Cymbal Federal](https://www.youtube.com/watch?v=DUHPjbQZtbE)

SPEAKER: In a previous video, you encountered a DDoS attack on Cymbal Federal's website. Let's continue with that example. To engage in recovery, you start by restoring affected systems and data from clean and verified backups. You ensure that these backups have not been compromised by the malware. Then you gradually reconnect systems to the network once they are confirmed clean and secure. This should be done in a controlled manner to monitor for any signs of malware resurgence. Then you ensure all systems are updated with the latest patches and security updates. This is to mitigate vulnerabilities that the malware may have exploited. Then you strengthen security measures based on the lessons learned from the incident. This could include updating firewall rules, enhancing endpoint protection, and improving network monitoring capabilities. You conduct thorough testing to validate that all systems are functioning normally and that security measures are effective. You implement a rigorous, ongoing monitoring to identify any unusual activities that might suggest residual malware or new compromise attempts. Finally, you need to review and update the incident response plan to incorporate learnings and improve responses for future incidents. This is the reporting phase. You'll learn more about this phase in the next video.

### Video - [Report on an incident](https://www.cloudskillsboost.google/course_templates/1195/video/522277)

* [YouTube: Report on an incident](https://www.youtube.com/watch?v=3P5SwTSzGVw)

SPEAKER: In the reporting phase, you document the incident, you analyze the incident's impact and response effectiveness, and share key takeaways. During reporting, you write a detailed record of what happened and what you learned from the experience. Reports have two audiences, the internal SOC audience, who accesses report details and ServiceNow, and external audiences, which vary by incident type, who are notified from other operational channels. The SOC manager is typically in charge of communicating with external audiences, while you, as a security analyst, focus on technical reporting in ServiceNow. There are four key factors that you need to describe during reporting. One, provide a timeline of events and key decision points. Two, provide root cause analysis and the identified vulnerabilities. Three, describe the resources expended and lessons learned. Four, provide recommendations for future procedures and training. Let's briefly look at each one. Being accurate about the timeline helps identify any missteps or areas where future responses can be improved. Determining the root cause enables you to address these vulnerabilities and prevent similar attacks in the future. It's important to analyze the resources that were used and share insights gained. This provides valuable information for future incident response planning. Finally, you use the learnings from your analysis to offer recommendations to strengthen the incident response plan and provide training to improve response capabilities. Depending on the company, this training may be given by you, the Tier 2 analyst, or may be offered by other specialists or outsourced. Let's imagine you are creating your final report for Cymbal Federal. What format do you need to follow? Your report will need to be well-structured, as it is critical for effective knowledge sharing and future improvement. As such, you should include the following. An executive summary that is a concise overview of the incident, its impact, and key findings. The timeline in terms of chronological breakdown of events, actions taken, and decision points. The root cause analysis, which includes a detailed explanation of how the incident happened and vulnerabilities that were exploited. Your assessment of the response effectiveness. Describe how well the response team handled the situation, highlighting successes and areas for improvement. Key takeaways, lessons learned, and actionable recommendations. Supporting evidence, logs, and technical details in the appendices. Once you've completed your incident report, it is time to move on to the postmortem.

### Video - [Postmortem](https://www.cloudskillsboost.google/course_templates/1195/video/522278)

* [YouTube: Postmortem](https://www.youtube.com/watch?v=Mf4cvO5I3SE)

SPEAKER: A post-mortem is usually only held for large incidents or incidents that were handled poorly. The post-mortem is a crucial step for organizational learning. During the post-mortem, you analyze your strengths and weaknesses in order to improve the incident management process and the system security posture. During a post-mortem, you start by gathering feedback by collecting input from all participants involved in the incident response. You also analyze your communication and collaboration. You identify areas for improvement in how information is shared and decisions are made. This allows you to determine unclear or undefined roles, responsibilities, interfaces, and authority. Then you assess the effectiveness of the tools used and incident response plans in order to identify potential gaps. This allows you to identify the following, infrastructure problems, organizational policy and procedural problems, technical or operational training needs, improvements needed for tools required to perform protection, detection, analysis or response actions. Finally, based on the findings, you update the playbooks. You develop trainings to refine response procedures based on lessons learned and ensure everyone is updated with the latest best practices.

### Video - [Postmortem for a malware attack at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522279)

* [YouTube: Postmortem for a malware attack at Cymbal Federal](https://www.youtube.com/watch?v=r3ngDLMZpL8)

SPEAKER: Let's return to an earlier example in which there was a malware attack at Cymbal Federal. As a tier 2 analyst, you contained the situation, recovered the situation, and closed the incident. Now, it's time for the postmortem. This will likely be led by other specialists, but the tier 2 analyst will be involved, offering data, outcomes from analysis, and recommendations. During this phase, you start by gathering feedback through individual interviews. You conduct confidential conversations with key personnel involved in the response, from IT to management. You gather candid insights on strengths, weaknesses, and suggestions for improvement. You also hold a dedicated session with the incident response team. You collectively analyze their performance, identify areas of friction, and brainstorm potential workflow optimizations as a form of debriefing. You conduct employee surveys as anonymous questionnaires distributed to all impacted employees. This is to gauge their understanding of the situation, the effectiveness of communications, and their level of preparedness for future incidents. Then, after collecting the information, you pass it on to the next step, which is analyzing communications and collaborations. Now you analyze the effectiveness of communication and collaboration during the incident. You review the incident timeline and examine the sequence of communication events. You identify delays, bottlenecks, or discrepancies in information flow. Then you check the channel effectiveness by assessing the suitability of the communication channels that were used. You evaluate if internal tools, external platforms, or emergency protocols were used optimally. You analyze the collaborative decision-making process during the response and identify areas for improved transparency and shared ownership. Then you move towards evaluating the tools and procedures. For tools and procedures, you review the adequacy of the incident response platform. You identify any limitations or lack of features that hinder response efficiency. Then you assess the effectiveness of deployed security tools in detecting, containing, and mitigating the attack. You identify gaps in coverage or areas for configuration improvement. You verify the accuracy and completeness of existing playbooks and procedures in order to ensure they reflect current technologies and best practices. Then you define actionable next steps. The actions on the level of the SecOps have a direct effect on operations and should be reflected in playbooks. This is the point at which you need to review the playbooks and incorporate lessons learned from them. This includes updating response protocols, escalation procedures, and communication workflows. Then you conduct targeted training sessions for all impacted teams based on areas identified for improvement. For Cymbal Federal, this includes phishing awareness, data security practices, and incident response procedures. You launch company-wide initiatives to elevate cybersecurity awareness and engagement. You promote vigilance and proactive reporting of suspicious activity. But is there anything else you need to do with the findings from your postmortem? Based on the findings of the postmortem, Cymbal Federal might trigger a long list of actions that should be applied on the whole infrastructure. This list could include, but is not limited to the following-- increase host and network monitoring, enable maximum host logging, auditing, and accounting programs, disable unnecessary services. Verify there are no weaknesses in the configuration files for those services. Install all the latest vendor security patches and upgrades, if approved and tested. Update firewall rule sets. Update boundary router ACLs. Update IDS/IPS signatures. Review any guidance, advisories, or bulletins to see if there are other recovery actions or security enhancements that can be enabled or installed. Install new security mechanisms that may help protect ISs or detect malicious activity. This can include programs like file-integrity checkers, URL checkers, et cetera. Implement any needed filtering. Update any security policies to reflect or support these security improvements.

### Video - [Support processes for escalation and collaboration](https://www.cloudskillsboost.google/course_templates/1195/video/522280)

* [YouTube: Support processes for escalation and collaboration](https://www.youtube.com/watch?v=m0rDXON-08c)

SPEAKER: As a reminder, support processes are used to ensure information sharing and joint action by IT, security, and legal teams. As a tier 2 analyst, you will engage with support processes during escalation and when you communicate and collaborate with other team members. Support processes leverage predefined communication channels and roles that help minimize friction and ensure a swift and decisive response. Let's start with a quick review of the escalation. Incident escalation is when you involve higher levels of expertise or authority to address more complex or severe incidents. Escalation ensures the timely resolution of complex and critical incidents as you delegate tasks and expertise effectively. As a tier 2 analyst, you play a crucial role in the SOC hierarchy. But sometimes your expertise needs a boost. Let's take a moment to examine how the escalation process unfolds, including involving tier 3 and alternative pathways. Let's imagine that you are a tier 2 analyst at Cymbal Federal. You've exhausted your tier 2 troubleshooting arsenal, and the incident remains unresolved. Now what? There are two escalation paths that you may consider. You can escalate the incident to a tier 3 analyst. These highly specialized experts possess deep knowledge of specific domains or technologies, such as malware analysis or cloud security. Tier 3 analysts are not present in all SOCs, so this may not always be an option. Or you may choose to escalate the incident to another tier 2 analyst for a second look. This analyst may offer a different expertise or perspective. This collaborative approach can yield fresh insights and unlock new solutions. Note-- platform issues may need to be escalated to the Google Platform Engineering team itself. You can rely on the SOC manager to help you with such out-of-the-box scenarios. Now let's discuss support processes in the context of incident escalation. The escalation process itself involves documentation. Before escalating, you need to ensure that your investigation and findings are clearly documented. This saves time and provides critical context for the recipient. You also need to communicate through the appropriate escalation channel, email, internal ticketing system, or direct chat with the designated team. You clearly state the reason for the escalation and provide a concise summary of the incident. Once escalated, you need to actively collaborate with the recipient, provide additional information as needed, and participate in problem-solving discussions.

### Video - [Common questions on support processes](https://www.cloudskillsboost.google/course_templates/1195/video/522281)

* [YouTube: Common questions on support processes](https://www.youtube.com/watch?v=Md-a2GWWbII)

SPEAKER: In this video, you'll discuss some common questions related to support processes used during escalation. First, do tier 2 analysts ever work together on tickets? Absolutely. In complex cases, you need to benefit from multiple perspectives and skills. And you collaborate using shared documents, chat channels, and calls to brainstorm. Collaboration between tier 2 analysts is needed in order to troubleshoot and assign tasks effectively. Now, how do tier 2 analysts work with tier 1 analysts? As a tier 2 analyst, you work closely with tier 1 analysts. This may involve asking clarifying questions during ticket reviews, providing guidance on handling issues, and even joining calls for joint investigations and log analysis. What about ServiceNow tickets? How often do you update ServiceNow tickets? You need to strive for transparency throughout the resolution process. This means you are expected to update ServiceNow tickets at any time with key findings, decisions, and progress notes, not just at the end of each phase. Keeping the ServiceNow ticket up to date keeps everyone informed and facilitates smooth handovers. So when do you escalate incidents to the SOC manager? There is a clear escalation process that you are expected to follow. Immediately contact the SOC manager for high-impact incidents, roadblocks beyond your scope, or critical decisions requiring their input. This is done through a dedicated channel for timely awareness. How does the SOC manager receive updates? Through ServiceNow and ad hoc communication. You need to prioritize keeping the SOC manager informed and provide concise summaries of progress, outstanding tasks, and potential risks before your shift ends. Finally, how do you hand over to other tier 2 analysts during shift changes? In order to assure a seamless handover with other tier 2 analysts, you need to leave detailed notes in ServiceNow. You also need to brief incoming analysts on critical issues and open tickets. You're also expected to answer any questions to ensure the smooth continuation of tasks and collaborations.

### Video - [Module review.mp4](https://www.cloudskillsboost.google/course_templates/1195/video/522282)

* [YouTube: Module review.mp4](https://www.youtube.com/watch?v=nrycKdzx0lc)

SPEAKER: Let's quickly recap what you've learned. In this module, you explored incident response for Tier 2 analysts, including how to handle incident tickets escalated from Tier 1. This involves understanding the preliminary analysis done by Tier 1, reassessing the severity and priority of the incident, and determining next steps for a more in-depth investigation. This module also covered strategies for deeper analysis, advanced techniques for containing and remediating incidents, and how to oversee the recovery process by compiling a comprehensive report, and possibly, a post-mortem. This module concluded with a discussion on when and how to escalate in order to ensure a swift and thorough resolution of the incident. Now that you have a solid understanding of these topics, you're ready to advance to the next module.

### Quiz - [Knowledge check](https://www.cloudskillsboost.google/course_templates/1195/quizzes/522283)

## Runbooks in action: Predefined incident response processes for Tier 1 and Tier 2 analysts

In this module, you will learn about runbook processes that handle common incident response processes on Google Distributed Cloud (GDC) air-gapped. Then, you will learn how runbooks assist in incident response by Tier 1 and Tier 2 analysts. Next, you will explore the high-level, end-to-end incident management processes that are provided by a runbook. Finally, you will learn about the most common incidents covered in the GDC runbooks. You will see this in practice by exploring a runbook example at Cymbal Federal.

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/1195/video/522284)

* [YouTube: Module overview](https://www.youtube.com/watch?v=ol82nNWKlQM)

SPEAKER: Welcome to Runbooks in Action, Predefined Incident Response Processes for Tier 1 and Tier 2 analysts. In this module, you will learn about runbook processes that handle common incident response processes on Google Distributed Cloud, GDC, air-gapped. First, you will discover three different types of documents that help you in incident management-- runbooks, playbooks, and incident response plans. However, the focus of this module will primarily be on understanding and using runbooks effectively. Then you will learn how runbooks assist in incident response by tier 1 and tier 2 analysts. Next, you will explore the high-level end-to-end incident management processes that are provided by a runbook. Finally, you will learn about the most common incidents covered in the GDC runbooks. You will see this in practice by exploring a runbook example at Symbol Federal.

### Video - [Introduction to coded guidelines](https://www.cloudskillsboost.google/course_templates/1195/video/522285)

* [YouTube: Introduction to coded guidelines](https://www.youtube.com/watch?v=7H-8MznfdBE)

SPEAKER: Let's get started with a quick review of an incident. An incident isn't just a bump in the road. An incident is a potential digital wildfire, urging you to take immediate action to contain and extinguish it. An incident is a cyber alarm blaring, jolting you from calm operations to a race against the clock in order to protect data and systems. With an incident, every second counts. You require a precise response and clear thinking while under pressure. All of these requirements have led to the development of predefined guidelines. These are known as incident response plans, playbooks, and runbooks. Incident response plans, playbooks, and runbooks facilitate your job by ensuring you follow a coordinated and effective response. You will learn more about each of these guidelines shortly. For now, it's important to note that each of these coded guidelines is essential for effective incident response. Let's take a moment to explore the benefits of having coded guidelines. Let's imagine you are faced with an incident. Coded guidelines streamline your workflow by ensuring there is a standardized and consistent response. This means you don't ever need to think about whom to contact. A runbook dictates a clear escalation path based on incident severity. This minimizes response time and reduces the risk of human error. Coded guidelines also offer clear steps and decision points. This removes the need for on-the-spot analysis. It ensures you are able to act quickly and decisively. Coded guidelines also help you improve your efficiency and effectiveness by streamlining incident handling. For example, the guidelines offer clearly defined priorities that help you focus on the most critical tasks first. This enables you to maximize the impact of your response efforts. Coded guidelines also foster enhanced communication and collaboration. This facilitates better communication between the various teams involved in incident response. For example, the guidelines outline consistent reporting templates. This ensures clear and concise communication with stakeholders and external entities. Finally, coded guidelines ensure a clear flow of information, both internally and externally. Robust documentation and streamlined reporting enhance traceability, accountability, and compliance, and facilitate informed decision-making. For example, predefined reporting mechanisms facilitate timely and accurate updates for both internal and external audiences. This improves your overall cybersecurity effectiveness. In the following video, you'll be introduced to the different types of coded guidelines.

### Video - [Incident response plans, playbooks, and runbooks](https://www.cloudskillsboost.google/course_templates/1195/video/522286)

* [YouTube: Incident response plans, playbooks, and runbooks](https://www.youtube.com/watch?v=hP8_40Zc1fs)

SPEAKER: The SOC uses incident management plans, playbooks, and runbooks. Incident Response Plans, also known as IRPs, offer a big picture framework for handling any security incident, regardless of complexity. IRPs provide definitions about the scope of incidents, roles and responsibilities of team members, communication protocols, escalation procedures, recovery strategies, and post-incident analysis methods. Playbooks are tactical guides that provide detailed, step-by-step instructions and workflows for responding to specific types of security incidents. This ensures consistent and efficient incident handling across the organization. Playbooks provide clear, actionable procedures for resolving individual incident scenarios. Playbooks also offer decision trees or flowcharts to guide your actions. Playbooks list readily available resources, tools, and contact information for each scenario. Runbooks are detailed instructional guides that offer step-by-step guidance for completing specific tasks within a process or resolving particular issues. Runbooks provide clear and concise instructions for individual actions. They use decision trees or flowcharts to help you navigate different scenarios. Runbooks also list required tools, resources, and references and define success criteria and potential troubleshooting. Now that you have a general understanding of IRPs, playbooks, and runbooks, let's take a deeper dive to understand how they differ from one another. Let's build a comparative table to develop a fuller understanding of the focus, scope, and level of detail found in each guideline. To do this, let's visualize the three guidelines as a performance. First comes the Incident Response Plan, IRP. Think of it as the conductor, setting the stage for the entire performance. The IRP lays out the broad strokes for incident response. What types of incidents are covered? Who fills each role? How does information flow? How do you recover and learn from each incident? The IRP is the overarching framework and the constitution of your response system. Next come the playbooks. Think of this as the art directors. Playbooks act as the directors for specific acts within the overall performance. Playbooks focus on broader process areas, outlining strategies and roadmaps for tackling major incident types, like phishing attacks or data breaches. When you think of playbooks, imagine them as laws and regulations within the IRP, guiding your response to different scenarios. Finally come the runbooks. Think of this as the stage crew. Runbooks are the dedicated stage crew. They provide granular, step-by-step instructions for individual tasks within a performance or specific incident scenarios. Runbooks detail precisely what to do for each action, such as isolating affected systems or collecting evidence. Runbooks are the operational manuals that keep the show running smoothly. As you can see, IRPs, playbooks, and runbooks are all essential instruments in your incident response orchestra. When you understand their distinct roles and hierarchical relationships, you can compose a harmonious and effective response to any security incident. Each element plays a unique part in ensuring your team can navigate the security maze with precision and efficiency. Let's discuss a few additional considerations. Playbooks and runbooks are often used interchangeably, with the preferred term depending on context and organizational preference. Playbooks chart high level strategies, while runbooks offer step-by-step guides for specific tasks. Both work together, like a map and guidebook, to help you conquer complex challenges, especially in incident response. While the core functions of IRPs, playbooks, and runbooks remain the same in SecOps, their content and focus may need to be adapted to encompass the broader scope, integrated operations, automated workflows, and compliance considerations of your specific environment or security approach. As a security analyst, you will use playbooks and runbooks. Moving forward in this module, this guidance document will be referred to as a runbook.

### Video - [Determining ownership assignment](https://www.cloudskillsboost.google/course_templates/1195/video/522287)

* [YouTube: Determining ownership assignment](https://www.youtube.com/watch?v=uOB-6tN0Pk8)

SPEAKER: In earlier modules, you learned about the importance of clear ownership. When responsibility is clearly assigned, it ensures a rapid and coordinated response. Each incident is promptly identified and passed down the appropriate expertise chain. Runbook processes assign ownership of different steps and actions to different tiers of security analysts based on their expertise and experience. This allows you to ensure efficient resolution of incidents while optimizing resource allocation. It also ensures appropriate escalation when necessary. Let's look at an example to illustrate the breakdown of ownership responsibilities for different users. Let's consider who owns a ticket, tier 1, tier 2, or tier 3 analysts. Runbooks provide clear guidelines for a tiered approach that ensures that GDC SecOps can effectively handle any incident, big or small. Each level plays a crucial role with defined tasks. All levels work together like a well-oiled machine to safeguard the organization's security posture. Tier 1 analysts act as the frontline guardians of an organization's cyber security. Tier 1 analysts primarily focus on initial incident identification, triage, and basic troubleshooting. Tier 1 analysts follow runbook protocols for the following-- monitoring security tools and alerts, conducting preliminary investigations to gather crucial information, implementing basic containment measures, such as account lockouts or system isolation, escalating complex incidents to tier 2 analysts for deeper analysis. As a tier 2 analyst, you act as the incident response detective. You use runbook guidelines for advanced troubleshooting and initial remediation. This is where you delve deeper into incidents by meticulously analyzing logs, network traffic, and endpoint data to dissect the root cause and assess the overall impact. From your detailed analysis, you implement refined containment and mitigation strategies, restore affected systems, and initiate remediation procedures. You seamlessly escalate critical incidents to those requiring additional specialized expertise to tier 3. Tier 3 analysts represent the elite response unit. You adhere to runbook protocols in order to handle complex investigations, customize remediations, and engage in advanced threat hunting. You participate in in-depth forensic analysis to pinpoint the full scope of a compromise and craft intricate remediation plans. You hunt for advanced threats and zero day vulnerabilities to ensure no malicious actors remain undetected. You also mentor and collaborate with tier 1 and tier 2 analysts. You actively liaise with other teams like threat intelligence and engineering in order to achieve a holistic incident resolution. The ownership of a ticket within SecOps is influenced by several factors, with the complexity of the incident being paramount. More complex incidents necessitate advanced skills and are thus assigned to higher tiers. Ticket assignment is guided by runbook directives that outline escalation procedures based on the incident's intricacy. This ensures tickets are managed with the appropriate level of expertise for effective resolution. The urgency of the response is another critical factor in determining ticket ownership. Time-sensitive incidents may necessitate immediate attention from higher tiers. Runbook protocols specify rapid escalation paths to ensure that urgent issues are promptly addressed by the most qualified analysts in order to efficiently mitigate potential damage. Required expertise also dictates ticket ownership. Incidents involving specific technologies or vulnerabilities are directed to analysts with specific knowledge. This is also outlined in runbook protocols and ensures that such tickets are escalated and handled by personnel who are adept in the relevant domain. This guarantees an effective and technically sound resolution. Finally, the availability of resources plays a crucial role in ticket ownership. Resource allocation is optimized by assigning tasks to the most suitable tier based on the current workload and expertise. Runbook guidelines ensure that incidents are managed efficiently and by appropriately skilled analysts, balancing the demands of incident resolution with operational capacity. In the following video, you'll learn about using an impact assessment to judge impact severity.

### Video - [Determining impact severity](https://www.cloudskillsboost.google/course_templates/1195/video/522288)

* [YouTube: Determining impact severity](https://www.youtube.com/watch?v=IQNU2-tnBA8)

SPEAKER: The level of severity of an incident is determined by an impact assessment. Impact-assessment severity is a critical component of runbook processes. It allows analysts to quickly determine the potential consequences of a security incident and tailor their response accordingly. The impact assessment serves as a crucial factor and helps you prioritize incidents, allocating resources, and escalating to appropriate tiers. Here is an example of an impact-assessment severity. An incident is classified as critical if there has been significant disruption to business operations, serious data loss, or reputational damage. In such cases, escalation is not just an option. It's a necessity. Escalate the incident to tier 3 analysts who can activate emergency-response plans and undertake a full investigation and remediation. When an incident is of high severity, like a malware infection in key systems or unauthorized data access, it suggests a significant, but not catastrophic, impact. Your response should be urgent, usually involving tier 2 or tier 3 analysts. The focus should be on containment, mitigation, and thorough investigation. Incidents with a moderate severity level, such as an unsuccessful phishing attempt or a vulnerability in a non-critical system, cause minor disruptions. Here, you would typically involve tier 1 or tier 2 analysts for investigation and resolution. Your response might include implementing containment measures and updating security protocols. Escalation in these incidents is based on the situation and not always required. Finally, low-impact incidents barely disrupt operations and don't involve data loss or significant reputational damage. Examples include false alarms or minor software issues. In these cases, you would handle verification and resolution, usually at the tier 1 level. You would also document the incident for a future reference. Escalation in such circumstances only happens rarely. Runbooks help you make decisions regarding incident-severity level, which equips you with predefined-response strategies. This enables a precise understanding of the necessary actions and the identification of responsible parties. This, in turn, ensures efficient incident management tailored to the specific threat and its potential impact.

### Video - [Runbooks in SecOps](https://www.cloudskillsboost.google/course_templates/1195/video/522289)

* [YouTube: Runbooks in SecOps](https://www.youtube.com/watch?v=9n0qUIQT-fc)

SPEAKER: Let's quickly review the purpose of runbooks. Runbooks are an essential tool that serve as a detailed guide for handling cybersecurity incidents. Runbooks provide you with structured and clear guidelines on how to respond to various types of security threats and scenarios. These include procedure documentation, incident types and responses, role and responsibility clarification, checklists and flowcharts, integrations with tools and systems, communication protocols, post-incident actions, regular updates, et cetera. A runbook in SecOps is a critical resource that helps you standardize your response to security incidents. Runbooks are dynamic documents that adapt to the changing security landscape and provide teams with up-to-date and actionable guidance. Runbooks offer security analysts many advantages. Let's explore each one. Runbooks offer security analysts step-by-step tactics to address attack vectors at different granularity levels. For example, against a web application attack, a runbook might advise a tier-1 to do the following. One, analyze web server logs for unusual traffic patterns. Two, if suspicious activity is confirmed, activate preconfigured web application firewall rules to block the attacker's IP. Three, escalate to tier-2. For tier-2, the runbook might outline the following. One, deep dive into application logs and code bases to identify the exploited vulnerability. Two, work with development to deploy a targeted patch, while tier-3 performs forensic analysis to determine the attacker's scope and intent. Runbooks also ensure seamless collaboration across tiers. By following the outlined processes, the SOC can guarantee a consistent, effective, and timely response. For example, as a tier-1 analyst, you use the runbook to quickly identify the appropriate escalation path based on incident severity and attack type. As a tier-2 analyst, you use the incident response plan as a shared reference for investigation methodologies and threat intelligence sources. And as a tier-3 analyst, you leverage the runbook for advanced containment procedures and incident response coordination with external parties, such as law enforcement. Runbooks also define clear frames for each action. This helps to eliminate confusion and delays. For example, as a tier-3 analyst, the runbook establishes that you are expected to escalate a critical incident within 2 minutes. This triggers an automated notification chain and activates predefined incident response workflows. As a tier-2 analyst, the runbook establishes timelines for investigation, containment, and recovery. Finally, runbooks act as damage control blueprints, helping to minimize downtime. For example, for a DDoS attack, the runbook for a tier-2 analyst might include the following-- activate preconfigured traffic filtering rules to mitigate the attack load, work with network engineers to reroute traffic through alternate paths, ensure service continuity for critical applications. Runbooks empower security analysts in many ways. You are able to take fast and accurate action. You don't need to fumble to make a decision during critical situations, as the runbook offers clear, step-by-step instructions to guide a quick and effective response. You can confidently tackle complex workflows. You always know exactly what to do step by step due to the predefined procedures found in the runbook. Furthermore, the runbook breaks everything down into bit-sized, actionable tasks. You can easily adapt to the ever-changing threat landscape. New threats pop up all the time, but you won't be caught off guard. Your runbook can be easily updated and scaled to handle whatever comes your way. So what is included in a runbook? Let's explore some basic characteristics. A runbook offers clear and actionable instructions for each step of the incident response process. For example, immediately isolate the suspected user account to prevent further access. The runbook targets specific types of attacks or incidents and offers detailed information and instructions. For example, review email headers for spoofing indicators and collect attachment samples using a secure transfer protocol. The runbook tailors responsibilities and actions to the expertise of different analyst levels. For example, within 5 minutes, notify the tier-2 analyst with the identified user, email details, and attachment sample. The runbook prioritizes actions based on their potential impact on business operations and data confidentiality. For example, analyze email headers and attachments for malicious URLs, domains, or file attributes related to known phishing campaigns. The runbook follows a data-driven methodology. Runbooks help you identify relevant data sources and analysis methods to assist your investigation. For example, use threat intelligence feeds and sandbox environments to verify attachment behavior and assess potential malware payloads. The runbook is containment-focused. It helps you prioritize actions to quickly isolate and contain the threat to minimize damage. For example, if malicious intent is confirmed, trigger a pre-configured quarantine script to isolate the user's endpoint and block communication with the phishing server. The runbook is remediation-oriented. It provides clear instructions for removing the threat and restoring affected systems to a secure state. For example, do a deep dive into compromised endpoint logs and network traffic to identify any data exfiltration attempts. The runbook is recovery-focused. It outlines steps to restore normal operations and minimize the impact on business functions. For example, work with IT to deploy targeted malware removal tools and ensure complete eradication of the threat. The runbook is learning-oriented. It encourages you to perform post-incident analysis and documentation of lessons learned to improve future responses. For example, coordinate system restoration procedures, including password resets for affected users and patching any exploited vulnerabilities.

### Video - [Runbooks for Tier 2 incident response](https://www.cloudskillsboost.google/course_templates/1195/video/522290)

* [YouTube: Runbooks for Tier 2 incident response](https://www.youtube.com/watch?v=LEWj5qn4ACk)

SPEAKER: As discussed in the previous video, runbooks assist tier-2 analysts during incident investigation by providing a systematic approach to analyzing and understanding the intricacies of a cyber incident. This informs subsequent actions in order to enable an effective resolution. Let's take a look at how tier-2 analysts can use runbooks during their incident response workflow. Imagine you are a tier-2 analyst at Symbol Federal. How could you use a runbook to assess an incident? You start with the initial assessment. In this step, you analyze security alerts and logs to gather basic information. You classify the incident based on its nature and severity. The runbook helps you by providing a checklist of initial indicators to look for. It also standardizes the classification process to ensure consistency and speed in the initial response phase. The next step is data collection. You focus on relevant data sources and use forensic tools. This is done while maintaining the chain of custody to ensure data integrity. The runbook assists by outlining the approved forensic tools and procedures for data collection. This ensures you follow best practices for evidence admissibility. Then you start root cause analysis. This involves identifying the attack vector, analyzing the attack timeline, and identifying the systems and data that were affected by the incident. The runbook offers guidelines on how to systematically approach the analysis, and suggests specific logs and artifacts to review for a thorough investigation. Then you move on to containment and mitigation. This includes isolating compromised systems, disabling affected accounts, and patching identified vulnerabilities to prevent further damage. The runbook guides you by providing step-by-step instructions for containment actions and mitigation strategies to quickly reduce the impact of the incident. To preserve evidence, you document all your findings, including the steps you took during analysis. This is in order to preserve the integrity of the collected evidence for a future reference or legal purposes. The runbook helps by offering templates and protocols for documentation. This ensures all evidence is accurately recorded and securely stored. Next, you report and communicate. Critical incidents need to be escalated to relevant stakeholders. You provide regular updates and collaborate with external entities as part of your comprehensive response. The runbook facilitates this by specifying communication plans and providing reporting formats to ensure clear, timely, and effective information sharing with all involved parties. Finally, you engage in a post-incident analysis and learning session. This is a required step for critical incidents. You evaluate the effectiveness of your response and possibly revise security policies and procedures based on sharing findings and lessons learned. This helps improve future incident response. The runbook aids by providing a framework for conducting post-incident reviews. This helps you identify what worked well and what can be improved. The guidelines from the runbook help ensure that lessons are systematically captured and integrated into future policies and training. In each step, the runbook is a critical tool, ensuring that you, as an analyst, have the guidance necessary to navigate the complexities of incident assessment and response effectively. Before you conclude this video, it's important to note why runbooks were created in the first place. Why is an effective response strategy essential? As a security analyst, you need to be adept at rapidly identifying and resolving security incidents. A runbook helps you contain the spread of threats within your organization. A runbook also provides you with mitigation strategies in order to minimize the impact of incidents on business operations and data confidentiality. This helps you maintain business continuity. Runbooks establish guidelines for evidence gathering. This knowledge is vital for legal compliance and organizational accountability. Runbooks also enable you to continuously improve your incident response capabilities and overall security posture. This continuous learning and adaptation help you be better prepared for future threats.

### Video - [Runbooks for containment, remediation, and recovery](https://www.cloudskillsboost.google/course_templates/1195/video/522291)

* [YouTube: Runbooks for containment, remediation, and recovery](https://www.youtube.com/watch?v=q9l5uISDJg8)

SPEAKER: Security analysts use containment, remediation, and recovery actions to effectively handle cyber incidents. This approach is from a document known as the orchestrated response plan. This document aims to mitigate immediate threats, resolve issues at their root, and restore your systems to normal functionality. The orchestrated response plan's effectiveness is significantly enhanced by runbooks, which provide you, the security analyst, with detailed, step-by-step instructions to execute containment, remediation, and recovery actions efficiently. This streamlines the process of mitigating threats, resolving issues at their core, and ensuring a swift return to normal operations. Runbooks establish clear actions you need to follow if you need to contain an incident. Let's explore an example of containment actions for tier 1 and tier 2 analysts as outlined in a runbook. Halt any further unauthorized access or data leakage. Disconnect any systems that have been compromised from your network. Stop further unauthorized activities. Disable accounts by immediately revoking access to any accounts that have been compromised. Stop malicious processes. Actively seek out, and terminate any processes that appear suspicious or malicious as identified during your investigation. Quarantine infected files. Isolate any files that have been infected to prevent them from executing and spreading within your system. Block malicious IPs through your firewall. Use intrusion detection/prevention systems to block known malicious IP addresses. As you can see, these proactive steps are essential to swiftly controlling and mitigating the effects of a cyber incident. Runbooks also outline remediation actions. These steps are vital in effectively recovering from a cyber incident and bolstering your system's security. Let's explore another example regarding malware. Remove the malware using an antivirus or anti-malware software. Eradicate any malicious code from your systems. Check patch vulnerabilities. Apply necessary security patches and updates to fix vulnerabilities. Clean affected systems to ensure the threat is completely removed. Reset passwords for the impacted accounts. Update the security configurations. After remediation, the runbook guides you through the steps for a system recovery. Each of these steps is crucial to efficiently recovering from a cyber incident and strengthening your future response strategies. Ensure the data is returned to a clean state. Reimage compromised systems. Install the operating system and applications on the affected systems for a completely clean environment. Test the restored systems before reconnecting them to your network. Thoroughly check the functionality and security of the restored systems. Resume normal operations. Continue to monitor for any unusual activities. Analyze your response and identify improvements for your incident response plan. It is crucial that an orchestrated response plan adopt a structured approach. This is in order to ensure containment, remediation, and recovery actions, and to effectively mitigate, resolve, and restore systems in the aftermath of a cyber incident. The orchestrated response plan should include the following. Clearly defined procedures-- all analysts should have access to detailed instructions and best practices for consistency and efficiency. Automated tools and scripts-- analysts should be able to leverage automation to accelerate tasks and reduce the chances of human error. Regular testing and training-- analysts should participate in drills and simulations regularly in order to ensure they are well prepared for an effective response. Communication and coordination-- analysts should be able to maintain clear and effective communication with all parties involved in the response process. Adhering to these steps will enhance the effectiveness and reliability of your response.

### Video - [Runbooks for post-incident actions](https://www.cloudskillsboost.google/course_templates/1195/video/522292)

* [YouTube: Runbooks for post-incident actions](https://www.youtube.com/watch?v=1PHL54f_GRM)

SPEAKER: How do runbooks apply to post-incident activities? As you may remember, post-incident actions in cybersecurity refer to the set of activities carried out after a cyber incident is resolved. These activities focus on detailed analysis and documentation. These actions aim to draw key lessons from the incident in order to improve and strengthen security measures. Post-incident activities aim to enhance the organization's resilience against future cyber threats. So what do runbooks recommend for post-incident actions? To manage post-incident activities, you should conduct a comprehensive review of the root cause of the incident, document the lessons learned, and share these findings organization-wide to prevent future occurrences. Assess and revise existing security policies and procedures, create new ones as needed, and implement security awareness training for staff. Focus on promptly patching vulnerabilities that were exploited, conducting regular vulnerability scans and establishing robust vulnerability management processes. Test the efficacy of updated security controls, engage in incident response simulations, and refine your runbook processes based on these tests. Keep stakeholders informed about the incident, prepare detailed incident reports, and share relevant information with the broader security community for collective learning and resilience.

### Video - [Common runbooks for GDC](https://www.cloudskillsboost.google/course_templates/1195/video/522293)

* [YouTube: Common runbooks for GDC](https://www.youtube.com/watch?v=TYw4HcjqoUo)

SPEAKER: Runbook processes are designed to address various types of security incidents and events. Once you identify the type of attack you are facing, the runbook tailors your response to ensure swift and effective resolution. Here are some common types of attacks addressed by runbook processes. Phishing attacks-- this is when you receive fake emails, texts, or websites that lure you into giving up your information. Malware-- this is when malicious software infects your system to steal data, disrupt operations, or demand a ransom. DoS and DDoS-- these are attacks that flood your network with traffic to make it unavailable. Web application attacks-- this is when attackers exploit vulnerabilities in web applications to steal your data or inject malicious code into your system. Password, also known as brute force attacks, happen when attackers try to guess your passwords to steal your accounts. Physical attacks happen when attackers gain physical access to steal equipment, plant malware, or disrupt operations. Zero-day attacks occur when attackers exploit unknown vulnerabilities before you can patch them. As a security analyst, you can rely on runbooks to provide guidance on how to respond to each specific type of attack. In addition, runbook processes may also address general categories of incidents. These include security policy violations, system outages, data breaches, and privacy incidents. Here are the incident categories that are used at GDC. Note that this is not an exhaustive list. However, these are the only categories for which Google has developed runbooks.

### Video - [Runbooks at Cymbal Federal](https://www.cloudskillsboost.google/course_templates/1195/video/522294)

* [YouTube: Runbooks at Cymbal Federal](https://www.youtube.com/watch?v=oF-MQYYlTOQ)

SPEAKER: To see the runbook in action, let's explore an example. Imagine you are a tier-1 analyst at Cymbal Federal. You discover a ransomware process on GDC. What do you do? You turn to your runbook, which instructs you to begin an initial data-gathering process. During this process, you gather relevant data about the alert. One, alerts from security tools. Initial alerts or notifications from endpoint protection, intrusion detection systems, or security information and event management-- SIEM-- systems that indicate suspicious activity or known ransomware behavior. Two, system logs. Basic system logs show unusual activity, such as repeated access failures, unexpected software executions, or changes in file permissions. Three, user reports. Reports from users experiencing issues, such as inability to access files, ransom notes appearing on their screens, or significant system performance degradation. Four, ransom notes. Identification and collection of any ransom notes left by the attacker. These often contain details about the ransomware variant, payment instructions, and contact information for the attackers. Five, encrypted files. Identification of encrypted files, including any changes to file extensions, which can sometimes indicate the ransomware variant. Six, network traffic anomalies. Basic analysis of network traffic to identify any sudden spikes in activity, especially communication with known malicious IP addresses or command-and-control servers. Seven, affected systems and users. A preliminary list of affected systems and users. These are gathered from user reports, system alerts, and initial scans. Eight, date and time of infection. Estimating the date and time of the initial infection based on the earliest signs of suspicious activity or reports from users. Nine, entry points. Initial identification of potential entry points, such as phishing emails, malicious downloads, or exploited vulnerabilities based on user reports and security tool alerts. This information will later be used to create a ticket. Next, you engage in triage. As you've seen, the purpose of the triage phase is to validate the alert, identify the category and scope of the infection, and cross-reference against previous tickets or intelligence sources. You also complete any emergency containment procedures, such as removing network cable or removing user access. A key part of this step is to define the response priority and strategy. Then you move on to the investigation phase, where you collect all relevant data and perform a root cause analysis. The key to this step is defining the scope and all information that will be acted upon during containment. The runbook can, again, provide guidance, such as identification of infected systems, pinpointing which systems are infected by the ransomware to prevent further spread. This includes workstations, servers, and network devices. Network segmentation-- isolating affected systems from the network to stop the ransomware from spreading to clean systems. This may involve disabling network ports, segmenting networks, or isolating segments of the network. User account controls-- identifying and disabling compromised user accounts that the ransomware may be using to propagate or access network resources. Data backups-- assessing the availability and integrity of backups for affected systems. This involves identifying unaffected backups that can be used for recovery and ensuring they are not connected to the network to prevent them from being encrypted. Traffic analysis-- monitoring network traffic for signs of ransomware communication with command-and-control servers. This could help in further isolating affected systems. Encryption activity monitoring-- identifying and halting active encryption processes where possible, using security tools capable of detecting ransomware behavior. Critical assets protection-- prioritizing the protection of critical assets that have not yet been affected by the ransomware. This may include moving critical data to secure storage or applying additional security measures to protect these assets. Communication channels-- establishing secure and effective communication channels for the incident response team to coordinate containment efforts without relying on potentially compromised network systems. External notifications-- determining if and when to notify external parties such as law enforcement, cybersecurity insurance providers, and affected stakeholders in accordance with legal and regulatory obligations. Legal and regulatory considerations-- reviewing any legal or regulatory requirements that impact the containment strategy, including data breach notification laws and industry-specific compliance requirements. Following the investigation phase comes the containment and remediation phase. You turn to your runbook, which states that ransomware activity can be contained or isolated through a variety of tactics and methods. Successful containment and remediation require planning and thoroughness. In the case of a ransomware attack at Cymbal Federal, your runbook specifically suggests you take the following actions to contain and remediate the incident. You disconnect all infected workstations and servers from the network to prevent the ransomware from spreading to uninfected systems. This includes both wireless and wired connections. You implement emergency changes to the network configurations to create secure zones. This ensures critical segments of the network are isolated from the compromised areas. You quickly identify and disable any user accounts that were logged into the infected systems at the time of compromise, or show signs of unauthorized activity. This cuts off the attacker's access. You verify the integrity and availability of backups by checking the most recent backup logs. You ensure that backup systems are disconnected from the network and uninfected. You use EDR tools to monitor endpoints for signs of ransomware activity, such as unusual encryption processes, and stop these processes where detected. You immediately move sensitive data from network-accessible locations to secure storage. You apply additional encryption to protect the data from being accessed or encrypted by the ransomware. You set up a secure out-of-band communication method for the incident response team. You avoid the use of potentially compromised email systems. You check if it's already done, and if not, you engage with external cybersecurity experts or incident response services. You assist in analyzing the attack, containing the ransomware, and beginning the recovery process. You prepare for timely notification of internal stakeholders, affected clients, and regulatory bodies in compliance with legal and contractual obligations. Based on the initial analysis of the attack, you adjust firewall rules, apply security patches, and update antivirus signatures to protect against known vulnerabilities exploited by the ransomware. Finally, at the end of the process comes the recover and report phase. The goal now is to restore normal business operations as quickly as possible. During this phase, you describe the ransomware impact and its effect on the operational status of an asset or how it hindered business operations. You engage in a follow-up where you evaluate defense capabilities relating to events and incident management. As you have seen, the runbook serves as a critical tool throughout the entire process, even though it might not provide a step-by-step action plan for dealing with a ransomware attack. Instead, the runbook offers a structured framework that guides you through the necessary steps to recover from the incident and report on its impact. The runbook helps you ensure that all actions align with best practices and organizational policies. This facilitates a more coordinated and efficient response.

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/1195/video/522295)

* [YouTube: Module review](https://www.youtube.com/watch?v=ybqwXvktOH4)

SPEAKER: Let's quickly recap what you've learned. In this module, you were introduced to runbooks, playbooks, and incident response plans. You then pivoted to focus primarily on runbooks and explored how runbooks assist tier 1 and tier 2 analysts in incident response. This module featured numerous examples, including a walkthrough at Cymbal Federal, in which you experienced the end-to-end incident management processes provided by a runbook. This module concluded with common runbooks for GDC. Now that you have a solid understanding of these topics, you're ready to wrap up this course. Note that you may wish to enroll in course 3 of Google Distributed Cloud Air-Gapped Security Operations Fundamentals. In this course, you will deep dive into SecOps on GDC for tier 3 analysts.

### Quiz - [Knowledge check](https://www.cloudskillsboost.google/course_templates/1195/quizzes/522296)

## Resources

Review course content

### Document - [Course Slides](https://www.cloudskillsboost.google/course_templates/1195/documents/522297)

### Document - [Additional Resources](https://www.cloudskillsboost.google/course_templates/1195/documents/522298)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

---
id: 1101
name: 'Virtual FAQ with data store agents'
type: Course
url: https://www.cloudskillsboost.google/course_templates/1101
date_published: 2024-07-10
topics:
  - Data
  - Vertex AI
---

# [Virtual FAQ with data store agents](https://www.cloudskillsboost.google/course_templates/1101)

**Description:**

In this course, you will learn how to develop a generative agent capable of answering questions from websites, documents, and/or unstructured data. 

**Objectives:**

* Understand data store agents and how the fit in the Vertex AI ecosystem
* Understand how to scope, design and implement data store agents
* Understand the difference between data store types and data source types
* Understand how to connect a data store to an agent
* Determine the best way to create an evaluation set, a rating scale, and execute a test plan for data store implementations
* Identify common issues and troubleshoot them along with data store responses.

## Introduction to Vertex AI Search, and Conversation and Gen AI agents

This module introduces Vertex AI and data store agents, the use cases that data store agents unlock when designing a conversational application and the typical steps involved in their development

### Video - [What is Vertex AI?](https://www.cloudskillsboost.google/course_templates/1101/video/491353)

* [YouTube: What is Vertex AI?](https://www.youtube.com/watch?v=r9RP4YI8V_Q)

Welcome to the virtual FAQ with data store agents customer user journey! In this module, you’ll learn how to develop a generative agent capable of answering questions from websites, documents, and or structured data. In contrast to traditional means of FAQ generation, data store agents are quick to set up and allow for automatic extraction of relevant information, synthesization of answers, as well as the surfacing of relevant URLs. The agenda for this course is as follows. We start by introducing Vertex AI Search and Conversation and data store agents. Next, we talk about the first step in the implementation process which is to determine the scope and design. Then, we talk about the build phase which includes determining data store types and data source types. After this, we will talk about connecting a data store to an agent. Next comes adding personalization. The next phase is Testing. Here we will talk about evaluation sets, rating scales, and test plans. We will also consider different types of testing. We then talk about deployment and post-deployment monitoring and optimization. We conclude by talking about common issues and troubleshooting. Let’s start by exploring Vertex AI Search & Conversation and Gen AI Agents. In this introductory section, we will introduce Vertex AI and data store agents. Next, we will talk about some advantages of data store agents, what use cases are appropriate for them, and give a high-level overview of data store agent implementation. So what is Vertex AI? Vertex AI gives our customers multiple avenues to access and leverage Google Cloud’s AI capabilities to innovate faster. Integrated within a broader ecosystem that allows it to use next-generation AI models and infrastructure, it contains various products, including those related to Contact Center AI. One of these products is Vertex AI Search and Conversation. This is a collection of APIs and tools, including Dialogflow APIs. Using Vertex AI Search and Conversation, you can make use of new generative AI capabilities while at the same time seamlessly integrating with Dialogflow CX.

### Video - [Data store agents and its advantages](https://www.cloudskillsboost.google/course_templates/1101/video/491354)

* [YouTube: Data store agents and its advantages](https://www.youtube.com/watch?v=i83sBjDgTfU)

With that brief introduction, let us answer the question: What is a data store agent? We are ready to define terms. A Data store agent is an agent built on Vertex AI Search and Conversation. By providing a Knowledge Base such as a website, collection of documents, and or structured data, the agent can parse the content and create a virtual agent powered by large language models. So, why should you use a data store agent? To understand why to use a data store agent, we have to take a step back and define large language models. A large language model (or LLM) is a type of language model able to achieve general-purpose language understanding and generation. LLMs acquire these abilities by using massive amounts of data to learn billions of parameters during training. Pre-training is done on petabyte-scale corpuses of text followed by fine-tuning on a specific task, resulting in large models with 10s to 100s of billions of parameters. For our purposes, Generative AI is the application of a model such as an LLM to generate text-based answers on user input, and it does this by acting as a sort of 'word probability machine' based on the corpus that it was trained on. This is exactly how the PaLM API and other text generation models in the Vertex AI Model Garden work. The bad news is that the information used to train an LLM might be outdated by weeks, months, or even years. For instance, a corporate AI chatbot may lack specific information regarding the organization’s products or services. This can lead to incorrect responses that erode confidence in the technology. In this example, the answer that the Agent gave to the question “Who was the first woman to play baseball?” is correct but not the one to the question “What is the world record for diving?” because Alexey Molchanov beat his own record in 2023, while the agent was indexed only up until 2021 This is where retrieval-augmented generation (RAG) comes in. RAG combines LLMs with vector databases, graph databases, and document stores to generate up-to-date and grounded responses. Consider all the information that an organization has — the structured databases, the unstructured PDFs and other documents, the blogs, the news feeds, the chat transcripts from past service sessions. In RAG, this vast quantity of dynamic data is translated into a common format and stored in a knowledge library that’s accessible to the generative AI system. The data in that knowledge library is then processed into numerical representations using a special type of algorithm called an embedded language model and stored in a vector database, which can be quickly searched and used to retrieve the correct contextual information. Retrieval Augmented Generation (RAG) implementations such as Data Store Agents in Vertex AI Conversation and Dialogflow CX allows an agent to tap into additional data resources at runtime to answer very specific questions without retraining or fine tuning an LLM. That’s why RAG approaches are often used to generate responses grounded in the content of existing knowledge bases. Let us highlight five benefits to data store agents from a security and scalability perspective. First, Vertex AI Conversation is deployed on GCP and scales elastically, so you can easily add more users or traffic to your chatbots. This can be done without having to worry about performance or managing underlying infrastructure. Second, Vertex AI Conversation is a managed solution with Google’s security and data residency standards. Ensuring confidence that your virtual agents meet your serving requirements. Third, Vertex AI Conversation is served with an SLA rating of 99.5% to 99.9% Fourth, access transparency can be enabled to provide logs that capture the actions that Google personnel take when accessing customer content. Fifth, in addition to the default encryption for data at rest, customer-managed encryption keys (or CMEK) can be used to protect customer resources for specific compliance or regulatory requirements Multi-regional Vertex AI data stores benefit from all these features.

### Video - [Good use cases for data store agents](https://www.cloudskillsboost.google/course_templates/1101/video/491355)

* [YouTube: Good use cases for data store agents](https://www.youtube.com/watch?v=UUSYmjLvGo8)

Now that we’ve seen some advantages of data store agents, it’s time to start identifying some good use cases for them. Note that data store agents can be customer-facing or employee-facing. As we will discuss in later sections, understanding your use case in this way impacts decisions about which sorts of underlying documents to use as well as how you assess the performance of your agent. One good use case for data store agents includes questions that can be answered via your organization’s documents or website. Another such use case is FAQs that do not require database lookups. Examples include product FAQs, troubleshooting FAQs, and general company FAQs. By contrast, avoid using data handlers in the following cases. First, cases where the answers cannot be found in the content you have available. Second, cases in which the answers require database lookups, such as checking a user bill amount. Third, cases in which data redaction is required, such as cases with sensitive medical information. Finally, cases in which you require deterministic agent responses, such as cases in which you need to provide legally-approved languages.

### Video - [High level overview of data store agent implementation](https://www.cloudskillsboost.google/course_templates/1101/video/491356)

* [YouTube: High level overview of data store agent implementation](https://www.youtube.com/watch?v=4cX6ZRAPUKQ)

You’ve decided to add a data store agent. How, at a high level, should you implement it? And what are the implementation phases? There are broadly two types of implementations for a data store agent. It can be used as a standalone agent or implemented within an existing DFCX agent. This training will focus on the first option, with some details regarding the second option covered in other training. There are four phases for data store agent implementation: One is Scope and design, in which use cases and experiences are defined. Two, Build, in which the technical work of developing a data store agent is done. Three, Testing, in which you determine whether your data store agent is capable of handling your scoped use cases and edge cases. Also note that, as with all software development, the goal of testing is often to discover changes that need to be made. And lastly, four, Deployment and ongoing optimization, in which you begin your process of collecting feedback, and improving the agent based on this feedback.

### Quiz - [Introduction to Vertex AI Search and Conversation and data store agents Quiz](https://www.cloudskillsboost.google/course_templates/1101/quizzes/491357)

## Scope and design

This module explores the "Scope & Design" phase in a data store agent implementation, how to identify its objectives, as well as the relevant data sources and success criteria.

### Video - [Scope and design](https://www.cloudskillsboost.google/course_templates/1101/video/491358)

* [YouTube: Scope and design](https://www.youtube.com/watch?v=NYFrRQ_fshc)

Now that you have a solid foundation about what data store agents are and the process involved in implementing them, let’s take a deep dive into the first phase, scope and design. In this section, we’ll be discussing what it means to define the scope and objectives, how to identify relevant data sources, and how to determine the success criteria. Let’s start by talking about defining the scope and design objectives. First, you want to define the problem you’re trying to solve. An example of a problem statement could be: “Customers want to find answers and links to their problems on our public assistance website that our search solution cannot help with” This will require you to go through 3 steps: First is to collect your available data. This can be in various forms whether it’s a website, internal documents, training materials, and so on. You should gather all information pertinent to the questions you would like your data store agent to answer. Second, determine the scope of information. Define whether the agent must only use public-facing information, or if it can draw on private information as well. We will define public versus private data in a later section. And lastly, finalize the scope of the data store agent’s capabilities. This includes the questions it should answer and how it should handle questions which it should not answer directly. The next essential aspects to consider are the critical user journey and the user experience channel or channels. Let’s look at user journeys first. This is about defining and understanding the end-to-end experience for your highest volume use cases. Typically, the user is viewing a catalog of product offerings when a chat bubble appears on their browser asking, “Do you need assistance?”, at which point they typically answer, “Yes,” or ask their questions. Defining the CUJ can help developers accommodate for this. Next is the user experience channel which is pertinent for formatting. For example, if the data store agent is hosted in a text chat interface, answers in the form of bulleted lists may be highly preferable. But if the agent assists by voice, this type of formatting can be extremely confusing. Another part of the scope and design phase is identifying relevant data sources. When it comes to data store agents, there are two broad categories under which all information falls: public information and private information. Public data sources simply relate to content available on the public internet. Setting up a data store agent only with content available on the public Internet is convenient and solves most use cases. However, if your data store agent must be able to answer questions using data not publicly available, you must gather additional private content to supplement this. The final part of the scope and design phase is determining the success criteria. In order to serve end users, you must also align on criteria to demonstrate value prior to productionisation. Minimally, two key artifacts need to be created: First, an agreed-upon minimum accuracy in terms of quality and safety. And second, a plan for continuous improvement and iteration.

### Quiz - [Scope and design Quiz](https://www.cloudskillsboost.google/course_templates/1101/quizzes/491359)

## Build

This module explores the "Build" phase in a data store agent implementation by analysing the difference between data stores and data sources and highlighting the distinction between three types of data stores: web data stores, unstructured data stores, and structured data stores

### Video - [Data store types](https://www.cloudskillsboost.google/course_templates/1101/video/491360)

* [YouTube: Data store types](https://www.youtube.com/watch?v=GW8rRQFqRsk)

After determining the scope and design for your data store agent, you can start with the building phase. The first step is to determine what type of data store you will use, and that is what we will discuss next. We will distinguish between data stores and data sources and explain the relationship between them. Then, we will discuss the three types of data stores: web data stores, unstructured data stores, and structured data stores. As a reminder, a data store is a collection of data sources such as website domains, PDF’s, FAQ documents and more that are queried by the GenAI agent to answer end user's questions. There are three different data store types, each supporting various types of data and different input mechanisms. Web data is typically collected from Google search indexes, while structured and unstructured data can be uploaded through cloud storage buckets or BigQuery. Web and unstructured data stores accommodate HTML and PDF content, while structured data stores handle data in CSV format. The first data store type, namely Websites, is for public content. The other two, unstructured or structured documents, are for private content. It’s important to know that although there are three data store types, there are four different sources for your data store. If you are planning to use a public website as your data store, then the source should be a public website. But if you are planning to use private content, in other words for structured or unstructured data, then you can use the three other types of sources: BigQuery, Cloud Storage, or API. This training will discuss the first three types of source (Website, BigQuery, and Cloud Storage) but will not be discussing APIs further because access is currently restricted. This diagram helps you visualize the relationship between data stores and data store sources. If you choose a web data store, the source will be a website (or websites). If you choose either unstructured or structured data stores, the source will be either BigQuery, Google Cloud Storage, or API. Let’s explore the middle layer, doing a deep dive into each of the three possibilities: Web data stores, unstructured data stores, and structured data stores. Now, we are ready to talk about the three types of data stores. First up is web data stores. A website data store uses search to index content from a publicly available data source, as in websites. This works through search crawling the content available at the designated URL and creating an indexed list of content for the data store agent to call upon for answers. There are some important considerations you should keep in mind about how a web data store accesses designated public information. First, PDFs are readable and will be included in the data store. And second, there is a maximum of 1 million documents that can be indexed for any data store. If your designated site exceeds this limit, you may need to consider a different type of data store, curate the content of the site, or reduce the scope of the data store URLs. Lastly, developers should be aware that web data stores respect robots.txt. Robots.txt files tell search engine crawlers which URLs the crawler can access on your site. For additional information about robots.txt or quota and limits, please refer to the Additional Resources document. Next, we’re going to discuss unstructured data stores. Unstructured data can be uploaded with or without metadata, however, including metadata is highly recommended and will yield better results. In particular, when you provide a title and URL as metadata, the agent can use this information during a conversation to assist the user. So, let’s explore the process of uploading unstructured data with metadata. To upload documents with metadata, you will need to create JSONL files. JSONL, short for ‘JSON Lines,’ is a format where each line is one JSON object describing one document. We will see some examples in the upcoming slides. Using unstructured data as your input for a data store can be as simple as two steps: First, upload your JSONL files to either BigQuery, or Google Cloud Storage. And then input the URI for that bucket into your data store creation window. Here you can see an example of a JSONL file with metadata. Note that each line contains an ID, content (which tells you about the file’s type and current location), and JSON data (which tells you its title and URL). Now, let’s inspect the fields present in the JSONL example of the previous slide: First is the id: This serves as a unique identifier for the document within the datastore. Second is the content dot mime type: It indicates the MIME type of the document, with support for formats like “application or PDF” and “text or html”. Third is the content dot URI: This is the URI link leading to the document’s path in the cloud storage GCS bucket. And fourth is the content dot JSON data: This field represents a single-line JSON string that describes a JSON object. It may include an optional title and URL fields. Creating an unstructured data store without metadata is a simpler process. You only need to specify the GCP bucket location or BigQuery location where your files are stored. Note that if you select this option, document titles will not be used in indexing or retrieval of information. Meanwhile, the URL provided by Vertex Conversation will be the location of the file within the bucket from which you uploaded it. When using an unstructured data store, keep in mind that the maximum document size is 100 Megabytes. Now, let’s move our focus to structured data stores. In structured data stores, information is organized in a specific format and follows a schema, such as a question, an answer, a title or a URL. These data stores are used to store frequently asked questions and their answers. When a user's question is matched with high confidence to an uploaded question, the bot will return the corresponding answer to that question without any modification. You also have an option to provide a URL for each question and answer pair, which will be returned by the bot. When uploading data to the data store, it’s important to use the CSV format. Each file should include a header row describing the columns to ensure proper organization. Here is an example of how the data should be structured in your CSV. The schema has four columns: question, answer, title, and URL. Note that the title and URL are optional. This concludes our discussion of the three types of data stores: Web data stores, unstructured data stores and structured data stores.

### Video - [Data sources](https://www.cloudskillsboost.google/course_templates/1101/video/491361)

* [YouTube: Data sources](https://www.youtube.com/watch?v=-nproougNYs)

Now that you know about the different data stores, let’s explore data sources. Specifically, we will focus on three types of data sources: Websites, cloud storage, and BigQuery. Let’s start with using a website as a data source. Using a website as your data source is as simple as identifying the URL that should be crawled. The field highlighted in green is where you can define URLs to include in your data store. The field highlighted in red is where you can define URLs to exclude from your data store. And the text highlighted in blue indicates the formatting for your URLs. An asterisk is a wildcard for a pattern. For example, an asterisk following a dot com indicates that the entire domain is to be included or excluded. And an asterisk in front of a domain (such as mysite dot com) indicates that you want to use the entire domain. But in order to index a web data store, you must verify your ownership of the domain. To do this, simply click on the ‘verify’ option (highlighted in red on the screen), which becomes available after adding the domain to your data store. If verification is not possible for some reason, you must request a domain verification exception. For more information, refer to the Additional resources document. After clicking ‘verify’, you will be redirected to the Google Search Console admin portal, where you can enter the domain you wish to verify. Once you enter the domain, you will be transitioned to the following window. Here you will receive specific verification instructions. Keep in mind that these instructions may vary depending on your domain registrar. Simply follow the instructions to successfully verify your domain. This example shows one example of doing domain verification via DNS. Other methods are available for domain verification. For more information, see resource number 16 in the additional resources section. For situations where verification is not possible, you have two options. First, you can use a basic site search. This feature crawls and indexes public information websites. An example of this is a government website with information owned by the public. By contrast, the website of a company, even if it’s publicly accessible, will likely not count as a public information website, because the information will be owned by that company. Second, when the information you wish to index is not public but verification is not possible, you can submit an exemption request. It’s essential to ensure the use case is legitimate and provide a justification when requesting an exemption. Next, we’re going to talk about using Google Cloud Storage as your data source. Recall that this is an option if you’re using structured or unstructured documents. When using private documents, one option is to let your data come from cloud storage. If you do not already have a cloud bucket with the files you wish to use, you can follow the Cloud Storage quickstart instructions to create a bucket and upload your files. The quickstart instructions require you to provide: a URI for the bucket, the content/data to be indexed and a metadata file (which is highly recommended in the case of unstructured data). If you are using unstructured documents and choose to use a metadata file, this can be placed in the same bucket as your base files or in a separate one. For more information, refer to the Additional resources document. Moving on, let’s talk about BigQuery-based data sources. To use a BigQuery-based data store, all you need to do is provide the path to the data source and indicate whether you are using structured or unstructured data.

### Video - [Connecting a data store to an agent](https://www.cloudskillsboost.google/course_templates/1101/video/491362)

* [YouTube: Connecting a data store to an agent](https://www.youtube.com/watch?v=LeVs6z3Z6vw)

Now that you know all about Data stores and data types, you are ready to learn how to connect it to an agent, and that is what the next section is going to cover. Specifically, we will discuss the two different UIs in which you can connect a data store to a CX agent. One is the DFCX UI, and the other is the Vertex Conversation UI. Let’s start by talking about how to add a data store in the DFCX UI. In order to connect a data store to a DFCX agent, you need a DFCX agent to begin with. One starting point is the DFCX UI. If you select the option to create a new agent here, you are given the following two options: One: Auto-generate. If you take this option, it will immediately link you to the Vertex Conversation UI to begin creating the agent. Within the Vertex Conversation UI, after creating your agent, you will be able to connect it to data stores. Or two: Build your own. : If you take this option, you will remain within the DFCX UI. Once your agent is created, you will not be automatically prompted to add a data store. Instead, you will have to take a few more steps to do so. You will have the option of doing so either within the DFCX UI or within the Vertex Conversation UI. Once you have a DFCX agent created, you are ready to connect your data store to it. As we noted, there are two ways to do so. The first method is within the DFCX UI. To do this, go to the page where you wish to add the data store. You should be able to see and click the “Edit data stores” option. Once you’ve clicked on “Edit data stores”, you can select which data store you wish to edit. If you don’t see the “Edit data stores” option, you may need to add the “Data stores” state handler to the page. Once added to the page, click on the plus icon next to Data stores. From here, you are now able to select a data store from the drop-down menu. If there are no datastores connected to the agent, you may connect existing datastores using the "See all datastores" button. Alternatively, you can create a new one by clicking one of the drop-down menus and selecting "Create data store". Once a datastore has been created or connected, you may then select it from the datastore dropdown. To ensure that your DFCX agent returns the responses you receive from your data store, you should make sure that the correct parameter has been added to the Agent responses section. During the setup process, the following parameter should have been added to the “Agent Says” field automatically: “dollar sign request dot knowledge dot answers zero”. You can also customize the way in which answers are returned via the data store. In particular, you can specify the maximum number of links to be sent in an individual response. The highest value you can set is 5. You can also customize various generative AI settings in the “Generative AI” section of the DFCX agent settings. Note that whether you created your agent within the DFCX UI or the Vertex Conversation UI, the only place to customize it is within the DFCX UI. To do this, go to “Generative AI” settings under “Agent settings”. Here, you can enter banned phrases, grounding level and information regarding the agent’s identity. You can also select the generative model to use. Let’s talk about adding phrases that you want to ban. If that phrase is included in the prompt sent to the generative model or if the generative model produces an utterance with that phrase, it will revert to a fallback option. You can also customize the grounding confidence settings. Each response generated from the content of connected data stores is evaluated on a confidence level. This gauges the confidence that all information in the response is supported by information in the data stores. You can customize which types of responses to allow by selecting the lowest confidence level you are comfortable with. If a response comes back with a strictly lower confidence than that level, it won't be shown. For example, if you have the grounding confidence set to low, and the results from the data store has a low confidence rating, then the results will be sent to the LLM to be used as context. Whereas if you have the grounding confidence set to high, low confidence results will not be sent to the LLM for context. Consequently, the LLM might say that it can not help to answer the relevant question. Moreover, you can control the “Data store prompt” setting. This helps control the prompt that is sent to the data store agent, and therefore it controls the responses you’ll get back. Adding information about your agent here, such as its identity and the name of your company, will help in making sure that the response from the data store fits with the persona and goals of your agent. Finally, note that you can select a generative model to use. In this example, “gemini pro” is selected. Next, let’s explore the other option, connecting a data store in the Vertex UI. As we noted earlier, you can create an agent within the Vertex Conversation UI. To do so, start by selecting the “Chat” option. Next, provide the company name, agent name, and location of your agent. Finally, select the data store or stores you wish to associate with your agent. At this stage, if you have not yet created a data store you can do so by clicking the “create a new data store” button.

### Video - [Add personalization](https://www.cloudskillsboost.google/course_templates/1101/video/491363)

* [YouTube: Add personalization](https://www.youtube.com/watch?v=FiN28yBuC-Q)

Another fascinating aspect of developing data store agents is that you can add information about the user to help personalize responses. And that is what we will be exploring next. Personalized information allows us to customize data store agent responses by adding additional details about the end user. For example, maybe we know that the user has a certain subscription plan or owns certain devices. Now, suppose they say they wish to upgrade their phone. If we pass along information about the user’s plan and what devices they have, we may be able to get more targeted and relevant information regarding potential upgrades. Personal information is provided to the Dialogflow API as JSON, as in this example. Note that you’ll want to make your property names and values descriptive to achieve the best results. There are two options for presenting this personalized information. The first is via the Dialogflow API. If you choose this option, you must provide this data each time you send a detect intent request. You provide it in the query Params dot end User Meta data field in the Sessions dot detect Intent method. The second method to provide data about end users is through the Dialogflow Messenger application. To do this, you use the set context method. If you use this method, you only need to send this information one time per Dialogflow session.

### Quiz - [Build Quiz](https://www.cloudskillsboost.google/course_templates/1101/quizzes/491364)

## Testing

This module explores the "Testing" phase in a data store agent implementation by providing an overview of how to create an evaluation set, what rating scale to use, how to create and execute a test plan and how to distinguish between different types of testing.

### Video - [How to create the evaluation set](https://www.cloudskillsboost.google/course_templates/1101/video/491365)

* [YouTube: How to create the evaluation set](https://www.youtube.com/watch?v=qF7Yb0nx-C4)

After you have configured your data store agent, it's critical to test it. In this section, we will discuss various aspects of the testing phase. We start by discussing how to create an evaluation set. Next, we’ll talk about using a rating scale. After this, we’ll explore creating and executing a test plan. We’ll conclude by talking about the various types of testing. First up, creating evaluation sets. An evaluation set is a collection of queries and ideal responses which reflect those that will be asked in production by end users. Evaluation sets are used to evaluate how well the data store agent responds and to prompt adjustments as needed. Also note that these include not only queries that you feel the data store agent can answer completely, but also things like small talk, adversarial questions and out-of-scope queries. In all of these cases, the data store agent should be able to generate some sort of response, although it will not always be able to answer the question. For instance, in the case of an out-of-scope query, the appropriate response might be to politely decline to answer. An evaluation set is the primary tool with which developers should align to produce a production-ready data store agent, and it should therefore be created in consultation with stakeholders. There are a few essential components that each evaluation set should have. The first is the questions. You should create realistic questions that represent queries your agent could encounter. Ideally, your evaluation set would include one “hard” and one “easy” question from the same data store like a document or a website. Next, you will need to include the expected answers. Similarly, you will want an expected link, which is the most pertinent to answer the question from the user. Note that as testing continues, you may identify changes that you need to make to the expected answers and links. Next is Snippets, pieces of content given to the data store agent which it uses to generate an answer. This is the information from your data source that your answer is grounded in. So, for example, it might be a part of your webpage that the generative AI can use to answer the question. Finally, you may want to include Subjective question difficulty scores, as a measure to track whether goals are being reached and if low-hanging fruit are being addressed.

### Video - [Using a rating scale](https://www.cloudskillsboost.google/course_templates/1101/video/491366)

* [YouTube: Using a rating scale](https://www.youtube.com/watch?v=DQQ6JhqxGZM)

Let’s move on to discuss rating scales. After setting up the Evaluation set, you will need to adopt a standard rating scale for all testers and evaluators. Here are two examples of rating scales that have been used. Some decision points include the endpoints of the scale, and how to handle cases in which the data store only provides a URL. They also specify whether the provided URL and answer are rated separately. Typically, question and answer pairs are almost always one of four types of scenarios. The first scenario, small talk, deals with non-informational or chit-chat queries which could be questions like “What’s your favorite color?” The second scenario, uninformative response with no URL, refers to a scenario where the bot is unsure how to answer a question and lacks a relevant URL. In these cases, the bot will provide neither. Phrases like “I’m not sure I understand the question. Could you try rephrasing?” are common in this type of scenario. The third scenario is an uninformative response with a source URL. In these cases, the bot indicates that it cannot find a response but does provide a URL. It may say, for instance, “Here is a link that may be helpful.” And the final scenario is one in which the bot provides information and relevant source URL or URLs for the requested information. We will inspect each of these categories in more detail now. The end goal for evaluating a data store agent’s response is to assign a numerical rating that can be tracked through iterations of a bot. When rating a data store agent response, it is important to follow these 5 steps. Step 1 applies to a rating format that includes scenarios as criteria, in which before evaluating a response, you first assign the response to one of four categories or scenarios. Each scenario has its own set of ranking guidelines that help determine how a response should be evaluated. For step 2, read through the rating guidelines. In Steps 3 and 4 you use these guidelines to evaluate both the answer and URL. The answer is the generated text that GenAI Agents return while the URL is the source where the information is found. Finally, step 5 includes filling out the remaining questions. We will discuss specifically how each of these metrics should be evaluated on the next slide. Regardless of rating scale, there are three pieces of information you will most likely need to evaluate. First, how accurate was the response based on information available, and how well did it answer the query? Second, how well does the provided URL resolve the user’s query? As in, does the URL give logical next steps to solve their query and or does it apply to the query they presented? Third, does the response contain harmful information, for example, material damaging to the company brand. The next three are often dependent on the use case, but are normally important as well. First is a skip flag to indicate when a query and answer are unevaluable, as in gibberish queries. Second is the related intent section where you can indicate the intent the utterance would match to in your taxonomy. This of course only applies if you’re adding the data store agent to an existing DFCX agent with an existing NLU taxonomy. Third is a no-match flag to indicate when the data store agent failed to return an informational response, for example, by asking a clarification question. It’s a good idea to create a baseline so as to track quality over time. Note that how you use your baseline will vary from use case to use case. For instance, sometimes it may be most important to have no ratings at the lowest end of the scale (for example if your end user is a customer), whereas for other use cases, it’s important to have a large number of very high-quality responses. This example shows what a rating for a question and response pair looks like. The query is “bundling options for tv”. Since the answer returns information about the question and a URL, this question is a typical scenario 4, “Informative response with source URL” . In this example, we assume that this is the best available and accurate Answer. Additionally, the URL provides a link to this information where the user can explore further. Hence, both the Answer and URL are perfect answers and therefore rated at plus 5. Furthermore, the information is accurate and helpful, so both the harmful and skip flag are set to “no”. The related intent is indicated and a “no match” event did not occur, so “no match” is set to “no”. Now that we’ve seen an example, let’s run through each of the scenarios in a little more detail. Scenario 1 is when the query is either not a request for information or is not relevant to the use case. A perfect answer includes an appropriate response that fits with the branding and persona you are aiming for. This could possibly be a polite refusal to answer directly or an answer which is predetermined based on branding. A slightly good answer is one that’s appropriately polite but perhaps a little awkward. Hurtful answers will be inappropriate or otherwise problematic. Providing a URL to a small talk query is typically harmful as there is little likelihood of a pertinent source in the data store, but this is perhaps dependent on the use case. In this example of scenario 1, the user inquires about an irrelevant topic that the bot does not have information about. The answer is constructed appropriately with the bot explaining to the user that it does not have the answer to the question. If the answer said “My favorite color is blue.” this could be considered hurtful or helpful depending on the branding and persona established. The URL is given a rating of perfect because a URL is not needed for this question. Scenario 2 is a case where the bot provides neither an answer nor a URL in response to an informational query. An answer rating of “slightly good” pertains to responses that ask for relevant follow-up information. This is the sort of information that is really needed to answer the user’s question. So for instance, the data store agent should not ask a follow-up for more information when that information is available in its data store. On the other hand, a neutral answer will be extremely limited. And a Hurtful answer rating is given when an unnecessary follow-up question is asked or something is said against the brand or persona. Whereas a neutral URL rating indicates that no URL was given. In the example for Scenario 2, the query is “Do I have to call a team member?” This query is vague, so the bot asks for clarification on the question. The answer is respectful with an apology as well, so the answer is rated as slightly good. No URL is given so the URL is rated a 2. It is also good to note that this response triggered a no match event, so the ‘No Match’ flag is set to Yes. Let’s talk about another example. This time the question is “How many hotspots do most plans have?”. We’re assuming this data store agent is serving a telephony use case. Within its data store it should have information about the data limits of various plans. These cases are extremely rare, but should be looked for during testing and development as a potential indication of missing context or content. Scenario 3 involves an informational query that the bot indicates it cannot answer directly, while attempting to provide a helpful URL. The answer should be rated as good if the bot indicates a legitimate reason for being unable to answer the question. For example, the question relies on personal information the bot lacks. It should be rated neutral if the bot just says it cannot answer the question and refers to the link. And a harmful answer is one that is inconsistent with brand or persona. Unlike the previous 2 scenarios, this scenario necessarily requires reviewing the URL provided as well. Basically, the more helpful the URL is in answering the user’s query, the higher it should be rated. A 5 indicates the best possible URL from among those available, one that fully resolves the user query. As the URL becomes less and less useful, points are removed, until we hit the lowest point on the scale, 1, which is a URL that does not help the user resolve their query and may be misleading or harmful in some way. In this example for scenario 3, the user queries, “Is 5G included in my phone plan?” The answer is uninformative because it contains a response with no information and suggests a URL instead. Therefore, the answer is rated as neutral. Say the example URL answers the user’s question, but doesn’t provide additional information regarding the next steps for solving the user query. In that case, the URL would be rated as good. Scenario 4 involves a case where the bot provides an informative response and a source URL. An answer rating of five indicates a perfect answer, one that fully addresses what the user needs on a subject. The intermediate ratings are accurate but not complete answers to the user’s question. The lowest point on the rating scale is reserved for answers that are wrong or misleading. Let us turn to rating the URL in scenario 4. A perfect URL is one that is the best available and fully resolves the user’s query. As we go down the scale, we begin to see URLs that are lacking in one way or another; a better URL may be available or the URL may be missing relevant information. The worst sort of URL in this case is one that causes active harm, for example by misleading the user. URL ratings may be especially helpful here in gauging the quality of your knowledge base. This example of scenario 4 has a query asking “What is the cheapest package you offer to get unlimited 5G? The answer says “Our 5G package is $25/line.” The information is correct and addresses the user’s question, but it misses some key information like the plan name. Therefore, this answer is ranked as Good. Here, we assume the URL contains all of the 5G plans which includes the cheapest one and its corresponding information. Therefore the URL are rated as Perfect.

### Video - [Creating and executing a test plan](https://www.cloudskillsboost.google/course_templates/1101/video/491367)

* [YouTube: Creating and executing a test plan](https://www.youtube.com/watch?v=VVE66a8lHAU)

So far, you‚Äôve learned about Evaluation sets and rating scales. Next, let‚Äôs explore how to create and execute a test plan. There are a number of considerations when it comes to testing operations planning. You should: Define the testing process and key stakeholders. Identify the types of testing and define key roles and responsibilities. Define the process and frequency for refreshing the data store. Identify the ticketing system that will be used for tracking defects or features. Set up and automate the ticketing process. And lastly, define the process to deploy new versions of the Vertex AI Search and Conversation to production. There are also a number of best practices. First, define standard hashtags like hashtag bug, hashtag eval, and hashtag followed by your username to define and identify golden test cases in a simulator that can then be quickly identified in the future. Second, Gen AI by design is not deterministic, so when evaluating answers a manual review of answers is required to assess the quality and pass or fail decisions. We should not be looking to do exact text matches. Third, unit tests should be created by developers and validated by the Quality Assurance (or QA) team. Fourth, the QA team should stress test the agent and should cover 100% of the functionality. Executing the test plan is a complex, time-intensive and important effort. Testing of data store agents are a mix of manual and automated efforts with a high focus on human manual testing to verify the accuracy of results and check for possible hallucinations. For efficiency and productivity, developers, QAs and other stakeholders should respectively execute testing of different sorts and in different environments.

### Video - [Types of testing](https://www.cloudskillsboost.google/course_templates/1101/video/491368)

* [YouTube: Types of testing](https://www.youtube.com/watch?v=fgp82agOtSU)

There are several different types of testing that can be done. The first type of testing is unit testing, which helps catch bugs early in the process. This can be done in the simulator or via test cases. Unit tests are most often created by developers, but can also be developed by the QA team depending on the team structure. Unit tests help to identify and address bugs early in the development process, preventing them from causing problems in more complex interactions or integrated systems. This typically involves testing for content in the data stores using different utterances and their variations. Crucially, you should note that unit testing is at least initially done in conjunction with development. The next type of testing is integration testing. This is required to ensure that your data store agent is correctly integrated. The goal here is to ensure that end-to-end, the application will function as desired. It is also recommended to test using different channels. For example, on a desktop you might test multiple browsers from different networks (for example WiFi residential internet, public internet, or corporate internet). While on mobile, you might test multiple devices (for examlpe Apple iOS, or Android) to verify mobile experience is as expected. But take note that this can be part of integration testing or part of UAT. There is also performance testing. This type of testing helps identify any performance issues that arise, such as issues related to timing and scale. Sample metrics include Response Time, which is the agent’s average response time. Here, you should identify any variations or delays. Concurrence is the ability to handle multiple concurrent users and maintain performance. And scalability, which is the ability to scale up to handle increased user loads and maintain performance. Another crucial form of testing is user acceptance testing. This, in simplest terms, is having testers play the role of real-life users, interacting with the agent in a natural conversation flow. This will help ensure that real-life users will derive value from what you have built. Examples of aspects you should test include, accuracy and relevance of responses, NLP and context handling, bias and fairness, safety and security, user satisfaction, and lastly overall experience. Another form of testing is black box testing. This involves testing by those unfamiliar with the underlying workings of the product, so people outside the team or real users are the best participants for this type of testing. A final form of testing is regression testing which is a key type of testing when building a virtual agent to ensure that changes introduced to the agent don't break existing functionalities. This type of testing can be done within Dialogflow or via a script. If you do wish to use a script, one option to do so is with SCRAPI, which has built in features supporting building an evaluation set, running it, rating responses and visualizing them. You will likely need to perform regression tests multiple times during the data store agent development process as well as whenever data stores or the content in data stores is refreshed.

### Quiz - [Testing Quiz](https://www.cloudskillsboost.google/course_templates/1101/quizzes/491369)

## Deployment and post-deployment monitoring and optimization

This module explores the requirements for readiness and observability of a data store production deployment to ensure sustained performance over time

### Video - [Deployment and post-deployment monitoring and optimization](https://www.cloudskillsboost.google/course_templates/1101/video/491370)

* [YouTube: Deployment and post-deployment monitoring and optimization](https://www.youtube.com/watch?v=8gS4vpFIzek)

Well done, up to this point, you’ve covered plenty of new territory in the field of data store agent implementation. You’ve learned how to determine the scope and design of a data store agent. And you’ve gained valuable knowledge about the building phase including data stores, data types as well as how to link different data stores to an agent. Then you learned all about testing including evaluation sets, rating scales and types of testing. In the next section, we will talk about deployment and ongoing optimization. At this point, you are finally ready for production. This is an exciting stage of the process but one where you will need to pay careful attention to both data and expectations. If you are concerned about quality or potential end user backlash, consider a dark launch or an internal launch and collect some data first before a full launch. You could also consider a canary launch. If you are starting out using the Vertex AI Search and Conversation (or Dialogflow CX) you should consider enabling the following observability features of the product so that you can diagnose the performance of your Virtual Agent: First, Cloud Logging which logs Dialogflow query Input and query Result in Cloud Logging. Second, Interaction logging which logs Dialogflow queries and responses directly in the Dialogflow Console. This is useful if you want developers to see conversations directly in the console. And third, BigQuery export which will export every interaction to BigQuery so you can run analytics and reports. You’ve enabled logging and made it to production, now let’s start talking about what to monitor! Once you have launched to production, you should begin reviewing traffic, billing, and end user queries. For traffic patterns, you should ensure that volumes are what you expect and there aren’t unusual patterns that indicate problems. Next, you should ensure that your billing and operational costs are in line with expectations and make adjustments as necessary. Finally, you should examine end user queries and topics to gain insight into any patterns that emerge and any content adjustments that may be needed. For an in depth overview of the monitoring and logging, please refer to the performance management modules of the CCAI Academy curriculum.

### Quiz - [Deployment & Ongoing Optimization Quiz](https://www.cloudskillsboost.google/course_templates/1101/quizzes/491371)

## Common issues and troubleshooting

This module explores the common issues (e.g. permission errors, indexing issues, ungrounded responses, and other infrastructure errors) you can encounter when deploying data store agents and the most effective solutions for troubleshooting, including the outreach to Google Cloud Support

### Video - [Common issues and troubleshooting](https://www.cloudskillsboost.google/course_templates/1101/video/491372)

* [YouTube: Common issues and troubleshooting](https://www.youtube.com/watch?v=c7xt5eFgsr0)

Just like with any development process, there are common issues related to data store agent development. Let’s discuss some of the common issues and troubleshooting methods. There are two very common sets of issues. First, there are cases in which the query you send is appropriate for the data store agent, but fails to return a response. Here, some troubleshooting options include adding content to the data store, adding personalization, and adjusting Gen AI configurations, such as the model used, grounding level, or agent persona. It is important to know that lowering the grounding levels is somewhat risky and should only be used as a last resort. Another set of cases is those in which the query you send is inappropriate for the data store agent, but it nonetheless returns a response. Here, you can remove content from the data store, add personalization, or adjusting Gen AI configurations. Another common issue is receiving a “permission denied” error. This can typically be fixed by ensuring that the requisite permissions are in place. Note that even if you enable Vertex Conversation AI and Search, you still need to make sure individual users (or user groups) are granted access. There are two different options for permissions: one is editor, and the other is reader. If the user needs to make changes to the interface, they need an editor. If they are just looking at the system, reader will be sufficient. There is also the problem of no responses coming back from the agent. Often, this is because the website or documents have not finished indexing. During indexing, the user is unable to converse with the Dialogflow CX agent about any information that is being indexed. You can view the indexing status in the Vertex Conversation AI console. You can view the indexing status in the Vertex Conversation AI console. Yet another potential problem is that one’s website is too large to index properly. To resolve this, you can use filters to limit the number of documents being indexed for your website. If you must have more than 200, 000 pages, reach out to a Google contact. You might also encounter the problem of responses that are ungrounded. Data store agents include a grounding check to guarantee that the information from the response provided can be found within the data sources. One way to resolve this is reducing the grounding threshold, although this can lead to hallucinations. The best practice in most cases is rather to make any required adjustments to data store content first. Yet another issue is quota max outs. If you find your quota is maxed out, you need to reduce your scope or increase your quota. Additionally, here are some further issues you may see and their solutions: Call search failing, ReAct turn failing, and the Responsible AI safety triggering. If all else fails, you can contact cloud support for help. To do this you will need to raise a cloud support case in the cloud console. You’ll need to provide some information that can be used to diagnose the problem, including the project ID, chat engine ID, DFCX agent ID, query performed, and the expected performance. Thanks so much for spending some time learning about data store agents with us. Congratulations on completing this training and good luck with creating your very own data store agents!

### Quiz - [Common errors and troubleshooting Quiz](https://www.cloudskillsboost.google/course_templates/1101/quizzes/491373)

### Lab - [Create a chat and voice FAQ bot with Conversational Agent Playbooks and Data Stores](https://www.cloudskillsboost.google/course_templates/1101/labs/491374)

This labs explains how to create a Generative Chat App with Vertex AI Agent Builder and Dialogflow.

* [ ] [Create a chat and voice FAQ bot with Conversational Agent Playbooks and Data Stores](../labs/Create-a-chat-and-voice-FAQ-bot-with-Conversational-Agent-Playbooks-and-Data-Stores.md)

## Additional Resources

This module includes the list of additional resources that complement the course learning

### Document - [Additional Resources](https://www.cloudskillsboost.google/course_templates/1101/documents/491375)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

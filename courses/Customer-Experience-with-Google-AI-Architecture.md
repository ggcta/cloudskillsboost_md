---
id: 1002
name: 'Customer Experience with Google AI Architecture'
type: Course
url: https://www.cloudskillsboost.google/course_templates/1002
date_published: 2025-01-29
topics:

---

# [Customer Experience with Google AI Architecture](https://www.cloudskillsboost.google/course_templates/1002)

**Description:**

In this course you will learn the key architectural considerations that need to be taken into account when designing for the implementation of Conversational AI solutions. Please note Dialogflow CX was recently renamed to Conversational Agents and CCAI Insights were renamed to Conversational Insights, and this course is in the process of being updated to reflect the new product names for Dialogflow CX and CCAI Insights.

**Objectives:**

* Understand an overview of the Conversational AI Platform and resource management within Conversational AI.
* Understand the fundamentals of Conversational Agents design.
* Learn the details of planning for an agent assist.
* Gain an understanding of how to plan for Conversational AI insights implementation and review target user personas.
* Learn how to analyze developer operations and the best tools for release automation.
* Understand the details of Security and Compliance considerations.

## Conversational AI Resource Management

After completing this module, you will gain knowledge of the key architectural resourcing considerations for the implementation of Conversational AI solutions. You will also be able to explain the main integrations that enhance Conversational AI solutions and explore at a high level how Conversational AI works with Vertex AI. Lastly, you will gain a high level understanding of the key features of Conversational AI Platform as a solution.

### Video - [Conversational AI Resource Management Overview](https://www.cloudskillsboost.google/course_templates/1002/video/523143)

* [YouTube: Conversational AI Resource Management Overview](https://www.youtube.com/watch?v=O7_zHSAgc5c)

SPEAKER: Welcome to CCAI Architecture. In this course, we'll explore several topics to help you succeed in designing, building, and maintaining your CCAI solutions architectures. The training will cover six key areas. We'll start with CCAI resource management, where you'll learn about the infrastructure and resources needed to set the foundation for a strong Contact Center AI architecture. Then we'll go over the required steps to plan for the deployment of virtual agents CCAI Agent Assist and CCAI insights. Finally, we'll address deployment and operations and look at essential security and compliance practices. Let's get started. Let's start by taking a look at architectural resourcing considerations for CCAI. We have four main objectives for this section. First, we'll explain what the main operational environments are, along with resourcing and access considerations that need to be made upfront to implement CCAI solutions. Then we'll review the integrations that can enhance CCAI solutions, both native and Google Cloud, as well as third parties. After that, we'll explore how CCAI fits into the Vertex AI stack. And finally, we'll close the section with a brief overview of the advantages of leveraging the Contact Center AI platform to take full advantage of Google Cloud resources. Let's get started. Several factors need to be taken into account when preparing to build or transform your contact center using CCAI solutions. Asking some basic questions up front can help understand the best resources that require deployment to achieve the vision for your target architecture. The first question that needs to be asked is, What solutions are in scope for your CCAI implementation? Are you looking to connect your customers with your staff, with bots? Does your contact center need to be modernized? If so, consider using CCAI platform, Google's Contact Center as a Service, or CCaaS. Note that we'll focus mainly on the other CCAI components during this training, but we will briefly mention CCAI platform again shortly. The next question to ask is, Are you looking for assistive technologies that enable your staff to do an efficient and better job at resolving your customers' needs? If so, consider using our Agent Assist capabilities. Or maybe you're looking for help with scaling up your ability for self-serve in your call center and improve customer satisfaction without increasing your staffing levels. If so, consider implementing a Virtual Agent. Are you interested in performing deep analytics on how your customers are interacting with your Contact Center? If so, consider using CCAI Insights to derive customer, agent, and Contact Center Key Performance Indicators, or KPIs. The answers to these questions will help determine which resources you'll need to support these solutions and whether you'll need special infrastructure to support the level of availability and resiliency you desire. Now let's turn our attention to an essential consideration for organizing your CCAI resources, the interconnection of your technologies. This is a critical aspect to consider as it will determine how seamlessly your CCAI components can communicate and share data. To ensure efficient and effective operations, you need to define the resources required to support your operational environments. Once you have a clear understanding of the resources needed, you can then begin to map out the interconnection of your technologies. Finally, it's important to consider how you will capture data from your CCAI solution to measure operational success. This data will be essential for tracking key performance indicators and identifying areas for improvement. Here's an example of the level of the connection that the answer to these questions will unlock amongst different solutions in the CCAI portfolio. As shown in this diagram, a holistic CCI solution can encompass a combination of telephony, virtual agents, and human agent assistive technologies. On top of these technologies, you can also leverage CCAI Insights to analyze your data, interact with APIs and the data layer, and connect with other services to round out and customize your solution. The needs of the business are ultimately what drives the decision around which solutions should be added to your CCI infrastructure, so make sure to clarify those requirements and their expected impact upfront.

### Video - [Operational environments](https://www.cloudskillsboost.google/course_templates/1002/video/523144)

* [YouTube: Operational environments](https://www.youtube.com/watch?v=sav79pc0Q40)

SPEAKER: After gaining business buy-in on which solution can drive the most impact, you can start setting up your operational environments. When you build a CCAI solution, it is important to adhere to the strictest and least privileged access for the underlying resources, user, and service accounts to preserve the security and robustness of your architecture. This starts with knowing the difference between projects and virtual agents within Google Cloud and how to implement the correct number of each for easy and consistent operations. Projects are a logical collection of cloud resources that delegate identity access management access controls. For CCAI specifically, the best practice is to create two projects, the first to host your nonproduction development and test resources and a second project that contains your staging and production resources. Some users opt to have three separate projects, one for development, one for staging, and one for production. Ultimately, the decision lies with you and your client organization, as long as it allows for a clear separation between production and development. Virtual agents are a logical collection of interactions, targeting fulfillments that help end users get answers to their questions. You usually only need one virtual agent to support all nonproduction environments and a second virtual agent to support your production environments. Creating more than two virtual agents in the same project is generally required only if you have a need to handle interactions for completely different types of users or lines of business. If two virtual agents are targeting different types of end users and are being developed or operated by different teams, you should consider placing them in separate projects to manage their access controls independently. This is usually done to manage access controls when different teams manage the virtual agent development and operations. This will prevent cross virtual agent access. Lastly, please note that virtual agents are often referred to simply as agents. So when you hear the term "agent" from a resource perspective, keep in mind that it always refers to virtual agents rather than human agents. The next critical decision to be made in the setup of a new operational environment is deciding between public and private connectivity, between clients and the Dialogflow API. If you use public methods, you do not need to set up any additional infrastructure. Your Dialogflow client will simply connect to a Dialogflow API endpoint, which is public. Note that when you use this public API endpoint, this does not mean that your Dialogflow communications are publicly accessible. Instead, they are encrypted with Transport Layer Security, or TLS, and use a service account and OAuth credentials for authentication and authorization. Private communication, on the other hand, requires the configuration of a private interconnection to a Google Cloud VPC. This process is a bit more complex than the public communication, requiring Private Service Connect for Google Cloud APIs to the VPC. This is to ensure the IP address for the Private Service Connect can reach the customer's private network and the addition of Dialogflow hostnames to DNS that point to the private Service Connect IP address. Ultimately, the decision lies with you or your clients and the specific circumstances of the implementation. Most virtual agent implementations rely on public communication, while those on specific industries or locations might opt for private connectivity. This diagram shows an example of how both public and private communications can flow between end users, virtual agents, and human agents. Let's zoom in and break this down so we can go over the main aspects. If your organization or the customer organization you are working with cannot use Google's public API endpoints, then they need to set up a private interconnect. The private interconnect must be set up between the data center where the organization's chat or voice server exists in Google Cloud. In the VPC, where that interconnect lands, a Private Service Connect needs to be set up to communicate with Dialogflow. Also, an internal DNS server is required to resolve the Dialogflow hostnames to the organization's Private Service Connect IP address. Let's fill in some details about how this can work in your environment by taking the example of a virtual agent that's to be implemented within the solution. As we already mentioned, Dialogflow has public API endpoints and can use TLS, oAuth, and VPC Service Controls to ensure privacy and security. This is usually the fastest way to send requests to Dialogflow, and it doesn't sacrifice security. However, in environments where private connectivity is a must, you can leverage a private interconnect to reach Dialogflow's APIs. If Agent Assist is in scope, then you'll need to determine the following. Are you implementing a Contact Center as a Service, or CCaaS? Or are you implementing an on-premises service that has native integration with Google CCAI and the Agent Assist functionality in the Dialogflow API? If you are implementing a CCaaS solution, then this system will manage sharing the conversation utterances to Dialogflow, and it will automatically surface information to your human agent based on the system's configuration. If Agent Assist is not in the solution scope, then the incoming audio stream must be routed directly to the virtual agent. There are two ways to send the audio to Dialogflow. The first option is to send gRPC requests to the Dialogflow APIs. This involves using one of Dialogflow's gRPC APIs designed to handle audio input. Available APIs include Analyze Content, Detect Intent, Streaming Analyze Content, and Streaming Detect Intent. Another option is to use the SIP endpoint provisioned by the Google Telephony Platform, or GTP.

### Video - [Access control](https://www.cloudskillsboost.google/course_templates/1002/video/523145)

* [YouTube: Access control](https://www.youtube.com/watch?v=AndKZRHBwQ4)

SPEAKER: Next, let's take a look at how you can control access to CCAI services and APIs. It's very important to follow best practices for access control to ensure your resources are well protected by following the principle of least privilege. The backbone of a robust access-control system is Identity and Access Management, or IAM. IAM is a framework of policies and technologies to ensure that the right users have the appropriate access to the right resources. With IAM, you can define who has permission to do what on which cloud resources. It also relies on the concept of roles. Roles are simply bundles of permissions that define what actions a user or service account can take on Google Cloud resources. That means a role might contain multiple, smaller permissions that allow actions like viewing data, launching virtual machines, or changing firewall settings. Google Cloud offers a selection of predefined roles to quickly address typical use cases. However, if you need very specific, fine-grained permissions, then you also have the flexibility to create custom roles best aligned with your security policies. At the beginning of your journey toward building a CCAI solution, we recommend that you create the following groups, where relevant. If you're developing virtual agents, the primary agent configurations should be managed by your developer operations team, the VA ops group, with its own role. Your team of conversation developers, the VA flow devs, require the ability to edit flows with a separate role from the VA ops group. Similarly, anyone developing webhooks within Google Cloud, the VA webhook devs, will need a variety of roles depending on which technologies you choose to use. The most common role the webhook devs need is the Cloud Run administrator role. However, they'll also need to receive the Dialogflow webhook admins role so they can configure agent webhooks. When you assign IAM roles to these groups, access to cloud resources is granted to all the users who are members of it. For Agent Assist, your developers, the AA devs group, will have both the Dialogflow admin role but also the Pub/Sub admin role due to the importance of Pub/Sub plays in Agent Assist. When it comes to insights, your CCAI analysts, the CCAI analysts group, typically receives the BigQuery admin and contact center insights editor roles. Please note that these are some of the main recommended roles. And your final list will vary depending on precise requirements and restrictions. Similarly, if you are deploying CCAI services through the CCAI platform, of which more details are provided later in the training, then assign the contact center AI platform admin role to a CCAIP admins group. To assign additional access controls for CCAIP users, you can use the CCAI platform portal.

### Video - [Google Cloud and third-party integrations](https://www.cloudskillsboost.google/course_templates/1002/video/523146)

* [YouTube: Google Cloud and third-party integrations](https://www.youtube.com/watch?v=o477jwaUAm4)

SPEAKER: Now let's go through a high-level overview on how CCAI solutions integrate with other Google Cloud and third-party services. When building the operational readiness of your target infrastructure, keep in mind that there are several Google Cloud Services beyond what is immediately available in CCAI. These services can greatly complement and support CCAI solutions. The most popular are Cloud Logging, Cloud Monitoring, BigQuery, Looker Studio, sensitive data protection with the cloud DLP API, Cloud Functions, and Cloud Run. Let's briefly explore each of these services. Cloud Observability is important to keep a pulse on the performance of your CCAI solution. Cloud Logging supports your observability needs by enabling you to capture log information from your cloud resources. This can greatly enhance your ability to monitor your virtual agent interactions. Cloud Monitoring helps you collect and observe important metrics, events, and metadata. Such information is important when looking at the performance of CCAI solutions and other associated components. The most common metrics observed are error rates and latency, but many other Key Performance Indicators, or KPIs, can be configured. BigQuery helps you build data warehouses when you need interaction logging and analytics for your CCAI solutions. This can greatly advance your ability to adapt, maintain, and evolve your CCAI solution. BigQuery data can be easily viewed with Looker Studio, which can help you create reports and visualize your data. This is exceptionally important when you want to monitor performance of the virtual agent or other CCAI services. Sensitive data protection and more specifically the Cloud Data Loss Prevention component, or Cloud DLP, is a service that helps you protect and secure Personally Identifiable Information, or PII, in your data. It works by identifying the particular PII based on a template and set of PII types. Once PII is identified, the data can be masked, replaced, or removed. Note that when implementing a virtual agent, it is very important to identify any parameters collected that would be considered PII to help prevent them from being logged. Finally, virtual agents can connect to systems in order to look up information or carry out transactions. These connections to your APIs are known as webhooks. Cloud Functions and Cloud Run are two popular options to get webhook code up and running, and are often used with Dialogflow. The popularity of these options is largely due to the ease of implementation of microservices, coupled with the elasticity to rapidly scale up and down. Other options include Kubernetes Engine, Compute Engine, App Engine, or Apigee. Another type of integration facilitated by CCAI solutions is with telephony and chat providers. These are key to any successful CCAI implementation. Dialogflow provides one-click integrations with many popular vendors and technologies. And when one-click integrations don't exist, it allows for the development of a custom connection through CCAI APIs. This section will not go into details on these types of integrations, since they will be covered in detail in a separate module of the CCAI Academy.

### Video - [The Vertex AI ecosystem](https://www.cloudskillsboost.google/course_templates/1002/video/523147)

* [YouTube: The Vertex AI ecosystem](https://www.youtube.com/watch?v=ktY_0p-3aKk)

SPEAKER: Now let's zoom out to a bird's eye view of the Vertex AI ecosystem and understand where CCAI fits into it. As we've discovered, seamless integrations are key to fully unlocking the business value of your CCAI solutions. This is because they promote a comprehensive end-to-end approach that removes the friction often experienced when building legacy contact centers. They do this by stitching different solutions together for incremental gains. When you partner with Google Cloud for your AI needs, you get a comprehensive technology offering built on Vertex AI. Vertex AI is a machine learning, or ML platform, that lets you train and deploy ML models and AI applications. And you can also customize large language models, or LLMs, for use in your AI powered application. The platform stack is multi-layered and multi-purpose. Starting at the bottom, there's Google's world class AI optimized infrastructure with GPU and TPU accelerators fully integrated with Google Data Cloud. On top of it sits the Vertex AI Model Garden, a one-stop shop to find first party, open source, and third party large language models. AI platform leverages the resources from the Model Garden to provide end to end tooling to build, deploy, and monitor Gen AI models and pipelines. Vertex AI Search and Conversation is the interface that developers can then lean on to access the AI platform resources to quickly and easily infuse chat, Gen AI, and search into their enterprise applications. And lastly, AI solutions such as Contact Center AI sit on top of the stack. They leverage the Vertex AI Search and Conversation to deploy chatbots and voice bots at scale. This means that Contact Center AI takes advantage of the full stack of resources and capabilities available in Vertex AI. In order to accommodate different use cases, Vertex AI capabilities were made accessible, both through the Vertex AI Search and Conversation console, as well as natively, or out of the box in CCAI. For example, a customer that has a high level of AI proficiency may want to build highly customized use cases. These customers can take advantage of independent or build your own components of Vertex and assemble them according to their needs, like Model Garden, AI platform, Search, Conversation, and third party LLMs. Other clients might be after low code or no code products ready for use in customer service use cases. In this instance, the best solution for them is to leverage off the shelf packaged products like CCAI platform, Dialogflow, Agent Assist, or Insights. Vertex also offers a number of prebuilt solutions for specific verticals or use cases like food ordering and financial services. Prebuilt allow you to leverage templates that just require fine-tuning to adapt to specific use cases.

### Video - [Conversational AI Contact Center integrations](https://www.cloudskillsboost.google/course_templates/1002/video/523148)

* [YouTube: Conversational AI Contact Center integrations](https://www.youtube.com/watch?v=LEPYU-B9isk)

SPEAKER: Contact center AI services are the building blocks that power an AI-driven contact center. In order to leverage these services, an underlying contact center platform is needed. In this section, we will explore at a high level the available integration options with CCAI and the choices that customers have when wishing to adopt CCAI services. First, some background. In 2019, Google Cloud started working with the leading ISVs to enable native integrations between their platforms and Google Cloud's Contact Center AI Services. This allowed customers to easily integrate with Genesis, NICE, Avaya, Cisco, Five9, and many others. It resulted in customers being able to add advanced conversational AI capabilities to their existing traditional contact center infrastructure. For many, this extended the life of their existing contact center solution. However, this integration can be suboptimal when it comes to operation, observability, as well as end-to-end serviceability. That's what originated the demand for a fully managed native end-to-end Google Cloud solution for contact centers' operations. That solution is called Contact Center AI Platform, or often referred to as CCAIP. This is Google Cloud's own CCAS offering for a modern, AI-powered contact center as a service. CCAIP works hand in hand with Dialogflow for virtual agents, Agent Assist for real-time guidance, as well as insights to understand contact center analytics, customer sentiment, and trends. It also works well with all the most popular CRMs and supports multiple channels, such as voice, mobile, and web chat, SMS, social channels, and email. CCAI Platform is a great option to pursue for streamlined setup and quick results, and it's easier to manage than a CCAI integration with OEM partners. Your choice between implementing new infrastructure and retaining your existing contact center solution will directly influence the range of options and strategies available to you. Let's go over the different options. You can use CCAIP if you're looking for a new contact center as a service platform or full Google native solution. You can start with Google Cloud CCAI today and retain the option to easily switch platforms in the future by opting for CCAI over the top, which adds CCAI solutions' AI capabilities to an existing platform. Lastly, as a third option, you can leverage CCAI's integration with OEM partners if you want to retain your existing contact center infrastructure. Ultimately, the choice resides with you and your customers based on existing needs and circumstances.

### Quiz - [Conversational AI Resource Management Quiz](https://www.cloudskillsboost.google/course_templates/1002/quizzes/523149)

## Planning for Conversational Insights

After completing this module, you will be able to understand the main infrastructure considerations required to plan for the deployment of Conversational Agent.

### Video - [Planning for Conversational Insights](https://www.cloudskillsboost.google/course_templates/1002/video/523150)

* [YouTube: Planning for Conversational Insights](https://www.youtube.com/watch?v=AUT5p4Mf-No)

SPEAKER: In the next section, we'll go through the infrastructure considerations required to plan for the deployment of virtual agents. The objectives for this section are to help you review the prerequisite platform considerations to the design of virtual agents and learn the key considerations to account for when designing virtual agents. Before starting with platform design fundamentals, it is important to note that there are two distinct Dialogflow editions, Dialogflow CX and Dialogflow Essentials, also known as Dialogflow ES. Dialogflow CX is the more recent capable enterprise-grade that allows you to create agents of varying complexity. You should always create new agents using Dialogflow CX, unless you or your organization already have resources built with Dialogflow Essential. Continuing development in Dialogflow ES is reasonable if you don't expect the complexity of your use cases to increase dramatically. In that case, you may want to switch to Dialogflow CX. Please note that the scope of this training only covers Dialogflow CX. When planning for virtual agents, you should always start by referencing cloud foundations. Cloud foundations is the process of designing and setting up the essential components of your cloud environment. This includes configuring networks, establishing security measures, and defining how you will manage your cloud resources. To successfully deploy Google Cloud foundations for CCAI, you must build a team that will focus on three core areas-- design the network architecture and connectivity, establish security protocols and resource management, including project structure, access controls and monitoring, and third, implement billing and capacity planning strategies, with a focus on resource labeling for detailed cost analysis. The team must also build an automation framework to streamline Google Cloud CCAI resource deployments, while adhering to policy-based compliance standards. This framework must seamlessly integrate with the company's existing CI/CD and DevOps workflows, so the team will have to evaluate the current CI/CD tools to propose an optimized framework and determine the most suitable automation scope. Once your cloud foundations and automation framework are in place, you can then start the discovery phase for your virtual agent deployment. Keep in mind the following questions while preparing for this phase. First, what's the scope, one agent or multiple agents? What data residency is needed? Do you need high availability and disaster recovery? What languages will your agent support? Which time zones? What networking and security architecture will you implement? Additionally, how will you maintain data privacy through the collection and storage of data? This training will provide you with the foundational knowledge to answer these questions. However, based on the channels where you plan to deploy your virtual agent, you should also consider the following questions. What channels will be supported? How can you design omnichannel? How can you support it? Why do you need session and context management for Dialogflow CX and CCAI? And lastly, how do you design interactions? How can you mix predictive flows with generative AI, such as data store agents and generative agents? Note that the answers to these questions does not necessarily have architectural impacts, and it requires the introduction of advanced bot-building concepts, so they will be covered in detail in the learning path dedicated to virtual agent development. Let's start by discussing availability. To achieve high service availability for Dialogflow agents, there are two main approaches you could consider. First, you can employ multiple load balanced regional agents. This strategy distributes traffic across multiple agents located in different regions. Second, you could simply use a global agent. This approach centralizes traffic through a single agent, offering simplified management. Let's look at both options. Let's consider a scenario where you might use multiple regional agents for high availability. In the case of a regional failure, you would failover to a second regional Dialogflow API endpoint that is healthy and can continue serving requests. However, using multiple regional agents introduces considerable incremental complexity into your infrastructure and operations system. Let's explore what this means. The first is infrastructural complexity. It requires an L7 proxy to manage availability through health checks, and redirects the routes to the nearest available region. Additionally, it introduces operational complexity to keep the configuration for multiple regional agents in sync because the agents are deployed independently, so they have unique agent IDs. In light of these complexities, the most common configuration is using a single global virtual agent to provide availability. A single global virtual agent can route requests to the next available agent in the nearest available region. This is our recommended option, as this achieves high availability while minimizing infrastructure and operational overhead. The next key choice you need to make for your virtual agent deployment is about languages. This means understanding which languages your end users may speak and how many languages you would like your agent to support. For example, what if you were to deploy your agent to serve customers primarily based in Canada, where there are two national languages? In this instance, you may want to develop a virtual agent that is capable of answering queries in English and French. This means that you might have two different back end systems that need to be integrated, or as many that are locale or language specific. You also need to understand how to support the multiple ways that your customers will access your CCAI solution. Some examples of these different channels include chat from the web, chat from a mobile app, chat from a text messaging service, voice services like Avaya and Twilio, and more. Sometimes your contact center design needs to use more than one channel at a time. This is where omnichannel comes in. For example, you can support both chat and voice channels simultaneously. To do so, you need to decide how to route each channel and optimize their responses, determine your web chat framework and webhook integrations, and lastly, integrate your back end system with other relevant systems, such as customer relationship management and ticketing. To enhance session management and data analysis, we suggest storing session information within your middleware, in addition to using Dialogflow CX and CCAI. This strategy enables you to leverage stored session data for reporting, analytics, and advanced features, such as session restoration. For instance, you can utilize a tool like Cloud Datastore to save a well-organized NoSQL document comprised of key session attributes, which can serve as the foundation for the development of future advanced features. Examples of some of the attributes are conversation profile, session ID, SST and TTS parameters, turns, participant, call timestamp, and direction of phone calls. To support a consistent omnichannel experience, consider using a central location to manage user data and conversation history in one place. Omnichannel systems might be more challenging to build, but they can offer a superior customer experience over single-channel systems. Lastly, regardless of whether your CCAI solution interacts with your customers by text or voice, it is important that it handles sensitive data very carefully when asking for user input, for example, during user authentication. Some user input is subject to compliance scrutiny if classified as payment card industry, or PCI, or protected health information, also known as PFI. Examples of sensitive data include name, address, phone numbers, email address, health information, and credit card information. To help you protect sensitive data, you can use tools like Sensitive Data Protection and the Data Loss Prevention API to remove personal identifiable information from your data and comply with privacy laws and regulations. You also need to understand how the sensitive data is sent to other APIs and if the data in transit needs additional encryption beyond standard TLS. We just looked at considerations, such as agent availability, language, channels, and input validation. Later, we will be addressing other important deployment, security, and compliance topics that are also important for virtual agents. But before we do that, let's consider planning for other key CCAI components.

### Quiz - [Planning for Conversational Insights Quiz](https://www.cloudskillsboost.google/course_templates/1002/quizzes/523151)

## Planning for Agent Assist

After completing this module, you will have knowledge of the key architectural considerations to account for when planning to implement solutions with Agent Assist, as well as the main Agent Assist components and workflow.

### Video - [Planning for Agent Assist](https://www.cloudskillsboost.google/course_templates/1002/video/523152)

* [YouTube: Planning for Agent Assist](https://www.youtube.com/watch?v=9AWsMYfaMjY)

SPEAKER: Welcome to planning for Agent Assist. Our objectives here include understanding the key architectural considerations that need to be taken into account when planning to implement solutions with Agent Assist. First, what is Agent Assist? Agent Assist is a CCAI solution that empowers human agents through the power of AI. Imagine human call center agents equipped with a digital sidekick that offers in-the-moment assistance, guiding them through complex customer interactions. The core idea here is productivity. With Agent Assist, your human agents can handle more queries more efficiently. Agent Assist speeds up your call center agents' response time and lifts the quality bar of each customer and human agent interaction. A number of key considerations are required when you plan to implement Agent Assist in a contact center. In order of priority, the decisions include-- what Agent Assist features will be used? How will input chat or audio be sent in to Agent Assist? How will responses be presented to human agents on their agent desktop? And lastly, how does Agent Assist integrate with other GCP components and other CCAI solutions? Let's explore at a high level how you can answer these questions. Agent Assist offers a powerful suite of features to enhance the level of service that your human agents can provide to your customers. The features include-- Smart Reply and Smart Compose, which streamlines chat interactions by proposing accurate and contextually appropriate responses, saving precious time for both agents and customers. There's also Generative Knowledge Assist, which provides agent-facing gen AI agents and proactively surfaces generative answers with relevant knowledge articles. Baseline LLM summarization offers real time abstractive call summary with customizable focus areas and writing styles. Sentiment analysis allows you to better understand customer interactions at a deeper level by detecting the customer prevailing emotions, both positive and negative, during the interaction. And finally, the live transcription feature transcribes every word of the interaction between the customer and the agent in real time. Let's break down how Agent Assist processes customer interactions and provides support to agents. First of all, input can come in the form of chat or voice. Let's understand the chat integration process first. The customer's chat client and the agent desktop are both participants in the conversation. The chat back end server, pictured here as the customer serving stack, integrates with Agent Assist using Dialogflow APIs. In the first step, the customer initiates a text chat, which is then transmitted to the API via the customer serving stack. Following this, transcripts and recommendations are relayed from the API to the customer serving stack based on the input text. Finally, in the last step, the customer serving stack transfers the information to the agent desktop. Now let's see the second type of input integration, which involves the integration process for voice input. This method offers two approaches, one through gRPC-based API integration and the other via SIPREC-based integration. To integrate Agent Assist using gRPC, first establish a conversation profile and initiate the conversation using Dialogflow APIs. Then, define participants and their roles-- human_agent, automated_agent, or end_user. To enable raal-time transcriptions for the customer or human agent, utilize Dialogflow's streaming analyze content method to transmit their audio stream. This process will seamlessly provide those real-time transcriptions and enable Dialogflow to generate relevant suggestions for the agent. Now let's see another type of voice input integration. This is facilitated through a SIPREC endpoint, a protocol that you can use to establish recording sessions and report metadata. When a customer calls a company's support line, the session border controller, or SBC, can use SIPREC to fork a copy of the audio stream to Google Telephony Platform, or GTP. GTP forwards this stream to CCAI and Agent Assist, which analyzes the conversation in real time using speech to text, or STT. Based on this analysis, Agent Assist generates relevant suggestions for the human agent. These suggestions are delivered to the agent's desktop application, either through REST APIs or by subscribing to the relevant Pub/Sub topic. We hope you now have a good overview of the two main ways of integrating customer infrastructure to Google's Agent assist. Let's finally discuss what the end-to-end architecture of an Agent Assist integration may look like. Use border controllers to minimize the path between participants when managing calls that use human agents, and use Google Cloud's SIPREC endpoint to duplicate conversation media streams being sent to Agent Assist. SIPREC offers reduced latency compared to gRPC API integration. Its global endpoint intelligently routes connections to the closest server, and regionalisation further minimizes delays. This is especially beneficial for non-streaming gRPC APIs that send audio in bulk and the streaming API, which sends audio in chunks. The primary advantage of SIPREC integration is that it allows for real time forking and transmission of the audio stream to Agent Assist.

### Quiz - [Planning for Agent Assist Quiz](https://www.cloudskillsboost.google/course_templates/1002/quizzes/523153)

## Planning for Conversational AI Conversational Insights

After completing this module, you will have knowledge of the key architectural considerations to account for when planning to implement solutions with Insights, as a standalone solution or in conjunction with Conversational Agents and Agent Assist.

### Video - [Planning for Conversational AI Conversational Insights](https://www.cloudskillsboost.google/course_templates/1002/video/523154)

* [YouTube: Planning for Conversational AI Conversational Insights](https://www.youtube.com/watch?v=rIo_UjWOG2s)

SPEAKER: In this section, we'll cover the key architectural considerations required when planning for the implementation of CCAI Insights. Our objectives for this section are to-- understand the preliminary decisions required to plan for an Insights implementation; discover Insights' key features and how they can be integrated with Dialoflow CX, Agent Assist, and other cloud components; and review the target user personas that can get the most value leveraging Insights. Let's dive right in. When planning for a CCAI Insights implementation, it's important to ask yourself four key questions. First, what problem does Insights solve for my organization? Next, what features will be most valuable for my use cases? You also need to determine how Insights integrates with other GCP components and other CCAI solutions. And lastly, which user personas does CCAI Insights solve for? Contact centers generate large amounts of data on a daily basis in the form of call recordings, chat transcripts, and conversation metadata. These data sets are a rich source of crucial information, but extracting insights out of this large amount of data can be a daunting task. This is where CCAI Insights can offer significant value for contact center management. CCAI Insights uses Google's large language models, or LLMs, to transform your contact center data from Insights into action. Here's how CCAI Insights works. First, input data is uploaded, in the form of audio recordings or chat transcripts. CCAI Insights then converts the audio files to text, and sends the chat and audio transcripts to sensitive data protection for processing. Within Insights, information can be extracted, summarized, analyzed, and highlighted to inform various metrics, such as customer satisfaction and agent quality. Topic modeling is for discovering various topics or areas of conversation, also referred to as call drivers, between contact center agents and end users. Highlighters capture relevant segments of a conversation that apply to a particular area of interest. A smart highlighter is pre-configured with a set of phrases like "authentication info," "check issue resolved," and "confirm issue resolved," while custom highlighters can be created to capture any custom keywords or segments. While analyzing the conversation, Insights provides sentiment analysis and LLM summarization of a conversation. It also extracts important entities like price, model number, and so on. Insights Console also enables users to search any conversation based on transcript, keywords, agents, metadata topics, highlighters, summarization, entities, and more. Such data can then be leveraged to take action, like providing agent coaching, inform the development of a virtual agent, or generally improve contact centers' workflows. So how does this magic work behind the scenes? There are multiple ways to ingest conversations into CCAI Insights. There is a live path that ensures that as soon as conversations are completed in Dialogflow CX Virtual Agent or Agent Assist, they are ingested into Insights automatically. We can also enable integration between CCAIP and CCAI Insights. This sends audio files or transcripts to a Cloud Storage bucket which can be used later by Insights. We can also ingest conversations by directly uploading the audio files or transcripts in Cloud Storage bucket and then importing them when required within Insights. All the paths to ingest conversations into Insights use speech to text for transcription and sensitive data protection for data redaction. Once conversations are ingested, we can apply topic modeling, smart and custom highlighters, sentiment analysis, summarization, entities extraction, and more features into Insights. We can then export them into BigQuery to connect with a custom dashboard on Looker. This exported conversation in BigQuery can also be used as a data source to build ML models on Vertex AI. There are several personas that can make use of the data extracted from CCAI Insights. The first persona is the customer experience leader. Their goal is to improve the customer experience with the contact center. Their pain points include agent training and turnover and understanding customer history. The customer experience leader wants to analyze conversations, establish informed best practices, and discover new uses for gen AI. So they'll mostly benefit from sentiment analysis and LLM summarization, which showcases metrics like customer sentiment, satisfaction, issue resolution, result, and more. The second persona is the contact center operations manager. Their goal is to predict workforce needs and to ensure that staff and tools are in place to handle call center volume and objectives. Their pain points include forecasting and scheduling. Their desire is to use precise, AI-based planning to reduce burnout, and to assign the correct training courses to staff members who need them. Topic modeling, along with metadata features like turn counts or conversation length, are great features that appeal to this persona. The last persona is the agent supervisor. Their goal is to ensure that agents are handling conversations effectively and meeting contact center goals. Their pain points are real-time awareness of agent performance, personalized coaching, and agent burnout. The agent supervisor wants to use personalized data to help individual agents improve and boost job satisfaction, so they'll benefit greatly from the ability of Insights to generate a conversation summary, create a mapping of agents and topics successfully handled over time, and to highlight important parts of a conversation, like if an agent verifies a customer's account information correctly.

### Quiz - [Planning for Conversational AI Conversational Insights Quiz](https://www.cloudskillsboost.google/course_templates/1002/quizzes/523155)

## Conversational AI Deployment and Operations

This module will explore the key deployment and operational considerations for the ongoing launch and maintenance of your Conversational AI solutions, inclusive of a release management pipeline and a process for release automation.

### Video - [Overview](https://www.cloudskillsboost.google/course_templates/1002/video/523156)

* [YouTube: Overview](https://www.youtube.com/watch?v=-wMvhX2zO1U)

SPEAKER: In this section, we'll explore the key deployment and operational aspects that will help you launch your CCAI solution and keep it up and running. The objectives for this section are to-- define the key developer operations required for release management, explain how to select tools to automate release operations, determine how to extract useful information from your data, and create a plan for outages with disaster recovery and business continuity. Let's get started. Two key decisions are generally required to set up our DevOps for release management. First, how will you manage your environments for development, testing, and release? And second, what interface will be used to differentiate between normal and anomalous operations and to measure performance? Let's see how we can answer these questions. This diagram is an example of a workflow for managing development processes within non-production environments. As you can see, multiple flows can move through this process, both in parallel and independently. This means developers and release managers can collaborate on various features or updates simultaneously. The use of distinct environments-- like draft, unit testing and ready to merge-- supports these parallel efforts and helps to ensure the quality and stability of the final product. By carefully overseeing each development phase within designated environments, developers and release managers can identify and fix issues early on. This ultimately expedites the development process, even with multiple work streams occurring at once. The goal is to produce a "golden artifact," a thoroughly tested and validated release candidate ready for a production deployment. Once you have your golden artifact, it's time to launch to production. There are two considerations you may want to take into account. First, roll out your new version to production in a gradual manner whenever possible. For example, by starting with 1% of the traffic and increasing it gradually until you are at 100%. Second, your production environment should be fully automated, with human intervention happening only in emergency situations, also known as a break-glass intervention.

### Video - [Automation of Conversational AI infrastructure](https://www.cloudskillsboost.google/course_templates/1002/video/523157)

* [YouTube: Automation of Conversational AI infrastructure](https://www.youtube.com/watch?v=r9k_vhMZ1aM)

SPEAKER: Let's learn more about how to leverage automation to manage your deployment process and CCAI infrastructure. What tools are available to automate release operations and maintenance for Dialogflow CX agents? The Dialogflow API, the Dialogflow Client Libraries, and the SCRAPI Python Scripting API. Let's dive into each of these. Dialogflow has multiple API versions, which should not be treated like product versions. Each version coexists and targets different ways of working with different Dialogflow resources. So version 2 should not be considered older and in need of replacement by version 3. If you are considering leveraging Dialogflow's public APIs to manage your operations, then there are several factors that you must keep in mind. First, Google Cloud's Dialogflow APIs are fully featured. You can create and use tools that leverage these APIs to automate and reconfigure deployments. Also, these APIs are designed with Remote Procedure Calls, or RPCs, in mind, rather than RESTful design. So the Dialogflow APIs can be challenging to work with if you are mostly familiar with RESTful API approaches. The client libraries work in a comparable way to the APIs, allowing you to access the APIs from some of your favorite programming languages. And finally, you can enable your application to use your own custom libraries to call the Dialogflow API service. If that's your preferred option, then please refer to the Google Cloud documentation website for the API requests that work best with your environment. It's important to understand that Google's APIs undergo a series of operational states to ensure their stability and effectiveness. Each API version has its own life cycle, which includes three main stages. Generally available-- this stage represents a stable and supported version of the API. Enhancements are made, but no breaking changes are introduced without prior notice and a specified timeline. Beta-- in the beta phase, new functionality is being stabilized. Based on real world usage, we may make enhancements or changes to improve the API. Support is gradually being implemented. Alpha-- alpha APIs introduce innovative ideas that may still require refinement. They are supported exclusively by Google engineering and may not function as expected in all cases. Over time, older APIs may become deprecated, accompanied by a phase-out schedule. Additionally, as products evolve, features from older APIs may be integrated into newer ones. In short, Dialogflow native APIs are a great way to access Dialogflow, but they can be challenging to use. A common alternative to Dialogflow APIs is an open-source API called SCRAPI. SCRAPI, or Dialogflow CX Scripting API, is a high-level Python API to simplify the experience of building, developing, and maintaining Dialogflow CX agents. SCRAPI is an ideal tool for automating release operations for your Dialogflow CX agent and handle a significant portion of the underlying complexity. It does this by allowing you to write cleaner, more concise, and inherently Pythonic code that can greatly empower you to focus on the core logic of your automation tasks. You may be asking yourself, why choose SCRAPI over building Dialogflow agents yourself from scratch? SCRAPI handles authentication and regionalization under the hood. It reduces the amount of code needed when building your agents, and it empowers you to work with data in familiar and intuitive Python structures, such as lists and dictionaries. SCRAPI also offers a suite of powerful extensions that seamlessly integrate with the tools that you use every day. These extensions include pandas data frames, Google Sheets, webhook building and cloud functions, and advanced machine-learning capabilities. These extensions enhance SCRAPI's ability to simplify your development journey, allowing you to focus on delivering value. You can also use SCRAPI to easily extract Dialogflow CX resources from an agent, such as intents and entities. You can then operate and modify these resources. Dialogflow can then write these modified resources back to the same agent or transfer them to other agents. You can store resources in an external version control tool such as GitLab, GitHub, Bitbucket, and more. This enables you to set up CI/CD pipelines for bot building, maintenance, and quality assurance. Another important consideration is that Google Sheets is a common tool leveraged by the operations team to manage and modify their intents and training phrases when tuning their Dialogflow CX NLU. So having support for Google Sheets with SCRAPI is an additional aspect that should make you consider leveraging this open API over other tools. Lastly, please keep in mind that Google Sheets integration with Dialogflow CX is bidirectional. This enables you to export and import data from Google Sheets directly to your Dialogflow CX agent in the appropriate format. Also under the hood, SCRAPI uses pandas dataframes to help support this integration. For more information on migrating data from Dialogflow CX to Google Sheets, refer to the Additional Resources document.

### Video - [Data insight extraction](https://www.cloudskillsboost.google/course_templates/1002/video/523158)

* [YouTube: Data insight extraction](https://www.youtube.com/watch?v=pRQFcnmCIl0)

SPEAKER: Now that we have an understanding on how to access Dialogflow programmatically, let's review some of the best practices for data insight extraction within Dialogflow CX. In addition to CCAI Insights, customers have the option of extracting data from Dialogflow CX directly into BigQuery. You can perform this operation by following three simple steps. First, set up a cloud data loss prevention API template to make sure that no sensitive data makes it into your BigQuery export. You should do this before you set up your export to reduce the risk of unwanted data exposure. Next, go to your Agent Settings in Dialogflow CX and enable both conversation history and BigQuery export. Finally, select the data set and the table to be used for the export. Remember that the Dialogflow agent and the BigQuery data set must be in the same project. This is an example of the schema your table should follow in order to receive exported interaction data from Dialogflow. The table needs to have the necessary fields to store basic metadata, such as your project and your agent IDs, but also full request and response objects, and so on. Partitioning the table, as shown here, helps minimize the impact of large analytical queries on performance and billing. This approach also allows you to define a data exploration policy that matches your needs. Make sure this table exists and has the correct structure before setting up your BigQuery exports. Keep in mind that Google Cloud platform also offers logging tools that can be very useful to debugging and troubleshooting your Virtual Agent. In Cloud Logging, basic filters allow you to perform a basic field search against any field except timestamp. For instance, you can find log entries that contain "foo" in any field, "foo" or "bar" in any field, and "foo" and "bar" in any field. Advanced filters allow you to do even more. You can use wildcard characters, range operators, and Boolean expressions. You can also search timestamp fields.

### Video - [Disaster recovery and high availability in Conversational AI](https://www.cloudskillsboost.google/course_templates/1002/video/523159)

* [YouTube: Disaster recovery and high availability in Conversational AI](https://www.youtube.com/watch?v=hVS5j4AG6U4)

SPEAKER: Now let's review some of the best practices for business continuity, disaster recovery, and high availability within CCAI and Dialogflow specifically. Dialogflow CX uses Google Cloud resilient and scalable global infrastructure, including its built-in protection and network. Despite having such robust infrastructure, incidents can still happen. Let's explore Google Cloud's recommended business continuity and disaster recovery best practices for your CCAI infrastructure. The first step should be to understand your organization's backup and recovery processes. This is a crucial part of developing an effective plan for business continuity and disaster recovery. Let's explore how, starting from business continuity. Business continuity plans, or BCPs, outline how essential services will continue despite disruptions. These plans can include provisions for data backup and other measures to maintain business functionalities. Building a solid infrastructure for CCAI requires stringent adherence to all backup and business continuity processes established by the organization. This ensures a coordinated and effective response to potential disruptions. As an example of how you can support business continuity, utilize a CI/CD pipeline for building and deploying Dialogflow CX agents. Also, make sure to collaborate with your operations and information security teams to identify any existing processes they'd like to incorporate in the plan. By doing so, you can ensure alignment and leverage existing capabilities to ensure the robustness of your infrastructure. Disaster recovery is a subset of the broader business continuity strategy to help you restore data after an event. Disaster recovery plans contemplate three types of measures. The first is preventative, which involves planning and developing familiarity with pertinent documentation. Next is detective, which establishes alerts that signal system or component failures for real-time monitoring. And lastly, there's corrective, which is inclusive of the procedures to prepare for and recover from outages. These corrective actions ensure swift data restoration, minimizing downtime and potential data loss. When planning for disaster recovery, it's also important to define two KPIs, recovery time objective, or RTO, and recovery point objective, or RPO. RTO refers to the maximum amount of downtime an organization can tolerate after an incident. It determines the time frame within which business operations must be restored to an acceptable level. RPO, on the other hand, specifies the tolerable amount of data loss. It defines the point in time to which data must be restored to meet business requirements, ensuring that critical data is not permanently lost. Establishing appropriate RTO and RPO values is essential for designing an effective data recovery plan that aligns with the organization's priorities and risk tolerance. The second best practice, as previously mentioned, is to configure your agent to use Cloud Logging. Once you enable Cloud Logging for an agent, you can browse these logs using the Cloud Logs Explorer. This enables you to use additional Google Cloud services, create metrics, and monitor for service health. Another recommended best practice is to use the Dialogflow CX built-in backup capabilities and APIs to export agents on a regular basis. Agent backups are complete snapshots of the current state of an agent. They are important for archiving the system and its components on a regular basis. This can considerably shorten RPOs in the case of an incident. Dialogflow periodically creates backups for all agents when any changes are made after the previous backup. If need be, you can also create agent backups manually. When you restore a backup, the whole agent is overwritten. We recommend that you periodically export these backups to a source code repository or to a Google Cloud storage bucket. For more information on exporting agents, including how to export using GitHub, in JSON format, and with the agent API method, see the appropriate resources in the Additional Resources section. The fourth best practice is to create a list of all the related services that Dialogflow uses. This includes webhooks and the external services that your webhooks rely on as dependencies. Knowing about these services will help you create more resilient webhooks and Dialogflow agents. When designing webhooks, you want to consider the following. How are the webhooks implemented, and where are they deployed? If your webhooks integrate with other services, make sure that you design the services to provide continuity and error reporting. Create your Dialogflow agent design so that it can handle latency and availability issues with downstream webhooks. And when your webhook depends on external services, find out about the latency and availability SLAs for these services. We'll go into more detail about webhooks in later modules of the CCAI Academy. As previously mentioned in the training, the number one recommendation you should keep in mind to ensure your Dialogflow CX availability is to use a global agent. With this guidance in mind, here are some disaster recovery scenarios and ways to recover from them. If there is a Google Cloud regional outage, use a global Dialogflow agent to direct requests automatically to a healthy region. If the back end connection between Dialogflow CX and the fulfillment service goes down, make sure that you configure your webhook timeout values to provide a graceful redirection to a live agent. The disaster recovery best practices include understanding the organization's backup and recovery processes, utilizing Dialogflow CX built-in backup capabilities and APIs to export agents, and assessing the scope of the Dialogflow and/or CCAI related services. In addition, the last disaster recovery best practice to keep in mind for your CCAI solution is to test out your disaster recovery and business continuity plans on a regular basis. When you conduct a disaster recovery and business continuity testing, make sure you schedule time with your operations team to simulate an end-to-end outage scenario. The scenario must include both your Dialogflow CX agents and all their related components, such as webhooks. This test will help you identify any gaps that need to be addressed. To sum up, reliability takes work, but it is the foundation of user trust. Reliability equals habit. If customers can't count on your virtual agent to work consistently, then they'll ask for a live representative instead. Broken features drive them back to traditional channels, so constant investment and defensiveness against degradation of reliability is paramount to ensure a global, resilient, and sustainable quality of your service.

### Quiz - [Conversational AI Deployment and Operations Quiz](https://www.cloudskillsboost.google/course_templates/1002/quizzes/523160)

## Security and Compliance

After completing this module, you will be able to describe the key pillars of Data Security, determine how to perform PII redaction, and enable other compliance protocols for Conversational AI solutions.

### Video - [Data security](https://www.cloudskillsboost.google/course_templates/1002/video/523161)

* [YouTube: Data security](https://www.youtube.com/watch?v=R0AmjN0XWQw)

SPEAKER: In this last section, we'll cover important security and compliance aspects for your CCAI solution. Our objectives in this section include learning about data security, redaction and removal of personal identifiable information, and other relevant compliance considerations. First up, let's review some data security considerations. The security of the data exchanged between systems in a contact center AI implementation must be prioritized. It requires a definition of how data will be securely transferred and received, and the parameters for data retention to ensure compliance with relevant regulations. Answering these two questions when setting up your data security strategy can help you establish the necessary framework to protect sensitive information while preserving the effective functioning of the system. Keep in mind that all data that flows within the contact center AI platform is encrypted in transit and at rest. Data stored by Dialogflow is encrypted at rest by default. Google uses the Advanced Encryption Standard, or AES algorithm, to encrypt data at rest. All data at the storage level is encrypted with AES 256 by default. End user messages to Dialogflow are encrypted in transit by default. Google Cloud Services accept requests from around the world using a globally distributed system called the Google Front End, or GFE. GFE terminates traffic for incoming HTTP, HTTPS, TCP, and TLS proxy traffic, provides DDoS attack countermeasures, and routes and load balances traffic to the Google Cloud Services themselves. All data stored within Google Cloud is encrypted at rest using the same hardened key management systems that we use for our own encrypted data. These key management systems provide strict key access controls and auditing, and encrypt user data at rest using AES 256 encryption standards. No setup, configuration, or management is required. In support of the data security strategy for your CCAI infrastructure, you can either enable or disable Dialogflow logging. Let's review the implications of both choices. When you enable Dialogflow logging, conversation data is saved in an internal Google Cloud Storage location. This data can include user utterance texts, bot responses, and conversation contexts. You can configure how long the logs are retained, typically between 1 and 30 days. You can request deletion of data by opening a deletion request. The data becomes inaccessible immediately and is physically wiped within 24 hours. And lastly, you can configure DLP API templates to redact sensitive data in real time, which offers sound governance and security practices. When you disable data flow logging, no conversation data stays persistent, but you can use fulfilment to save the data in a storage solution of your choice. Ultimately, the choice lies with you. However, Google recommends enabling Cloud logging in order to unlock the full capabilities and features available within Dialogflow and the related Google Cloud components.

### Video - [PII redaction](https://www.cloudskillsboost.google/course_templates/1002/video/523162)

* [YouTube: PII redaction](https://www.youtube.com/watch?v=A3b2Ce7VfjE)

SPEAKER: Now that we've talked about data security, let's zoom in on a specific category of data, Personal Identifiable Information, or PII. Let's review the mechanisms and best practices you can leverage to ensure that PII is redacted when deploying your CCAI solutions. Specifically, how can we make sure that sensitive data such as PII doesn't make it into logs or similar systems? The challenge lies in the fact that organizations often cannot determine when user conversations with virtual agents include sensitive information. So having a set of features to enable automated redaction is critical to alleviate the operational burden of ensuring that sensitive user data is protected. Such features are called parameter redaction and security settings. They greatly simplify data management within Dialogflow and in adjacent systems. Setting these features allows you to specify which parameters should be redacted, use the default DLP API inspection configuration, or create a custom inspection template that is unique to your environment and needs. As a result, when configuring a Dialogflow virtual agent, sensitive user data is handled in line with industry best practices and in accordance with security and compliance requirements. The Google Cloud service of choice for redaction of sensitive data is called Sensitive Data Protection. This service contains the Cloud Data Loss Prevention API, or Cloud DLP, which is used by CCAI. Sensitive data protection protects sensitive data while at rest or in transit to minimize the risk of unauthorized exposure. Sensitive data protection can identify sensitive information in the data, such as Social Security numbers, credit card numbers, or phone numbers, and either redact or hide it. This helps align to regional standards, as many countries have their own governing institutions which define the type of data that is considered sensitive and how it should be protected. For example, the European Union adheres to the General Data Protection Regulation, or GDPR, which sets legal guidelines on how businesses collect and process customer information. So how does the integration between sensitive data protection in Dialogflow work? During a conversation, Dialogflow CX sends user responses to the Cloud DLP API for analysis. The Cloud DLP API then identifies sensitive data patterns in the Dialogflow user utterance and agent response based on the redaction strategy for the Dialogflow agent. Cloud DLP either masks this data or removes it from conversation logs and transcripts. This redaction unlocks the ability to analyze data, develop apps safely, and prevents sensitive information from being stored or viewed inappropriately. For additional information on content methods for DLP, please refer to resource number 17 in the Additional Resources documentation at the end of the training. Please note that sensitive data protection uses the configuration options set in the Security Settings API. When enabled, Dialogflow becomes the data source and client that makes the DLP API request. For more information about sensitive data protection security settings, see the Additional Resources document at the end of the training. Also, keep in mind that the DLP API request itself is encrypted in transit, stateless, and not persistent. The DLP API also supports data residency, which allows you to process the data in the region of your choice. Lastly, the API response is synchronous, which means that it returns immediately after completing the request. For more information about redaction strategy, see the Additional Resources document at the end of the training. Now let's look at how you can configure sensitive data protection in Dialogflow CX for data redaction. First, you need to create an inspection template and a de-identification template. An inspection template defines the types of data that you want to redact. A de-identification template details the methods that you want to use to redact the data. And info types represent the objects used to enable PII filtering input data for inspection and de-identification. This screenshot shows an example of what these items look like in the Google Cloud Console. Once you have created the templates, you need to reference them in the Dialogflow Security Settings page in the Dialogflow Console. Next, select the DLP inspection template option. When configured, these security settings help enable data redaction and data retention. After you create the inspection template, it will appear in your agent's security settings dropdown menu. Select this inspection template and click Save. After you map the inspection template to your agent in security settings, the agent logs display redacted text for the parameters you defined. For example, if you have an inspection template that detects credit card numbers and you apply the template to your Dialogflow agent, then any credit card numbers detected in your agent's responses are replaced with a masking character. Now let's look at how to redact parameters. Parameters often contain data from user inputs, and they are especially interesting in the context of PII redaction. Parameters are used in Dialogflow to store and retrieve data. You can create parameters by defining them in the Dialogflow Console. Parameters are used for intent responses, parameter prompts, and the parameter value field. To set the parameters in Dialogflow that you want to redact, follow these steps. First, in the Dialogflow Console, go to the Parameters page. Next, select the parameter that you want to redact. Check the box for redact in log. And finally, click Save. Dialogflow now knows this parameter should be redacted. So far, we have covered PII redaction only in the context of Dialogflow CX. Next, let's discover how this works within two other main components of CCAI, Agent Assist and Insights. Redaction in Agent Assist works exactly like we have seen in Dialogflow for redacting or masking PII from live transcriptions. You can manage this feature in the conversation profile security settings. Within these settings, you can reference inspection templates and de-identify templates to define the specific PII data you wish to redact. Once enabled, Agent Assist will automatically redact the defined PII data in real time during transcriptions. Now let's look at PII protection in CCAI Insights. Before feeding transcripts into Insights, you can redact PII with the following steps. First, prepare both inspection and de-identification templates. Then use the API to add these templates into the configuration. Next, use CCAI Insights to transcribe speech into text by creating a custom STT recognizer. And keep in mind that this technique requires a telephony model. And lastly, configure redaction, speech, and analysis parameters for all upload conversation requests. If needed, remember that you can configure speech and redaction settings individually per request, which overrides the project settings. If you wish to manage the DLP API directly, you can also use the DLP Runbook. For more information about these topics, see the Additional Resources document at the end of the training.

### Video - [Other compliance considerations](https://www.cloudskillsboost.google/course_templates/1002/video/523163)

* [YouTube: Other compliance considerations](https://www.youtube.com/watch?v=5k2b7hLELvE)

Now let's turn our attention to other security and compliance considerations that Dialogflow CX is subject to in. An effort to help customers control the transmission and access of sensitive and proprietary enterprise data, we are offering a suite of compliance measures to help them launch features with trust. These controls aren't always needed, but there are at least four factors to consider. The first thing to consider is, what is the use case? Next, you need to determine if any personally identifiable information is being stored or processed. Then identify what sort of content is used in this use case. Is the content publicly available or internal only? Finally, are you serving customers in countries with specific data regulations? These answers will then dictate which security controls might need to be in place. Security controls are a requirement for all-new CCAI services, and they are based upon four key components-- data residency; access transparency; customer-managed encryption keys, or CMEK; and virtual private cloud service controls, or VPC-SC. Let's explore each of these in the next section. The first of these components is data residency, also known as DRZ, and it allows you to select the location of the data storage at rest. Customer core content is stored at rest and monitored for adherence to customer-selected locations with regression prevention enabled. Customer core content includes LLM content and tuned models, among others. In-use data storage hosts both visible and auditable customer operations inclusive of a direct user request, a user-scheduled operation, or an operation triggered by user-configured settings such as an auto scaling event or alert and any audited action visible via access transparency logs, cloud audit logs, or any decryption using CMEK. Data residency requirements and guarantees can be defined according to three dimensions-- data type, data state, and location type. Data types allow you to classify data according to a number of semantic types-- customer core content, customer service configuration, customer security configuration, customer-defined attributes, Google-generated customer metadata, or GGCM, and Google Cloud operational data. Independently from these data types, data can also be classified as personal. As per the General Data Protection Regulation, or GDPR, personal data is any information which is related to an identified or identifiable natural person. For more information on GDPR, see the additional resources document. Data states, also known as the data life cycle, divides digital data into three states-- data at rest, data in use, and data in transit. Some definitions of these terms commonly ascribe physical states to the semantic delineation, such as data at rest is on a hard drive or data in transit is in memory. However, it is important to note that Google and customer definitions are not always aligned, and it is therefore important to confirm the data residency requirements. When there is a question between two states for data residency compliance purposes, we recommend that you select the strictest definition. The strictness order is, from most to least, at rest, in use, and in transit. Finally, a resource's location-type attribute represents where you must instantiate or deploy a resource. For most Google Cloud resources, you can select the resource location. The recognized types of locations are zone, region, multiregion, jurisdiction, and global. Regions, multiregions, and jurisdictions are the most important types when considering data residency requirements. For more information on locations, see the additional resources document at the end of the training. Access transparency, also known as AXT, lets you receive real-time notifications as structured logs when a Google staff member accesses your data. The access transparency log entries include the following details-- the affected resource and action, the time of the action, the reasons for the action, for example, the case number associated with a customer support request, and, lastly, data about who is acting on the content, for example, the location of the Google staff member. For more information on AXT, please refer to the additional resources document at the end of the training. CCAI does not directly encrypt or decrypt data in or your clients' systems, so customer managed encryption keys, also known as CMEK, let you encrypt at rest data in Google Cloud Services using a key you or your client can manage in cloud Key Management Store, or KMS. This functionality lets you have greater control over your data and automatically integrates with CMEK-compliant storage. The prerequisite for using CMEK is that CCAI products require External Key Manager, EKM, validation. Refer to the additional documentation at the end of the training for more information, and if you are interested in activating CMEK for your project, please contact Google Cloud AI platform support. Please remember that, once CMEK has been activated, you cannot change the key or version used to encrypt your data. Once activated, you will only be able to use a single key for all CMEK-encrypted resources within a project. Also, it is not possible to convert existing resources that are not CMEK encrypted into CMEK-encrypted resources. The last security control component is virtual private cloud service controls, also known as VPC-SC. This component lets you control how your data or your customers' data can be accessed. It includes IP ranges and devices, and it is critical to prevent operations that could cause exfiltration. An example of where you might use VPC-SC is if your organization owns intellectual property in the form of highly sensitive data or handle sensitive data that is subject to additional data protection regulations, such as PCI DSS. Another example is if you migrate from an on premises environment to the cloud and one of your goals is to replicate your on-premises network-based security architecture. To protect your highly sensitive data, you might want to ensure that your resources can only be accessed from trusted networks. To mitigate data exfiltration risks, make sure to use fine-grained controls to ensure secure data exchange across organizational boundaries. Also, as an administrator, make sure that client access of the shared resources is segregated from privileged user access. Similarly, clients with access to sensitive data should only read public data sets but not write to them. VPC Service Controls enhances the security of your applications and services by controlling access to them from unauthorized networks. This helps protect against external threats, such as data breaches and cyber attacks. Additionally, VPC Service Controls provides fine-grained control over who can access your services, even within your trusted network. This helps prevent unauthorized access to sensitive data and services, even by malicious insiders or compromised code. There are also other additional benefits of using VPC-SC, as in, first, VPC Service Controls help prevent access to private data from unauthorized networks using stolen credentials. VPC-SC also helps prevent data exfiltration by malicious insider or compromised code. Another benefit is that, by controlling access to your services at the network level, VPC Service Controls ensure that your services are only accessible to authorized users and networks, regardless of the IAM policies that are applied. Finally, VPC Service Controls allow you to monitor and track who is accessing your services, when they are accessing them, and what actions they are taking. This information can be used for security analysis, incident response, and auditing purposes. To summarize, VPC Service Controls offers a robust solution for isolating resources within Google Cloud and VPC networks, ensuring network security. It extends perimeters to on-premises networks by way of authorized VPNs or Cloud Interconnect Landing Zone VPCs. This enables you to maintain strict access control to Google Cloud resources from external environments. Furthermore, VPC Service Controls allow for secure data exchange between perimeters and organizations, using customized ingress and egress rules. As mentioned, advanced access management is another key feature, which enables context-aware access to resources based on client attributes through the implementation of ingress rules. For more details on these use cases, see the Additional Resources section at the end of the training. Compliance with the Payment Card Industry Data Security Standard, or PCI DSS, is possible with CCAI and Dialogflow. Here is a summary of the essential steps involved in order to operate with PCI DSS compliance. First, de-identify PCI data using cloud-to-DLP templates to remove it from logs. This ensures that sensitive information is masked or removed during processing. Second, redact sensitive user input in agent using parameter redaction. By doing this, you prevent sensitive information from being exposed in the transcript. Next, remove data promptly by deleting or overwriting sensitive data as soon as it is no longer required retaining it unnecessarily increases the risk of exposure. Finally, strongly consider encrypting data with webhooks. This is essential if downstream systems are not PCI DSS compliant, as it ensures that sensitive data remains protected throughout its life cycle. In addition to the security controls, Dialogflow CX and its generative features are compliant with the following certifications. HIPAA, or Health Insurance Portability and Accountability Act, sets national standards for protecting the confidentiality, integrity, and availability of electronic-protected health information. ISO 27001 is the international standard for information security. It sets out the specification for an effective information security management system. ISO 27017 provides cloud-based guidance, along with seven new cloud controls that address responsibility between the cloud service provider and the cloud customer, the removal and/or return of assets when a contract is terminated, the protection and separation of the customer's virtual environment, virtual machine configuration, administrative operations and procedures associated with a cloud environment, customer monitoring of activity within the cloud, and virtual and cloud network environment alignment. ISO 27018 relates to one of the most critical components of cloud privacy the protection of personally identifiable information, or PII. ISO 27701 is a global privacy standard that focuses on the collection and processing of personally identifiable information, or PII. SOC 1 is a report which documents a cloud service provider's internal controls that may be relevant to a customer's financial reporting. This report is particularly useful for organizations that audit financial statements. SOC 2 is a report based on the Auditing Standards Board of the American Institute of Certified Public Accountants, or AICPA, existing Trust Services Criteria, TSC. The purpose of this report is to evaluate an organization's information systems relevant to security, availability, processing integrity, confidentiality, and privacy. And lastly, the SOC 3 report has been developed based on the Auditing Standards Board of the American Institute of Certified Public Accountants, or AICPA, Trust Service Criteria, or TSC. The SOC 3 is a public report of internal controls over security, availability, processing integrity, and confidentiality. More details about these compliance certifications can be found in the Additional Resources section at the end of the training. Congratulations on completing this training on CCAI architecture. And good luck building your solutions with CCAI.

### Quiz - [Security and Compliance Quiz](https://www.cloudskillsboost.google/course_templates/1002/quizzes/523164)

## Additional Resources

This module includes the list of additional resources that complement the course learning.

### Document - [Additional Resources](https://www.cloudskillsboost.google/course_templates/1002/documents/523165)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

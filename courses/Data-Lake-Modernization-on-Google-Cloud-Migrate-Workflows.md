---
id: 486
name: 'Data Lake Modernization on Google Cloud: Migrate Workflows'
type: Course
url: https://www.cloudskillsboost.google/course_templates/486
date_published: 2024-01-17
topics:
  - Dataproc
---

# [Data Lake Modernization on Google Cloud: Migrate Workflows](https://www.cloudskillsboost.google/course_templates/486)

**Description:**

Welcome to Migrate Workflows, where we discuss how to migrate Spark and Hadoop tasks and workflows to Google Cloud.

**Objectives:**

* Describe options on migrating Spark to Google Cloud
* Migrate spark Jobs directly to to Dataproc (“Lift and Shift”)
* Optimize Spark Jobs to run on Google Cloud
* Refactor Spark Jobs to use native Google Cloud services
* Convert a Spark job to a serverless implementation using Cloud Functions

## Migrate Workflows

Welcome to Migrate Workflows, where we discuss how to migrate Spark and Hadoop tasks and workflows to Google Cloud.

### Document - [Course Introduction](https://www.cloudskillsboost.google/course_templates/486/documents/449626)

### Video - [Introduction](https://www.cloudskillsboost.google/course_templates/486/video/449627)

* [YouTube: Introduction](https://www.youtube.com/watch?v=Lhx2wv9gnJ4)

Hello and welcome to Migrating Spark and Hadoop to Google Cloud. In this content will explore how to migrate Spark and Hadoop tasks and workflows to Dataproc, which is Google Cloud's managed service for running Hadoop workloads. First, we'll look at different options for migrating Spark workloads. Then we'll look at how to migrate those Spark jobs directly to Dataproc. That's what we call the lift and shift approach. After you migrate your jobs to Dataproc, the next thing that you want to do is to optimize them in order to make them run more efficiently. On Google Cloud when you're optimizing. One of the things that you might want to think about is whether you want to continue doing those jobs, using the Hadoop ecosystem or using native Google Cloud services like BigQuery or Data Flow. Last, we will take a Spark job that we've optimized and look at how to convert it to be a completely serverless implementation that is triggered using Google Cloud functions.

### Video - [Migrating Hadoop to Google Cloud](https://www.cloudskillsboost.google/course_templates/486/video/449628)

* [YouTube: Migrating Hadoop to Google Cloud](https://www.youtube.com/watch?v=QcXeyrnDSh0)

So the first part is that we will look at how to migrate Hadoop to GCP. The Hadoop ecosystem has been very popular for over a decade when it comes to processing large datasets datasets that meet one of three criteria either the voluminous they have huge volumes or they're moving very fast. They have very high velocity, or they have a lot of variety in the sense that they have structured data, they have unstructured data, etc.. And because Hadoop has been around for a long time and huge ecosystem has grown up around Hadoop, and you will find Hadoop workloads involving everything from Avro, which is a No. Five format, to Pig, which is a scripting language to MapReduce, which is the traditional Hadoop way of doing things written in Java and Yarn, which is a cluster management system, etc.. So when people talk about Hadoop, they're essentially talking about a combination of all of these technologies. However, over time, it's become pretty obvious that the best way to write jobs on Hadoop is to use Apache Spark. Apache Spark allows you to do things in a much faster way than more traditional technologies than Hadoop, such as big or such as MapReduce. So when you go into a client site, you would often find that the majority of workloads are in Spark, and which is why in this module we'll focus on migrating a Spark workload, although the principles are going to be the same, regardless of which other kind of technology that you're dealing with, but where they are different. We will go ahead and will highlight those to you. So, first of all, why are clients looking to migrate their Hadoop clusters? Well, that's because on premises, their Hadoop clusters have a lot of limitations. What kind of limitations? Well, the first and major thing is that it's not elastic. Right. What we mean by elastic is as the number of things that you want to do on a cluster grows, you want this cluster to be bigger, to be able to process things, to do things as fast as it was doing it before. But in order to do that, the cluster needs to be able to scale fast. In other words, you need to be able to add a machine and get it online very fast. But in the Hadoop ecosystem, the way a MapReduce job works is that it is fast because every machine in a distributed system processes data that is local to that machine. But. But if you want that data to be local to the machine, when you add a new machine, that new machine doesn't have any data on it. So you have to get the data onto to that machine as well. So that is a huge problem with an on premises Hadoop cluster because you have to move data around every time you add new machines. So that also means that you tend to have capacity limits. So if you have a Hadoop cluster that has 30 machines in it, there is a certain amount of data that it can process. And when your data grows beyond that certain amount, you not only need to add new data, you need to actually move data around to make it be processed by all of those machines. And this lack of separation between the storage and compute resources is a huge business problem because very few businesses have this case where the computational requirement and their data requirement grows at the same pace. Very commonly, you will find that you have a certain amount of data and you want to do more things on that data. And because you want to do more things on that data, you want more compute or maybe the things that you're doing on the data remain pretty much the same, but you keep getting more and more and more data, and so you need to basically store that data in place and that becomes a problem. And because the rate of storage and the rate of compute growth is usually different, not having a separation between storage and compute makes it really hard to manage a Hadoop cluster. And it's not just this problem because most Hadoop clusters and most organizations are not limited to a small group of people or a small business organization. Instead, they're spread out over multiple business units. And now all these business units have these problems. So it's not just that my sales organization has a capacity limit. It might also be that the marketing team has a new campaign that they're going to run, and they're running into the same capacity limits on the cluster that the sales team is using or that the engineering team is using. So when you have an on premises system A lot of companies that are using on premises, Hadoop systems are looking at moving to the cloud. And there are many ways in which using Google Cloud platform can save the clients time, money and effort compared to the on premises Hadoop system that they're currently using. So many times when a company has an on premises Hadoop solution and they're basically looking at that end of life, or they're looking at replacing those machinery or replacing a license. They say, Well, nope, forget about all this. We're not going to do things on premises anymore. We're going to move to the public cloud. And when you're moving to the public cloud, Google Cloud provides you amazing value. So on Google Cloud, when we bring in a Hadoop workload, we bring it into a product called Cloud Dataproc. And Dataproc is essentially a product that's built to make it easy to migrate a Hadoop workload. BigQuery is a product that is optimized for running a data warehouse. Dataproc, on the other hand, is optimized for running Hadoop workloads. It's a migration product in itself, which means it has built in support for Hadoop workloads that run on premises can work unchanged on Dataproc. And the reason that you do that, you move it to Dataproc is that the the many of the problems that we talked about in terms of managing capacity, managing hardware, etc., they kind of go away because Dataproc provides you managed hardware configuration and it provides you very importantly, simplified version management. One of the biggest problems on the Hadoop ecosystem is that every one of those tools is an open source tool that's developed to its own different timeline. And it can be a really hard problem to go find the correct version of Pig and Spark that work well together, r Hive and Yarn that work well together. And then you basically taking all of the workloads that you have and you're trying to basically figure out what version of all of these will keep things safe and correct. Well, on Dataproc, it's a lot simpler because Google Cloud manages just the versions for you. And every Dataproc version consists of a version of all of these open source libraries that work well together. So it simplifies the version management. So instead of having to manage the versions of each individual Hadoop technology, you only need to think about which version of Dataproc are you using. And finally, and this is what we will get into when we look at optimization of data proc you, it gives you the ability to flexibly configure based on jobs and by based on the kinds of things that you need to do so that you can optimize your storage and your compute separately. So if someone is going to be moving their Hadoop workload to GCP, what does it actually look like when you go into that client site? Do you go All-In? Do you say, okay, I'm going to take your Hadoop workload, I'm going to modernize it, I'm going to go fully serverless. Or do you take a more of a phased approach? Well, the phased approach is less risky. And so that's the thing that we're going to recommend to you. So what does that phased approach look like? Well remember that the client is starting from an on premises system and on premises they probably have some kind of a vendor distribution that's installed Cloudera, Hortonworks, etc. And as we talked about on premises, they have a cluster which is tightly circumscribed. They have 30 machines, they may have 7000 machines, but they have a certain number of machines. And those machines have very specific amount of storage associated with that. And that entire cluster is very highly controlled but it's not flexible at all. Right. As we talked about, every time more data comes in, they have to realize that they have to add more compute and then they have to basically move data around. They have to do all of the management. They have to manage the versions and all of that stuff. So that's the situation that they're in. The first phase that we will talk about is to minimize disruption. So we want everything to work as is. So what we'll do is that we could take what they are running on premises and lift it and shift it and put it onto Google Cloud. But even this by itself can provide a lot of value, right? Because it can basically provide cloud based disaster recovery or business continuity. Right. So even though we're just taking we're just doing a lift and shift and we're not changing anything about the code base or how the data is organized, we're still going to be tightly coupled in terms of compute and storage. We still get some of the benefits of the fact that we're running on the cloud, that now you have the opportunity to run this thing in multiple regions, for example, but also because now that the system is on the cloud, provisioning becomes a lot easier. And because provisioning becomes a lot easier, it's possible to support new use cases like data exploration, etc., without affecting what's happening in production. Okay, the next phase, once you have it lifted and shifted, is to think about how do I decouple, compute and storage? Again, the primary problem with running a Hadoop workload on premises is not that it's on premises, it is that there is. There's no way to do separate out compute and storage on Google Cloud. If you move your data out of the Hadoop system, out of HDFS, out of the Hadoop file system, and you move that data into cloud storage, now you've separated out compute and storage and your Dataproc cluster is reading your data off cloud storage. And now this data cluster can be multitenant or it can be single tenant, and it basically gives you this ability to run multiple clusters on the same data and which allows you to then look at optimizing things and thinking about right sizing each of these clusters. So if you have a job that only runs for an hour, you might be able to have the cluster up for only an hour. The other things, of course, is that you can now think about things like availability, running it in multiple regions, being able to position this thing from this, optimize phase to a re-architect phase, which is a final phase that we'll talk about. And in that phase we will look at all these workloads that we're running and all these different multi-tenant clusters, and we'll start looking at how to evaluate them, figure out how, which kind of Dataproc clusters to move into and scope these clusters to be very specific jobs. Right. So we want job specific clusters that spin up and spin down just as needed. So in the optimized phase, we are basically looking at taking the current cluster configuration and figuring out the right sizes, etc. and the re-architect phase. We're actually going all in on all the measurements that we have done in the optimized phase. The final phase is once you have it architected, you're running it in cloud data. And many customers never do this. But if the customer wants, we can now go from running a Hadoop workload in a better way to going completely cloud native, making use of fully serverless systems, making use of a managed data warehouse, making use of managed data pipelines, making use of streaming analytics. Right. So you can think about how to build at data warehouse that's fully managed, that's fully serverless, and that gives the client a lot more abilities than they could do in the past with their on premises system. But we talked about this as a phased approach, but it does not have to be serial. It's not that you have to do a lift and shift before you do the optimize, right? So in many cases you do it based on the workload. You look at the risk associated with the workload for workload. That is very, very, very risky and something that needs it's HDFS. Maybe you will stop at phase one. You never go any further than that. Or maybe if the workload is SQL analytics, you will look at the code and say, I'm not going to have to migrate all of this code over to Dataproc. I will just take the Spark SQL statements and write them into BigQuery. Maybe just skip all this migration, go from phase zero on premises straight to the cloud native phase, which is BigQuery. So you do this based on a workload, but it's helpful to think of this as a phased process and explicitly think for every workload which phases you're going to implement, because that helps you set the milestones that help you set the delivery, and that helps you set expectations at the client site.

### Video - [Lift-and-Shift to Dataproc](https://www.cloudskillsboost.google/course_templates/486/video/449629)

* [YouTube: Lift-and-Shift to Dataproc](https://www.youtube.com/watch?v=OQu9ZAo4sIs)

So let's look at how to lift and shift to cloud data. Remember that on premises the client probably has a monolithic cluster, one big cluster that's serving multiple lines of businesses. So when you're moving to cloud data proc carefully. Look at this because it's very common that different lines of businesses actually need different datasets. So you don't need to move to one big Dataproc cluster. You can do a little bit of optimization even during the left hand shift and move to maybe three, maybe four Dataproc clusters where each data cluster corresponds to a single line of business. Why is this a big deal? Well, because it actually makes life a lot easier on the client site, right. When they have a single monolithic cluster. Now, it's not obvious who's using how much of that capacity. And there's a lot of problems with chargebacks and billing, etc.. If you move it to multiple Dataproc clusters, you can put them on different billing accounts and make life a lot easier for them. Start demonstrating value almost immediately. Not technical value, but business value. So what you can do is that you can basically take this on premises cluster, take all the associated workloads and move them to a single Dataproc cluster. It's not the best solution. It's definitely a possibility, especially as a first step. But I recommend that you actually explore a little bit about the client business problem and lift and shift not to a single Dataproc cluster, but to maybe a handful of clusters where these clusters contain workloads that don't have any data in common. Okay. So think multiple clusters. But ideally, these clusters are job specific, but we will get there at the start, try to at least make them line of business specific. Right. So think about billing accounts. Who pays for it? Which data do they need? And as long as two lines of businesses are basically processing completely disparate workloads with nothing shared, you can actually put them on to different clusters, make life easier on the client. If you're going to be migrating, there are some critical information that you need to identify. Right. So you're going to be going and looking at an on premises cluster and you're going to say what open source components are they using today? Which of those components do they actually want to maintain long term? Many cases, just because they're using something doesn't mean they want it retained. You want to go find the owner for every job that's running, who's running it? Do they really need it? Who's going to scream if that doesn't work anymore? Right. To figure out whether it's being used. And also for every open source component, it's being used on the cluster. What is the versioning? Which version of Spark are they using? Which version of Hive are they using? And the update expectations. In many enterprises, they're not using the latest version of Spark or HIVE and they don't want to update it for another six months, another year, because the update cycle for the team that's going to do this update maybe six or six months to a year away. So you may well have to think about which older version of Spark or whoever know whatever you need to run on your Dataproc cluster and how long you need to run it on. So go ahead and identify it. This note, this start. The second thing that you want to note about is the hardware. So where the first part, the open source components were, those are all about the software that's running on the cluster. The second thing is about the hardware characteristics of the cluster. Where is the data? Is it HDFS? Is it Hbase? Which jobs are reading that data? What kind of peak data throughput? And what kind of average data throughput is needed? Right. So what we mean by this is that we say how much data are processing and usually it'll turn out that you're basically processing data as it comes in and you basically tend to have a lot of data, not maybe during work hours and not much data coming in during night time, for example. So you want to basically have this idea in mind of what the usage patern is. The other thing that you want to keep in mind is how often is this data updated? If you have a reporting system, maybe the data comes in once a month, right? And you want to be aware of when in the month it comes in, because at that time there's going to be peak data usage. The next thing that you want to think about is that data. Where is it stored in terms of hardware? Is it stored on a hard HDD or is a door stored on a solid disk? What kind of CPU, what kind of RAM is on this cluster? And remember, the cluster is a bunch of different machines. So you may have to go inventory that entire set of machines and then look at the security and access control, who's able to access the cluster, who's able to read the data, who's able to write data? Right. And who can control jobs, who can set them up? Because you will have to map the security and access control that's on premises to cloud IAM to cloud identity and access management. The third thing that you want to think about and you want to find out right now, just think about find out is that timeline right? What is a quota? Right. What is the capacity prerequisites? How many jobs do they want to run? And also talk to the client, whether they want this incremental or do they want a forklift? Do they want to move that data piece by piece or do they want to move the data all at once? Sometimes this may be come down to the technical requirement. If you have a workload load, you need to move all the data that the workload relies on. So there's a data dependency here as well, but sometimes there's also a business dependency. So based on these, you might come up with an intermediate term architecture, maybe have an architecture where for a period of time the jobs are running in, both on premises and on cloud before you move them finally over. Okay, so in phase one, in the lift and shift architecture, you basically have these machines right there and you might say, I'm going to basically take the vendor distribution, Cloudera Hortonworks and run them on Compute Engine. Or you might say, okay, we're willing to will live with the risk and basically remove the vendor distribution and run it directly on Dataproc. And you will make this distinction based on the versions of software that are being actually run on premises. If the mapping is really close to a Dataproc version, the risk is really low and you can move directly to Dataproc. If, on the other hand, they're running a very, very, very old version of Spark and it's not really supported on Dataproc. This might be a first first de-risking option. Run it on the same version of Cloudera. Hortonworks that you're actually running on premises. Think about which region, which zone you want to run these in. But the important thing about this architecture is that the data is stored in HDFS. So whether you're running it in Dataproc or whether you're running the vendor distribution in compute engine, the Hadoop cluster, that itself has its HDFS on it and it's reading the data from each HDFS. So how does that data get there to its HDFS? Well, you have to migrate the data. So on premises, you have a data center and you have the cluster there and you basically looking at how to migrate the data to HDFS. Well, you can't just take the data from on premise and put it directly on the persistent disk drive that you may be running your HDFS on. What you have to do is that you have to stage the data, so you have to put it on cloud storage first. And the reason you do the migration to cloud storage is that cloud storage basically provides you multithreaded resumable uploads. It gives you a cloud transfer service to move large amounts of data. So it's a much better migration product for data than HDFS. So take your data, stage it on to cloud cloud storage and then from cloud storage. Now all your data is behind the Google firewall and then you can copy it over to the HDFS file system that you've set up on the Hadoop cluster. Now when you're setting up the HDFS file system, you will have to make a choice. Should you use HDD or should you use SSD? Right. Solid state disks are faster and normally you would use a solid state disk if on premises a client is using a strong, solid state disk. Right. Basically because you want to show very similar performance and the client will often want the same kind of performance characteristics as they had on premise. So you use a solid state disk if you need fast random I/O or fast sequential I/O, but it is more expensive, but it is probably a cost. It's something that they have decided they're going to be willing to pay because they need that speed on their workload. But more many workloads don't need that kind of speed because Hadoop workloads tend to be reporting workloads, etc., and they're not that time sensitive. And in that sense, you often see Hadoop clusters where the HDFS is a hard drive. HDD Right. And there the random I/O is going to be slow but sequential I/O like it is going to be reasonable. And because most Hadoop workloads read data up top to bottom, right file by file, sequential I/O is what you care about. And the performance of an HDD is fine enough and because it's so much cheaper, that tends to be the thing that many people choose when they look at running Hadoop workloads on compute engine. Okay. The the default, therefore, on Dataproc is a persistent hard drive. The reason they choose a persistent hard drive is, number one, it's durable to machine failures of the machine goes down and it comes back up. That data on the persistent hard drive is still there and that's important, right? Because the chances of machine failure, right. When once you have a cluster that is many thousands of machines, the chances are relatively high. Some machine somewhere is going to fail. And you want things to be durable and you want things you don't want to lose. You don't want to have to rerun the things that you've already run. Persistent hard drives, unfortunately, are computationally intensive. That's because of where a persistent hard drive is implemented is that it's actually a colossus. It's actually something like cloud storage. And so whenever you write on Colossus, you basically are writing three copies. And so if you're going to be using it for HDFS and Hadoop by default says that you need at least a replication factor of two. In reality, every time you write, you're actually writing six copies minimum. Okay, so it's pretty expensive. The other thing to keep in mind is that the size of your disk controls the IO, the larger the disk you buy, the faster the disk is smaller disks are slower, but you cannot assign a really large disk to an underpowered VM. So you need to basically also get a larger VM in order to get a larger disk and in order to get faster IO. So you want to keep in mind that all these three things are related. You cannot just get fast IO on a small disk. Okay. The one problem with the persistent hard drive is that it can only be accessed from a single note. You take a persistent hard drive and you attach it to a node and you can only read and write from that node. The second option for a compute engine disk is a persistent, solid state disk. As we talked about, it is faster than a persistent drive. But as with the persistent drive, the IO scales with this size and VM and it is somewhat more expensive. So basically the tradeoff here is a persistent hard drive is cheaper, a persistent, solid state drive is faster. The third option and the fastest is a local SSD. The local SSD is even faster than a persistent, solid state drive, but it is more expensive than a persistent SSD. Okay. But often. Right. If you need that increased speed and your workflow requires a lot of IO, the increased price is okay because your job runs faster and therefore you can shut the cluster down faster. So you have to actually do a measurement. Does the increased cost of the hard drive, is it made up by the less amount of time that you're running the job? The thing to remember with the local SSD is that it is not durable, right? If the machine goes down all the data on the local SSD, it's gone now, when you're running it on cloud Dataproc, we basically said we are moving a workload. You have to basically go do an inventory of what kind of open source technologies are running on the on premises cluster. So here's a mapping. Let's say you look at what's running on the on premises cluster. Some of those technologies are already installed on Dataproc. So just go look at the version. Make sure that the version version matches your needs. If in a few cases though, you might want to basically think about modernizing in place. So if the client is using its Hbase, maybe you don't want to continue using Hbase. You want to you want to think about using Cloud Bigtable instead. Maybe if the client is using Apache Beam, you want to basically think about running it on Cloud Dataflow, which the managed service on Google Cloud, maybe if they're using its Hcatalog, you want to think in terms of using Cloud SQL instead. If you're using Hive, maybe think in terms of not converting that workload into BigQuery, right? So in a few cases, you might want to basically think about converting it, but for the most part, you will take your open source workload and that open source software is available on Dataproc. So you will you're just doing a lift and shift and running it as is. So whenever you basically do a lift and shift, you have to ask yourself a few questions. And these are questions are going to going to be the same whether you're running a Spark or Hadoop workload on premises, are you running it on the cloud and the reason you ask these questions is that when you run into performance problems, if you run into performance problems, these are going to be helpful for you to troubleshoot the problems that you're running into. So questions that you need to ask. Number one, where is your data? Where is your cluster? If your data is stored in EU and your cluster, the compute instances are in North America. Well, we haven't solved the speed of light issue. It's going to be slow, right? It's going to have to have to move the data back and forth. So make sure that your data and your cluster are in the same region thats super important right. If you want high performance, they need to be the same region. And that's the only way that you can take advantage of the high bandwidth connections between the compute and storage. Secondly, what's happening to your network traffic? You have to go look at what kind of network rules are in place. Are you using VPN gateways? This is particularly important if you're basically doing a hybrid architecture and you have some data on premises that's being constantly mirrored to the cloud. Is it going through a VPN gateway? Is there a bandwidth throttle in place Are They're doing some kind of a traffic sniffing. Are there virus checks happening? Right. So look at what's happening to the network traffic because that that speed of transfer is going to affect the speed at which the end result appears. Then consider the actual data itself. How is it stored? What are you reading? Hadoop workloads work best if the number of input files is less than about 10,000 files. If you get more than 10,000 input files, just the overhead of opening and closing and all of those things is going to outweigh whatever processing you're going to be doing. So think of how many files are actually processing and make sure that that is relatively small but not so small. You don't want to process a single file because then you don't get distribution, right? So you have to find this happy medium. Fewer input files, but not very few files. Each of your files themselves have to be at least half a gig, right? Less than half a gig. Now, again, you're paying a lot of performance penalty in terms of that, the latency to go read that first byte. Remember we talked about how on SSD, for example, right, you basically have this thing where you need it. Basically that performance is basically on reading serially on HDDs, the performance is on reading serially. So you want to basically think about reading it as you go along. The next thing that you want to think about is how many CPUs you have in your cluster. The more CPUs you have, the bigger the disk sizes that you can have, right? And the better SSD performance that you have on that machine. Right? So it's all related to each other. So in general, you are better off having fewer input files, larger input files, more CPUs. Finally, think about the size of your persistent disk. Is the size of that disk limiting your throughput throughput increases the larger disks. So again, you want to you might you may not have as much data, but you might want to basically say, I'm going to basically make my disk larger just so that I get higher throughput. Okay. And finally, how many VMs do you have in your cluster? Right. If your computer's small, maybe you just need to add more machines so thats your final question, so how do you do this calculation? Let's say that on premises there are 50 nodes, right? And each of them has 12 cores and two hyperthreads per core. You say, okay, that's my on premises system. How do I size that on the cloud as a starting point you will say, Well, I need 50 times, 12 times two. All right, let me start with 1200 four virtual CPU VMs. Right? So this is basically 300n1 standard four, right? So 300n1 standard four gives you 1200. So basically equalizes what you have. But the same thing can also be obtained on the cloud with just 150 machines where each machine has eight CPUs. So which one do you pick? Well, the choice might come down to the persistent disk size right on option two, because there are fewer machines, the size of your disk that you can actually configure is smaller. And that might determine whether you go with option one or option two. Okay. Normally after you do your lift and shift, the next thing that you're going to do is you're in optimize phase. And in that optimize phase, the first thing you're going to do is that you're going to replace HDFS usage but by cloud storage, but not for everything. There are some things for which you will still use HDFS and for those things you still need a persistent disk, right? So don't ignore the size of the persistent disk. But wait a second, why do you need HDFS? Well, maybe someone's using Hbase. Maybe there is a lot of temporary shuffle going on. Or maybe they have a pipeline and they really only need the final output for other jobs. Right? HDFS is going to be faster than reading and writing from cloud storage. And so you might say for my interest pipeline data sets, I'm going to save them in HDFS my temporary shuffles, I'm going to save them in HDFS. So you're running your job and you want to basically say, I want to figure out what's happening. I don't know why this job is failing. How do you do that? Well, whenever you submit a Spark job to Dataproc, the logs show up in stack driver. So you go into stock driver and look at stack driven logging, look at stock driver monitoring. That's how you diagnose how your submitted Spark jobs are doing. But if your job itself is producing output so that output of your driver program that output is available in the GCP web console when you click on the job. So you go click on the job and you'll find the output of that job, but you're going to stack driver, you find all of the logs from all of the different machines. Just all those logs are actually in each separate machine and normal Hadoop systems. You have to assistant to each of those containers to get those jobs. Instead, what stack driver does is that it's basically consolidates it and centralizes it so that even after you delete the cluster, you still have this stack driver job logs. So Stack Driver is essentially collecting the logs, using Yarn and making them available to you. So that's one of the benefits of running something like this. On, on the cloud, you have these logs available even for even for jobs for which the cluster is no longer there. But when you go to Stack Driver now, you will find logs for all kinds of things that you have run, run in the past. Right? All of the clusters, especially if you make them job specific clusters going up and down all the time and you find logs everywhere. So to make it easier to find what you need, it's a very, very, very good idea to assign labels, assign a label to your cluster, who's creating it, what workload it's for, right, etc., and assign labels to your jobs themselves. And that way you can find the logs for your jobs or for your cluster much easier. The way you do this right, is that if you want to basically set the log level, if you're running something on Dataproc, is that when you submit a job, you can specify what the driver log level is or you can go into your code and explicitly hard core what the log levels. So either way you can set the log level when you submit it are always in your code and the log level that you do when you submit the job overrides the log level in the code. Now, as we talked about, you can monitor your jobs using stack driver monitoring. Just like that, you can look at your logs using stack driver, logging. You can access Yarn if you want to access, you want to go to the lower level and access the Yarn API itself and the Yarn user interface itself. You do that through an SSH tunnel. Okay. So you have to remember these couple of port numbers. The master node of Dataproc port 8088 is the Yarn resource manager and port 18080 is a Spark history server. So this two URLs give you access to the underlying data traditional Hadoop API if you need to do that. But remember that these two are available only while the cluster is up. If you delete the cluster, these are gone. Whereas you have you have the logs in stack driver. Okay. Now once Dataproc is running, one of the advantages is that you can manually scale Dataproc, you can add or you can remove clusters, you can add or remove workers. These workers that you're adding and removing, they could be standard workers, but also they can be preemptible VMs, preemptible VMs are VMs on which we provide a large discount, 70%, 80% discount. And you get this discount rate. No, it's a standard discount that you get if you get a preemptible VM. But the the drawback is the preemptible VM that if somebody else wants that VM, we will take it away. Right. So you're not guaranteed to hold on to the VM, but you get an amazing discount on it. So very often a strategy that people use for doing cost optimization on Dataproc is to decide how many workers they actually need to do the job. Let's say you need 12 workers. You can add another 12 preemptible workers. If you get those preemptible workers, that job gets done in half the time and it's like 40% cheaper. On the other hand, if you don't get those workers, you're back to where you where it takes a normal amount of time and you pay the normal amount of money. Right. So it gives you this additional benefit of a basically lower cost and faster where possible. Now you can add workers very easily, but you also can save preemptible machines or, you know, you're just scaling them manually. It's not just about adding workers, it's also about removing workers and removing workers. sounds kind of scary. So keep in mind a few things. First of all, if you're going to be doing downscaling and Spark, you cannot use an external shuffle service because if you have an external shuffle service, all of the data that's on that shuffle service would be gone, right, if it's stored on that worker. Similarly, if you're using Spark caching, Spark caching on that machine, now you have a problem because those, those machines can never exit because if you lose that cache, it's gone, right? If you're using Spark streaming, same problem. Right. So you don't how you shouldn't be doing dynamic allocation. And so in general, if you want to take all of these things that kind of summarize them, if you're running a batch or streaming workload, if the cluster is doing something, don't downscale it right. It's risky. But if the cluster is completely idle, that's when you can start downscaling workers to get optimal performance out of a Dataproc cluster. The most important thing I think is to think about IO, right? And in terms of IO, think about the file sizes. We talked about it, right? Tried to make sure that each file is at least half a gig. Actually, the larger it is, the better, you know, and think in terms of SSD disks, if you need faster IO performance, in many cases, the higher cost of an SSD disk is paid for by the less amount of time that you need to have the cluster up. Importantly, make sure that all your VMs are all in the same zone because you don't want inter VM communication to have to basically go across different zones, have the data in the same region, have the VMs in the same zone and no use preemptible VMs because preemptible VMs are not just about reducing cost, they're also about making things faster. And but then you say, wait a second, if it's a preemptible VM Did you just talk about of the other dangers with workers going away, etc.? Well, not to worry. On preemptible VMs, we turn off things like dynamic allocation, we turn off things like caching, etc.. So preemptible VMs don't have it's HDFS, they are safe to go away. So all of that stuff that we talked about, about downscaling workers, those are about standard VMs. Preemptible VMs are safe to to lose. I mean, you will still lose the small amount of work that the VM was working on when it was taken away, but that's about it. So preemptible VMs, right. And this is something that Dataproc does for you by default. You can't use it preemptible if have a storage it's created with a smaller boot size. Okay. Because the idea is that you're not really right actually storing shuffle data on it, for example, because you can't use external shuffle service on a on those kinds of things. And also because of all of these limitations of preemptible VM, you do not want to run a job that's 100% preemptible VMS because then where would the data get stored, where the shuffle data get stored? And there are some jobs that don't need any shuffle, but it's kind of hard to go figure all of those out. So in general, a recommendation don't have more than 50% of your workers be preemptible okay. And if you're going to be using preemptible VMs, go change your cluster configuration so that it is more tolerant of task failures. And in order to do that, you basically change the number of Max attempts that Yarn does, that MapReduce does, that Spark does. Right. In other would normally, let's say if if they try a task twice and if it doesn't work two times, they're basically saying the job failed. Well, if you have preemptible machines, maybe you wanted to try six types. So think about basically increasing all the max attempts on all of the underlying Hadoop components. But once you do this, remember, you can easily add and remove preemptible VMs from your cluster. It's not that something that you have to you have to decide when you start. You can always going to add the Dataproc configuration on the web console and change the number of preemptible VMs that you that you want to assign to that Dataproc cluster.

### Video - [Decouple Compute and Storage](https://www.cloudskillsboost.google/course_templates/486/video/449630)

* [YouTube: Decouple Compute and Storage](https://www.youtube.com/watch?v=eBgjx4o44q0)

So we've looked at how to lift and shift to cloud data. And the next thing that you need to do, because it's a precondition for all the improvements that are going to come later, is that you need to decouple, compute and storage. Why are we decoupling compute and storage? Why is this a problem in the first place? The original MapReduce paper was designed for a world where the data was local to the compute machine. So when Sanjay came about and Jeff Dean wrote their paper on MapReduce, they were basically talking about, we're going to basically take these commodity machines. We're going to take this very large data set. We're going to split it so that that data set pieces of it are local to each of those machines. And every machine processes. That data that is local to that machine takes the results of that processing and sends it to the reduced nodes. So the first set of nodes are called the map nodes, the ones that process the pieces of the input data and then the and then the reduced node combines all of those intermediate outputs into the final output. So that was the whole idea for MapReduce. Every step of MapReduce consists of taking an input data and processing the splits in order to make the split processing as efficient as possible. The idea was that you basically had these mapped machines, processed data that is local to those machines. Okay. But in the cloud, this is not a great solution, right? Well, it's the HDFS defaults like 64 megs. Again, this is ten, 15 year old technology on the cloud. You basically get much better performance. The larger your files are HDFS by splitting the data that determines how parallel execution works. So even before you know what you're going to do with the data, you have to decide how to split the data. And that's bad, right? Because you may have a job that is very computationally intensive. And because it is so computationally intensive, you actually want to take your data and spread it into 7000 pieces. Or you might have a job that is super fast. And so that same data, you only want it split into ten pieces. But you need to decide way beforehand which disks you're going to store, what data on. And that's a problem. And other problems. The IO your speed on the cloud, it actually scales with the disk size and your VM course. So the larger disk is the more cause you have in your VM, the faster your IO. So you really want to think about having computationally machines that are large because they will be faster in terms of IO and the other problem with HDFS is that the data is accessible from only a single node. Beginning again, the old MapReduce idea of your processing data locally yourself. But on the cloud you don't really have that idea of data local to you. Your persistent disk can be easily attached to other machines. So all the cloud HDFS is a bad solution like the locality bad. The HDFS normally spreads lock's blocks around. Replication is a problem and it's HDFS is. Oh my god. Right. I have commodity disks and so I'm going to basically take every piece of data that you have and replicate it at least twice. Well, on the cloud, we already have replication and everything that you store on Google Cloud Storage is stored three times. So if you basically have right on Colossus, if your persistent disk, it still stored three times, right? So if on a cloud Dataproc, you have a minimum of six copies of an HDFS block if you're basically storing it on a persistent drive in Colossus. So on the cloud HDFS is not a great solution. What should you do instead? Well, Colossus. Think about it. Is such setup. Such that any two machines within the data center have a petabyte bisectional bandwidth between them. What this means is that you could have 100,000 machines, and each of those machines can talk to each other at ten gigabits a second. So the whole idea is take advantage of the networking that's available in the Google data center that allows machines to read data from Colossus at speeds that approach that of a disk. Right. So the idea then is you have your data, it's stored on Colossus, it's stored on Google Cloud Storage. And then you have your machines that come up that read the data over the wire. They write their output back to no Google Cloud storage and the machines go away. So you start your cluster, you run the job, you delete your cluster, your data is on Google Cloud Storage. That data is no longer local to the machines. Right. So in the new world, it is not necessary for the map machines to read only data that's local to them. Our our network speeds are now fast enough that we can read it across the wire as long as. Right. It's not that you could read across a wire somewhere where the data is in a different continent, but you can read it across the wire on any data that is within the data center. So bottom line, use cloud storage as your persistent data store. Cloud storage is Hadoop compatible? What do you mean by that? Well, number one, in many cases it's faster than its HDFS. It requires a lot less maintenance because it provides its own durability guarantees and it allows the use of other GCP products. If you have your data in cloud storage, you can do a federated query from BigQuery, so you can have the same data being processed by two different GCP products. You can have the data also supply and for machine learning training. Right. So you basically enable use of the entire GCP range when you use cloud storage, where if your data is in HDFS, it's only accessible to the Hadoop cluster. And finally, it's a lot less expensive than a persistent drive. So cloud storage is a drop and replacement for HDFS. So you basically have your cloud storage connector and it's already installed on a date on Dataproc. So you can directly read from cloud storage from any of your Hadoop workloads. But if you're running an on premises machine in the hybrid setup, you can install this connector. It's an open source package. So if you have a non GCP cluster, you can still install it. So phase number two is to go ahead and decouple. So we're in phase number one. We had that reading from HDFS first. Now the Hadoop cluster is reading from Google Cloud Storage. And because it's now reading from Google Cloud Storage, we now have this extra ability to do an ad hoc query from BigQuery. Otherwise, it's pretty much the same architecture as before. The only difference that we have done is that instead of having disks that are tied in to our compute engine, we're moving at least some of the data out of HDFS and storing it in in Google Cloud Storage. So what are some of the advantages of using cloud storage versus HDFS? Well, number one, it's lower cost. Secondly, it gives you this separation from compute and storage. So if we have more data, fine. Keep it on cloud storage. It doesn't really affect the number of CPUs that you have. You're not really worried about IO performance being tied to the size of your compute cluster. These are completely separate. You can scale up and down your compute cluster. You can add and remove machines because all the data that you care about the input and output data for each of your jobs. It's stored on cloud storage. Thirdly, interoperability, as we talked about, you can basically have your data and cloud storage and you can read and write to cloud storage from the AI platform, from BigQuery, etc. and it gives you HDFS compatibility. So all that you will have to do is that you will have to go into the code where whatever is being read that you are l will say HDFS no column and you will change that to GST column. That's pretty much it. The rest of it will just work as is the last bit is that you actually also have high data availability. What we mean is that once you have your data on cloud storage, you can read that data from clusters in different zones. And that's a huge advantage. And you don't have to have this worry about how to do storage management because you can also set up a cloud storage such that the cost of your storage, you know, you can move to a different storage tier when it basically becomes old, etc.. So you can you can basically start doing all of those things automatically. Okay. And finally, it gives you quick startup because your data is already there on cloud storage and new cluster that comes up doesn't need to have data copied to it. If you have HDFS, you need to think about how do I basically get the data onto HDFS? You don't have to worry about that with cloud storage. So that gives you a much quicker startup. And finally, you also get IAM permissions and security and all of the security advantages that the cloud brings. One thing that cloud storage provides that is unique in the marketplace is that it's globally consistent. So even though we talked about clusters being able to read data from the same region for performance reasons, it is possible if you need to, to have clusters running across the world, reading and writing from the same bucket. And it would be globally consistent. Well it's not all roses. There are a few disadvantages. So what are some of the disadvantages of cloud storage versus HDFS? Firstly, IO variants can change where HDFS is dedicated and is available to your cluster in your cluster only cloud storage, the IO use speeds are somewhat variable. I'd say it's still high, but they vary. They can vary. Cloud storage is a blob store, and what we mean by a blob store is that you can read an entire file, you can write an entire file, but you don't get the ability to do file appends, you don't get the ability to truncate. It is not a POSIX file system. You cant do a seek into it. So cloud storage, even though we think of them as files, they're not really files, they're blobs. And you have to read and write the entire blob. And because of that, because it doesn't have that kind of file system information, some traditional workloads that rely on that file system information may not work. If you have a data format and you have a library that reads a local file, it will not it may not be able to read from cloud storage. And you may have to build some scaffolding to get that data storage locally in order to use the local API to read it in the cloud storage again. This is very similar to the first point, is that where HDFS is dedicated and it can directly read from the cluster. Cloud storage has high throughput, but the latency, the time to the first byte tends to be higher. And this is another reason why we say you want to use larger files when it comes to cloud storage. So when you are using cloud storage, avoid small reads, use large block sizes, right? Secondly, try to avoid iterating over lots of nested directories because blob stores are not a directory system. They're actually just a hash map, a lookup and iterating sequentially over lots of nested directories. That actually adds a lot of performance overhead. The next thing to remember is that cloud storage doesn't really have this concept of directories, right? if you do a move right, some gs foo bar to gs foo bar two. It doesn't actually work the way it would on a local file system where it's just you update an I node and you're done here. What it has to do is that it has to go find all the files that have the prefix foo bar and take all those files and copy them one by one to this new location and then delete the first one. Right. So this basically takes quite a bit of time and it's not atomic. So you want to be careful if you have a workload that kind of relies on a directory system, a POSIX file system, you're going to have problems. Right. But hopefully your Hadoop workloads don't and most Hadoop workloads don't. But be aware of this that you're not a POSIX filesystem. This concept of I nodes, local files, etc., they don't really work. Now when you're setting things up on your on your cloud storage, it can be tempting to basically say, I'm going to take my data and if my whatever the output shards are, if there are 3000 shards, I'm going to write the 3000 shards as is two cloud storage. But be careful there, because it's on cloud storage. Again, throughput is very high. Right. Not the latency. Not the time to the first bite. It's the sustained throughput. So the larger your object size, the larger your file size, the you basically get higher download throughput, higher upload throughput. And in this sense, we are different from the other clouds. Okay. So Google Cloud Storage is tuned for big data analytics. It's tuned for high throughput. And because it's tuned for high throughput, you want to basically think in terms of larger file sizes to take advantage of that higher throughput. Now you have to get your data onto cloud storage. That data is on premises. How do you get the data? Do you push all the data from on prem to the cloud? Or do you go read the data from on prem as needed? Do you do your push or do you do pull. Well, it depends. It depends on whether, you know, whether you need all the data or you don't need all the data. If you know for sure that you need a bit of data, it is better to push it and have it be available to the cloud Dataproc jobs when they need it. On the other hand, if there is a huge data set on premises and you're not really sure if you will actually need all that data, it can be helpful to think in terms of getting the data only if you know you need it, right? So make that decision about push based or pull based depending on whether you need all the data or whether you may or may not need the data. Now, do not remove the data to the cloud. There are several partners that have active, active replication and schedule migration capabilities. So use this flowchart to kind of decide whether you want to do one time migration or whether you need to schedule continuous migrations or you want active, active, real time migration or you need. Right. What you need and based on what you need, access the appropriate partner.

### Video - [Optimize Dataproc](https://www.cloudskillsboost.google/course_templates/486/video/449631)

* [YouTube: Optimize Dataproc](https://www.youtube.com/watch?v=kmVEfwFqJ1o)

So you've lifted and shifted the cloud Dataproc and you've gone through and decouple computing storage wherever possible. So you've replaced HDFS usage by Google Cloud usage. Now you're ready to optimize Dataproc. But I said replacing HDFS By Google Cloud Storage, wherever possible. What do you mean? Shouldn't you replace everything? No, not always. There are some cases where local HDFS is going to be necessary. We talked about some of these considerations in the previous lesson. If your jobs require a lot of metadata operations, you need to strore that metadata and HDFS if your job's involved a lot of heavy IO, it's better to save them in HDFS. If your jobs require data that's frequently modified or if you have directories that you're renaming. As we talked about, cloud storage doesn't handle these kind of things very well because it's a blob store. In those cases, you may want to store them in HDFS. If you're basically appending to files, well you can open to a blob, so you may want to store that data in HDFS or if you are your workload is sensitive to latency. Remember that we said cloud storage is great for high throughput, but the time to first byte is very high. So if your IO workload requires that time to first byte for that file to be very small, then you might want to store all that data in HDFS. So putting all this together, what's a general principle? The general principle is you tend to write the input data and the overall output data into cloud storage, but your intermediate outputs that aren't really needed by other jobs you might get away with keeping them on HDFS. You will get better performance. You don't have to worry about at the very granular level of whether it's that you're basically doing a pending or directory renaming, etc.. Okay, so don't go around and do a search and replace and change all your HDFS. to GS Think about it a little bit and change only your overall input and output to cloud storage. And think about the intermediate stuff. Maybe keep them on HDFS. If they don't involve any of these things that we talked about, then you can basically move them to GCS. Okay. Now when you're basically creating HDFS, now your input and output data are on cloud storage. So you basically get the cost savings by putting them on cloud storage and then only your intermediate files are on HDFS. And that way you get to reduce costs. Now also when you say we're going to reduce your cost on HDFS, what we're basically saying is we can now think in terms of decreasing the size of your primary persistent disk because you've hired off a lot of our data. Maybe you don't need that much data to store the intermediate files and then you can lower the size of your persistent disk, decrease the local HDFS slice. You can also increase the primary persistent disks for workers so that you can increase the local HDFS size for something. So maybe for more some more seasonal workers, you decrease the local size for other workers, you increase the local size. You may play around with this to figure out what the optimal sizes and for every worker that needs faster performance, you might decide that you want to attach SSDs and or you might decide that you're going to use persistent disks and not local SSDs because persistent disk cheaper. So you basically want to go around and think about the three options that you have. HDD, persistent disk, SSD and consider the cost versus performance tradeoff and choose the appropriate thing. Another thing that you want to think about is which region when you're storing your data and which region you're running your job. Again, if your data and your your compute nodes are in the same region, you will get the fastest performance. If they're in a different region. There's going to be that request latency. It's going to take a little while to read your data. So you may want to decide, is it okay for me to pay that extra time to read the data across the internet? Right. Or is it okay for me to make a copy of the data and basically have this data be copied and mirrored and available to both the clusters? And the problem is copying the data is now you have two copies of the data and you need to manage them. So you want to basically make this determination based on performance and based on governance. Are you is it okay to basically have two copies of the data? What will it mean in order to keep those two things up to date? The other thing that you want to keep in mind is access management. Who's able to read this data? Who's able to write this data? You do that through the IAM and what IAM does. Identity and access management is that it manages access to all cloud resources, including the Dataproc cluster and including cloud storage. And this is basically based on roles and accounts where an account could be a user could be a Google group, or could be a service account where a service account is basically a robot account and these users are given or these accounts are given a specific role, and that role gives them the ability to do specific things. The roles dictate that level of access that they have. Logs, as we talked about, appear in stack driver logging. And so you can actually go look at the logs. You are in the GCP console. You can also get logs using the command line client called G Cloud and there is a client library for stack driver API. There's also a rest API to access the logs for storage. As we talked about, the primary data store for GCP is cloud storage. And whenever you have unstructured data, that is what we suggest you use. But that's not the only option. You might decide to store your data not on cloud storage but in Cloud Bigtable, especially if you have data that requires extremely low latency and extremely high scalability. High throughput. Right. So if you remember that cloud storage, great cloud storage is about high throughput, but you're willing to live with latency to the first bite. It's the cheapest cloud Bigtable, on the other hand, is low latency. So you get really fast performance and high scalability. It's often used for use cases like Iot data, right? The other advantage of Cloud Bigtable is that the API with which you access Bigtable is each Hbased compliant. So if you have an  Hbased program, then Bigtable is a good place to land. That data. So Bigtable is often used also right beside the Iot use case. It's also used for sparse data. For example, if you have data where you know things are not completely filled out, for example, you have followership and things like that. Bigtable tends to be a good place to store that as well. The third option that you have on GCP for storage is BigQuery, where cloud storage is a preferred place to store unstructured data. BigQuery is a preferred place to store structured and semi structured data. So that's what we talked about as data warehousing. And we've looked at a lot of the advantages of using BigQuery that you can access data through SQL, but you can also access the data from your Spark workshops. And this gives you the ability in the next phase to start optimizing it further by taking queries that you're running on Dataproc and pushing them down to BigQuery, refactoring this job, making it run faster. And with BigQuery we have this new API called the Storage API that makes accessing data from BigQuery really fast from things like Dataproc and dataflow. So don't just replicate the on prem setup of Hadoop carefully. Think through how we are going to stored the data. Right? Do you put it on GCS? They leave it on each HDFS. Do you move it to Bigtable or do you move it to BigQuery? Okay. You know, on the on premises there, there's a lot of setbacks in terms of replication, right. Because persistent clusters are kind of expensive and the open source tools that are being used on prem, that might be pretty inefficient. And these clusters are very difficult to manage as we've been talking about quite a bit. So on cloud, don't think in terms of a big monolithic cluster that's up all the time, but instead think in terms of small, short lived jobs, specific clusters, a cluster that you create, you run the job and you delete it. That's the way you ideally you want to get to. So we'll call that an ephemeral cluster. And you want to think in terms of taking your jobs and moving them to an ephemeral cluster. So you might say, I have a set of jobs I need to combine them. I have to decide maybe jobs one and to go on to cluster one, because I can actually those two jobs are related. They share some data and therefore it's kind of good to run them together on the same cluster. And I'll delete cluster one after I've bought two jobs, one and two are complete, but you might say Job three is independent, is going to read from cloud storage, is going to do something and delete it. So I'll basically run Job three and Cluster two and job number four and Cluster three, right? So you could basically take the jobs that you're running on your on premises cluster and you can basically run them on individual clusters, ephemeral clusters on cloud Dataproc. And when you do that, you can basically think about each of those clusters. How big should they be? Right. What's there? It's HDFS, what's a cloud storage? Do I store my data in the same bucket or do they store them in multiple buckets? That question comes down to IAM permissions. Who can access the data? In general, it's easier and it's much more thoughtful to think in terms of ownership of the data, who can access it and keep data that's owned by different organizations or different parts of an organization in different buckets. So basically refactor your solutions to take advantage of GCP and make this move incrementally. So this is the phase three where you're basically doing a lift and re architecting. You're now basically have taken your jobs that were running in this one persistent cluster on premise and you're now running them on a cluster per job basis. And when you do that, you basically have a number of no clusters that are per job, but not everything can be per job. There are going to be a few clusters, maybe production workloads, maybe development previews that are semi long lived. You may have this one cluster to which people keep submitting jobs. Right, or may have some job that does runs all the time. And it's pretty much  long lived and that's okay. So not everything needs to be ephemeral. You might decide that there are some of these clusters that are actually up all the time. So when you think about lifting and re architecting, what are some of the advantages? And first of all, by taking these things and decoupling them and storing your data on GCS, it makes it easier for you to adopt managed services. Well, first managed services you might want to adopt as Dataproc because you allow yourself to start a cluster around the job and delete the cluster. But it also allows you to take advantage of things like Cloud Composer to manage your pipelines and the cost benefits are substantial. its much tighter now because you're only paying for the cluster for the time that it's up and your data cost because you're storing it on GCS is much less expensive than a persistent disk down which are storing the intermediate data as when the cluster is running again. And once you're using Dataproc right, you're, you're no longer being licensing fees, etc.. But what are some of the disadvantages? Well, you have to do this re-architecting and re architecting introduces some cost and complexity. We're not just we're not set we're not just saying take your data, move it over to GCS and just go ahead, do a search and replace. We're not saying take your data, keep it on, it's HDFS and don't make any changes. We're now asking you to think and do it on a case by case basis and that does introduce cost and complexity and risk. But once you do this right, you basically start to see a lot of business value out of it. So and then once you have migrated the customer to Dataproc, now if they have their data in GCS, they have their data in Bigtable, they have the data in BigQuery. Now you have to think about how do I train them, right? So the customers have to be trained to use BigQuery to use Bigtable to take full advantage of the cloud patterns. They have to know how Cloud IAM works so that they can appropriately manage and configure the systems. There is a cost associated with Dataproc. It's $0.01 per corporate average over the cost of whatever compute engine costs. And you will often hear about vendor lock in problems that that's really not the case because Dataproc is fully open source everything that we have added to support GCP is part of the open source package, so we have not forked any of these things. They're all back and they are in the original repositories. So with ephemeral clusters, the big advantage is you're paying only for what you use and what you're using isn't up all the time, right? The resources are not active all the time. Instead, they're only active when it's being used. So the cost benefits of ephemeral clusters are substantial, especially when it comes to workloads that are spiking, workloads that are not constant, but that go up and down depending on traffic, depending on the number of users on your web page, depending on the amount of data streaming and etc.. So ephemeral clusters are what we recommend, as much as possible. Go look at your jobs and try to move them to making them ephemeral. If you don't need a persistent cluster, maybe you need a persistent cluster, as we talked about, because you want to have a development cluster that everybody can do ad hoc exploratory work on. Or maybe you need a persistent cluster because you're running production jobs on it. And these production jobs are not spiky at all. If you need a persistent cluster, make it small and resize it as you need to. So what are the advantages of an ephemeral model? Well, you can support different cluster configurations for different jobs. If some job is computationally intensive, give it more VMs. If some job right requires like high, no, require GPUs, give it GPUs basically have a lot of advantages in terms of the different cluster configurations that you can have. You can scale those clusters independently. So if some job requires some extra traffic right now, that that jobs cluster alone can be made bigger or smaller. Right. It can auto scale those cluster stats. Well, and then you're only paying for resources when jobs are using them and the jobs are not using them. You can downscale the cluster or even delete the cluster. And so and because Dataproc manages just the clusters for you, you don't need to go ahead on maintaining those clusters and you don't need to maintain separate infrastructures either because these are all things that are now a very short lived. Now when you bring up a cluster, lots of times the standard Dataproc alone isn't enough. You might need some extra bit of software. How do you get that extra bit of software on there? But the way you do that is through what are called Dataproc initialization actions. So using an initialization action, you can define the configuration of the nodes in a cluster, what kind of software to then need and how many nodes are there. And so what you do is that you take your Spark and Hadoop cluster, then you break them up right into different clusters, each of which is running a different job. You look at those jobs and see What software do I need? And you put those extra piece of software that's needed by the cluster, you put those in an initialization action. Okay, so now each ephemeral cluster is there for just that one. Jobs, lifetime. So you create the cluster, you run the job, that job, writes It's output to persistent storage and then you delete the cluster, get that job. When it's running, it's writing everything to stack driver logging. So even if the cluster is gone, you have the logs and because the data is on persistent storage, you now have the ability to use a variety of other tools like Looker like Look Studio and other business intelligence tools. So you have these ephemeral data clusters. You want to basically make them tight, you want to optimize them. So start out by creating the smallest cluster that will do the job and then use workflow templates to scope the jobs that you're going to be running on. The ephemeral clusters. So scale this cluster to the minimum number of nodes and you run the workflow template. What's a workflow template? What does it look like? So here's an example of a workflow template. What it's doing is it's basically creating a Dataproc and it's basically setting up a startup script and initialization action for that cluster. And then it's basically saying, go ahead and in this cluster, right, go ahead and run this particular job. So that's the ADD job and then you're going to add that job. You want to add it to a cluster so that the one the piece of code before that is to create a cluster for the job. Once a job is done right, this cluster will exit because of the way we created this this cluster as being job specific. You can also add a job to an existing cluster, in which case a workflow template is just about organizing and orchestrating the jobs that live within a particular cluster. So you will see this in the lab that you're about to do. But wait a second. This workflow template sounds great, but that's about doing these jobs, right? One after the other. Is this the way to do regular scheduling? How do you do a regularly scheduled batch jobs? Well, what you do is that you create a cluster. You wait until the cluster is created. So that's your then your workflow template. You basically create your cluster and then you submit your job to the cluster Dataproc jobs, submit it, submit it by Spark and then you basically do a describe on the job, right? And once the job has been executed, you can basically delete the cluster. But if you have a streaming job, don't do an ephemeral cluster for a streaming job, you want a long running Dataproc cluster, basically because a streaming job by definition is going to keep getting new data all the time so that the cluster needs to be alive. The other reason that you might want to think about a long lived cluster is if you have, you know, ad hoc jobs that the user might submit, maybe there is a, you know, a night time where people aren't actually submitting a lot of jobs. And then at daytime, there's some they are submitting a lot of jobs, and you want it to be highly available in that case. Also, you want to basically keep a cluster around. Now, if you're going to be basically running a job, you have to basically decide how you migrate those jobs, right? So in order to do that, you have to figure out what data the job needs. So first of all, even before you migrate the code, before you migrate part jobs by Pig scripts or whatever, you first have to migrate that data sources. So first step is to migrate the data sources, and you do that step by step and then you migrate to spark workloads job by job. So don't think about moving all the data all at once. Instead, take one piece of data, move it over, and then move the jobs that depend on that data. Then you go back and move the next piece of data and then you move the next job over. And then once you do those, then you say, Okay, I've now moved these things over. What are other spark jobs that depend on the first job? And then you move those things over. And then finally, once you're sure that everything is working correctly, you shut down the Spark jobs in the old environment. So what is the recommended sequence for migration to GCP? Move your data first, experiment. Make sure that the data is correct. Think in terms of specialized, ephemeral clusters and wherever possible, push down to BigQuery, push down to a Bigtable, use GCP tools, use Google Cloud Storage, but do this whether it's appropriate. Every once in a while you're going to need a hybrid solution. Why? Maybe the data needs to be on premises, right? Or maybe this job has dependencies and those dependencies cannot move. So if you need a hybrid solution, so you need some jobs running on premises and some jobs running on the cloud, how do you set it up? Well, a typical hybrid solution has four major parts. First, you need an on premises Hadoop cluster that's doing the work. Secondly, you need a connection from that On-Premise cluster to GCP. Okay. Thirdly, you basically have a centralized data storage in GCP. And fourthly, you basically have cloud native components that work on the GCP data. Okay. So but then you have all of these four things. How do you keep them in sync? How do you make sure that the data that the on premises Hadoop clusters processing is synchronized with the data that the cloud cluster is processing? So that's a key concern, but keeping things in sync. So the basic idea here is that on premises you're basically running a cluster in a VPN, a virtual private network, and you use that to connect to Dataproc and Dataproc runs inside a virtual private cloud. VPC So that's the basic idea behind designing a hybrid solution. And this storage, right, is basically on either cloud storage. Are BigQuery a Bigtable as normal? So you can use all your cloud native services. But the idea is that you stage them into cloud storage and you move them everywhere else that you need. And the Dataproc clusters, because they're running in a way that you basically have and a faster connection and ability to read in both directions. Of course, a cloud native solution doesn't need to read in both directions, so it's a lot more straightforward. If you're doing a cloud native solution, you basically have ephemeral clusters and you have persistent clusters and you basically have all of your data in a storage service on the cloud. Life's a lot easier, so if possible, go towards a cloud native solution.

### Video - [Serverless ETL](https://www.cloudskillsboost.google/course_templates/486/video/449632)

* [YouTube: Serverless ETL](https://www.youtube.com/watch?v=NjIAf96Q1yQ)

So you've gone through your Dataproc and you found all of your jobs, you've written workflow templates, you know how to run these jobs, but how do you run them? When do you run them? Right. So it really depends on the reason in which you're running them. So think in terms of why you're going to be running them. Should you be running them on a schedule and should you be run them at 2 a.m. every day? Should you run it on the 13th of every month? Should you run it? Nope. Whatever the schedule. Every Monday. Right. If it's run on a schedule, the best way to invoke the workflow template is to use Cloud Scheduler. So the idea is that you would go to Cloud Scheduler, set up a schedule, and that's schedule on that schedule. Cloud Scheduler will basically use the workflow template which sets up the DAG that then creates a cluster, runs all of the jobs, deletes the cluster. Right. So if it's something that you should run periodically, use Cloud Scheduler, sometimes you'll want to run it on a trigger. The trigger might be every time a new data file comes in, I want to run this job. And if that's the trigger, then you use Cloud Functions. Cloud Functions are great for triggers, which could be on a new file and cloud storage could be on a new message and pops up. It could even be synchronous, like a user comes to a web page and when they when they click the link, we run the job and we basically give them the result back, right? However it does. So if it's on a trigger that triggers an event, then a Cloud Function is a good way to invoke that workflow template. Sometimes, though, it's not as simple as a simple scheduler, a trigger. It's much more complex. You're not you're not talking about running a single workflow template. You talk about running multi workflow templates that all have dependencies on each other. And if that's the case, then use Cloud Composer. Right. So Cloud Composer adds complexity. And I don't want you to think that you need Cloud Composer for every level of orchestration. If all you need is a simple schedule or a simple trigger. Think about Cloud Scheduler. I think about Cloud Functions. And only when you need more complexity should you go to Cloud Composer. Cloud Composer is a centrally managed airflow, so with Cloud Functions you can develop an application that is event driven. It is serverless and is very highly scalable. So it's a great solution. Let's walk through it a little bit. So an idea here might be every time an image comes into cloud storage, we want to do some amount of processing. We want to do an optical character recognition that invokes the Cloud Vision API. It'd be great, but I'd have to basically listen to a translation topic, find some words, do some translation with Cloud Functions, or it might be a new message that comes into Pub/Sub that needs to basically take that, write it out as a file, write it out as a translated text. Right. However, it is that we need we can basically take our jobs, think about what events need to drive them and write each of those as a very highly scalable microservice that's invoked from Cloud Functions. So Cloud Functions have a variety of different use cases, right? It could be based on a webhook whenever a new event comes from mobile, every time the user hits like on something or every time the user basically makes an action of some kind, it sends an HTTP message and the Cloud Function is triggered in response to that HTTP message. It could also be for lightweight ETL. Every time a new file ends up in cloud storage, a Cloud Function gets triggered and that Cloud Function does a bunch of processing and writes out to some persistent store. Maybe cloud storage, maybe BigQuery, maybe Bigtable, maybe even data store. Or it might be due to an Internet of Things, right? You basically have a new message that comes in and every time a message comes in, a Cloud Function gets triggered. This is something that you need to think about when a message comes in. Should it be this single microservice that gets launched in response to this message? Should it be ephemeral, in which case the Cloud Function, or they need a long running pipeline that's processing every message that comes in to pops up and doing aggregations. If what you need to do is time windowed aggregations, you would use Dataflow. But if you need a message, my message processing Cloud Functions are a very scalable, great alternative. So Cloud Functions can have asynchronous triggers, like things like a new file on cloud storage or a new log message in stack driver logging. So very common use case here would be every time a new table gets created in BigQuery, there is a new log message that BigQuery writes to Stack Driver. So when the new table gets created, a Cloud Function gets launched and it takes all of that table data and it does something to it. So you could basically have a variety of these asynchronous triggers that end up launching a Cloud Function. It could also be synchronous where it's a specific HDP request that gets sent to the Cloud Function and the Cloud Function sends back a response. So in order to write your Cloud Function, you basically think about, I'm going to write just this function that's going to take in an event and it's going to do this callback or it's going to take in a request and it's going to send back a response. Once you write this Cloud Function and you can write a Cloud Function in a variety of different languages in the lab, that's going to come up. We'll write it in Python, but you can write in a variety of different languages and you can do them in the GCP console itself, and you can basically type it in a text box or you can basically have it in a git repository and move it over, right? However it is you can now use, you can deploy it, you can depart from the GCP console, you can deploy it from G Cloud and once you have it, now that Cloud Function is deployed and every time the trigger happens, the Cloud Function will run and the Cloud Function will auto scale, right? If there's if there's lots and lots of files that show up, there will be like lots of Cloud Functions that would run in parallel. So Cloud Functions support logging, error, reporting, monitoring, and they're all very familiar just as Dataproc, all the logs show up in stack driver, just as BigQuery, all the logs stop in stock driver, Cloud Function logs all to show up in stack driver. You can monitor Cloud Functions, see what functions are running, how much memory are they using, etc. from the stack driver monitoring. And you can look at the number of executions, execution time, the memory usage, etc. by going to the Cloud Functions. Part of the GCP console and looking at it.

### Lab - [Migrating Apache Spark Jobs to Dataproc [PWDW]](https://www.cloudskillsboost.google/course_templates/486/labs/449633)

This lab focuses on running Apache Spark jobs on Dataproc. 

* [ ] [Migrating Apache Spark Jobs to Dataproc [PWDW]](../labs/Migrating-Apache-Spark-Jobs-to-Dataproc-[PWDW].md)

### Video - [Migration Strategies](https://www.cloudskillsboost.google/course_templates/486/video/449634)

* [YouTube: Migration Strategies](https://www.youtube.com/watch?v=-UD9n8Iie_o)

In the lab. We looked at all of the phases that we talked about lifting of shifting, decoupling, optimizing Dataproc, creating a Cloud Function. In this last section, let's look at the migration strategy itself. So we talked about how you migrate with your data first, that you migrate your data incrementally, taking your jobs, isolating your individual jobs from that existing infrastructure, taking that one job, figuring out what its needs are, what kind of data does it need? What kind of hardware does it need? Well, and figuring out the migration path for that one job. And then as you do it, you would basically find that there are some maybe some problems, problem two versions, problem with dependencies, etc., handle those problems as they arise and then create a proof of concept. Say, this is how we can take a typical job that you, Mr. or Mrs. Client have and move them over to the cloud. So create a proof of concept and then move that workload over and then go back and move the next workload and over. Do this thoughtfully and deliberately. Think in terms of what is impactful to the customer from a business standpoint. Again, spiky workloads are the ones that benefit the most from moving to the cloud. So when you are thinking about how to choose a workload to demonstrate impact, look at workloads in which that is spiky, and you can basically demonstrate tremendous cost savings there. So let's look at a typical incremental migration. A typical migration sequence involves first taking a part of the data, moving it to Google Cloud, and then experimenting with that data, figuring out all of the jobs that work on that data. How do we move it? Do we basically condense it and what we mwan by experimenting is that maybe the data consists of 6000 files and you basically start concatenating them, making them larger and the same data lossless. But instead of it being spread, over 6000 files is now spread over only 60 files and that's what gives you the best performance do that experimentation and having done that, move the next piece of data repeated and having moved all of the pieces of data that a job needs. Now you're ready to move the job over. So what kind of tasks should you pick? So one option, as you talked about, is to go ahead and pick something that is very spiky because it shows a lot of business impact. But if the client is very risk averse and what you really want to show them is that now we can do this on the cloud and very low risk option is backfilling. So the client has archive data that they're creating and for some reason some job failed and they have a missing piece of that archive and they need to backfill the archive. Now, this is often a great starting test case when you're trying to pick a workload to run. So backfill is can be done in a hybrid way. Everything is running on premises, but you basically moving that data over to the cloud and then you're figuring out that there is a gap in that data. You have the input data and you have the processed data and there's a gap in the process data. You can basically go back and rerun the job, fill out those gaps. So that's what we mean by a backfill hybrid model because it doesn't affect your production models in any way. Your production system continues to run and they don't want to actually go back and do backfilling on the production system because that would basically slow down all the real time workloads that they need to run. So this is a very safe, easy proof of concept to carry out. The other option that you will often get asked for is How do I do? Bursting to the cloud, I already have a cluster. It is completely swamped and every once in a while, end of the month, I basically get all these new jobs I need to run. So think in terms of extra jobs, you need to run and move those jobs over to the cloud. These jobs that are burst jobs try not to do bursting off a job itself, a job that's running on premise and on the cloud. That becomes hard because now you need to synchronize that data that the job depends on. Instead, think in terms of identifying which job you want to burst to the cloud and take that entire job and burst it to the cloud. So what you're trying to do is to find these kinds of jobs that run once in a while and basically move move that job and its dependencies and everything to the cloud so that their regular system doesn't have to do those jobs anymore. So good kinds of jobs are things that involve things like backups, archiving, etc.. So now you want to try to think about moving those kinds of jobs to the cloud as your burst scenario. The third option is, as we talked about, a hybrid cloud scenario where you're actually running a jobs that require the same data, both on the cloud and on prem. And when you do that, the biggest challenge, the longest pole, is going to be getting the networking right and getting that data synchronization right. And it's going to involve a VPN set up. It's going to involve peering. So get your network experts involved. The the other last option is a cloud native option. And the cloud native option is you're taking the on premises cluster. You're going to be turning it down. You're going to run completely on the cloud. And this is what gives customers the biggest benefits, because now they can start to become more and more cloud native move jobs if they're running in Hadoop over to fully managed services like BigQuery and Bigtable or even if they leave it on Dataproc taking advantage of things on Dataproc like ephemeral clusters, workflow templates, auto scaling, preemptible VMs, all of these things provide a lot of cost and management benefits. And of course, having these logs available, being able to do discovery by label, all of these are extra advantages that they may not have had on premises. It also allows them to run different versions of Hadoop for different versions of jobs. Right. They can try out a new version of Hadoop before they actually migrate their system over. So there are lots of benefits to running Cloud Native and you want to basically position that to your customers.

### Video - [Summary](https://www.cloudskillsboost.google/course_templates/486/video/449635)

* [YouTube: Summary](https://www.youtube.com/watch?v=spX3O_c2CH4)

In this content. We looked at how to migrate Spark and Hadoop workloads to Google Cloud. Let's review some key takeaways. First, we explored how using Google Cloud can save time, money and effort compared to using an on premises Hadoop solution. We also reviewed many challenges that an on premises Hadoop solution encounters and explored how moving to an environment where compute and storage are separate and where you have a lot of cloud native services can help resolve many of these issues. We also reviewed how lift and shift can often be the least risky way to migrate workflows. While it's not always the best solution, it can be a good first step and it provides the benefits of Google Cloud Security and disaster recovery. Then we explored how decoupling, compute and storage can allow you to have multiple clusters, all processing the same data. We also discussed how that provides increased cost, economics, high availability and disaster recovery, and how it positions you for optimization, which is the next phase in the migration. Then we looked at lifting and re architecting the system by making existing workloads job specific and moving them to clusters that are created for a very specific job and therefore can be ephemeral. Finally, we reviewed the tasks being completed in certain jobs and discussed moving some of those jobs away from the Hadoop ecosystem to Google Cloud native services such as BigQuery. We also looked at how to orchestrate these jobs by taking advantage of things like Cloud Functions, which gives you all of the scale and management capabilities of Google Cloud. In addition, we explored how storing unstructured data on cloud storage provides opportunities for machine learning and analytics. Last we discussed the creation of fully managed data pipelines on Google Cloud, which is a complete change in direction from self-management of Hadoop clusters for ETL.

### Document - [Additional Resources](https://www.cloudskillsboost.google/course_templates/486/documents/449636)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

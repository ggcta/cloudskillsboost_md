---
id: 1142
name: 'Networking in Google Cloud: Network Security'
datePublished: 2025-02-18
topics:
- Cloud Infrastructure
- Cloud Computing
- Networking
type: Course
url: https://www.cloudskillsboost.google/course_templates/1142
---

# [Networking in Google Cloud: Network Security](https://www.cloudskillsboost.google/course_templates/1142)

**Description:**

Welcome to the fourth course of the "Networking in Google Cloud" series: Network Security!
In this course, you'll dive into the services for safeguarding your Google Cloud network infrastructure.
The first module, Distributed Denial of Service (DDoS) Protection, covers how to fortify your network against Distributed Denial of Service (DDoS) attacks, ensuring uninterrupted availability of your services.
In the second module, Controlling Access to VPC Networks, you'll learn the network access control, enabling you to define permissions for who can access your resources and how.
Finally, in the third module, Advanced Security Monitoring and Analysis, we'll explore how to proactively detect and respond to potential threats, keeping your Google Cloud environment secure and resilient.
By the end of this course, you'll have a comprehensive understanding of Google Cloud network security.

**Objectives:**

- Deploy Cloud IDS and configure its settings according to specific security needs.
- Identify methods Google Cloud uses to mitigate the risk of DDoS for its customers.
- Define packet mirroring and explain its role in network analysis and troubleshooting.

## Welcome to Networking in Google Cloud

Welcome to the Networking in Google Cloud: Routing and Addressing course.

### Video - [Course Introduction](https://www.cloudskillsboost.google/course_templates/1142/video/525498)

- [YouTube: Course Introduction](https://www.youtube.com/watch?v=xrCI6Mbkmh4)

Welcome to the fourth course of the "Networking in Google Cloud" series: Network Security! In this course, you'll dive into the services for safeguarding your Google Cloud network infrastructure. The first module, Distributed Denial of Service (DDoS) Protection, covers how to fortify your network against Distributed Denial of Service (DDoS) attacks, ensuring uninterrupted availability of your services. In the second module, Controlling Access to VPC Networks, you'll learn the network access control, enabling you to define permissions for who can access your resources and how. Finally, in the third module, Advanced Security Monitoring and Analysis, we'll explore how to proactively detect and respond to potential threats, keeping your Google Cloud environment secure and resilient. By the end of this course, you'll have a comprehensive understanding of Google Cloud network security.

## Distributed Denial of Service (DDoS) Protection

Distributed Denial of Service (DDoS) Protection. Distributed Denial of Service Attacks are a major concern today and can have a huge impact on businesses if the business is not adequately prepared. In this module we will begin with a quick discussion on how DDoS attacks work and then review some DDoS mitigation techniques that are provided by Google Cloud.  We will finish up with a review of complementary partner products and a lab where you will get a chance to see some DDoS mitigations in action.

### Video - [Module Introduction](https://www.cloudskillsboost.google/course_templates/1142/video/525499)

- [YouTube: Module Introduction](https://www.youtube.com/watch?v=uZ4wJJ4bXHM)

Welcome to the Distributed Denial of Service Attacks (DDoS) Protection module. Distributed denial of service attacks are a major concern today. They can have a huge—and potentially fatal—impact on businesses if the business is not adequately prepared. We will start this module with a quick discussion on how DDoS attacks work. And then, we will review some DDoS mitigation techniques that are provided by Google Cloud. Then, we will finish up with a review of complementary partner products and a lab where you will get a chance to see some DDoS mitigations in action. OK, let's get started!

### Video - [How DDoS attacks work](https://www.cloudskillsboost.google/course_templates/1142/video/525500)

- [YouTube: How DDoS attacks work](https://www.youtube.com/watch?v=JFnHBYj2ki4)

A distributed denial-of-service (or DDoS) attack is a malicious attempt to disrupt normal traffic of a targeted server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic from multiple sources. Essentially, it is an attempt to make an online service unavailable by overwhelming it with traffic from multiple sources. DDoS attacks can come from individuals, cybercriminal groups, or can even be state-sponsored. In the diagram, attackers build networks of infected computers, known as 'botnets', by spreading malicious software through emails, websites, and social media. Once infected, these machines can be controlled remotely without their owners' knowledge. They are then used like an army to launch an attack against any target. Some botnets are millions of machines strong. For context, a large attack in 2017 had a strength of around four terabit per second. For reference, the whole internet has a bisection bandwidth of 200 terabits per second. Now, when you compare this to a single Google data center, which has a bisection bandwidth of 1,300 terabits per second, you can see we have internal capacity many times that of any traffic load we can anticipate. This means that, when there is an attack, we have time to isolate it and address it. Over the past few years, Google has observed that distributed denial-of-service (DDoS) attacks are increasing in frequency and growing in size exponentially. On August, 2022, a Google Cloud Armor customer was targeted with a series of HTTPS DDoS attacks which peaked at 46 million requests per second. This is the largest layer 7 DDoS reported to date—at least 76% larger than the previously reported record. In August 2023, we stopped an even larger DDoS attack—7½ times larger—398M rps. Cloud Armor blocked the attack ensuring the customer's service stayed online and continued serving their end-users.

### Video - [Google Cloud mitigations](https://www.cloudskillsboost.google/course_templates/1142/video/525501)

- [YouTube: Google Cloud mitigations](https://www.youtube.com/watch?v=UTI04x4Q_1g)

Now let's review some DDoS mitigation techniques that are provided by Google Cloud. Kai is a network engineer at Cymbal Corporation. Their current DDoS solution is outdated and resource-intensive, struggling to handle the increasing traffic volume and sophistication of modern attacks. Kai needs a scalable, cloud-based solution that is cost effective and does not require contracts or long-term agreements. A solution that can effectively defend their website without impacting performance. Let us see the ways you can address this challenge. Creating secure applications requires a multi-faceted approach which has been customized to fit your business’ needs, vulnerabilities, and resources. Properly understanding the different options available when facing a DDoS attack can help your organization create a plan to minimize the impact. Let’s look at these generalized strategies in more detail and discuss how Google Cloud helps you implement them. In this lesson, you will learn more about: Leveraging Cloud Load Balancing. Reducing the network attack surface. Isolating internal traffic. Using Cloud CDN. Using API management and monitoring. Leveraging the Google Cloud Armor defense service. Cloud Load Balancing provides built-in defense against infrastructure DDoS attacks— —and no additional configuration is needed. Placing a load balancer in front of your services will filter known-bad traffic streams before they reach your resources. Google Cloud offers load balancing at layer 4 (the transport layer, such as TCP or UDP) and layer 7 (the application layer, generally HTTP or HTTPS). The layer 4 load balancers automatically protect against things like UDP floods and TCP SYN floods. The layer 7 load balancers provide layer 4 protection plus protection from connection-based attacks like Slowloris. Google Cloud load balancers leverage Google’s global DoS mitigation service. If the system detects an attack, it will automatically configure the load balancers to drop or throttle traffic. An attack surface of a software environment is the sum of the different points where an unauthorized user can try to enter data to or extract data from this environment. Keeping the attack surface as small as possible is a basic security measure. Reducing the attack surface means reducing how much exposure your VMs have to the internet. You should host Compute Engine resources that require network communication on the same VPC network. If the resources aren’t related and don’t require network communication among themselves, consider hosting them on different VPC networks. For most applications implemented in Google Cloud, Google also recommends creating separate subnets within a network for each tier of an application (for example, web front end, services layer, and database backend). That is because subnetting is a convenient way to implement inter-network firewall restrictions. You can control individual ingress and egress traffic for compute resources using firewall rules. Be sure you are blocking both unused ports as well as unwanted sources. Remember, you can use firewall tags and service accounts to help control which targets to use for firewall rules. It is also important to ensure you restrict external traffic within your VPCs. Virtual machines should not be given public IP addresses unnecessarily. Even if you need to connect to the VM from the internet, leveraging solutions like Identity-Aware Proxy or bastion hosts can help restrict the internal traffic. You can also connect your on-premise network with your VPC network using VPN IPsec Tunnels or Dedicated Interconnect. Google’s Cloud Content Delivery Network (or CDN) is used to cache web content at over 90 edge locations, or points of presence (POPs), around the globe. Cloud CDN provides very similar protection as Google’s load balancers. In addition, requests for your content are routed to Google’s POPs (points of presence) rather than directly to your resources. Thus, Google Cloud’s resilient network infrastructure absorbs the brunt of attacks. This also naturally reduces the load on your resources even when there are no attacks. For IT, network, and DevOps teams, allowing access to backend services is often required to facilitate interactions between applications, services, customers, and business partners. This access can also introduce vulnerabilities and challenges. Putting an API gateway, or API management, in front of your backend services can help prevent denial of service attacks by: Throttling requests to limit the number of requests per client. Controlling access to API from a single centralized location. Adding the ability to monitor and track all API usage. In Google Cloud, use Apigee for implementing API management. Throttling requests to limit the number of requests per client. Controlling access to API from a single centralized location. Adding the ability to monitor and track all API usage. In Google Cloud, use Apigee for implementing API management. Google Cloud Armor is a DDoS and application defense service. It delivers defense at scale against infrastructure and web application Distributed Denial of Service (DDoS) attacks using Google’s global infrastructure and security systems. Similar to CDNs, Google Cloud Armor protection is delivered at the edge of Google’s network and can block attacks close to their source before they have a chance of affecting your applications. Google Cloud Armor works with the global external Application Load Balancer to provide built-in defenses against infrastructure DDoS attacks. It defends against both network-layer (L3/L4) and application-layer (L7) DDoS attacks, safeguarding your services from being overwhelmed by malicious traffic. Google Cloud Armor comes with pre-defined rulesets specifically designed to protect against the OWASP Top 10 web application vulnerabilities. These include common threats like SQL injection (SQLi), cross-site scripting (XSS), and insecure deserialization. You can easily configure Google Cloud Armor to block traffic originating from specific countries or regions. This is helpful for preventing attacks from known malicious sources or complying with regional regulations. Google Cloud Armor also provides detailed logs for analysis and monitoring of traffic patterns and potential security threats. Google Cloud Armor defense is customized using a security policy which can contain one or more rules. Rules tell your security policy what to do (the action), when to do it (the condition), and where to apply the rule (the target). Google Cloud Armor also provides several predefined rules to defend against cross-site scripting (XSS) and SQL injection (SQLi) application-aware attacks. Google Cloud Armor also provides the following features: Variety of load balancer support: Google Cloud Armor now supports a variety of load balancers: Global external Application Load Balancer Regional external Application Load Balancer Classic Application Load Balancer External proxy Network Load Balancer External passthrough Network Load Balancer Rate limiting: rate-based rules help you protect your applications from a large volume of requests that flood your instances and block access for legitimate users. Adaptive protection: helps you protect your Google Cloud applications, websites, and services against L7 distributed denial-of-service (DDoS) attacks such as HTTP floods and other high-frequency layer 7 (application-level) malicious activity. Cloud Armor bot management with reCAPTCHA Enterprise: helps you evaluate and act on incoming requests that might be from automated clients. Custom rules language: enables you to define prioritized rules with configurable match conditions and actions in a security policy. For the latest Google Cloud Armor updates, check out the Google Cloud Armor release notes. To explore Google Cloud Armor features further, check out the Securing your Network with Cloud Armor quest. Cloud Armor Enterprise expands upon Google Cloud Armor Standard, providing enhanced security capabilities for your applications and infrastructure. It offers flexible pricing models—annual for predictable budgeting or pay-as-you-go for scalability. Cloud Armor Enterprise includes unlimited access to the Web Application Firewall (WAF), covering rules, policies, and requests for comprehensive and simplified protection. Proactive security is bolstered by curated third-party IP lists and Google Threat Intelligence insights, keeping you ahead of emerging threats. The service employs advanced protection mechanisms, including machine learning-powered Adaptive Protection for Layer 7 and robust defenses against DDoS attacks for pass-through endpoints. If you opt for the annual plan, you'll gain access to DDoS bill protection and expert support from the DDoS response team, as well as in-depth visibility into DDoS attack patterns to help you strengthen your security posture. Cloud Armor Enterprise equips you with a robust and adaptable security toolkit to defend against the ever-changing threat landscape and keep your digital assets secure.

### Video - [Types of complementary partner products](https://www.cloudskillsboost.google/course_templates/1142/video/525502)

- [YouTube: Types of complementary partner products](https://www.youtube.com/watch?v=ESVczK5ZeeA)

As you have seen, here at Google, we offer some of the best in class platform security, but we did not stop there. Google also partners with a number of security-centric firms. In this section, we will review some of the complementary partner products. There are several different categories of security in our security ecosystem: Data protection, which includes things like: Governance Data loss prevention Data-centric audit and protection Encryption Hardware security modules Infrastructure protection, which includes: DDoS protection Network and application firewalls Intrusion detection and prevention Container security Scanning, logging, and monitoring, which includes a vulnerability scanner and security and information management tools. Identity and user protection, which includes: Single sign on Identity and Access Management Anti-malware Mobile device and application management Cloud access security brokers Configuration, vulnerability, risk, and compliance protection across all areas of your infrastructure. Infrastructure protection helps protect your cloud infrastructure and applications from cyberattacks. There are many industry leaders that provide services that can be leveraged from Google Cloud covering a wide range of solutions, including: Next generation firewalls Web application firewalls Web proxies and cloud gateways Server endpoint protection Distributed denial of service And container security Data protection partners can help protect your data from unauthorized access, as well as internal and external threats through encryption, key management, and policy-driven data loss prevention controls. Logging and monitoring partners help enable visibility and auditability of user and system activities in your infrastructure, while providing policy-driven alerting and reporting. Configuration, vulnerability, risk, and compliance partners can facilitate the visualization and inspection of your network and application deployments for vulnerabilities, security, and compliance risks, and assist with remediation.

### Video - [Lab Intro Configuring Traffic Blocklisting with Google Cloud Armor](https://www.cloudskillsboost.google/course_templates/1142/video/525503)

- [YouTube: Lab Intro Configuring Traffic Blocklisting with Google Cloud Armor](https://www.youtube.com/watch?v=iChNkes0weU)

Next, you will see Google Cloud Armor in action. In this lab, you will perform the following tasks: Configure an Application Load Balancer for a simple web application, And use Google Cloud Armor to blocklist an IP address and restrict access to an Application Load Balancer

### Lab - [Configuring Traffic Blocklisting with Google Cloud Armor](https://www.cloudskillsboost.google/course_templates/1142/labs/525504)

Configuring Traffic Blocklisting with Google Cloud Armor

- [ ] [Configuring Traffic Blocklisting with Google Cloud Armor](../labs/Configuring-Traffic-Blocklisting-with-Google-Cloud-Armor.md)

### Video - [Debrief](https://www.cloudskillsboost.google/course_templates/1142/video/525505)

- [YouTube: Debrief](https://www.youtube.com/watch?v=yGl4pX1PjYQ)

This concludes the module on DDoS protection. Before we wrap up, let's explore some useful Gemini prompts that can help you with related questions. The slide displays a few sample prompts to get you started. This module provided a comprehensive overview of Distributed Denial of Service (DDoS) attacks, their mechanisms, and how Google Cloud Armor effectively mitigates them. You learned about the various types of DDoS attacks and Google Cloud's multi-layered protection approach. Additionally, you explored complementary partner products that can enhance your defense strategy. In the hands-on lab, you configured Traffic Blocklisting with Google Cloud Armor, and a quiz reinforced your understanding of the key concepts covered in this module.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/1142/quizzes/525506)

#### Quiz 1.

> [!important]
> **Which Google Cloud service provides defense against infrastructure and application Distributed Denial of Service (DDoS) attacks?**
>
> - [ ] Google Cloud Armor
> - [ ] Cloud DNS
> - [ ] Cloud CDN
> - [ ] Cloud Load Balancing

#### Quiz 2.

> [!important]
> **Which two of the following statements are true about Google Cloud Armor?**
>
> - [ ] Google Cloud Armor is a ransomware defense service.
> - [ ] Google Cloud Armor protection is delivered at the edge of Google's network.
> - [ ] Google Cloud Armor is not currently compatible with any third-party partner security products.
> - [ ] Google Cloud Armor enforces access control based on IPv4 and IPv6 addresses or CIDRs.

## Controlling Access to VPC Networks

This module covers protecting your Google Cloud network infrastructure with Cloud Firewall, Cloud IDS, and Secure Web Proxy.

### Video - [Module Introduction](https://www.cloudskillsboost.google/course_templates/1142/video/525507)

- [YouTube: Module Introduction](https://www.youtube.com/watch?v=JATEd6S4QW8)

Welcome to the Controlling access to VPC Networks module. In this module, we’ll cover some ways to restrict access to your VPC networks. We’ll begin with an overview of the IAM (Identity Access Management) resource hierarchy and policy constraints. We will then cover firewall rules and how they further control access to your VPC networks. You will then use what you learned in a lab exercise, Controlling Access to VPC Networks, followed by a brief quiz. We will begin with IAM roles.

### Video - [IAM roles](https://www.cloudskillsboost.google/course_templates/1142/video/525508)

- [YouTube: IAM roles](https://www.youtube.com/watch?v=iGCveMx-edw)

Karen, a cloud network administrator, is tasked with ensuring that principles of least privilege are maintained when granting access to cloud network engineers. Sarah must be able to view VPC network firewall rules. Jamal is tasked with tracking user access to cloud networking resources. Kalani must be able to view VPC network configurations. How can Karen grant everyone the access that they need? To answer this question, let’s explore IAM first. In the diagram, you can see a sample IAM resource hierarchy. Let’s use the diagram to review how IAM works. Google Cloud resources are organized hierarchically as shown in this tree structure. The Organization node is the root node in this hierarchy. Folders are the children of the organization. Projects are the children of the folders. And the individual resources are the children of projects. Each resource has exactly one parent. IAM allows you to set policies at all of these levels, where a policy contains a set of roles and members. Let’s go through each of the levels from top to bottom, as resources inherit policies from their parent. The organization resource represents your company. IAM roles granted at this level are inherited by all resources under the organization. The folder resource could represent your department. IAM roles granted at this level are inherited by all resources that the folder contains. Projects represent a trust boundary within your company. Services within the same project have a default level of trust. The IAM policy hierarchy always follows the same path as the Google Cloud resource hierarchy. This means that, if you change the resource hierarchy, the policy hierarchy also changes. For example, moving a project into a different organization will update the project's IAM policy to inherit from the new organization's IAM policy. Another thing to point out is that child policies cannot restrict access granted at the parent level. For example, if someone grants you the editor role for Department X and someone grants you the viewer role at the bookshelf project level, then you still have the editor role for that project. Therefore, it is a best practice to follow the principle of least privilege. The principle applies to identities, roles, and resources. Always select the smallest scope that’s necessary to reduce your exposure to risk. NOTE: Deny policies take precedence over access policies. They provide more granular control. Deny policies were recently introduced so you can define deny rules that prevent certain principals from using certain permissions, regardless of the roles they're granted. Each project, folder, and organization can have up to 5 deny policies attached to it. In addition to the basic roles, IAM provides predefined roles that give granular access to specific Google Cloud resources and prevent unwanted access to other resources. These roles are collections of permissions. Most of the time, to do any meaningful operations, you need more than one permission. For example, in this slide, a group of users is granted the network viewer role on project_a. This provides the users of that group a lot of permissions. Some are illustrated on the right side. The permissions are classes and methods in the APIs. For example, compute.networks.list can be broken into the service, resource, and verb, meaning that this permission is used to list all of the VPC networks that project_a contains. Grouping these permissions into roles and having those roles represent abstract functions makes them easier to manage. Also, users can have multiple roles, providing flexibility. In addition to the predefined roles, IAM also provides the ability to create customized IAM roles. You can create a custom IAM role with one or more permissions, and then grant that custom role to users who are part of your organization. In essence, custom roles enable you to enforce the principle of least privilege, ensuring that the user and service accounts in your organization have only the permissions essential to performing their intended functions. For example, you might want a user to create, modify, and delete firewall rules but have read-only permissions to SSL certificates. In this case, the security administrator role provides too many permissions and the network administrator role does not provide enough. So, you can select the corresponding permissions for firewall rules and SSL certificates as shown on the left side along with any other permissions to create a new custom network administrator role. IAM provides a UI and an API for creating and managing custom roles. For more information on custom roles, refer to Custom roles in the Google Cloud documentation. Let’s focus on predefined roles that provide granular access to VPC networking resources. There is the network viewer role, that provides read-only access to all networking resources. For example, if you have software that inspects your network configuration, you could grant that software’s service account the network viewer role. Next, the network administrator role contains permissions to create, modify, and delete networking resources, except for firewall rules and SSL certificates. In other words, the network administrator role allows read-only access to firewall rules, SSL certificates, and instances to view their ephemeral IP addresses. The security administrator role contains permissions to create, modify, and delete firewall rules and SSL certificates. Now, there are other predefined roles for networking resources that relate to Shared VPC, which allow an organization to connect resources from multiple projects to a common VPC network. We will cover Shared VPC, along with those other predefined roles, in a later module of this course. For more information on these roles, see Compute Engine IAM roles and permissions in the Google Cloud documentation. Going back to the use case. Karen uses IAM to ensure the network engineers have just enough access to do their jobs. If a predefined role exists that provides just the access that a cloud network engineer needs, she adds the engineer to it. If no predefined role exists with sufficient permissions, Karen creates a custom role with just enough permissions for the network engineer job responsibilities and then adds the engineer to it.

### Video - [Firewall rules](https://www.cloudskillsboost.google/course_templates/1142/video/525509)

- [YouTube: Firewall rules](https://www.youtube.com/watch?v=I7gfMF1tm3Q)

Applying rules to all instances in the network means the rule will apply to every instance running in that VPC network without having to tag or mark the instances in any other way. Applying rules to instances tagged with a specified target tag requires any instance needing the firewall rule to be “tagged” with the firewall rule target tag. Lastly, applying firewall rules to specific service accounts will apply those rules to both new instances created and associated with the service account and existing instances if you change their service accounts. Note that changing the service account associated with an instance requires that you stop and restart it for the change to take effect. Google Cloud firewalls are stateful, which means that, for each initiated connection tracked by allow rules in one direction, the return traffic is automatically allowed regardless of any other rules in place. In other words, firewall rules allow bi-directional communication once a session is established. The connection is considered active if at least one packet is sent every 10 minutes. To apply firewall rules to multiple VPC networks in an organization, use firewall policies. Network firewall policies use tags. Tags are key-value pairs defined at the organization level that provide a flexible way to identify and group resources for firewall rules with granular control through IAM permissions. A firewall rule is composed of many settings that are specified by the following five parameters: Direction: rules can be applied depending on the connection direction, values can be ingress or egress. Source or destination: the source parameter is only applicable to ingress rules and the destination parameter is only applicable to egress rules. Firewall targets can be applied to all instances in a network, source tags, and service accounts, and can be further filtered by IP addresses or ranges. Protocol and port: the protocol, such as TCP, UDP, or ICMP and port number. You can specify a protocol, a protocol and one or more ports, a combination of protocols and ports, or nothing. If the protocol is not set, the firewall rule applies to all protocols. Action: an action can be set to either allow or deny, and will determine if the rule permits or blocks traffic. Priority: a numerical value from zero to 65,535, which is used to determine the order the rules are evaluated. Rules are evaluated starting from zero, so a lower number indicates a higher priority. If you do not specify a priority when creating a rule, it is assigned a priority of 1000. When evaluating rules, the first rule that matches is the one that will be applied. If two rules have the same priority, the rule with a deny action overrides a rule with an allow action. Implied IPv4 firewall rules are present in all VPC networks, regardless of how the networks are created, and whether they are auto mode or custom mode VPC networks. The default network has the same implied rules. Implied IPv4 allow egress rule. An egress rule whose action is allow, destination is 0.0.0.0/0, and priority is the lowest possible (65,535) lets any instance send traffic to any destination, except for traffic blocked by Google Cloud. Implied IPv4 deny ingress rule. An ingress rule whose action is deny, source is 0.0.0.0/0, and priority is the lowest possible (65,535) protects all instances by blocking incoming connections to them. A higher priority rule might allow incoming access. If IPv6 is enabled, the VPC network also has these two implied rules: The implied IPv6 allow egress rule. An egress rule whose action is allow, destination is any IPv6 address, and priority is the lowest possible (65,535) lets any instance send traffic to any destination, except for traffic blocked by Google Cloud. A higher priority firewall rule may restrict outbound access. Internet access is allowed if no other firewall rules deny outbound traffic and if the instance has an external IP address. Implied IPv6 deny ingress rule. An ingress rule whose action is deny, source is any IPv6 address, and priority is the lowest possible (65,535) protects all instances by blocking incoming connections to them. A higher priority rule might allow incoming access. The implied rules cannot be removed, but they have the lowest possible priorities. For more information, check out the Google Cloud documentation on default firewall rules. In Google Cloud, all projects get a default VPC created automatically. In addition to the implied rules, the default VPC network is pre-populated with firewall rules that allow incoming, or ingress, traffic to instances. The first rule is default-allow-internal, which allows ingress connections for all protocols and ports among instances within the VPC network. It effectively permits incoming connections to VM instances from others in the same network. The other three rules in the default network are default-allow-ssh, default-allow-rdp, and default-allow-icmp. These rules allow port 22, secure shell (ssh), port 3389, remote desktop protocol (RDP), and ICMP traffic respectively, from any source IP address to any instance in the VPC network. All of these rules have the second-to-lowest priority of 65,534. As you may have noticed some of these rules can be a little dangerous. These rules can (and should) be deleted or modified as necessary. Some network traffic is always allowed. For VM instances, VPC firewall rules, and hierarchical firewall policies do not apply to: Packets sent to and received from the Google Cloud metadata server, And packets sent to an IP address assigned to one of the instance's own network interfaces (NICs) where packets stay within the VM itself. IP addresses assigned to an instance's NIC include: The primary internal IPv4 address of the NIC. Any internal IPv4 address from an alias IP range of the NIC. If IPv6 is configured on the subnet, any of the IPv6 addresses assigned to the NIC. An internal or external IPv4 address associated with a forwarding rule for load balancing or protocol forwarding if the instance is a backend for the load balancer or is a target instance for protocol forwarding. Loopback addresses. And, addresses configured as part of networking overlay software you can run within the instance itself. Check out the link in the Course Resources section for more information. There is some network traffic that is always blocked on VPC networks. Google Cloud blocks incoming DHCP offers and acknowledgments from all sources except for DHCP packets coming from the metadata server. External IPv4 and IPv6 addresses only accept TCP, UDP, ICMP, ICMPv6, IPIP, AH, ESP, SCTP, and GRE packets. There are a few firewall rule best practices to help secure instances running in Compute Engine. Keep your firewall rules in line with the model of least privilege. Create rules to explicitly allow only traffic necessary for your applications to communicate. It is always best to minimize direct exposure to the internet. To do this, avoid having “allow” firewall rules defined with the source or destination range set to 0.0.0.0/0. To prevent ports and protocols from being exposed accidentally, create a firewall rule with the lowest priority that blocks all outbound traffic for all protocols and ports. This rule will override the implied egress rule that allows all outbound traffic and instead lock down your Compute Engine instances from making connections. You should then create higher-priority firewall rules for specific Compute Engine instances to open required ports and protocols. This helps prevent ports and protocols from being exposed unnecessarily. Another best practice is to adopt a standard naming convention for firewall rules. The exact format is not critically important, just create a standard and be consistent. An example of a naming convention would be to include the following information in your firewall rules: The direction, which is ingress or egress allow or deny indicating the rule’s action. The service or protocol name. The word “from” or “to” and then a short description of the source or destination. Examples using this formation would be ingress-allow-ssh-from-onprem and, egress-allow-all-to-gcevms. When applying firewall rules, you should consider using service account firewall rules instead of tag-based rules. The reason for this is that tag-based firewall rules can be applied by any user who has the Compute Engine instance administrator role, but users require explicit IAM rights to use a service account. Cloud Next Generation Firewall packages firewall rules into firewall policies. Cloud NGFW consists of more than just Allow or Deny rules at the VPC network level. Cloud NGFW provides the ability to apply: Policies to VPC networks globally or regionally. Policies hierarchically to organizations, folder, and projects— and the ability to delegate an action to a lower level in the hierarchy. Layer 7 filtering, allowing you to control traffic based on applications. And enhanced filtering, based on URL, fully qualified domain names, and geolocations. Cloud NGFW provides an intrusion prevention service to detect and block known attack patterns, and also integrates with Google Threat Intelligence, to stay updated on the latest threats. Hierarchical firewall policies let you create and enforce a consistent firewall policy across your organization. You can assign hierarchical firewall policies to the organization as a whole or to individual folders. These policies contain rules that can explicitly deny or allow connections, as do Virtual Private Cloud (VPC) firewall rules. Global and regional network firewall policies improve upon the previous VPC firewall rules structure. Similar to hierarchical firewall policies, these network firewall policy structures act as a container for firewall rules. Rules defined in a network firewall policy are enforced once the policy is associated with a VPC network, enabling simultaneous batch updates to multiple rules in the same policy. The same network firewall policy can be associated with more than one VPC network, and each VPC network can only have one global network firewall policy and one regional firewall policy per region associated with it. Both global network firewall policies and regional network firewall policies support IAM-governed tags, and all Cloud firewall enhancements moving forward will be delivered on the new network firewall policy constructs. A global network firewall policy provides a global firewall configuration structure to match the global nature of Google Cloud VPC networks. It applies to workloads deployed in all Google Cloud regions in the VPC network. A regional network firewall policy provides a regional firewall configuration structure for Google Cloud firewalls that can only be used in a single target region. When using regional network firewall policies, users can designate a target region for a firewall policy. The firewall configuration data will be applied to workloads only in that specific region and will not be propagated to any other Google Cloud regions. Firewall Insights, a component product of Network Intelligence Center, produces metrics and insights that let you make better decisions about your firewall rules. It provides data about how your firewall rules are being used, exposes misconfigurations, and identifies rules that could be made more strict. Firewall Insights uses Cloud Monitoring metrics and Recommender insights. Cloud Monitoring collects measurements to help you understand how your applications and system services are performing. A collection of these measurements is generically called a metric. The applications and system services being monitored are called monitored resources. Measurements might include the latency of requests to a service, the amount of disk space available on a machine, the number of tables in your SQL database, the number of widgets sold, and so forth. Resources might include virtual machines, database instances, disks, and so forth. Recommender is a service that provides recommendations and insights for using resources on Google Cloud. These recommendations and insights are per-product or per-service, and are generated based on heuristic methods, machine learning, and current resource usage. You can use insights independently from recommendations. Each insight has a specific insight type. Insight types are specific to a single Google Cloud product and resource type. A single product can have multiple insight types, where each provides a different type of insight for a different resource. Cymbal has recently migrated its on-premises networks to Google Cloud. Kwan, a network engineer, is tasked with securing the Cymbal VPC networks. The firewall solution from the on-premises network works, but Kwan wants a flexible solution that can be applied at multiple levels of the Cymbal cloud infrastructure hierarchy. What should Kwan use? Solution: Kwan should use Cloud Firewall. Cloud Firewall includes hierarchical firewall policies that can be applied at the organization, folder, project or VPC level. It also includes global and regional network firewall policies.

### Video - [Lab Intro Configuring VPC Firewalls](https://www.cloudskillsboost.google/course_templates/1142/video/525510)

- [YouTube: Lab Intro Configuring VPC Firewalls](https://www.youtube.com/watch?v=N2u_zCdA30o)

Next, in a lab exercise, you’ll control access to VPC networks. In this lab, you investigate Virtual Private Cloud (VPC) networks and create firewall rules to allow and deny access to a network and instances.

### Lab - [Configuring VPC Firewalls](https://www.cloudskillsboost.google/course_templates/1142/labs/525511)

Configuring VPC Firewalls

- [ ] [Configuring VPC Firewalls](../labs/Configuring-VPC-Firewalls.md)

### Video - [Cloud IDS](https://www.cloudskillsboost.google/course_templates/1142/video/525512)

- [YouTube: Cloud IDS](https://www.youtube.com/watch?v=dKfC1rSa6gs)

Let’s talk briefly about another Google Cloud security offering—Cloud IDS. Quinn, a network engineer at Cymbal Corporation, is looking for a way to improve the security of the company's cloud infrastructure. Cymbal has observed a concerning rise in cyberattacks targeting sensitive customer and financial data. These attacks range from unauthorized access attempts to the delivery and execution of malicious software. Additionally, covert monitoring tools and command-and-control attacks attempting to establish communication channels between compromised systems and external servers have been detected. Such threats pose a substantial risk to Cymbal's reputation, customer trust, and regulatory compliance, underscoring the urgent need for advanced security measures. Solution To mitigate these escalating cyber threats, Cymbal has implemented Google Cloud IDS. Cloud IDS is a network security service offered by Google Cloud that provides real-time detection of intrusions, malware, spyware, and command-and-control attacks. With comprehensive monitoring of both internal and external traffic, Cloud IDS offers Cymbal improved visibility into their network and system vulnerabilities. The scalability of the service allows Cymbal to adapt their threat detection capabilities as their infrastructure expands. As a fully managed service, Cloud IDS simplifies security management, enabling Cymbal's IT team to focus on other priorities while ensuring the safeguarding of their critical assets. Cloud IDS is an intrusion detection service that provides threat detection for intrusions, malware, spyware, and command-and-control attacks on your network. Cloud IDS works by creating a Google-managed peered network with mirrored VMs. Traffic in the peered network is mirrored, and then inspected by Palo Alto Networks threat protection technologies to provide advanced threat detection. Cloud IDS provides full visibility into network traffic, including both north-south and east-west traffic, letting you monitor VM-to-VM communication to detect lateral movement. Cloud IDS provides full visibility into network traffic, including both north-south and east-west traffic, letting you monitor VM-to-VM communication to detect lateral movement. Cloud IDS gives you immediate indications when attackers are attempting to breach your network, and the service can also be used for compliance validation, like PCI 11. In addition, Cloud IDS automatically updates all signatures without any user intervention, enabling users to focus on analyzing and resolving threats without managing or updating signatures. To better understand Cloud IDS, it’s important to understand how the service uses endpoints and packet mirroring. Cloud IDS uses a resource known as an IDS endpoint, a zonal resource that can inspect traffic from any zone in its region. Each IDS endpoint receives mirrored traffic and performs threat detection analysis. Cloud IDS uses Google Cloud packet mirroring, which creates a copy of your network traffic. After creating an IDS endpoint, you must attach one or more packet mirroring policies to it. These policies send mirrored traffic to a single IDS endpoint for inspection. The packet mirroring logic sends all traffic from individual VMs to Google-managed IDS VMs. For example, all traffic mirrored from VM1 and VM2 will always be sent to IDS-VM1.

### Video - [Lab Intro Getting Started with Cloud IDS](https://www.cloudskillsboost.google/course_templates/1142/video/525513)

- [YouTube: Lab Intro Getting Started with Cloud IDS](https://www.youtube.com/watch?v=a0fa9O6ortA)

Next, we will explore a lab exercise on Cloud IDS. In this lab, you deploy Cloud Intrusion Detection System (Cloud IDS), a next-generation advanced intrusion detection service that provides threat detection for intrusions, malware, spyware, and command-and-control attacks. You simulate multiple attacks and view the threat details in the Google Cloud console.

### Lab - [Getting Started with Cloud IDS](https://www.cloudskillsboost.google/course_templates/1142/labs/525514)

Deploy Cloud IDS (Intrusion Detection System), a next-generation advanced intrusion detection service that provides threat detection for intrusions, malware, spyware and command-and-control attacks, to simulate multiple attacks and view the threat details. 

- [ ] [Getting Started with Cloud IDS](../labs/Getting-Started-with-Cloud-IDS.md)

### Video - [Secure Web Proxy](https://www.cloudskillsboost.google/course_templates/1142/video/525515)

- [YouTube: Secure Web Proxy](https://www.youtube.com/watch?v=LHrN1brhNYg)

Let us next explore Secure Web Proxy and its use case. Secure Web Proxy is a Google Cloud service designed to enhance the security of outbound web traffic (HTTP/S) from various sources, including virtual machines, containers, serverless environments, and workloads outside of Google Cloud. It acts as a gateway, filtering traffic based on configurable policies that leverage cloud identities and web applications. This enables organizations to enforce granular control over web access, improving overall security posture while maintaining flexibility and ease of use. Secure Web Proxy provides the following benefits: Streamlined Cloud migration: Secure Web Proxy simplifies your transition to Google Cloud by maintaining your current security policies for outbound web traffic. This eliminates the need for third-party tools or manual configuration adjustments. Controlled access to external services: By allowing you to define granular access policies, Secure Web Proxy enhances the security of your network. You can establish specific identities for workloads or applications and then apply policies to various web locations. Monitored access to untrusted websites: Secure Web Proxy identifies and logs any traffic that deviates from your established policies, providing you with valuable insights. This allows you to monitor internet usage, uncover potential threats, and respond proactively to safeguard your network. Let’s explore the last one on the list. Kwan, a network engineer at Cymbal Corporation, is staring down a growing network infrastructure headache. Kwan needs a unified, automated solution that simplifies network management across both on-premises and cloud environments, while providing granular security and cost control. Secure Web Proxy lets you apply granular access policies to your egress web traffic so that you can secure your network. This allows you to programmatically restrict cloud workload access to only trusted external web services. Secure Web Proxy enables you to create very specific rules for outgoing web traffic from your cloud environment. This means you can define exactly which external websites and services your cloud workloads are allowed to access. By doing this, you can significantly increase the security of your network. You're essentially creating an allowlist of approved web destinations, preventing your systems from communicating with potentially harmful or unauthorized websites. This programmatic restriction ensures that your cloud workloads interact only with the specific external web services you trust, minimizing the risk of data breaches, malware infections, and other security threats. It's a proactive approach to cybersecurity that helps you maintain control over your network traffic and safeguard your valuable assets.

### Video - [Debrief](https://www.cloudskillsboost.google/course_templates/1142/video/525516)

- [YouTube: Debrief](https://www.youtube.com/watch?v=DpFHwSYeDlQ)

This concludes the module. Before we wrap up, let's explore some useful Gemini prompts that can help you with related questions. The slide displays a few sample prompts to get you started. In this module, you learned about controlling access to VPC networks using IAM. You saw a sample IAM resource hierarchy and were shown how IAM policies controlled access to the Google Cloud resources. You then saw how policy constraints and firewall rules can fine-tune resource access. We also covered SWP and Cloud IDS. You applied what you learned in a lab exercise and a quiz.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/1142/quizzes/525517)

#### Quiz 1.

> [!important]
> **Which IAM role contains permissions to create, modify, and delete networking resources, except for firewall rules and SSL certificates?**
>
> - [ ] Network viewer
> - [ ] Network administrator
> - [ ] Security administrator
> - [ ] Security viewer

#### Quiz 2.

> [!important]
> **Which type of IAM member belongs to an application or virtual machine instead of an individual end user?**
>
> - [ ] Cloud Identity domain
> - [ ] Google group
> - [ ] Service account
> - [ ] Google account

## Advanced Security Monitoring and Analysis

This module provides an overview of packet mirroring for enhanced network security. Learn how to leverage this tool for traffic inspection, threat detection, and troubleshooting. We'll also cover essential network security best practices and test your knowledge with a quiz.


### Video - [Module Introduction](https://www.cloudskillsboost.google/course_templates/1142/video/525518)

- [YouTube: Module Introduction](https://www.youtube.com/watch?v=MOWHpKSj-js)

Welcome to the Advanced Security Monitoring and Analysis module. This module provides an overview of packet mirroring for enhanced network security. Learn how to leverage this tool for traffic inspection, threat detection, and troubleshooting. We'll also cover essential network security best practices and test your knowledge with a quiz.

### Video - [Packet Mirroring for network traffic inspection](https://www.cloudskillsboost.google/course_templates/1142/video/525519)

- [YouTube: Packet Mirroring for network traffic inspection](https://www.youtube.com/watch?v=v-8Vr5L49k0)

Izumi, a network engineer at Cymbal Corporation, needs to monitor the network traffic from selected virtual machines (VMs) to determine if malicious activity is occuring. Organizations face challenges in monitoring and securing specific virtual machines (VMs) within their network. Traditional security measures might not be sufficient to detect sophisticated attacks that span multiple network packets and target specific VMs. This can lead to vulnerabilities and security breaches, compromising sensitive data and critical systems. Packet mirroring offers a solution by creating a copy of network traffic specifically from the selected VMs. This mirrored traffic is then directed to a security analysis platform where it undergoes deep packet inspection. By capturing and analyzing all packets within each flow, security teams can identify anomalies, detect complex attack patterns, and promptly respond to threats targeting those specific VMs. This proactive approach enhances security posture, safeguards sensitive data, and ensures the integrity of critical systems. Packet Mirroring clones the traffic of specific instances in your Virtual Private Cloud (VPC) network and forwards it for examination. Packet Mirroring captures all ingress and egress traffic and packet data, such as payloads and headers. The mirroring happens on the virtual machine (VM) instances, not on the network. Therefore, Packet Mirroring consumes additional bandwidth on the hosts. Packet Mirroring is useful when you need to monitor and analyze your security status. It exports all traffic, not only the traffic between sampling periods. For example, you can use security software that analyzes mirrored traffic to detect all threats or anomalies. Also, you can inspect the full traffic flow to detect application performance issues and to provide network forensics for Payment Card Industry Data Security Standards (PCI DSS) compliance and other regulatory use cases. We will elaborate on this further in the next few slides. Obviously, Packet Mirroring can generate significant data, so collector destination is generally an instance group behind a internal load balance or equivalent technology. One of the major limitations of Packet Mirroring is bandwidth consumption. Packet Mirroring consumes the egress bandwidth of the mirrored instances. However, there is a work-around. Use filters to reduce the traffic collected for mirrored instances. This filter can be used for IP address ranges, protocols, traffic directions, and a lot more. The current maximum number of filters that can be used for Packet Mirroring is 30. For more information, refer to the link in the speaker notes.

### Video - [Network security best practices](https://www.cloudskillsboost.google/course_templates/1142/video/525520)

- [YouTube: Network security best practices](https://www.youtube.com/watch?v=unM5ncdh7LQ)

Some of the network security best practices are listed on the slide. This list varies on a case-by-case basis based on the environment. Adopt a zero trust network model. This approach ensures that no user or device is implicitly trusted, regardless of their location inside or outside the organization's network. By verifying both user identity and context during access requests, you shift security controls from the network perimeter to individual users and devices, providing a more robust and granular approach to security. Secure connections between on-prem and Google Cloud: For organizations operating in hybrid or multi-cloud environments, prioritize secure connectivity between all environments to ensure data protection and minimize risks. Leverage Google Cloud's private access options like Cross-Cloud Interconnect, Dedicated/Partner Interconnect, and IPsec VPNs to establish secure, high-speed connections between your on-premises infrastructure and various cloud environments. Additionally, explore Private Service Connect for accessing Google APIs and published services with enhanced security, ensuring seamless communication while maintaining robust security measures. Disable default networks: to enhance network security and avoid IP address conflicts, disable the creation of default networks in Google Cloud projects. Plan your network and IP address allocation strategically across connected deployments and projects to ensure efficient and secure communication. As a best practice, limit the number of VPC networks per project to one for more effective access control. Secure your cloud perimeter with Google Cloud's tools like firewalls and VPC Service Controls. Employ Shared VPC to centralize network management and isolate workloads into separate projects, enhancing security and control. Create firewall policies and rules at multiple levels (organization, folder, VPC network) to allow or deny traffic based on various criteria, including IP addresses, protocols, ports, service accounts, and secure tags. Analyze your network. Google Cloud provides two tools, Cloud IDS and Packet Mirroring, to help you monitor and secure your network traffic in Compute Engine and Google Kubernetes Engine. Cloud IDS provides visibility into your VPC network traffic, while Packet Mirroring allows you to clone and forward specific VM traffic for further analysis and inspection with security tools. Use a web application firewall: strengthen the security of your external web applications and services by implementing Google Cloud Armor, a web application firewall (WAF) that also provides protection against DDoS attacks. For optimal protection of critical workloads, leverage the advanced features offered by Google Cloud Armor's Managed Protection Plus tier. Adopt automated infrastructure provisioning using tools like Terraform, Jenkins, or Cloud Build to create immutable environments for enhanced security and streamlined operations. Leverage Google Cloud's security blueprints as a foundation, or build upon them with your own automation to align with security best practices and guidelines. Monitor your network. Implement VPC Flow Logs and Firewall Rules Logging to gain near real-time visibility into your Google Cloud network traffic and firewall activity. Utilize tools like Cloud Logging, Cloud Monitoring, Firewall Insights, and Network Intelligence Center to track, analyze, and optimize your network security and performance.

### Video - [Debrief](https://www.cloudskillsboost.google/course_templates/1142/video/525521)

- [YouTube: Debrief](https://www.youtube.com/watch?v=Wc_-stMQ4SM)

This module provided an overview of packet mirroring for enhanced network security. You learned how to leverage this tool for traffic inspection, threat detection, and troubleshooting. The module also covered essential network security best practices and tested your knowledge with a quiz.

### Quiz - [Quiz](https://www.cloudskillsboost.google/course_templates/1142/quizzes/525522)

#### Quiz 1.

> [!important]
> **What is the primary purpose of Packet Mirroring in network security?**
>
> - [ ] To encrypt network traffic for privacy.
> - [ ] To redirect traffic to a different network interface.
> - [ ] To create a duplicate copy of network traffic for analysis.
> - [ ] To filter out unwanted traffic from a network.

#### Quiz 2.

> [!important]
> **Which of the following is a key benefit of using Packet Mirroring for network security analysis?**
>
> - [ ] It reduces network bandwidth usage.
> - [ ] It automatically patches vulnerabilities in software.
> - [ ] It directly prevents cyberattacks.
> - [ ] It enables the capture and inspection of traffic without impacting network performance.

## Course Resources

Student PDF links to all modules

### Document - [Networking in Google Cloud: Network Security Course Resources](https://www.cloudskillsboost.google/course_templates/1142/documents/525523)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)

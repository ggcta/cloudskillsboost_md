---
id: 169
name: 'Upgrading and Monitoring the Apigee Hybrid API Platform'
type: Course
url: https://www.cloudskillsboost.google/course_templates/169
date_published: 2023-11-03
topics:
  - Analytics
  - API
  - API Management
---

# [Upgrading and Monitoring the Apigee Hybrid API Platform](https://www.cloudskillsboost.google/course_templates/169)

**Description:**

This course discusses the upgrade process for Apigee hybrid, and teaches you how to monitor and troubleshoot the hybrid runtime plane components.

**Objectives:**

* Describe the upgrade and rollback process used for the Apigee hybrid installation.
* Troubleshoot and monitor the hybrid runtime plane components using logs, metrics, and analytics.

## Course Introduction

This course teaches you how to upgrade, monitor and troubleshoot Google Cloud's Apigee hybrid API platform.

### Video - [Course series introduction](https://www.cloudskillsboost.google/course_templates/169/video/419561)

* [YouTube: Course series introduction](https://www.youtube.com/watch?v=bn4Cqpp2-FI)

Hi, I'm Hansel Miranda, a course developer at Google. I’d like to welcome you to Managing Google Cloud’s Apigee API Platform for Hybrid Cloud. This is a series of three courses that teach you the concepts and skills required to install and manage the Apigee hybrid API management platform. In the first course, we discuss fundamental concepts, the hybrid architecture, and you learn how to install the Apigee hybrid platform. In the second course, you learn how to manage the platform, and about the practices used to secure the hybrid runtime components. The third course teaches you about upgrading, monitoring, and troubleshooting Apigee hybrid. These courses are intended for cloud architects and operations specialists who want to install, manage, and operate the Apigee API platform using the hybrid deployment model. You must be familiar with Linux commands and have a basic understanding of Google Cloud, Kubernetes Engine, and networking, as well as common web protocols and standards like REST and HTTP. Through presentations, demos, and a hands-on lab, you will learn how to install and operate the Apigee hybrid platform on Google Cloud. The course will cover the architecture, the installation process, and the techniques used to manage and monitor the hybrid runtime platform. Specifically, you will learn about the product fundamentals, the Apigee hybrid architecture, and how to install and operate Apigee hybrid. You will learn about API proxy deployment and environment management, how hybrid components are secured, and capacity planning and scaling the hybrid platform. You will also learn how to upgrade Apigee hybrid and how to use hybrid logging and monitoring to troubleshoot issues with the platform. The lab in this course will be done using Qwiklabs. Qwiklabs provisions you with Google account credentials, so you can access the Google Cloud Console for the lab at no cost. For each lab, Qwiklabs offers a free set of resources for a fixed amount of time and a clean environment with required permissions. This course provides you with the knowledge and skills needed to install and manage Apigee hybrid. Take time to understand the concepts introduced in the lectures and the techniques used in the lab. The lectures, together with the lab and demos, teach you how to install, manage, and perform common operational tasks like scaling, monitoring, and troubleshooting Apigee hybrid. We hope you enjoy the course.

### Video - [Course introduction](https://www.cloudskillsboost.google/course_templates/169/video/419562)

* [YouTube: Course introduction](https://www.youtube.com/watch?v=ulzlgR7X6XY)

Welcome to Upgrading, Monitoring and Troubleshooting Apigee Hybrid, the third course in the series on Managing Google Cloud's Apigee API Platform for Hybrid Cloud. In this course, you'll learn how to upgrade and roll back the Apigee hybrid runtime installation in your Kubernetes cluster. We will discuss how Apigee hybrid performs logging activities and how you can use the runtime logs for troubleshooting purposes. We will also review the various metrics generated by the hybrid runtime components. We will discuss Apigee Analytics and the various types of reporting dashboards available for you to use in Apigee hybrid. You will learn how to monitor and troubleshoot the Apigee hybrid runtime components. And we will discuss how we can make the best use of Apigee Support while using Apigee hybrid. Welcome to the course.

## Upgrade

This module describes the update and rollback process used in Apigee hybrid.

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/169/video/419563)

* [YouTube: Module overview](https://www.youtube.com/watch?v=ugTHZJ7rRu8)

In this module, you will learn how to upgrade your Apigee hybrid installation to a new release of the software distribution. We will also discuss rollback procedures, so you can roll back the Apigee Hybrid installation to a previous version.

### Video - [Upgrade process](https://www.cloudskillsboost.google/course_templates/169/video/419564)

* [YouTube: Upgrade process](https://www.youtube.com/watch?v=hqXsflrSpzA)

In this lecture, we will review the process to upgrade Apigee hybrid to a newer version of the software distribution. Before performing an upgrade, you should always review the release notes for the Apigee hybrid release version you are upgrading to. The release notes contain important information about the new features that are released, any features that are in beta, bug fixes, any required configuration file changes, and any updates to supporting software platforms. It is also recommended to back up your hybrid runtime installation and Cassandra database following the instructions in the Apigee hybrid documentation. Upgrading your version of Apigee hybrid requires a supported version of the Kubernetes platform. The minimum required Kubernetes version is documented in the release notes of the Apigee hybrid release version you are upgrading to. Confirm that your this platform version is supported. If it isn't, follow your platform provider documentation to upgrade it. You first download the new release of the Apigee hybrid distribution for your operating system. The software distribution packages are hosted in a public cloud storage repository. The next step in the upgrade process is to re-map your installation directory. Identify the base installation directory that was created when Apigee hybrid was originally installed. To find the base directory, inspect the value of the APIGEECTL_HOME environment variable. It will point to a directory that resides within the base directory. Extract the new version of the Apigee hybrid software in the base installation directory. Rename the current apigeectl directory. For example, if the current version is 1.1.1, rename the apigeectl directory to apigeectl_1.1.1. Rename the newly extracted installation directory to apigeectl. This is now where the environment variable $APIGEECTL_HOME points to. For some newer versions of Apigee hybrid, you may have to update the overrides.yaml file used to configure your runtime plane cluster. Make a copy of your current overrides file, and save the old file in case you ever need to roll back. Make the required changes to the overrides file based on the release documentation. You are now ready to apply the upgrade. Run the apigeectl init command to re-initialize the cluster with the updated overrides.yaml configuration file. This will update the Apigee hybrid system components. Run the apigeectl check-ready command to confirm that the initialization has completed. If you want to check for configuration errors before modifying the cluster further, use the --dry-run option with the apigeectl apply command. Then, update the hybrid workload components in the cluster by running the apigeectl apply command with the updated overrides.yaml file. Finally, re-run the apigeectl check-ready command to confirm that all the containers in the cluster are running. For production environments, you should apply the upgrades separately to each set of runtime components in the cluster. After the cluster is initialized, apply the new overrides file, first to the Cassandra datastore component, then to the telemetry components, the Redis components, the organization-scoped components, the environment-scoped components, and the virtualhosts components. In production environments, it is a good practice to run the apigeectl check-ready command after each component is upgraded. Apigee hybrid supports rolling updates to the runtime components in the cluster. In Kubernetes, rolling updates are implemented by incrementally updating pod instances with new ones that are scheduled on nodes with available resources. In the example, a new overrides.yaml configuration file is created with the memory property of the runtime message processor component increased from its current setting. You then apply the new configuration to the cluster by running the apigeectl apply command. After the configuration changes are applied, updated pods start up and replace the existing pods. Apigee hybrid supports AB rolling updates to the runtime components configuration. In this type of rolling update, a small percentage of traffic is initially directed to the updated pods. The traffic is increased incrementally until 100% of the traffic flows to the updated pods; the old pods are then deleted from the cluster. To implement an AB rolling update, use the revision property in your overrides.yaml configuration file. In the example, a new overrides.yaml configuration file is created with the revision property set to green and the memory property of the runtime message processor component increased from its current setting. The revision property can be set to any value that is different from the current setting. You then apply the new configuration to the cluster by running the apigeectl apply command. In addition to the Apigee hybrid release notes, you should also review the upgrade and release process documentation on the Apigee website. The documentation may describe additional steps to be performed when upgrading your hybrid release between specific versions.

### Video - [Rollback process](https://www.cloudskillsboost.google/course_templates/169/video/419565)

* [YouTube: Rollback process](https://www.youtube.com/watch?v=roHzCxaQvjc)

Let's discuss the process to roll back Apigee hybrid in the runtime plane. If you observe errors in the Apigee hybrid Runtime plane during or after an upgrade, you can roll the upgrade back. To roll back an upgrade, follow these steps. First, clean up any completed jobs in your cluster from the upgrade process. To delete a job, use the kubectl delete job command, passing in the name of the completed job to be deleted. Repeat the command for all the completed jobs in the apigee and apigee-system namespaces used in Apigee hybrid. Change the APIGEECTL_HOME environment variable to point to the directory that contains the previous version of apigeectl. Next, run the apigeectl apply command to update the hybrid workload components in the cluster with the overrides.yaml configuration file from your previous hybrid installation. Re-run the apigeectl check-ready command to confirm that all the containers in the cluster are running. Finally, check the status of the pods and check the status of apigeeds. Proceed to the next step only when the apigeeds pod is running. Note that it is a best practice to store your overrides.yaml file in source code control for easy access to previous revisions. Finally re-initialize Apigee hybrid by executing the command shown. It is a good practice to clean up any completed jobs in your cluster from the previous installation. To delete a job, use the kubectl delete job command, passing in the name of the completed job to be deleted. Repeat the command for all the completed jobs in the apigee-system namespace used in Apigee hybrid. Make sure to consult the rollback process documentation on the Apigee hybrid website. The steps to roll back might vary based on the source and target version of the hybrid software distribution.

### Quiz - [Upgrade](https://www.cloudskillsboost.google/course_templates/169/quizzes/419566)

#### Quiz 1.

> [!important]
> **When upgrading Apigee hybrid:**
>
> * [ ] You do not have to back up the runtime datastore used in your current Apigee hybrid installation.
> * [ ] You may need to upgrade the underlying Kubernetes platform.
> * [ ] You can upgrade Apigee hybrid from any previous version to the latest released version.

#### Quiz 2.

> [!important]
> **What is the recommended best practice to perform a rolling incremental (A/B) update to a hybrid runtime component?**
>
> * [ ] Set the revision property in the overrides.yaml file, and run the apigeectl apply command.
> * [ ] Rolling updates are not supported by Apigee hybrid.
> * [ ] Run the kubectl set command.
> * [ ] Using the kubectl set command or the revision property in the overrides.yaml file are both best practices.

#### Quiz 3.

> [!important]
> **When upgrading Apigee hybrid in a production environment, what sequence should you follow to upgrade the runtime plane components in the cluster?**
>
> * [ ] Upgrade environments, organization-level components, Cassandra, and telemetry components, in that order.
> * [ ] Upgrade organization-level components, Cassandra, telemetry components, and environments, in that order.
> * [ ] Upgrade Cassandra, telemetry components, Redis components, organization-level components, environments, and virtualhosts in that order.
> * [ ] Upgrade telemetry components, organization-level components, environments, and Cassandra, in that order.

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/169/video/419567)

* [YouTube: Module review](https://www.youtube.com/watch?v=RRV1AlyzfzQ)

In this module, you learned how to upgrade the Apigee hybrid runtime plane to a newer version of the software distribution. You also learned about the rollback process in case you need to rollback Apigee hybrid due to errors in the newer version. In the next module, you will learn how Apigee hybrid log system informational and error messages, and how you can use analytics and metrics data to monitor and troubleshoot Apigee hybrid.

### Document - [Reading: Upgrade considerations](https://www.cloudskillsboost.google/course_templates/169/documents/419568)

## Logging and Monitoring

This module discusses how Apigee hybrid generates logs, metrics and analytics data that can be used for monitoring purposes.

### Video - [Module overview](https://www.cloudskillsboost.google/course_templates/169/video/419569)

* [YouTube: Module overview](https://www.youtube.com/watch?v=ZOWZF8mWA1c)

In this module, you will learn how Apigee hybrid log system informational and error messages. You will also learn how you can use analytics and metrics data to monitor and troubleshoot the platform. Finally, we will discuss Apigee support model and how you can request support for issues related to Apigee hybrid.

### Video - [Logging](https://www.cloudskillsboost.google/course_templates/169/video/419570)

* [YouTube: Logging](https://www.youtube.com/watch?v=oXIz6mLkMOw)

In this lecture, you will learn how Apigee hybrid logs messages from the runtime plane and how you can view those messages for troubleshooting purposes. In later lectures, we will discuss how hybrid metrics and analytics are collected and reported and how you can use these capabilities to monitor Apigee hybrid. And we will discuss how you can leverage that Apigee hybrid support process to get help with your Apigee hybrid installation. All of the Apigee hybrid services that run in your Kubernetes cluster generate log information. This log information is useful for troubleshooting and debugging a given service or pod. If a pod's status indicates a problem, you can look at the log files for that pod to gain insight into the issue. Apigee support may request you to provide this log information to diagnose and solve a problem. Let's review how logging works in Apigee hybrid. Each runtime plane service in Apigee hybrid writes log data to stdout/stderr, which Kubernetes saves to the host filesystem. A logs collector for hybrid runs on each node in the cluster. The collector is a Kubernetes DaemonSet that has one pod replica per node. Apigee hybrid uses fluentd, which is an open source data collector application. Fluentd enables you to unify data collection and consumption. Fluentd collects the written log data from the host file system. The fluentd collector exports the logs to the Cloud Logging instance associated with your account on Google Cloud. You access the log data in the Cloud Logging UI in the Google Cloud console. On GKE, Apigee hybrid uses the default logging mechanism for all runtime plane components. You can view log data by using the kubectl logs command to directly query the hybrid runtime pod. You must provide the pod name and the pod namespace to the command. You can also view logs in the Cloud Logging UI section of the Cloud Console. To view hybrid runtime component logs in Cloud Logging, you select the Kubernetes Container as the audited resource type. You then select your cluster, the namespace in the cluster that contains the hybrid component and the specific component whose logs you want to view. In the example shown, the apigee-runtime or message processor component logs will be shown in Logs Explorer. Audit logs help you track activity on the resources in your project. Apigee hybrid uses Cloud Audit Logs in Google Cloud to write admin activity logs. The admin activity audit logs record operations that modify the configuration or metadata of a resource and cannot be disabled. You can also enable data access audit logs in Apigee hybrid. These logs record API calls that read the configuration or metadata of resources or update user provided resource data. Data access audit logs are disabled by default because they can be very large. Both the admin activity and data access audit logs (if enabled), can be viewed by using Cloud Logging or the gcloud command line tool.

### Video - [Metrics](https://www.cloudskillsboost.google/course_templates/169/video/419571)

* [YouTube: Metrics](https://www.youtube.com/watch?v=CyaoreAAMUo)

Metrics are an important feature, used to monitor the health of a system. In this lecture, you will learn how metrics are generated by that Apigee hybrid runtime playing components. Late in this module, you will learn how to use these metrics for monitoring purposes. Apigee Hybrid uses Prometheus to collect metrics from all the runtime playing components in the cluster. Prometheus is an open source monitoring tool kit that is deployed in your Kubernetes cluster as an operator addon, when you install Apache hybrid Prometheus scrapes application metrics from all hybrid services and sends the metrics to cloud monitoring. There's one Prometheus server running per cluster, let's review how metrics collection works in Apigee Hybrid. Prometheus Scrapes Metrics Data, be at http endpoints every few seconds from all the runtime services in the cluster, and then stores it. It then periodically sends the collected metrics data, to the cloud monitoring service running in Google cloud. The metrics data is associated with your Google Cloud account and project. You can access the metrics data, via the cloud monitoring you I and the cloud console, to configure metrics collection on your hybrid runtime components. Edit your overrides.yml file and provide the Google Cloud Project ID associated with your hybrid project, and the Google Cloud Region where metrics should be collected. This is also the region where the Apigee hybrid runtime component logs are sent. You must also provide the path to the service account key file, that was created for the metrics component during hybrid installation, metrics collection is enabled by default. To disable it, set the enabled property to false, after these changes are made, use the Apigee CTL Command, with the telemetry flag, to apply them to your cluster. You can view the metrics generated by Apigee Hybrid using the cloud monitoring metrics Explorer in the Google Cloud console. Using the metrics explore, you can create dashboards to plot the various metrics for each hybrid runtime component. You identify the runtime component, by specifying the resource type and name. Cloud monitoring then generates a dashboard for the selected metric for that resource or component. Apigee hybrid generates many useful metrics that you can use to monitor the health of your runtime plane. These include API proxy and target metrics that provide data on API request and response latencies, and traffic counts. Metrics are also available for the individual hybrid runtime components. For the Cassandra Component, metrics on JVM memory usage, compaction tasks, etc are all collected. The full list of metrics is available on the Apigee hybrid documentation website.

### Video - [Analytics](https://www.cloudskillsboost.google/course_templates/169/video/419572)

* [YouTube: Analytics](https://www.youtube.com/watch?v=9OZVEoDw30o)

In this lecture, you will learn about Apigee analytics and the reporting capabilities available in Apigee hybrid. Apigee Analytics collect and aggregates a large amount of information that flows through your API proxies. You can visualize this data with graphs and charts in the Apigee hybrid UI, or you can use the Apigee APIs to download the data for offline analysis. Apigee API Analytics collects and analyzes a broad spectrum of data that flows across API proxies, including response time, request latency, request size, and target errors. The complete list of data collected by analytics is available on the Apigee Documentation website. The Apigee API hybrid UI provides a set of predefined dashboards that you can use to view analytics data. Here are 3 sample dashboards. The proxy performance dashboard includes charts for various metrics such as total traffic received an average response time. The target performance dashboard includes charts for metrics such as traffic by target server and target response times. The error analysis dashboard includes charts for metrics such as proxy errors, target errors, and error by response code. To improve API response times and reduce latency, your API proxies can use the cache policies available in Apigee hybrid. The cache performance dashboard enables you to see how well your cache strategy is working. It includes charts that plot various metrics such as the cache hit rate, total cache hits, and API response time with cache. Apigee hybrid analytics currently includes a set of dashboards that you can use to track the performance of your APIs. In addition to the performance dashboards, analytics also includes developer engagement and traffic composition dashboards that plot the number of active app developers, as well as top 10 apps, developers, API products, and proxies. The error code analysis dashboard gives you a view into errors from your proxies, target servers, errors by response code, etc., and provides valuable insight into the source of errors from your APIs. The Device usage dashboard plots information about the devices and user agents that are being used to access your APIs. It lets you spot trends in the device types that are being used to access your APIs. The Geomap dashboard tracks traffic, and error patterns across geographical locations. The dashboard helps you analyze API trends by location and focus on locations and the errors that may be occurring. Apigee hybrid supports the creation of custom reports. Custom reports enable you to drill down into specific API metrics data for analysis. Use the Apigee hybrid UI to create a custom report that includes any of the built-in Apigee dimensions and metrics. Apigee hybrid provides a Metrics API that can be used to automate certain analytics functions, such as retrieving metrics periodically using an automation client or script. You can also use the API to build your own visualizations in the form of custom widgets that you can embed in portals or custom apps.

### Video - [Demo: Analytics in Apigee hybrid](https://www.cloudskillsboost.google/course_templates/169/video/419573)

* [YouTube: Demo: Analytics in Apigee hybrid](https://www.youtube.com/watch?v=Gg_O2M1FGG4)

This demo is about using Analytics in Apigee hybrid. Apigee hybrid collects and calculates a wealth of information that flows through your API proxies. You can visualize this data with graphs and charts in the hybrid UI, or you can download the raw data for offline analysis using the hybrid APIs. Analytics help you answer common questions, such as, how is the API traffic trending over time? Which API methods are most popular? Who are my top app developers? When is the API response time fastest or slowest? Geographically, where do I see the most API traffic? The answers to questions like these help you improve your APIs, troubleshoot problems, and make better business decisions related to your API program. This demo is part of the Managing Google Cloud's Apigee API Platform for Hybrid Cloud course. Assumes you have a working installation of Apigee hybrid, including the test install API proxy created in your hybrid organization. Login to the Apigee hybrid UI at apigee.google.com using your credentials. In the left navigation menu, click Analyze. You can view API metrics, developer or end-user Analytics in a set of predefined dashboards over a given time range and for a given hybrid environment. You can also create and view custom reports. Click the arrow next to API metrics to expand the list. Apigee hybrid collects and makes available Analytics related to API proxy performance, cache performance, error codes, proxy latency, and target backend performance. Click API proxy performance. This dashboard helps you see API proxy traffic patterns and processing times. You can easily visualize how much traffic you're APIs generate and how long it takes for API calls to be processed from the time they are received by Apigee hybrid and until they are returned to the client app. The traffic chart shows a breakdown of successful and error cause to the API proxy. While the average response time shows a breakdown of the average proxy time and average time taken by the target backend to process the request. Note that after a call is made to an API proxy, it can take up to a few minutes for the data to be accessible for display in the Analytics dashboard. Click Cache Performance in the navigation menu under Analyze API metrics, this dashboard displays the average cache hit rate if you're API proxy uses a cache policy. It also includes charts that plot the number of cache hits and the average response time of the proxy when the cache is used to serve API requests. Next click the Error Code Analysis in the menu under Analyze API metrics. This dashboard includes the error composition chart that shows the total number of errors broken down by proxy errors and errors received from the target backend. It also has chance that displays a further breakdown of proxy and target errors by HTTP status code, and by individual targets servers. Click the Latency Analysis dashboard in the left menu under Analyze API metrics. This dashboard includes charts that plot the API proxy response times, target backend response times, as well as the time taken by the API proxy to process the request and response. In the proxy list, select the proxy for which you view the Analytics data. We will select the TestInstall proxy. You can optionally set the region to view data collected for a specific region. These dashboards plot the median 95th and 99th percentile of the requests and responses received. Using these charts, you can easily determine how fast your target backend servers are responding, as well as the overhead in processing time that is incurred by the API proxy. Next, click Target Performance in the menu under Analyze API metrics. This dashboard includes charts that plot the traffic or total number of requests that pass from Apigee hybrid to the target backend servers. It also includes charts that plot the traffic composition of successful and error requests, the average proxy and target processing times for the requests and responses, the number of target errors broken down by HTTP status codes, and the request and response payload sizes. All of these charts can plot data for a specific target server by applying the target IP address filter in the dashboard. Click Develop Engagement in the navigation menu under Analyze Developers. The Developer Engagement dashboard displays a chart of the current total number of developers and the number of active developers, as well as the number of developers with apps and those that are highly active, generating more than 50 transactions per hour in your hybrid organization. Using this chart, you gain valuable insights into how your API program is performing in terms of the number of developers and applications that are consuming your APIs. The Traffic Composition dashboard further breaks down your API traffic by the top 10 proxies, developers, API products, and applications. This provides further insight into your top-performing API products and proxy is allowing you to focus on their usage and engagement with app developers and consumers. You can drill down into this data by setting the dimension filter to view charts for a specific API proxy, developer, product, or app over a monthly time period. The devices and geomap dashboards, under developers End Users, display charts that show traffic distribution by the calling device user agent and by geographic location. You can also create your own custom reports by selecting a dimension and metric to plot in the report. Once saved, Apigee hybrid will collect and aggregate the data for the specified dimension as traffic is received by the API proxies in that environment. You can then analyze the data using charts in the Custom reports dashboard. Apigee Analytics provides a comprehensive suite of out-of-the-box dashboards and custom reports which you use to operate and manage your API program.

### Video - [Monitoring and troubleshooting](https://www.cloudskillsboost.google/course_templates/169/video/419574)

* [YouTube: Monitoring and troubleshooting](https://www.youtube.com/watch?v=nDbev9pFs80)

In this lecture, we will discuss monitoring and troubleshooting Apigee hybrid. You will learn how to troubleshoot issues in the runtime plane. Monitoring the Apigee hybrid runtime plane involves checking the health of your Kubernetes cluster and the health of the pods that are running in the cluster. There are several metrics that can be used for cluster and pod monitoring. The metrics generated by the cluster and the runtime pods are sent to Google Cloud, where you can view and monitor them using dashboards in the Cloud Monitoring UI. When monitoring the overall health of your Kubernetes cluster, you determine whether the nodes in the cluster are operating normally and whether there is sufficient capacity. Many cluster metrics are available to gauge node resource utilization, such as CPU, memory, disk and network bandwidth utilization. To monitor the pods in your cluster, you can use Kubernetes metrics to track the number of pods in the cluster and their storage volume utilization. This can help you determine whether the number of pods running does not match the desired count, which indicates node or cluster resource constraints. Container metrics like CPU utilization provide the fraction of requested CPU and the amount currently in use by the container. Similar container metrics are also available for memory utilization. Both of these metrics can be used to gauge the resource usage, capacity, and health of your cluster. As discussed in a previous lecture, Apigee hybrid generates many application metrics for each of the runtime components in the cluster. You can use these metrics to monitor the health of those components and of the proxies that process the API traffic flowing through the cluster. Apigee hybrid collects various metrics from the runtime components and sends them to Cloud Monitoring on Google Cloud. Cloud Monitoring is a service that collects and ingests metrics, events, and metadata. it generate insights into this data via dashboards and alerts. You can use these predefined dashboards or create custom ones to view and analyze metrics data from your Kubernetes cluster. Using custom dashboards, you can analyze metrics from Apigee hybrid runtime components and create alerts and notifications based on thresholds that you define. An alert notification enables you to review and take action to resolve the condition that triggered the alert. A well-defined monitoring strategy relies on trained personnel, well documented processes, and having the right tools in place. Personnel are typically system administrators with experience in cloud operations, database management, devOps automation, and general operations. Processes to manage your Apigee hybrid operations should include event and incident management, change and release management, and capacity planning. To support your Apigee hybrid operations tasks, you need tools for configuration management, system observability and monitoring, and security and compliance tracking. As part of your monitoring and troubleshooting process, adopting a well-defined support and incident workflow is critical. The process should cover various phases in troubleshooting an issue, from detection, triage, service restoration and validation to root cause analysis. Each phase incorporates distinctive capabilities. It is important to have a central tool or console to detect and triage issues with the platform. A well-designed tool will have alert generation and integration with CRM tools to manage customer reporting and also visualization and diagnostic capabilities. Using runbooks and automation is a repeatable best practice when restoring services. Component and functional health checks are essential pieces of a service validation strategy after the service has been restored. A root cause analysis must always be performed for service outages in production environments. It helps document the cause and effect of the problem and helps to implement procedures to prevent recurrence. An alert that is generated by your monitoring system must have sufficient information that makes it actionable. Details in the alert notification should include the metric that triggered the alert, service information, and any other details that help the operator take corrective action. A best practice is to create playbooks that document the problem, any triggers, and steps to resolve or escalate the issue. This helps to create a well defined, repeatable process for operators to follow when similar issues arise in the future. In general, sending a notification of problems is not enough. Defining actionable alerts and playbooks to resolve the problems with automation is required and should be part of your monitoring and troubleshooting strategy. Let's review some common troubleshooting scenarios. Assume there are some requests to your API proxy that are failing intermittently or have increased latency. Apigee analytics is one of the tools that you can use to troubleshoot issues with your API proxies. It is easy to access and use the various analytics dashboards in the Apigee hybrid UI. You can review the error analysis, the API proxy and target performance, and latency dashboards to troubleshoot errors or latency issues with your API proxy. Using the charts in these dashboards, you can determine the source of the errors or latency to determine whether the issue is from the target backend or the API proxy itself. When monitoring your API management platform, it is important to focus on the runtime critical path. This includes the calling client application, any firewall and load balancers in front of the ingress gateway external to the cluster, the runtime message processor component that processes the API request, any firewall and load balancers in your network, and your backend system. The components that you manage within your infrastructure should support a high level of uptime SLA and must be continuously monitored. Issues with high latency or traffic interruption can be investigated at various places in the runtime critical path. For connectivity issues between the client applications and the hybrid runtime plane, check any firewall or load balancer configuration that you may have in front of your ingress gateway. For connectivity and latency issues between the API proxy and the target backend servers, perform the check on any network objects that may also lie within your backend network. Of course there may be other issues outside of the network that cause traffic interruption or latency. An unexpectedly large payload could cause the backend service to react unpredictably. You can mitigate this issue by implementing payload validation in your API proxy. Other issues related to API proxy complexity or runtime resource capacity can be investigated by examining the API logic in the current resource allocations in your cluster. The debug feature in Apigee hybrid is a useful tool that enables you to troubleshoot and monitor issues in your API proxy logic. Using debug, you can probe the policies in your API proxy as they process the request and response data that flows through the proxy. The debug tool displays the value of request and response metadata and any data you store in flow variables in your proxy. This enables you to view how this data is modified by your proxy logic and aids debugging issues with the API. Troubleshooting the analytics service involves checking connectivity between some of the runtime components that are used to stream and collect analytics data. The connections involved are between the runtime message processor and the Universal Data Collection Agent or UDCA component in the runtime plane and between UDCA and the Unified Analytics Platform or UAP component in the management plane. Pod file system capacity and directory permissions can also contribute to issues with the analytics service in Apigee hybrid. To troubleshoot UDCA operation, you can view the pod logs directly or within the Cloud Logging UI in the Google Cloud console. In the Cloud Logging UI, use the Kubernetes container filter to select the resource by selecting your hybrid cluster, namespace and the apigee-udca runtime component. You can then view the log entries generated by the UDCA runtime component. Let's discuss a few troubleshooting scenarios. One of the most common issues that arise is an error during API proxy deployment. Errors can be due to the proxy implementation logic, or the size of the API proxy bundle. The size and other product limits are documented on the Apigee hybrid resources website. Other errors due to management service availability, or connectivity issues between the management service and the runtime plane components, although rare, are possible. Errors can also be due to missing API proxy configuration dependencies such as key value maps and target servers. Make sure to configure these objects as part of your proxy development lifecycle in all of the hybrid runtime environments where they are needed. Another possible source of errors is that the runtime Synchronizer, Message Processor, or UDCA pods are not successfully running or there are connectivity issues between the Synchronizer or UDCA components and the management plane. To troubleshoot, you need to look at the individual component pod log files to determine the cause of the error. The message processor runtime component deploys API proxies and executes proxy logic. A message processor pod can sometimes indicate that it is not in a ready state. This can be caused by connectivity issues with the synchronizer runtime component, or between the synchronizer component and the management plane. To troubleshoot, make sure that the synchronizer is up and running and that the service account used to configure the synchronizer or for the environment is valid. You can use the apigeectl command to restart the synchronizer by providing your overrides.yaml configuration file and the synchronizer component type. For errors due to validation of encryption keys, make sure that the configured key is base64-encoded and that the key length is supported by Apigee hybrid. To help isolate a problem with API proxies, check whether you can make an API proxy call directly from inside the apigee-runtime pod bypassing the ingress gateway. To accomplish this, first get the list of all runtime pods in the apigee namespace for your environment. Set up port forwarding to the specific pod by providing the name of the runtime pod. Call a deployed API proxy by using the curl command line utility on the forwarded port and using the basepath URL of the proxy. The response from the proxy will indicate whether it is functioning as expected. You can also call the management API on the runtime message processor pod to send a request to the classification tree API. The response from this API will list information about all of the deployed proxies. To help with further troubleshooting, you can enable DEBUG mode to include more detailed information in the apigee-runtime message processor pod logs by making an API call to the logsessions management API. After you finish debugging an issue, you should be sure to reset the logging mode back to INFO, using the same API call the sessions parameter set to info. To troubleshoot issues with the synchronizer component, you can view the synchronizer pod logs for the hybrid environment in which the issue occurs. Use the kubectl logs command with the pod name. To troubleshoot synchronization issues with the management plane, check the versions.properties file to confirm that the current active version matches the folder name that contains the downloaded contract data. To do this, use the kubectl command to start a shell on the synchronizer pod and provide the name of the pod. Then compare the active.version property with the contract folder name to confirm that they match. If they do not match, check the synchronizor logs for details to debug the issue further. Also confirm that the configuration properties for the synchronizer component have correct values as per the hybrid configuration reference documentation. In Apigee hybrid, Cassandra is a stateful component in the runtime plane with external storage attached that uses Persistent Volume Claims, or PVCs. You may sometimes see that a Cassandra pod is stuck in a pending state during startup. This indicates that Kubernetes cannot schedule the pod on a node. This may happen because the node doesn't have sufficient resources, such as CPU or memory, available to create the pod. Another possible reason is that the pod is waiting for the persistent volume to be created. You can get more details on the source of the error by running the kubectl describe command, providing the pod name and namespace. For errors due to insufficient resources, you can resize the runtime data nodepool in the cluster or use larger machine types for the Cassandra pods. For errors due to persistent volumes, use the kubectl describe command on the PersistentVolumeClaim resources to further investigate the cause of the issue. During startup, the Cassandra pods are sometimes stuck in the CrashLoopBackoff state. You can determine this by running the kubectl get pods command. This indicates that Kubernetes cannot create the pod. Using the kubectl logs command to check the Cassandra pod error log for more information or details on the error. If an error indicates data center differences, the pod has a stale persistent volume attached. To resolve this issue, delete the old or stale PersistentVolume claims. For new installations, delete all of the PVCs and retry the Cassandra setup. For errors that indicate that the Truststore directory is not found, verify that the key and certificates that are configured in your overrides.yaml configuration are valid. If a node that runs a Cassandra pod fails, the pod status will stay in a pending state and the node will indicate a status of NotReady. You can determine the status of a node by using the kubectl get nodes command. To fix a failed Cassandra node, use the nodetool command and provide the name of the cassandra pod to check the node status and remove the node. Next, remove the pod's PersistentVolumeClaim to prevent the Cassandra pod from attempting to start up on the failed node because of node affinity. To do this, run the kubectl delete pvc command and provide the name of the PVC. Update the volume template in your hybrid configuration file to use the new node hostname, and apply the configuration to your cluster by using the kubectl apply command and providing the name of the volume template configuration file. The Apigee Drupal developer portal is installed and managed by you; therefore, you must maintain and troubleshoot any issues with the portal. The Apigee integrated developer portal, on the other hand, is hosted and maintained by Google in the management plane on Google Cloud. You need to monitor the Drupal developer portal and troubleshoot any issues that may cause the service to become unavailable. Any misconfiguration with the credentials that the portal uses to access its local database or connectivity issues to the database can cause the portal to become unavailable. The developer portal also makes management calls to the Apigee hybrid management server, in the Apigee hybrid management plane. Make sure that there are no connectivity issues and that the portal is configured with the correct credentials to access the management plane. Data synchronization issues between the portal and the management plane can cause Apigee entities to be unavailable. Verify that the synchronization jobs are correctly configured in the developer portal. Diagnostic collector is a tool that captures diagnostic data on the Kubernetes components of an Apigee hybrid instance on demand, and stores them in Google Cloud storage buckets. You invoke diagnostic collector with the apigeectl diagnostic command. Diagnostic collector captures these types of data: Changing Log levels, Jstack, POD configuration.yaml, PS -ef output, TCP dump, and TOP output. When Diagnostic collector captures the data, it is uploaded to a storage bucket in your Google Cloud project. You can view the stored data in the Google Cloud console. You can optionally choose to share this data with Google Apigee Support when you create a support ticket, however, no user runtime data or sensitive information is captured in the data collected by Diagnostic collector. There are few prerequisites that you must complete before running Diagnostic collector. You must create a Google Cloud Storage bucket with a unique name in your Google Cloud project. You can create and manage buckets with the gsutil commands or using the Google Cloud console. You must also create a service account with the Storage Admin role (roles/storage.admin) in your project, and download the service account . json key file. The service account can have any unique name. In order to use Diagnostic collector, you must first configure the Diagnostic stanza in your overrides.yaml file to select the type of information, the Apigee container, and the individual pods you want diagnostic data from. For more information on configuring the overrides.yaml, see Configuring overrides.yaml for Diagnostic collector. Next, run Diagnostic collector. Once you have run Diagnostic collector, get the pods in the apigee-diagnostic namespace. Make a note of the name of the Diagnostic collector pod name, then, check the logs replacing POD_NAME with the name of the Diagnostic collector pod. Finally, after you have collected the data, delete the Diagnostic collector. You cannot run it again until you have deleted it.

### Video - [Demo: Monitoring Apigee hybrid](https://www.cloudskillsboost.google/course_templates/169/video/419575)

* [YouTube: Demo: Monitoring Apigee hybrid](https://www.youtube.com/watch?v=hzz2gQCAPfs)

Welcome to this demo on monitoring Apigee hybrid. To manage your Apigee hybrid runtime installation and keep it operating efficiently, you must monitor the health of your Kubernetes cluster, its resources, and the services it runs. This demo will cover some of the basics of logging and monitoring of your Google Kubernetes Engine cluster using tools available in Google Cloud. As prerequisites, you must have Apigee hybrid v1.10 or later installed and running in a cluster on GKE. This demo does not perform the install of Apigee hybrid. If you do not have an existing Apigee hybrid installation, you can follow the tasks in the Installing and Managing Apigee Hybrid lab in Qwiklabs. You should also have an Apigee hybrid environment named ‘test’ and a properly configured environment group named ‘test-group’. The test environment must be added to the environment group. You should also deploy the test API proxy to the test environment. Make sure your clusters healthy and all Apigee hybrid runtime plane components are running. You can check the status of the cluster and its workloads in the Google Cloud console, and also by running the command kubectl get pods and providing the Apigee namespace. Use code to test the API by setting an environment variable and running curl. This verifies that the API is functioning as expected. To view cluster events, you can use the kubectl get events command. Kubernetes events are objects that provide insight into what is happening inside the cluster, such as what decisions were made by the scheduler or why some pods were evicted from the node. Events provide details to aid you in troubleshooting problems with the cluster. To list all events in the Apigee namespace, you can run the command kubectl get events for the Apigee namespace. All of the Apigee  hybrid services that are run in a Kubernetes cluster output operational log information. This log information is useful for monitoring and troubleshooting the service. For example, if a service’s pod status indicates a problem, you can look at the log files for that pod to gain insight into the issue. If there are events in your cluster of pods that are failing, you can view pod logs to determine what the error is. First, let's identify the pod using the get pods command with the show-labels option. This command lists all the pods with their names in the Apigee namespace. The show-labels option includes all labels assigned to the pod. Alternatively, you can list specific pods for a given hybrid runtime component using the app label assigned to the component. For example, to view the pods for the Apigee synchronizer component, you can run this command. Here, we provide the app=apigee-synchronizer label name and value to the get pods command and that returns the name of the Apigee synchronizer pod. Similarly, you can list the Apigee runtime pods for the test hybrid runtime environment. You can provide the name of the environment, which in this case is test, and the value of the app label, which is apigee-runtime. The output of the command lists the three Apigee runtime pods. To get the logs for one of the test runtime pods, use the pod name of one of the pods from the output of the previous command in the kubectl logs command. For pods that have more than one container, you can specify the -c option with the container name in the command. The output of the logs command includes a list of log entries that was generated for this Apigee runtime pod. Apigee hybrid sends log information to Cloud Logging, where you can search, filter, and analyze logging data from the various runtime components. You can use the Cloud Logging UI to view and filter log data from the hybrid runtime plane. To access Cloud Logging in the Cloud Console, navigate to Logging > Logs Explorer, under Operations. You can run a query by providing certain log fields. Under the Log fields section in the UI, select Kubernetes Cluster. This adds an entry of resource type Kubernetes Cluster in the query builder. For location, select the cluster region. And for the cluster name, select apigee-hybrid, which is the name of the runtime cluster. Click Run query to execute the query that you added to query builder. You can filter log entries by clicking into the query preview box. To view entries for when the apigee-cassandra pods were created, we add the string create pod apigee-cassandra to the query builder. And click Run query again. As you can see, the query results are updated to list only the entries that were recorded when the apigee-cassandra pods were created and their status. Monitoring the cluster with Cloud Monitoring. The Apigee hybrid runtime components generate metrics that can be used for monitoring purposes. These metrics are forwarded to Google Cloud. You can use Cloud Monitoring in Google Cloud to monitor the health of the hybrid runtime plane. To access the Monitoring UI in the Cloud Console, navigate to Monitoring > Overview, under Operations. On the Overview page, in the dashboard section under Infrastructure, click on VM instances. A list of your VM resources that are used in the cluster are displayed. Click View Metrics and a set of charts that plot CPU utilization, memory utilization, and other metrics are displayed. You can further filter these metrics using the Metrics explorer. In the Metrics dropdown list, we select Kubernetes Container, followed by the CPU request utilization metric and click Apply. The resulting chart shows the CPU request utilization metric for the various containers in the cluster. We can filter this further by adding a filter. For the filter label, you select container-name and for the value we select apigee-cassandra. The chart now only shows the CPU request utilization metric for the apigee-cassandra pods in the cluster. Click Save chart to save the chart to your monitoring dashboard. To control your new dashboard add Dashboard Name. You can view this dashboard from the Dashboards Overview page and selecting the name of the dashboard that was created earlier. You now have a dashboard view of the apigee-cassandra pods that can be used to monitor their CPU request usage. Creating monitoring alerts. Monitoring alerts are a key part of your overall monitoring strategy. It is a best practice to monitor important resource metrics and to be alerted when those metrics cross certain threshold values. With alerts, you can take appropriate action to address resource usage. Let's create a monitoring alert for the apigee-cassandra resource. First, we create an email notification channel to get notified of any alerts that are triggered by an alert policy. In the Cloud Console, under Operations, we go to Monitoring > Alerting. On the Alerting page, we click Edit Notification Channels, and on the Notification channels page, scroll down and click Add New for the email notification channel type. You provide your email address where you would like to receive the alert notifications. You can name your notification channel based on the type of alert you are expecting. Then click Save to save the channel. Next, to create an alert, we click + Create Policy. In the Select a metric dropdown list, we select Kubernetes Container and the CPU request utilization metric. We then add a filter for the container name to select only the apigee-cassandra containers. Then click Done. For this alert policy we configure a trigger. The condition for this trigger will be threshold and we set a threshold value of .05. For this condition, the alert will trigger when the apigee-cassandra CPU usage exceeds 5% at any time. This threshold is set artificially low for testing purposes. We click Next and select the notification channel that was created earlier. We then name our alert policy. And click Next again. And finally Create Policy to create the alert. To view the alert notifications when they are triggered, access your email inbox to view the notification email for each alert. You can view the alerts in the Incidents section on the Monitoring, Alerting page in the Cloud Console. As you can see, there are a bunch of alerts that have been triggered. The alerts or incidents are displayed in the Incidents section on the Alerting page in the Cloud Console. They are also listed on the Monitoring Overview page. You can click an incident to view the incident details. To acknowledge the incident, click Acknowledge Incident. For this incident, the CPU usage was .127 that exceeded the .05 value of the threshold that was set. In a production environment, you will need to investigate the cause of the incident and take actions to resolve it. The incident can be closed after the condition that triggered the alert no longer exists. In summary, many more metrics and components can be monitored in a similar manner. Using the Cloud Monitoring Metrics explorer, you can create additional dashboards and alerts to monitor the health of your Apigee hybrid runtime plane. Thanks for watching this demo.

### Video - [Apigee Support](https://www.cloudskillsboost.google/course_templates/169/video/419576)

* [YouTube: Apigee Support](https://www.youtube.com/watch?v=77Nf-PiCyvM)

In this lecture, we discussed the role of Apigee support, and how you can request and receive support on Apigee hybrid. Google Cloud has multiple service centers that provide continuous support Apigee products. You can receive support from any of these teams based on your location and time zone. You can initiate support requests in an APigee Support Portal by filing a support ticket. In the widely used Apigee community portal, you can get answers to your technical questions on Apigee products and services. Links to access these resources are provided in the upcoming slides of this lecture. The Apigee status portal provides continuous updates on product releases, scheduled maintenance and any service outages. You can subscribe to receive email notifications from the status portal whenever Apigee creates, updates or resolves an incident. The Apigee community portal is an excellent resource for answers to technical questions on Apigee products and services. You can also ask questions and receive answers from Apigee solution architects and other members of the community. On handling a support request, Apigee support personnel provide timely responses based on the priority of the request and your support plan. They engage with Apigee product engineering and operations teams as necessary to help you resolve your issue. Here's a sample timeline for a P1 priority support request with an enterprise support plan. The Initial Response Goal when a support ticket is created is 15 minutes with a resolution goal of 60 minutes. The enterprise and mission critical support plans also include escalation of the support requests to Apigee leadership. Here are some of the best practices to follow when creating a support request. You should always include the business impact of the issue because it helps determine the priority of the request. Reference any existing request ticket numbers and provide your contact information in the request. Include all relevant technical information that will help the support team triage the issue. Try to combine multiple issues in the same request, create separate support requests and provide relevant information as needed. Apigee support as well defined plans that include support services and performance goals. This includes the scope of support provided, initial response and resolution goals, service request delivery, support channels and methods of contact. The links provided have full details on the scope of Apigee support services. Based on your pricing plan, Apigee currently includes hybrid entitlements. Note that these entitlements can change with future product releases. Hybrid is only included in enterprise and enterprise plus pricing plans. In addition, hybrid product limits are documented on the Apigee website. These are technical limits on various hybrid entities and resources are either currently enforced or planned to be enforced on the hybrid platform. Many resources are available to you as you work with Apigee services. Follow these links to learn more about Apigee products and services, read documentation, access training and certification materials and learn about upcoming Google Cloud events.

### Quiz - [Logging and monitoring](https://www.cloudskillsboost.google/course_templates/169/quizzes/419577)

#### Quiz 1.

> [!important]
> **Which three analytics capabilities are supported in Apigee hybrid?**
>
> * [ ] Customize existing analytics dashboards in the hybrid UI.
> * [ ] Track operational performance of API proxies.
> * [ ] Measure adoption of the API program by application developers.
> * [ ] Create custom reports.

#### Quiz 2.

> [!important]
> **To properly monitor the health of the Apigee hybrid runtime plane, which metrics should be monitored?**
>
> * [ ] Pod and container metrics
> * [ ] Metrics for the Kubernetes cluster, node, pod, container and application workloads
> * [ ] Kubernetes cluster and node metrics
> * [ ] Hybrid application workload metrics

#### Quiz 3.

> [!important]
> **Which is a valid critical path of components to troubleshoot when there are issues in the runtime execution of an API proxy?**
>
> * [ ] Synchronizer, Message Processor, UDCA
> * [ ] Ingress gateway, Message Processor, Cassandra
> * [ ] Apigee Connect, MART, Cassandra
> * [ ] Message Processor, fluentd, UDCA

### Video - [Module review](https://www.cloudskillsboost.google/course_templates/169/video/419578)

* [YouTube: Module review](https://www.youtube.com/watch?v=9fZ9jZGgqzE)

In this module, you learned how Apigee hybrid logs system informational and error messages and how you can use analytics and metrics to monitor and troubleshoot Apigee hybrid. You also viewed a demo on monitoring Apigee hybrid. Finally, you learned about the Apigee hybrid support model and how you can request support for issues related to Apigee hybrid.

### Video - [Course review](https://www.cloudskillsboost.google/course_templates/169/video/419579)

* [YouTube: Course review](https://www.youtube.com/watch?v=-LAcnQh1YDw)

I want to thank you for taking the course on upgrading, monitoring, and troubleshooting Google Cloud's Apigee hybrid API platform. In this course, you learned how to upgrade and roll back the Apigee hybrid runtime installation in your Kubernetes cluster. We discussed how Apigee hybrid performs logging activities and how you can use the runtime component logs for troubleshooting purposes. We also reviewed the various metrics generated by the hybrid runtime components. We discussed Apigee Analytics and the various reporting dashboards available for you to use in Apigee hybrid. We also discussed monitoring and troubleshooting techniques for the Apigee hybrid runtime components. Finally, we discussed how you can involve Apigee Support to help troubleshoot issues in your Apigee hybrid installation. This was the last course in the series on Apigee hybrid. We hope you enjoyed learning about managing Google Cloud's Apigee API platform for hybrid cloud.

### Document - [Reading: What's next](https://www.cloudskillsboost.google/course_templates/169/documents/419580)

## Course Resources

PDF links to all modules

### Document - [Upgrading and Monitoring the Apigee Hybrid API Platform Course Resources](https://www.cloudskillsboost.google/course_templates/169/documents/419581)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.google)

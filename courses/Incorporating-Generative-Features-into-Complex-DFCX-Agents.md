---
id: 1104
name: 'Incorporating Generative Features into Complex DFCX Agents'
datePublished: 2024-07-10
topics: []
type: Course
url: https://www.cloudskillsboost.google/course_templates/1104
---

# [Incorporating Generative Features into Complex DFCX Agents](https://www.cloudskillsboost.google/course_templates/1104)

**Description:**

In this course you will learn how to integrate multiple advanced generative capabilities within a Dialogflow CX agent.

**Objectives:**

- Discover Gen AI and its benefits that are available for Dialogflow.
- Explore the world of Generators together with their examples.
- Understand what Generative Fallback entails and how to add it to your agent.
- Learn how to evaluate the implementation methods for data stores.
- Understand how to route between playbooks and stateful DFCX flows, and how to pass parameters between them.
- Understand testing and the most common types of testing applicable to Gen AI features.

## Gen AI and Dialogflow CX: A recap

After completing this module, you will be able to explain Generative AI and its benefits, as well as summarize the Generative AI features that are available in Dialogflow. You will also be able to classify the relationship between Vertex AI and Dialogflow and recognize where to integrate Generative AI within a conversational agent.

### Video - [What is generative AI and what are its benefits?](https://www.cloudskillsboost.google/course_templates/1104/video/491498)

- [YouTube: What is generative AI and what are its benefits?](https://www.youtube.com/watch?v=VpjU6QVnEQc)



### Video - [What generative AI features are available for Conversational Agents?](https://www.cloudskillsboost.google/course_templates/1104/video/491499)

- [YouTube: What generative AI features are available for Conversational Agents?](https://www.youtube.com/watch?v=cpEFJgqNQ-I)

Now that we have reviewed some advantages of generative AI and where is is most applicable for CCAI use cases, let’s deep dive into how Generative AI applies to Dialogflow. There are four generative AI products available in DialogFlow CX today. The first is playbooks. Playbooks allow you to design and build conversational flows using natural language. Thanks to Playbooks now flows can be built much quicker, by leveraging various of-the-box features and the ability to write instructions in natural language. Second are datastores. Data stores allow you to use information found in websites and internal documents to answer questions from end users. Third are generators. Generators allow you to integrate an LLM call into a stateful Dialogflow CX flow. For instance, using a generator you can quickly summarize some text.on a specific conditional route. Finally, there’s generative fallback. Generative Fallback can be configured as a default when a stateful Dialogflow CX flow hits a no-match. It works as conversational glue that can allow the virtual assistant to handle conversational fallout like small talk and requests for repetition.

### Video - [What is the relationship between Vertex AI and Conversational Agents?](https://www.cloudskillsboost.google/course_templates/1104/video/491500)

- [YouTube: What is the relationship between Vertex AI and Conversational Agents?](https://www.youtube.com/watch?v=RGg0RLquB0s)

Now that we’ve reviewed the four generative products available for Dialogflow, let’s develop an understanding of their relationship to Vertex AI. Playbooks and data stores are expected to be accessible from two different Google Cloud locations: within the Dialogflow CX UI and within the Vertex UI.   As of early 2024, you can only access generators and generative fallback from within Dialogflow CX UI console. While it’s possible to access these features in both places, each, as of early 2024 allows the user to perform slightly different actions. For example, you can ONLY create data stores within the Vertex UI, but they can be attached to Dialogflow CX agents in either Vertex UI or the Dialogflow CX UI. We’ll be discussing this in more detail later in the course.

### Video - [Where can I integrate generative AI within a conversational agent?](https://www.cloudskillsboost.google/course_templates/1104/video/491501)

- [YouTube: Where can I integrate generative AI within a conversational agent?](https://www.youtube.com/watch?v=SJ48mmx8jrI)

Given these four features: playbooks, data stores, generators, and generative fallback, a natural question arises: where should I incorporate them within my Dialogflow CX agents? To identify where to incorporate your generative AI features, it is important to distinguish between the three common flow types in a Dialogflow agent. The first is what’s commonly referred to as “Steering”. This is the initial routing in the agent and involves identifying a user’s request. Steering encompasses the initial intent identification, disambiguation, and any business rules. For instance, say a user gives the utterance “billing”. This vague utterance now requires some disambiguation to understand what the user wants. The user could request to pay their bill or raise issues with a charge on the bill. Next, are informational flows. These involve answering a users’ questions. They do not support the user in taking any action. This could be a user simply asking “when does the store open?” Finally, there are transactional flows. These involve taking some action to fulfill a user request. For instance, perhaps the user wants to order a product. A transactional flow would process the order. Now, let’s take an example of a virtual agent built to help users resolve various requests about their bill. Let’s dive deep into each of these three flow types and see where generative features can be integrated. To do so, we will use the following example call flow. Your own call flow will of course be different, depending on your business needs. Let’s start with steering. As mentioned, this involves identifying the user’s main task. Here, there are a couple of places where you might consider integrating generative features. First, when it comes to the core of steering (which is identifying what a user wants to do) you can build this either through intents and stateful Dialogflow CX flow, or through a playbook. A stateful Dialogflow CX flow may give you slightly more control, but a playbook will likely be quicker to build. There are still opportunities to incorporate generative AI, even if opting for a stateful Dialogflow CX flow for steering. Suppose you ask a user what they wish to do and your Dialogflow CX NLU does not understand them. You can add a data store to handle no-matches and answer the question from a website. You can also integrate a generative fallback to act as conversational glue in the case that the user says something like “repeat” or “hi”. Next are transactional flows. These are flows where the user wants to do something, such as make a payment or viewing a bill. There are two main options for how to structure such flows: either use playbooks or stateful Dialogflow CX flows. Generally speaking, playbooks will be faster to develop and will allow for more flexibility, but you will have somewhat less control over what the bot says and the order in which things are done. In this example the “Balance Inquiry” use case is a playbook but “Bill High” is also a transactional flow but stateful. Let’s take a closer look at “Bill High” to learn more about how to integrate generative AI into stateful transactional flows. Even if you choose to use a stateful Dialogflow CX flow, there is still the option to incorporate generative elements. In this example, Bill_High is a stateful flow because there needed to be stricter conversational logic. In this flow, you can use generative fallbacks as conversational glue, handling requests to repeat and various forms of chit-chat like repeating bill information. Another example of incorporating generative features in stateful Dialogflow CX is to use generators for specific goals. In this example the feature can help with summarizing a payment confirmation in the Make_Payment flow. You can also use a data store to handle informational questions throughout both Bill_High and Make_Payment flows. For instance, perhaps while exploring the customer’s bill, they have a question about what a late fee is. You could use a data store to answer this type of question. Finally, there are informational flows where the user simply wants to request information. This example shows that when intent identification & authentication fails, we can send the user to a data store which does not require any backend data. For example, if the user asks, “How can I reduce my bill”, and we can’t authenticate them, then passing this question to a data store can allow for answering the question in general terms and give links to further information. If this was a stateful flow it may allow you to control the response exactly with a static response, but it would require maintenance if the answers changed. It also requires you to add content for each additional question. By contrast, with the use of a data store, you don’t need to add content for each additional question, provided the answers are present in your data store. This still requires maintaining the underlying documents or website on which the data store is based. However, this is typically something that the customer service business already has a process in place for. The bottom line is that Generative AI can realistically be applied to any part of a conversation within DialogFlow, and they can be very powerful when combined together or with stateful flows.

### Quiz - [Gen AI and Dialogflow CX: a recap Quiz](https://www.cloudskillsboost.google/course_templates/1104/quizzes/491502)

## Generators

After completing this module, you will be able to explain how Generators can be used and provide an example of how to generate a personalized conversation summary for the human agent.

### Video - [Understanding Generators](https://www.cloudskillsboost.google/course_templates/1104/video/491503)

- [YouTube: Understanding Generators](https://www.youtube.com/watch?v=buplX8C3sZc)

Now that we’ve explored some examples of where you might incorporate generative AI within a Dialogflow CX flow, let’s deep-dive into each feature to understand how best to incorporate them within Dialogflow CX, starting with Generators. We’ll start with an overview of generators, explaining what they are, along with when and how to use them. Then, we’ll explore an sample use case; generating a personalized conversational summary for a human agent. Generators let you make a call to a large language model (or L-L-M) natively from within Dialogflow CX. You can configure the generator to do anything you would normally ask an LLM to do. It is configurable using fulfillments that you specify. Some use cases where you might consider Generators include: Summarization, parameter extraction, data transformation, and the handling of operator requests. There are four key concepts that influence the outputs of your generator. The first is which LLM model you use. The second is the written instructions given to the generator. The third is model configurations like “temperature” which allows you to control the model behavior. And the final is session parameter value; pieces of data imported from Dialogflow CX that can be provided to the LLM model. You can access all generators through the Manage tab of Dialogflow CX. Here you can also click “Create” to create a new generator. Once there, you’ll be prompted to give a display name for the generator and a text prompt. Note that you can also create a new generator directly on a fulfillment, as we shall see in a moment. When creating a generator, select which model to use along with the other configuration settings. Please keep in mind that models evolve over time. New models, and model versions, become available frequently. Make sure you read the documentation and release announcements to stay up-to-date. The other configuration settings are: Temperature, Token Limit, Top-K & Top-P. Temperature controls the degree of randomness and creativity in the response. A higher temperature yields more surprising and diverse outputs. While a lower temperature yields more predictable and “safe” responses. Token Limit controls how many tokens can be generated in a response. Tokens are roughly equivalent to words or word pieces. If you expect your response to be shorter, you can expect a marginal performance gain by lowering this value. Be aware that a lower token limit won’t necessarily generate shorter responses. If you go too low, you might cut the model’s output mid-thought. Top-p and top-k limit the range of tokens the model considers. This makes responses less diverse but more focused on the most likely options. Generally speaking, the higher these values, the more randomness there will be. Top-k indicates how many tokens we choose between. For example, a value of 40 means we choose between the forty most probable tokens. Top-p operates by probability. Basically, we order the possible tokens by probability and sum up their probabilities until we hit the top-p value and then stop. For example, if our Top-P value was point-95, and the first three tokens had probability values of point-4, point-3, and point-26, then we’d stop after these because they sum up to point-96. Now let’s learn how to create a Generator directly on a fulfillment. Generators can be added to any fulfillment in Dialogflow CX. Note that you can add several generators to a single fulfillment. You should specify all the parameters you would like to input into the generator. For this, you need to specify the name of the placeholder in your prompt and the session parameter it maps to. So, for example, suppose you want to reference a session parameter called “session dot params dot destination city” as “dollar sign city”. In this case, you should add an input parameter with placeholder “city” and parameter “session dot params dot destination city”. To continue the example, now suppose that your session parameter had a value of “Berlin”. “Berlin” would get passed in as the value of “dollar sign city” via the input parameters. And thus, Berlin could be used in the LLM prompt. Keep in mind that there are a 2 special generator prompt placeholders that allow you to utilize information about prior turns within the conversation. The first is conversation which includes the previous turns in the conversation except for the last user utterance. You should use conversation if you want the generator to contextually understand previous things the user said. For instance, you can use this if the goal of your generator is to summarize the conversation. If you pass in the previous turns, the generator should be able to generate a summary on this basis. The other placeholder it last-user-utterance. You should use last-user-utterance if you want the generator to use the last thing the user said. For instance, this is useful if the user is asking questions about a bill and you want to look up the answers in a database. You can also specify output parameters, which will let you save the results of the generator as Dialogflow CX session parameters. The parameters need to be formatted as: Dollar sign, request, dot generative dot X. Where X is the name of your session parameter. Unless you set this, you will not be able to use the generated response in any way. The outputs can be used like any other session parameter within Dialogflow CX. For example, you might have the agent read it out to the user. Now that we have seen how to add and use generators, let us look at some concrete examples of prompts. This first example shows a generator that summarizes text. Here is another example that uses information gathered from a database. This highlights generative AI’s abilities to extract and summarize relevant information. One cautionary note: with an example like this, you need to be aware of the possibility of hallucination. Here’s one final example in which the user requests to speak with an operator. There are some nice features in this example. As you can see, first the prompt gives instructions about the sort of tone we expect from the generator response. In particular, that the response should be polite. Second, the prompt includes some instructions about what not to do. For instance, it says not to ask the user any questions. There are a large number of additional examples of generator prompts available that cover: Content summarization, Conversation summarization, Markdown formatting, And Question answering. There’s also: Code generation, Escalation to a human agent, Search query generation, Customer information retrieval, And updating a JSON object. Now, let us watch a video to see an example of configuring a generator in DFCX.

### Video - [Example: Generating a personalized conversation summary for the human agent](https://www.cloudskillsboost.google/course_templates/1104/video/491504)

- [YouTube: Example: Generating a personalized conversation summary for the human agent](https://www.youtube.com/watch?v=LCAzugoFBGs)

Now let’s look at a more in depth example involving generators. We will focus on a use case in which a personalized conversation summary is generated to be passed to a human agent. A generative summary that only focuses on the conversation itself is, in most cases, less valuable than one that also includes information about the user. Here we’ll explore how to offer a summary that includes both conversation details and information about the user. We can generate the summary in four steps. In step one, the user indicates that they would like to speak to an agent, or a particular user query triggers a transition to agent. In step two (either at the time this event happens, or ideally somewhere earlier in the conversation) Dialogflow calls a webhook to retrieve user-related information. In step three, we use a generator to write a summary of the conversation, including the user information we retrieved during step 2. Finally, in step four, we initiate an agent handoff where we also inject our summary and user metadata. In the process we just explored, step 3 is typically the most complicated as it involves configuring the generator itself. It is important to include a prompt to your generator that provides not only a conversation summary with history, but also the main user intent, the sentiment, and a short handover response that acknowledges what the user is asking about. In the next slide, we’re going to show an example of configuring a generator that solves this task. Here is a sample generator prompt. Let’s examine three sections of the prompt in more detail. First, briefly describe the overall goals. It’s generally best practice to start a generator prompt with a description of goals. The second sentence describes the expected structure of the output. Giving details about this structure is very important. When the system hands off information about conversation history and user details to some second system, that second system likely expects this information in a particular format. The third part of the prompt gives details about the expected structure of the inputs. This includes both user history and conversation history. It is very helpful for the generator to know exactly what format it should expect to receive these details in. In this example, the generator is told that it should expected to receive the details in JSON format. With these three sections you have a fully operational generator the outputs JSON. Here’s one more additional thing about generator prompts that you should keep in mind. Don’t be too lengthy in your instructions. This is so as to avoid going over the token limit. One option to decrease overall prompt length is to adjust the webhook you use to gather user information to restrict what user data it will pass on to your generator. Lastly, let’s talk about how we pass the output of our generator to a live agent. When it comes to passing along your generator output to a live agent, there are few things to keep in mind. First, it’s important to convert the generator output to an appropriate format so that Dialogflow CX can work with it. For instance, you’ll want to ensure that the summary is an object. Second, you’ll want to make sure to output whatever parameter values will be needed. One option is to include the output fields in a custom payload.

### Quiz - [Generators Quiz](https://www.cloudskillsboost.google/course_templates/1104/quizzes/491505)

### Lab - [Enable informed decision making with a conversational agent that uses generators and data stores](https://www.cloudskillsboost.google/course_templates/1104/labs/491506)

Use Vertex AI Agent Builder and Conversational Agents to build, deploy and configure a conversational agent to assist people who want to donate blood and ensure they meet the required eligibility requirements.

- [ ] [Enable informed decision making with a conversational agent that uses generators and data stores](../labs/Enable-informed-decision-making-with-a-conversational-agent-that-uses-generators-and-data-stores.md)

## Generative Fallback

After completing this module, you will be able to compare Generative Fallback with Generators, customize Generative Fallback and add it to your agent.

### Video - [Generative Fallback](https://www.cloudskillsboost.google/course_templates/1104/video/491507)

- [YouTube: Generative Fallback](https://www.youtube.com/watch?v=nUO8EPN02gE)

Now, let’s talk about generative fallback. We’ll first introduce generative fallback and compare it to generators. Next, we’ll review how to customize your generative fallback. Finally, we’ll talk about adding generative fallback to your agent. As discussed at the beginning of this course, generative fallback is an LLM-based feature used to generate agent responses when end-user input does not match an intent. It helps serve as a sort of conversation glue, when you need to handle or improve parts of the conversation that don't require exact, pre-written answers (like in no-match event handlers in specific flows, pages, or when collecting data). Situations where generative fallback can be helpful include: The ID collection processes. When gathering credit card information. After sending an SMS. Or in conversational flows that ask open-ended questions like "Anything else?" As with generators, you can set up generative fallback by creating a text prompt. This prompt is like an instruction for the Large Language Model (LLM), telling it how to respond to user input. You may be asking, “how is this different from generators?” There are two primary differences between the two. The first is that generative fallback is developed to handle a few use cases out-of-the-box. The second is that you can only have one generative fallback prompt per Dialogflow CX agent (we’ll talk about this later in the training). Generative fallback can be thought of as being developed specifically for functions of conversation repair and chit chat. Some examples of this are greeting and saying goodbye to the user, handling smalltalk, repeating information, and summarizing the conversation. Generative fallback configuration includes a default template prompt that can handle these use cases. But you can also create a custom template that modifies the prompt that generative fallback uses. In other words, you can use a predefined text prompt that will be populated automatically referred to as the default template or you can add your own prompts referred to as custom templates. Given the options of both generators and generative fallback, a natural question arises, which should I use when? In general, you want to use generative fallback in cases where conversational repair can be helpful and we don’t need the response to be exact. Generators, on the other hand, are great for handling specific tasks that can be clearly defined via instructions. To illustrate how generative fallback can be used, let’s compare these two conversations. The left conversation does not have generative fallback enabled, while the right does. Note how on the left the virtual agent offers generic open-ended questions. For example, “I didn’t get that. Can you say it again?” & “I missed what you said. What was that?”. On the other hand, in the conversation on the right, the virtual agent offers specific targeted responses to the user inputs. Generative Fallback can gracefully handle user input, including greetings, off-topic conversation, and hangups. Let’s now dive deeper into configuring generative fallback. Generative fallbacks can be configured in the Machine Learning tab of agent settings within Dialogflow. You can use the default prompt template or create your own custom template. You can also add banned phrases to ensure that generative fallback is only called when it should be and won’t generate any damaging content. Please note that the banned phrases do not need to be comprehensive of topics that are generally recognized as harmful. For example, violent or explicit content. Rather, banned phrases should be used for phrases that are sensitive given your particular situation, like a competitor company. If you do create your own custom template, note that, as with the case of generators, there are some predefined placeholders that you can use. These include: conversation, last-user-utterance, flow-description, and route-descriptions. Once Generative fallback is configured in the ML tab, it can be added to any page as an option in no-match event handlers by simply selecting the “Enable generative fallback” checkbox. Now, let’s watchan example of configuring a generative fallback in DFCX.

### Quiz - [Generative Fallback Quiz](https://www.cloudskillsboost.google/course_templates/1104/quizzes/491508)

### Lab - [Conversational Agents with Generative Fallbacks](https://www.cloudskillsboost.google/course_templates/1104/labs/491509)

This labs explains how to increase intent coverage and handle errors gracefully with generative fallback.

- [ ] [Conversational Agents with Generative Fallbacks](../labs/Conversational-Agents-with-Generative-Fallbacks.md)

## Data stores

After completing this module, you will be able to explain the pros and cons of data store implementations, configure data stores as a fallback, and add a Datastore to Dialogflow CX stateful flow via a webhook.

### Video - [Data store implementations](https://www.cloudskillsboost.google/course_templates/1104/video/491510)

- [YouTube: Data store implementations](https://www.youtube.com/watch?v=JeVwzaPPp_M)

Next, let’s turn to data stores. As a reminder, data stores allow you to provide answers to informational questions from a user. They return generated answers to user questions based on information from websites and documents. We’ll start with an overview of the various types of data store advanced implementations and consider their pros and cons. Next, we’ll deep dive two types of data store implementations: data stores as a fallback and data stores via a webhook. Let’s review the ways in which data stores can be implemented within a Dialogflow CX agent. The three primary ways to use data stores are: As a standalone agent with a data store as a dialog manager for the entire interaction. Augmenting a stateful Dialogflow CX flow to call a data store Or augmenting a generative playbook to call a data store. In this training, we will focus on the second method because we the other two methodologies were covered in prior training modules. Augmenting a Dialogflow CX flow to call a data store offers two different choices. The first is to trigger a data store as a fallback if no intent or parameter is matched. This is the native integration for data stores. The second is to call data stores via a webhook. Let’s take a closer look at these options. The first option is to add it as a fallback if we fail to match an intent or parameter. There are a few key advantages to adding it as a fallback. First, it works out of the box; this is a native integration. Second, it does not require you to use a webhook, which, among other advantages, means that there will not be any latency caused from calling a webhook. Finally, you do not need to create or maintain any intents or parameters related to your questions. The second option is to add a call to a data store as a webhook. This gives you tight control over exactly when you call a data store. This also allows a data store to be called on a specific intent route if desired. It also lets you control exactly which data store is triggered. For instance, maybe you may have 2 data stores, one for orders and the other for billing. With a webhook you can configure one data store to be triggered for billing-related queries and the different data store to be triggered for order status related queries.

### Video - [Data stores as a fallback](https://www.cloudskillsboost.google/course_templates/1104/video/491511)

- [YouTube: Data stores as a fallback](https://www.youtube.com/watch?v=LyDzSpO0NvQ)

Let’s take a closer look at the first option: configuring a data store as a fallback if no intent or parameter is matched. The first step is to open your agent and access the page where you want to add your data store. Next, select “Add state handler,” and then select the “Data stores” option from the state handler dropdown. Once you have your state handler on the page, select “Edit Knowledge” to choose your data store for the page. Please note that only data stores you’ve connected to your agent will be visible. If you’d like to add additional data stores to your agent, select “See all data stores” and add the data store through the Vertex Search and Conversation console. Additionally, if you would like to create a new data store, you can select “Create new data store” within the corresponding data store type dropdown. The next step is to ensure that your Dialogflow CX agent returns the responses you receive from your data store. So you should make sure that the correct parameter has been added to the Agent responses section. During the setup process, the following parameter should have been added to the “Agent Says” field automatically: “dollar sign request dot knowledge dot answers open bracket zero closed bracket”. You can also customize the way in which answers are returned via the data store. In particular, you can specify the maximum number of links to be sent in an individual response. The highest value you can set is 5 Adding a data store where it functions as a fallback means that the agent will first try to see if any intents or parameters match. If they don’t match, then we next try to see if the data store can give an answer. This means that if we want a user request to trigger a data store, we need to make sure we don’t first match an intent or parameter. There are three strategies to consider for doing so. First, if you are replacing an intent or parameter with a data store, you should make sure it’s not in scope. Second, suppose you remove all of these intents and parameters, but still find yourself matching an intent/parameter that you don’t wish to. For example, let’s say that user requests like “explain late fee” should be sent to your data store. But they’re currently matching a nearby intent, “waive late fee”. And suppose that you want to keep “waive late fee” in scope. Here, you have two options: One is to add phrases like “explain late fee” to the default negative intent. The second is to raise the confidence threshold for this agent. Here is a demo that shows this feature in action.

### Video - [Data stores via a webhook](https://www.cloudskillsboost.google/course_templates/1104/video/491512)

- [YouTube: Data stores via a webhook](https://www.youtube.com/watch?v=92khVQZ3UiY)

The other way to add a datastore to a Dialogflow CX stateful flow is to do so via a webhook. As a reminder, this gives you more control over exactly when to call a data store and which data store to call. Let’s gain a better understanding of adding a data store via a webhook using the following scenario. You have an agent with 10 different intents defined at the start page. You want to use a data store to answer the user’s questions only for 3 of those intents. Currently, once Dialogflow matches an intent in a route, it can’t also invoke a data store. As we have seen, data stores are invoked only after no intents or other route conditions are a match in the current state of the conversation. What you can do is “force” the data store invocation by calling a webhook. Let the webhook fetch the data store answer you need, separately from your agent’s regular flows and pages. Let’s find out more about how this would work. To better understand this scenario let's look at the general architecture for setting up a webhook to call a data store. On the bottom left, we have the user sending in their query. This is sent to a page of a DFCX agent, Page A. This agent calls a webhook, which in turn calls a cloud function. This function sends a detect intent request to a different page of a DFCX agent, Page B. This is the page where your data store is in scope. Note that Page A and Page B can be belong to the same agent or separate agents. The data store returns a response, which then Page B returns in its detect intent response. This in turn gets sent via the cloud function to Page A which then returns it to the user. Now that we’re familiar with the architecture, let’s look at implementation in more detail. When adding a data store via a webhook, there are four steps. They are: Adding a data store to an agent, Creating a webhook, Attaching the webhook to an agent, and adding the webhook to a particular Dialogflow CX page. The first step is to add your data store to an agent. The reason for doing so is that your webhook will work by calling Dialogflow CX on a particular Dialogflow CX page. So you need to identify the page you will use and then attach your data store to that page. You’ll want to be sure to set up this page so that only the data store is in scope in it. So there shouldn’t be any intents in scope and the page should not allow for parameter collection. Also, note that this page can be in a totally new Dialogflow CX agent if you’d like. In other words, it’s possible to have two separate Dialogflow CX agents, A and B. You can add a webhook to A and have it call a page located in B. Now, you are ready to create your webhook. This will be a slightly complicated process. Assuming we’re creating a standard webhook, the timeout needs to be increased to 30 seconds. This is because data stores occasionally take over 5 seconds to respond Then grant Dialogflow API client permission to this account so your cloud function has permission to make the call. At a high level, the webhook works as follows. First, you receive the user utterance. You pass it and other relevant bits of session information into the webhook. The webhook calls the detect intent method, passing in this information, to get an answer from the data store. Finally, the webhook returns the response to the ongoing session back to the session the user is connected to. For more information on this process, please refer to the additional documentation in the Additional Resources section at the end of the training. The third step is to add the webhook to your agent. To add a webhook, access the Manage tab. Then select Webhooks. Finally, select Create New. Now that the webhook has been added to your agent, the final step is to add the webhook to your Dialogflow CX page. Go to the page in question, select the box to enable webhooks, select your webhook, and add the appropriate tag. Here’s a video that shows this process in action.

### Quiz - [Data stores Quiz](https://www.cloudskillsboost.google/course_templates/1104/quizzes/491513)

## Playbooks (Generative Agents)

After completing this module, you will be able to route between playbooks and stateful DFCX flows and pass parameters between them.

### Video - [Playbooks (Generative Agents)](https://www.cloudskillsboost.google/course_templates/1104/video/491514)

- [YouTube: Playbooks (Generative Agents)](https://www.youtube.com/watch?v=o7bLrQA8ayA)

Now, let’s turn our attention to playbooks. As a reminder, playbooks allow you to create a transactional flow using natural language. Here, we’ll talk about how to route between playbooks and stateful DFCX flows. We’ll also explore how to pass parameters between playbooks and stateful DFCX flows. Note that in DFCX, these are called playbooks. However, in the context of Vertex AI Conversation, they are referred to as “Generative Agents”. So how does routing between playbook flows and stateful Dialogflow CX flows work? There are two ways to route from one flow to another. You can explicitly route to another flow. Or you can return to a previous open flow. Each of these ways of routing can be used for both stateful flows and playbooks. Let’s begin with the first method. Within a flow you can explicitly route to another flow. For example, within your plans flow, you might have instructions that say that if the user asks for an international plan, route them to the international flow. If you move explicitly from one flow to another in this way, the system keeps track of this movement. So, for instance, if you route in this way from the plans flow to the international flow, the system remembers that you were in plans and didn’t end that flow. If you do end the international flow, the system automatically moves you back to where you were in the plan flow. In other words, we keep an ordered list of incomplete flows. After you complete a flow, we move you back to the most recent incomplete flow. This is the second way to transition between flows. It happens automatically, so there’s nothing you need to do. But we’ll talk more about it later. To move from a stateful flow to a playbook, access the portion of the agent you’d like to transition from. Select the radio bubble for “Playbook” and then select which playbook you want to transition to in the dropdown. In this example, we have selected a playbook named “Plans”. Within the instructions, indicate when to transition and which flow to transition to. The syntax for transitioning is: Dollar sign, Open curly brace, The word FLOW (all capitalized), Colon, The name of your flow And a close curly brace. If you begin typing this, autocomplete should help. Note that in addition to instructions, you should also include some examples in your examples tab in which you move from your playbook to the flow. Passing parameters in between playbooks and stateful flows is a bit more complicated. Let’s start with stateful flows. Hover to the right of a flow name and click the three dots to access the menu. Select the top option; Flow settings. Navigate down to the options for “Input parameters” and “Output parameters”. You can use these options to specify parameters you can send to or from stateful flows. Input parameters are parameters that your stateful flow can take in (from a playbook). Output parameters are parameters that your stateful flow can send (to a playbook). The next step is to fill in the parameter’s fields. As an example, let’s take the fields of an input parameter. There are three fields: the name of the parameter, its type (for instance a string, number, or boolean) and a description of it, inclusive of examples. Likewise, you can also pass parameters in and out of playbooks. You can access these from the Parameters tab of your playbook. As with flows, you need to specify the parameter, type, and description. As always, include some examples with your parameters.

### Video - [Demo: Pass parameters between flows and playbooks](https://www.cloudskillsboost.google/course_templates/1104/video/491515)

- [YouTube: Demo: Pass parameters between flows and playbooks](https://www.youtube.com/watch?v=gaDRtbL6XEs)

Now, let’s watch a video to see an example of how to pass parameters between flows and playbooks.

### Quiz - [Playbooks Quiz](https://www.cloudskillsboost.google/course_templates/1104/quizzes/491516)

## Testing

This module explores why testing and quality assurance is important when implementing with Gen AI and deep dives into the most common types of testing applicable to Gen AI features.

### Video - [Testing](https://www.cloudskillsboost.google/course_templates/1104/video/491517)

- [YouTube: Testing](https://www.youtube.com/watch?v=FodS6Sf8-xc)

Once you have added your generative AI features, it is time to test them to ensure the quality of the outputs. In this section we will reinforce the importance of testing when implementing Gen AI features in Dialogflow and explore the different types of testing. Given that generative features do not always return the same output when given the same input, it is important to test carefully and not have an expectation that your automated testing will have a passing rate of 100 percent. To help increase consistency in outputs (insofar as you can), we recommend having a temperature level as low as possible. But given the variability, we recommend a mixture of automated and manual tests. Also, it is very important to carefully monitor production traffic, especially on initial release, to ensure a good user experience. What are the various types of tests you should run? The first type of testing is unit testing, which helps catch bugs early in the process. This can be done in the simulator or via test cases. Unit tests are most often created by developers, but can also be developed by the QA team depending on the team structure. Unit tests help to identify and address bugs early in the development process, preventing them from causing problems in more complex interactions or integrated systems. Crucially, you should note that unit testing is at least initially done in conjunction with development. Next is single-shot testing. Single-shot testing is when you develop an evaluation set which minimally consists of queries expected in production and the expected output from the LLM. We recommend you automatically run these queries through your agent. Each test needs to be run at the appropriate place in the agent. For instance, if you’re testing a bill details generator, you have your test runner run your queries through the page where it is scoped. We cover constructing and running evaluation tests at length in our separate training discussing standalone data stores, as it is the primary form of data store testing. It is worth noting that it is not a strict requirement that you run these tests automatically. You can manually run these through the DFCX simulator if the test set is small enough to not warrant automating. Lastly, you should evaluate the responses as compared to the expected output through a mix of automatic similarity checks and human-manual review for content similarity and completeness. Note that if you develop an automatic test runner then it will likely be through external tooling such as SCRAPI. The next type of testing is integration testing. This is required to ensure that your generative features are correctly integrated. The goal here is to ensure that end-to-end the application will function as desired. This is especially crucial for this training, which focuses on incorporating generative features into larger agents. For instance, when it comes to playbooks, you’ll want to add tests to ensure that we transition successfully between stateful flows and playbooks, passing along parameters as appropriate. Next is performance testing. This helps identify any performance issues that arise, such as issues related to timing and scale. Sample metrics include: Response Time, which is the agent’s average response time. Here, you should identify any variations or delays. Concurrency is the ability to handle multiple concurrent users and maintain performance. Scalability is the ability to scale up to handle increased user loads and maintain performance. Another crucial form of testing is user acceptance testing. This, in simplest terms, is having testers play the role of real-life users, interacting with the agent in a natural conversation flow. This will help ensure that real-life users will derive value from what you have built. Examples of aspects you should test include context handling, bias and fairness, safety and security, user satisfaction, and overall experience. Another form of testing is black box testing. This involves testing by those unfamiliar with the underlying workings of the product. People outside the team or real users are the best participants. Finally, we have regression testing. Although a category of its own, these tests are largely created during the development process. In essence, once a unit or integration test passes consistently and the function is relatively crystallized, we can turn it into a regression test. At this point, we’re not testing for new performance, but checking for potential degradation. In other words, regression tests check if something has stopped working. These tests are typically added to, and run from, Dialogflow test cases. For something like single-shot testing, they can be added to your external automated testing. If you want to use a script then try SCRAPI. It’s built-in features support running test sets. You’ll likely need to perform regression test multiple times during the development process (and whenever you adjust your agent). Congratulations, you’ve completed this course on incorporating generative AI into your Dialogflow CX agent! We wish you success as you work to incorporate generative AI into your agents!

### Quiz - [Testing Quiz](https://www.cloudskillsboost.google/course_templates/1104/quizzes/491518)

## Additional Resources

This module includes the list of additional resources that complement the course learning.

### Document - [Additional Resources](https://www.cloudskillsboost.google/course_templates/1104/documents/491519)

## Your Next Steps

### Badge - [Course Badge](https://www.cloudskillsboost.googleNone)
